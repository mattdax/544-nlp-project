{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.4096385542168672,
  "eval_steps": 500,
  "global_step": 4000,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0006024096385542169,
      "grad_norm": 1.5560017824172974,
      "learning_rate": 4.999246987951807e-06,
      "loss": 3.2004,
      "step": 1
    },
    {
      "epoch": 0.0012048192771084338,
      "grad_norm": 1.997064471244812,
      "learning_rate": 4.998493975903615e-06,
      "loss": 3.1482,
      "step": 2
    },
    {
      "epoch": 0.0018072289156626507,
      "grad_norm": 1.5352808237075806,
      "learning_rate": 4.997740963855422e-06,
      "loss": 3.1304,
      "step": 3
    },
    {
      "epoch": 0.0024096385542168677,
      "grad_norm": 1.4374537467956543,
      "learning_rate": 4.99698795180723e-06,
      "loss": 2.9942,
      "step": 4
    },
    {
      "epoch": 0.0030120481927710845,
      "grad_norm": 1.7295955419540405,
      "learning_rate": 4.996234939759037e-06,
      "loss": 3.1322,
      "step": 5
    },
    {
      "epoch": 0.0036144578313253013,
      "grad_norm": 2.4129886627197266,
      "learning_rate": 4.995481927710844e-06,
      "loss": 3.0901,
      "step": 6
    },
    {
      "epoch": 0.004216867469879518,
      "grad_norm": 1.53774094581604,
      "learning_rate": 4.9947289156626514e-06,
      "loss": 3.0746,
      "step": 7
    },
    {
      "epoch": 0.004819277108433735,
      "grad_norm": 1.5671591758728027,
      "learning_rate": 4.993975903614458e-06,
      "loss": 3.1166,
      "step": 8
    },
    {
      "epoch": 0.005421686746987952,
      "grad_norm": 1.5100337266921997,
      "learning_rate": 4.993222891566265e-06,
      "loss": 3.0484,
      "step": 9
    },
    {
      "epoch": 0.006024096385542169,
      "grad_norm": 1.6100335121154785,
      "learning_rate": 4.992469879518072e-06,
      "loss": 3.1846,
      "step": 10
    },
    {
      "epoch": 0.006626506024096385,
      "grad_norm": 1.5346754789352417,
      "learning_rate": 4.99171686746988e-06,
      "loss": 3.0907,
      "step": 11
    },
    {
      "epoch": 0.007228915662650603,
      "grad_norm": 1.6097053289413452,
      "learning_rate": 4.990963855421687e-06,
      "loss": 3.1056,
      "step": 12
    },
    {
      "epoch": 0.00783132530120482,
      "grad_norm": 1.5273281335830688,
      "learning_rate": 4.990210843373494e-06,
      "loss": 3.0029,
      "step": 13
    },
    {
      "epoch": 0.008433734939759036,
      "grad_norm": 1.6634138822555542,
      "learning_rate": 4.989457831325302e-06,
      "loss": 3.1393,
      "step": 14
    },
    {
      "epoch": 0.009036144578313253,
      "grad_norm": 1.5672446489334106,
      "learning_rate": 4.9887048192771085e-06,
      "loss": 3.0395,
      "step": 15
    },
    {
      "epoch": 0.00963855421686747,
      "grad_norm": 1.6599860191345215,
      "learning_rate": 4.987951807228916e-06,
      "loss": 3.17,
      "step": 16
    },
    {
      "epoch": 0.010240963855421687,
      "grad_norm": 1.6183897256851196,
      "learning_rate": 4.987198795180723e-06,
      "loss": 3.0149,
      "step": 17
    },
    {
      "epoch": 0.010843373493975903,
      "grad_norm": 1.6367567777633667,
      "learning_rate": 4.986445783132531e-06,
      "loss": 3.0557,
      "step": 18
    },
    {
      "epoch": 0.01144578313253012,
      "grad_norm": 1.5787116289138794,
      "learning_rate": 4.985692771084338e-06,
      "loss": 2.9972,
      "step": 19
    },
    {
      "epoch": 0.012048192771084338,
      "grad_norm": 1.6632744073867798,
      "learning_rate": 4.984939759036145e-06,
      "loss": 2.9813,
      "step": 20
    },
    {
      "epoch": 0.012650602409638554,
      "grad_norm": 1.6701604127883911,
      "learning_rate": 4.984186746987953e-06,
      "loss": 3.063,
      "step": 21
    },
    {
      "epoch": 0.01325301204819277,
      "grad_norm": 2.0289077758789062,
      "learning_rate": 4.9834337349397595e-06,
      "loss": 3.1063,
      "step": 22
    },
    {
      "epoch": 0.013855421686746987,
      "grad_norm": 1.7468914985656738,
      "learning_rate": 4.982680722891567e-06,
      "loss": 3.0317,
      "step": 23
    },
    {
      "epoch": 0.014457831325301205,
      "grad_norm": 1.7177053689956665,
      "learning_rate": 4.981927710843374e-06,
      "loss": 3.0626,
      "step": 24
    },
    {
      "epoch": 0.015060240963855422,
      "grad_norm": 1.685558795928955,
      "learning_rate": 4.981174698795181e-06,
      "loss": 3.0317,
      "step": 25
    },
    {
      "epoch": 0.01566265060240964,
      "grad_norm": 1.805503249168396,
      "learning_rate": 4.980421686746988e-06,
      "loss": 3.0812,
      "step": 26
    },
    {
      "epoch": 0.016265060240963854,
      "grad_norm": 1.6212949752807617,
      "learning_rate": 4.979668674698796e-06,
      "loss": 2.9552,
      "step": 27
    },
    {
      "epoch": 0.016867469879518072,
      "grad_norm": 2.0517477989196777,
      "learning_rate": 4.978915662650603e-06,
      "loss": 3.0266,
      "step": 28
    },
    {
      "epoch": 0.01746987951807229,
      "grad_norm": 1.6428290605545044,
      "learning_rate": 4.97816265060241e-06,
      "loss": 2.9747,
      "step": 29
    },
    {
      "epoch": 0.018072289156626505,
      "grad_norm": 1.7700673341751099,
      "learning_rate": 4.9774096385542175e-06,
      "loss": 3.0747,
      "step": 30
    },
    {
      "epoch": 0.018674698795180723,
      "grad_norm": 1.7667503356933594,
      "learning_rate": 4.976656626506024e-06,
      "loss": 3.0569,
      "step": 31
    },
    {
      "epoch": 0.01927710843373494,
      "grad_norm": 1.7524465322494507,
      "learning_rate": 4.975903614457831e-06,
      "loss": 3.0153,
      "step": 32
    },
    {
      "epoch": 0.019879518072289156,
      "grad_norm": 1.774735689163208,
      "learning_rate": 4.975150602409639e-06,
      "loss": 3.037,
      "step": 33
    },
    {
      "epoch": 0.020481927710843374,
      "grad_norm": 1.7779752016067505,
      "learning_rate": 4.974397590361446e-06,
      "loss": 2.9809,
      "step": 34
    },
    {
      "epoch": 0.02108433734939759,
      "grad_norm": 1.8699010610580444,
      "learning_rate": 4.973644578313254e-06,
      "loss": 3.0567,
      "step": 35
    },
    {
      "epoch": 0.021686746987951807,
      "grad_norm": 1.7334027290344238,
      "learning_rate": 4.972891566265061e-06,
      "loss": 2.9463,
      "step": 36
    },
    {
      "epoch": 0.022289156626506025,
      "grad_norm": 1.7609328031539917,
      "learning_rate": 4.972138554216868e-06,
      "loss": 2.9326,
      "step": 37
    },
    {
      "epoch": 0.02289156626506024,
      "grad_norm": 1.814315676689148,
      "learning_rate": 4.971385542168675e-06,
      "loss": 2.9606,
      "step": 38
    },
    {
      "epoch": 0.023493975903614458,
      "grad_norm": 1.823574185371399,
      "learning_rate": 4.970632530120482e-06,
      "loss": 3.0073,
      "step": 39
    },
    {
      "epoch": 0.024096385542168676,
      "grad_norm": 2.6629130840301514,
      "learning_rate": 4.96987951807229e-06,
      "loss": 3.0191,
      "step": 40
    },
    {
      "epoch": 0.02469879518072289,
      "grad_norm": 1.8284250497817993,
      "learning_rate": 4.969126506024097e-06,
      "loss": 3.0019,
      "step": 41
    },
    {
      "epoch": 0.02530120481927711,
      "grad_norm": 1.8359827995300293,
      "learning_rate": 4.968373493975904e-06,
      "loss": 2.9233,
      "step": 42
    },
    {
      "epoch": 0.025903614457831327,
      "grad_norm": 2.3709397315979004,
      "learning_rate": 4.967620481927711e-06,
      "loss": 2.9344,
      "step": 43
    },
    {
      "epoch": 0.02650602409638554,
      "grad_norm": 1.7280223369598389,
      "learning_rate": 4.966867469879519e-06,
      "loss": 2.7996,
      "step": 44
    },
    {
      "epoch": 0.02710843373493976,
      "grad_norm": 1.9490025043487549,
      "learning_rate": 4.966114457831326e-06,
      "loss": 2.9419,
      "step": 45
    },
    {
      "epoch": 0.027710843373493974,
      "grad_norm": 1.8118245601654053,
      "learning_rate": 4.9653614457831325e-06,
      "loss": 2.8691,
      "step": 46
    },
    {
      "epoch": 0.028313253012048192,
      "grad_norm": 1.9268324375152588,
      "learning_rate": 4.96460843373494e-06,
      "loss": 2.8751,
      "step": 47
    },
    {
      "epoch": 0.02891566265060241,
      "grad_norm": 1.8548219203948975,
      "learning_rate": 4.963855421686747e-06,
      "loss": 2.9031,
      "step": 48
    },
    {
      "epoch": 0.029518072289156625,
      "grad_norm": 1.9112457036972046,
      "learning_rate": 4.963102409638554e-06,
      "loss": 2.9107,
      "step": 49
    },
    {
      "epoch": 0.030120481927710843,
      "grad_norm": 1.8848193883895874,
      "learning_rate": 4.962349397590362e-06,
      "loss": 2.9058,
      "step": 50
    },
    {
      "epoch": 0.03072289156626506,
      "grad_norm": 1.9256013631820679,
      "learning_rate": 4.961596385542169e-06,
      "loss": 2.9399,
      "step": 51
    },
    {
      "epoch": 0.03132530120481928,
      "grad_norm": 1.993452548980713,
      "learning_rate": 4.960843373493977e-06,
      "loss": 2.9217,
      "step": 52
    },
    {
      "epoch": 0.031927710843373494,
      "grad_norm": 1.9353128671646118,
      "learning_rate": 4.9600903614457835e-06,
      "loss": 2.9403,
      "step": 53
    },
    {
      "epoch": 0.03253012048192771,
      "grad_norm": 1.9440993070602417,
      "learning_rate": 4.959337349397591e-06,
      "loss": 2.8833,
      "step": 54
    },
    {
      "epoch": 0.03313253012048193,
      "grad_norm": 1.9619643688201904,
      "learning_rate": 4.958584337349398e-06,
      "loss": 2.9449,
      "step": 55
    },
    {
      "epoch": 0.033734939759036145,
      "grad_norm": 1.8817287683486938,
      "learning_rate": 4.957831325301205e-06,
      "loss": 2.8913,
      "step": 56
    },
    {
      "epoch": 0.03433734939759036,
      "grad_norm": 2.5624420642852783,
      "learning_rate": 4.957078313253013e-06,
      "loss": 2.9439,
      "step": 57
    },
    {
      "epoch": 0.03493975903614458,
      "grad_norm": 1.958603024482727,
      "learning_rate": 4.95632530120482e-06,
      "loss": 2.8326,
      "step": 58
    },
    {
      "epoch": 0.035542168674698796,
      "grad_norm": 2.0451064109802246,
      "learning_rate": 4.955572289156627e-06,
      "loss": 2.9386,
      "step": 59
    },
    {
      "epoch": 0.03614457831325301,
      "grad_norm": 1.9563013315200806,
      "learning_rate": 4.9548192771084345e-06,
      "loss": 2.8671,
      "step": 60
    },
    {
      "epoch": 0.03674698795180723,
      "grad_norm": 2.115953207015991,
      "learning_rate": 4.9540662650602415e-06,
      "loss": 2.9424,
      "step": 61
    },
    {
      "epoch": 0.03734939759036145,
      "grad_norm": 1.972489833831787,
      "learning_rate": 4.953313253012048e-06,
      "loss": 2.7965,
      "step": 62
    },
    {
      "epoch": 0.03795180722891566,
      "grad_norm": 2.1234753131866455,
      "learning_rate": 4.952560240963855e-06,
      "loss": 2.8227,
      "step": 63
    },
    {
      "epoch": 0.03855421686746988,
      "grad_norm": 1.9756735563278198,
      "learning_rate": 4.951807228915663e-06,
      "loss": 2.8408,
      "step": 64
    },
    {
      "epoch": 0.0391566265060241,
      "grad_norm": 2.0340046882629395,
      "learning_rate": 4.95105421686747e-06,
      "loss": 2.8616,
      "step": 65
    },
    {
      "epoch": 0.03975903614457831,
      "grad_norm": 2.019714117050171,
      "learning_rate": 4.950301204819278e-06,
      "loss": 2.8578,
      "step": 66
    },
    {
      "epoch": 0.04036144578313253,
      "grad_norm": 2.019116163253784,
      "learning_rate": 4.949548192771085e-06,
      "loss": 2.8288,
      "step": 67
    },
    {
      "epoch": 0.04096385542168675,
      "grad_norm": 1.9843062162399292,
      "learning_rate": 4.948795180722892e-06,
      "loss": 2.8236,
      "step": 68
    },
    {
      "epoch": 0.04156626506024096,
      "grad_norm": 2.0338430404663086,
      "learning_rate": 4.948042168674699e-06,
      "loss": 2.7741,
      "step": 69
    },
    {
      "epoch": 0.04216867469879518,
      "grad_norm": 2.3002982139587402,
      "learning_rate": 4.947289156626506e-06,
      "loss": 2.8032,
      "step": 70
    },
    {
      "epoch": 0.0427710843373494,
      "grad_norm": 2.77919340133667,
      "learning_rate": 4.946536144578314e-06,
      "loss": 2.6654,
      "step": 71
    },
    {
      "epoch": 0.043373493975903614,
      "grad_norm": 2.038694381713867,
      "learning_rate": 4.945783132530121e-06,
      "loss": 2.8343,
      "step": 72
    },
    {
      "epoch": 0.04397590361445783,
      "grad_norm": 2.03530216217041,
      "learning_rate": 4.945030120481928e-06,
      "loss": 2.7558,
      "step": 73
    },
    {
      "epoch": 0.04457831325301205,
      "grad_norm": 2.009891986846924,
      "learning_rate": 4.944277108433736e-06,
      "loss": 2.7467,
      "step": 74
    },
    {
      "epoch": 0.045180722891566265,
      "grad_norm": 1.9370596408843994,
      "learning_rate": 4.943524096385543e-06,
      "loss": 2.6901,
      "step": 75
    },
    {
      "epoch": 0.04578313253012048,
      "grad_norm": 2.1392924785614014,
      "learning_rate": 4.9427710843373496e-06,
      "loss": 2.7825,
      "step": 76
    },
    {
      "epoch": 0.0463855421686747,
      "grad_norm": 2.181187152862549,
      "learning_rate": 4.942018072289157e-06,
      "loss": 2.7199,
      "step": 77
    },
    {
      "epoch": 0.046987951807228916,
      "grad_norm": 2.059657573699951,
      "learning_rate": 4.941265060240964e-06,
      "loss": 2.7017,
      "step": 78
    },
    {
      "epoch": 0.04759036144578313,
      "grad_norm": 2.0000810623168945,
      "learning_rate": 4.940512048192771e-06,
      "loss": 2.7297,
      "step": 79
    },
    {
      "epoch": 0.04819277108433735,
      "grad_norm": 2.0452146530151367,
      "learning_rate": 4.939759036144578e-06,
      "loss": 2.7294,
      "step": 80
    },
    {
      "epoch": 0.04879518072289157,
      "grad_norm": 2.025296926498413,
      "learning_rate": 4.939006024096386e-06,
      "loss": 2.709,
      "step": 81
    },
    {
      "epoch": 0.04939759036144578,
      "grad_norm": 1.9991015195846558,
      "learning_rate": 4.938253012048193e-06,
      "loss": 2.7013,
      "step": 82
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.1129090785980225,
      "learning_rate": 4.937500000000001e-06,
      "loss": 2.7777,
      "step": 83
    },
    {
      "epoch": 0.05060240963855422,
      "grad_norm": 1.9001072645187378,
      "learning_rate": 4.9367469879518075e-06,
      "loss": 2.6266,
      "step": 84
    },
    {
      "epoch": 0.05120481927710843,
      "grad_norm": 2.0370075702667236,
      "learning_rate": 4.9359939759036144e-06,
      "loss": 2.6731,
      "step": 85
    },
    {
      "epoch": 0.051807228915662654,
      "grad_norm": 2.113426685333252,
      "learning_rate": 4.935240963855422e-06,
      "loss": 2.6682,
      "step": 86
    },
    {
      "epoch": 0.05240963855421687,
      "grad_norm": 2.028594493865967,
      "learning_rate": 4.934487951807229e-06,
      "loss": 2.6077,
      "step": 87
    },
    {
      "epoch": 0.05301204819277108,
      "grad_norm": 2.107243776321411,
      "learning_rate": 4.933734939759037e-06,
      "loss": 2.6638,
      "step": 88
    },
    {
      "epoch": 0.053614457831325305,
      "grad_norm": 2.032470941543579,
      "learning_rate": 4.932981927710844e-06,
      "loss": 2.632,
      "step": 89
    },
    {
      "epoch": 0.05421686746987952,
      "grad_norm": 2.035618305206299,
      "learning_rate": 4.932228915662652e-06,
      "loss": 2.6337,
      "step": 90
    },
    {
      "epoch": 0.054819277108433734,
      "grad_norm": 2.0753800868988037,
      "learning_rate": 4.9314759036144585e-06,
      "loss": 2.6409,
      "step": 91
    },
    {
      "epoch": 0.05542168674698795,
      "grad_norm": 2.0134119987487793,
      "learning_rate": 4.9307228915662654e-06,
      "loss": 2.5818,
      "step": 92
    },
    {
      "epoch": 0.05602409638554217,
      "grad_norm": 2.088212490081787,
      "learning_rate": 4.929969879518073e-06,
      "loss": 2.6167,
      "step": 93
    },
    {
      "epoch": 0.056626506024096385,
      "grad_norm": 2.1010773181915283,
      "learning_rate": 4.92921686746988e-06,
      "loss": 2.5543,
      "step": 94
    },
    {
      "epoch": 0.0572289156626506,
      "grad_norm": 2.039689540863037,
      "learning_rate": 4.928463855421687e-06,
      "loss": 2.5772,
      "step": 95
    },
    {
      "epoch": 0.05783132530120482,
      "grad_norm": 2.0662152767181396,
      "learning_rate": 4.927710843373494e-06,
      "loss": 2.5832,
      "step": 96
    },
    {
      "epoch": 0.058433734939759036,
      "grad_norm": 2.0541329383850098,
      "learning_rate": 4.926957831325302e-06,
      "loss": 2.5983,
      "step": 97
    },
    {
      "epoch": 0.05903614457831325,
      "grad_norm": 1.9729784727096558,
      "learning_rate": 4.926204819277109e-06,
      "loss": 2.5724,
      "step": 98
    },
    {
      "epoch": 0.05963855421686747,
      "grad_norm": 2.0437204837799072,
      "learning_rate": 4.925451807228916e-06,
      "loss": 2.5535,
      "step": 99
    },
    {
      "epoch": 0.060240963855421686,
      "grad_norm": 2.0962624549865723,
      "learning_rate": 4.924698795180723e-06,
      "loss": 2.5762,
      "step": 100
    },
    {
      "epoch": 0.0608433734939759,
      "grad_norm": 2.101814031600952,
      "learning_rate": 4.92394578313253e-06,
      "loss": 2.5978,
      "step": 101
    },
    {
      "epoch": 0.06144578313253012,
      "grad_norm": 1.958775281906128,
      "learning_rate": 4.923192771084338e-06,
      "loss": 2.5598,
      "step": 102
    },
    {
      "epoch": 0.06204819277108434,
      "grad_norm": 1.9599649906158447,
      "learning_rate": 4.922439759036145e-06,
      "loss": 2.5176,
      "step": 103
    },
    {
      "epoch": 0.06265060240963856,
      "grad_norm": 2.0039255619049072,
      "learning_rate": 4.921686746987952e-06,
      "loss": 2.5377,
      "step": 104
    },
    {
      "epoch": 0.06325301204819277,
      "grad_norm": 3.2920899391174316,
      "learning_rate": 4.92093373493976e-06,
      "loss": 2.5399,
      "step": 105
    },
    {
      "epoch": 0.06385542168674699,
      "grad_norm": 2.010145664215088,
      "learning_rate": 4.920180722891567e-06,
      "loss": 2.5805,
      "step": 106
    },
    {
      "epoch": 0.06445783132530121,
      "grad_norm": 1.9549479484558105,
      "learning_rate": 4.919427710843374e-06,
      "loss": 2.4889,
      "step": 107
    },
    {
      "epoch": 0.06506024096385542,
      "grad_norm": 1.9183729887008667,
      "learning_rate": 4.918674698795181e-06,
      "loss": 2.4688,
      "step": 108
    },
    {
      "epoch": 0.06566265060240964,
      "grad_norm": 2.0119619369506836,
      "learning_rate": 4.917921686746988e-06,
      "loss": 2.5069,
      "step": 109
    },
    {
      "epoch": 0.06626506024096386,
      "grad_norm": 1.99326753616333,
      "learning_rate": 4.917168674698796e-06,
      "loss": 2.5252,
      "step": 110
    },
    {
      "epoch": 0.06686746987951807,
      "grad_norm": 1.9048348665237427,
      "learning_rate": 4.916415662650603e-06,
      "loss": 2.4236,
      "step": 111
    },
    {
      "epoch": 0.06746987951807229,
      "grad_norm": 1.9281142950057983,
      "learning_rate": 4.91566265060241e-06,
      "loss": 2.4867,
      "step": 112
    },
    {
      "epoch": 0.06807228915662651,
      "grad_norm": 1.8916959762573242,
      "learning_rate": 4.914909638554217e-06,
      "loss": 2.4362,
      "step": 113
    },
    {
      "epoch": 0.06867469879518072,
      "grad_norm": 2.005871295928955,
      "learning_rate": 4.9141566265060246e-06,
      "loss": 2.4842,
      "step": 114
    },
    {
      "epoch": 0.06927710843373494,
      "grad_norm": 1.8948609828948975,
      "learning_rate": 4.9134036144578315e-06,
      "loss": 2.394,
      "step": 115
    },
    {
      "epoch": 0.06987951807228916,
      "grad_norm": 2.2376580238342285,
      "learning_rate": 4.912650602409638e-06,
      "loss": 2.4407,
      "step": 116
    },
    {
      "epoch": 0.07048192771084337,
      "grad_norm": 2.0686135292053223,
      "learning_rate": 4.911897590361446e-06,
      "loss": 2.4062,
      "step": 117
    },
    {
      "epoch": 0.07108433734939759,
      "grad_norm": 1.930152416229248,
      "learning_rate": 4.911144578313253e-06,
      "loss": 2.4261,
      "step": 118
    },
    {
      "epoch": 0.07168674698795181,
      "grad_norm": 1.875993013381958,
      "learning_rate": 4.910391566265061e-06,
      "loss": 2.3722,
      "step": 119
    },
    {
      "epoch": 0.07228915662650602,
      "grad_norm": 1.8852531909942627,
      "learning_rate": 4.909638554216868e-06,
      "loss": 2.3569,
      "step": 120
    },
    {
      "epoch": 0.07289156626506024,
      "grad_norm": 2.092510461807251,
      "learning_rate": 4.908885542168675e-06,
      "loss": 2.3888,
      "step": 121
    },
    {
      "epoch": 0.07349397590361446,
      "grad_norm": 1.8730748891830444,
      "learning_rate": 4.9081325301204825e-06,
      "loss": 2.4182,
      "step": 122
    },
    {
      "epoch": 0.07409638554216867,
      "grad_norm": 1.8035399913787842,
      "learning_rate": 4.9073795180722894e-06,
      "loss": 2.2984,
      "step": 123
    },
    {
      "epoch": 0.0746987951807229,
      "grad_norm": 1.9557102918624878,
      "learning_rate": 4.906626506024097e-06,
      "loss": 2.4341,
      "step": 124
    },
    {
      "epoch": 0.07530120481927711,
      "grad_norm": 1.8813270330429077,
      "learning_rate": 4.905873493975904e-06,
      "loss": 2.383,
      "step": 125
    },
    {
      "epoch": 0.07590361445783132,
      "grad_norm": 1.813943862915039,
      "learning_rate": 4.905120481927712e-06,
      "loss": 2.3538,
      "step": 126
    },
    {
      "epoch": 0.07650602409638554,
      "grad_norm": 1.7292146682739258,
      "learning_rate": 4.904367469879519e-06,
      "loss": 2.2667,
      "step": 127
    },
    {
      "epoch": 0.07710843373493977,
      "grad_norm": 1.861366629600525,
      "learning_rate": 4.903614457831326e-06,
      "loss": 2.3727,
      "step": 128
    },
    {
      "epoch": 0.07771084337349397,
      "grad_norm": 1.74802827835083,
      "learning_rate": 4.902861445783133e-06,
      "loss": 2.2513,
      "step": 129
    },
    {
      "epoch": 0.0783132530120482,
      "grad_norm": 1.7850054502487183,
      "learning_rate": 4.9021084337349405e-06,
      "loss": 2.2218,
      "step": 130
    },
    {
      "epoch": 0.0789156626506024,
      "grad_norm": 1.7506104707717896,
      "learning_rate": 4.901355421686747e-06,
      "loss": 2.2828,
      "step": 131
    },
    {
      "epoch": 0.07951807228915662,
      "grad_norm": 1.731820821762085,
      "learning_rate": 4.900602409638554e-06,
      "loss": 2.2761,
      "step": 132
    },
    {
      "epoch": 0.08012048192771085,
      "grad_norm": 1.755720853805542,
      "learning_rate": 4.899849397590361e-06,
      "loss": 2.3186,
      "step": 133
    },
    {
      "epoch": 0.08072289156626505,
      "grad_norm": 1.7338565587997437,
      "learning_rate": 4.899096385542169e-06,
      "loss": 2.2804,
      "step": 134
    },
    {
      "epoch": 0.08132530120481928,
      "grad_norm": 1.8071579933166504,
      "learning_rate": 4.898343373493976e-06,
      "loss": 2.2959,
      "step": 135
    },
    {
      "epoch": 0.0819277108433735,
      "grad_norm": 1.9786641597747803,
      "learning_rate": 4.897590361445784e-06,
      "loss": 2.2409,
      "step": 136
    },
    {
      "epoch": 0.0825301204819277,
      "grad_norm": 1.6879152059555054,
      "learning_rate": 4.896837349397591e-06,
      "loss": 2.2382,
      "step": 137
    },
    {
      "epoch": 0.08313253012048193,
      "grad_norm": 1.8779938220977783,
      "learning_rate": 4.896084337349398e-06,
      "loss": 2.2671,
      "step": 138
    },
    {
      "epoch": 0.08373493975903615,
      "grad_norm": 1.8117834329605103,
      "learning_rate": 4.895331325301205e-06,
      "loss": 2.2668,
      "step": 139
    },
    {
      "epoch": 0.08433734939759036,
      "grad_norm": 1.6286499500274658,
      "learning_rate": 4.894578313253012e-06,
      "loss": 2.1936,
      "step": 140
    },
    {
      "epoch": 0.08493975903614458,
      "grad_norm": 1.636011004447937,
      "learning_rate": 4.89382530120482e-06,
      "loss": 2.1925,
      "step": 141
    },
    {
      "epoch": 0.0855421686746988,
      "grad_norm": 1.6798195838928223,
      "learning_rate": 4.893072289156627e-06,
      "loss": 2.2347,
      "step": 142
    },
    {
      "epoch": 0.086144578313253,
      "grad_norm": 1.6778078079223633,
      "learning_rate": 4.892319277108435e-06,
      "loss": 2.1811,
      "step": 143
    },
    {
      "epoch": 0.08674698795180723,
      "grad_norm": 1.6967830657958984,
      "learning_rate": 4.891566265060242e-06,
      "loss": 2.2221,
      "step": 144
    },
    {
      "epoch": 0.08734939759036145,
      "grad_norm": 1.6377365589141846,
      "learning_rate": 4.8908132530120486e-06,
      "loss": 2.214,
      "step": 145
    },
    {
      "epoch": 0.08795180722891566,
      "grad_norm": 1.6111297607421875,
      "learning_rate": 4.8900602409638555e-06,
      "loss": 2.1416,
      "step": 146
    },
    {
      "epoch": 0.08855421686746988,
      "grad_norm": 1.6616981029510498,
      "learning_rate": 4.889307228915663e-06,
      "loss": 2.2005,
      "step": 147
    },
    {
      "epoch": 0.0891566265060241,
      "grad_norm": 1.702279806137085,
      "learning_rate": 4.88855421686747e-06,
      "loss": 2.2599,
      "step": 148
    },
    {
      "epoch": 0.08975903614457831,
      "grad_norm": 1.6837502717971802,
      "learning_rate": 4.887801204819277e-06,
      "loss": 2.2017,
      "step": 149
    },
    {
      "epoch": 0.09036144578313253,
      "grad_norm": 1.6179723739624023,
      "learning_rate": 4.887048192771085e-06,
      "loss": 2.1898,
      "step": 150
    },
    {
      "epoch": 0.09096385542168675,
      "grad_norm": 1.6871484518051147,
      "learning_rate": 4.886295180722892e-06,
      "loss": 2.2026,
      "step": 151
    },
    {
      "epoch": 0.09156626506024096,
      "grad_norm": 1.5723150968551636,
      "learning_rate": 4.885542168674699e-06,
      "loss": 2.1576,
      "step": 152
    },
    {
      "epoch": 0.09216867469879518,
      "grad_norm": 1.7300187349319458,
      "learning_rate": 4.8847891566265065e-06,
      "loss": 2.1398,
      "step": 153
    },
    {
      "epoch": 0.0927710843373494,
      "grad_norm": 1.5798197984695435,
      "learning_rate": 4.8840361445783134e-06,
      "loss": 2.1461,
      "step": 154
    },
    {
      "epoch": 0.09337349397590361,
      "grad_norm": 1.6042051315307617,
      "learning_rate": 4.883283132530121e-06,
      "loss": 2.1018,
      "step": 155
    },
    {
      "epoch": 0.09397590361445783,
      "grad_norm": 1.5775691270828247,
      "learning_rate": 4.882530120481928e-06,
      "loss": 2.1388,
      "step": 156
    },
    {
      "epoch": 0.09457831325301205,
      "grad_norm": 1.5323243141174316,
      "learning_rate": 4.881777108433735e-06,
      "loss": 2.1614,
      "step": 157
    },
    {
      "epoch": 0.09518072289156626,
      "grad_norm": 1.5488330125808716,
      "learning_rate": 4.881024096385543e-06,
      "loss": 2.1201,
      "step": 158
    },
    {
      "epoch": 0.09578313253012048,
      "grad_norm": 1.5187963247299194,
      "learning_rate": 4.88027108433735e-06,
      "loss": 2.0941,
      "step": 159
    },
    {
      "epoch": 0.0963855421686747,
      "grad_norm": 1.5431574583053589,
      "learning_rate": 4.8795180722891575e-06,
      "loss": 2.1005,
      "step": 160
    },
    {
      "epoch": 0.09698795180722891,
      "grad_norm": 1.570328712463379,
      "learning_rate": 4.8787650602409644e-06,
      "loss": 2.1341,
      "step": 161
    },
    {
      "epoch": 0.09759036144578313,
      "grad_norm": 1.5035520792007446,
      "learning_rate": 4.878012048192771e-06,
      "loss": 2.1305,
      "step": 162
    },
    {
      "epoch": 0.09819277108433735,
      "grad_norm": 1.465175747871399,
      "learning_rate": 4.877259036144579e-06,
      "loss": 2.0771,
      "step": 163
    },
    {
      "epoch": 0.09879518072289156,
      "grad_norm": 1.6254162788391113,
      "learning_rate": 4.876506024096386e-06,
      "loss": 2.0199,
      "step": 164
    },
    {
      "epoch": 0.09939759036144578,
      "grad_norm": 1.4805916547775269,
      "learning_rate": 4.875753012048193e-06,
      "loss": 2.0465,
      "step": 165
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.4420905113220215,
      "learning_rate": 4.875e-06,
      "loss": 2.0727,
      "step": 166
    },
    {
      "epoch": 0.10060240963855421,
      "grad_norm": 1.395176649093628,
      "learning_rate": 4.874246987951808e-06,
      "loss": 2.0347,
      "step": 167
    },
    {
      "epoch": 0.10120481927710843,
      "grad_norm": 1.520964503288269,
      "learning_rate": 4.873493975903615e-06,
      "loss": 2.0657,
      "step": 168
    },
    {
      "epoch": 0.10180722891566266,
      "grad_norm": 1.4806395769119263,
      "learning_rate": 4.8727409638554215e-06,
      "loss": 2.0843,
      "step": 169
    },
    {
      "epoch": 0.10240963855421686,
      "grad_norm": 1.4548052549362183,
      "learning_rate": 4.871987951807229e-06,
      "loss": 2.031,
      "step": 170
    },
    {
      "epoch": 0.10301204819277109,
      "grad_norm": 1.4452883005142212,
      "learning_rate": 4.871234939759036e-06,
      "loss": 2.0503,
      "step": 171
    },
    {
      "epoch": 0.10361445783132531,
      "grad_norm": 1.3989262580871582,
      "learning_rate": 4.870481927710844e-06,
      "loss": 2.0321,
      "step": 172
    },
    {
      "epoch": 0.10421686746987951,
      "grad_norm": 1.412711262702942,
      "learning_rate": 4.869728915662651e-06,
      "loss": 2.013,
      "step": 173
    },
    {
      "epoch": 0.10481927710843374,
      "grad_norm": 1.3780540227890015,
      "learning_rate": 4.868975903614459e-06,
      "loss": 2.0583,
      "step": 174
    },
    {
      "epoch": 0.10542168674698796,
      "grad_norm": 1.3271026611328125,
      "learning_rate": 4.868222891566266e-06,
      "loss": 1.9821,
      "step": 175
    },
    {
      "epoch": 0.10602409638554217,
      "grad_norm": 1.431795358657837,
      "learning_rate": 4.8674698795180725e-06,
      "loss": 2.0173,
      "step": 176
    },
    {
      "epoch": 0.10662650602409639,
      "grad_norm": 1.3380274772644043,
      "learning_rate": 4.86671686746988e-06,
      "loss": 2.003,
      "step": 177
    },
    {
      "epoch": 0.10722891566265061,
      "grad_norm": 1.2584476470947266,
      "learning_rate": 4.865963855421687e-06,
      "loss": 1.909,
      "step": 178
    },
    {
      "epoch": 0.10783132530120482,
      "grad_norm": 1.4187318086624146,
      "learning_rate": 4.865210843373494e-06,
      "loss": 2.0355,
      "step": 179
    },
    {
      "epoch": 0.10843373493975904,
      "grad_norm": 1.361886739730835,
      "learning_rate": 4.864457831325302e-06,
      "loss": 1.9713,
      "step": 180
    },
    {
      "epoch": 0.10903614457831326,
      "grad_norm": 1.4159613847732544,
      "learning_rate": 4.863704819277109e-06,
      "loss": 1.9387,
      "step": 181
    },
    {
      "epoch": 0.10963855421686747,
      "grad_norm": 1.3011329174041748,
      "learning_rate": 4.862951807228916e-06,
      "loss": 1.9765,
      "step": 182
    },
    {
      "epoch": 0.11024096385542169,
      "grad_norm": 1.2086681127548218,
      "learning_rate": 4.862198795180723e-06,
      "loss": 1.9255,
      "step": 183
    },
    {
      "epoch": 0.1108433734939759,
      "grad_norm": 1.3825139999389648,
      "learning_rate": 4.8614457831325305e-06,
      "loss": 1.9819,
      "step": 184
    },
    {
      "epoch": 0.11144578313253012,
      "grad_norm": 1.257860541343689,
      "learning_rate": 4.860692771084337e-06,
      "loss": 1.9878,
      "step": 185
    },
    {
      "epoch": 0.11204819277108434,
      "grad_norm": 1.2405449151992798,
      "learning_rate": 4.859939759036145e-06,
      "loss": 1.9199,
      "step": 186
    },
    {
      "epoch": 0.11265060240963855,
      "grad_norm": 1.3239364624023438,
      "learning_rate": 4.859186746987952e-06,
      "loss": 2.0082,
      "step": 187
    },
    {
      "epoch": 0.11325301204819277,
      "grad_norm": 1.1693154573440552,
      "learning_rate": 4.858433734939759e-06,
      "loss": 1.915,
      "step": 188
    },
    {
      "epoch": 0.11385542168674699,
      "grad_norm": 1.1413384675979614,
      "learning_rate": 4.857680722891567e-06,
      "loss": 1.936,
      "step": 189
    },
    {
      "epoch": 0.1144578313253012,
      "grad_norm": 1.2409249544143677,
      "learning_rate": 4.856927710843374e-06,
      "loss": 1.98,
      "step": 190
    },
    {
      "epoch": 0.11506024096385542,
      "grad_norm": 1.262948751449585,
      "learning_rate": 4.8561746987951815e-06,
      "loss": 1.9579,
      "step": 191
    },
    {
      "epoch": 0.11566265060240964,
      "grad_norm": 1.3258872032165527,
      "learning_rate": 4.8554216867469884e-06,
      "loss": 1.94,
      "step": 192
    },
    {
      "epoch": 0.11626506024096385,
      "grad_norm": 1.110916256904602,
      "learning_rate": 4.854668674698795e-06,
      "loss": 1.9427,
      "step": 193
    },
    {
      "epoch": 0.11686746987951807,
      "grad_norm": 1.1721619367599487,
      "learning_rate": 4.853915662650603e-06,
      "loss": 1.9126,
      "step": 194
    },
    {
      "epoch": 0.11746987951807229,
      "grad_norm": 1.1373347043991089,
      "learning_rate": 4.85316265060241e-06,
      "loss": 1.903,
      "step": 195
    },
    {
      "epoch": 0.1180722891566265,
      "grad_norm": 1.1013853549957275,
      "learning_rate": 4.852409638554218e-06,
      "loss": 1.9345,
      "step": 196
    },
    {
      "epoch": 0.11867469879518072,
      "grad_norm": 1.0667864084243774,
      "learning_rate": 4.851656626506025e-06,
      "loss": 1.8671,
      "step": 197
    },
    {
      "epoch": 0.11927710843373494,
      "grad_norm": 1.0770890712738037,
      "learning_rate": 4.850903614457832e-06,
      "loss": 1.9074,
      "step": 198
    },
    {
      "epoch": 0.11987951807228915,
      "grad_norm": 1.009749174118042,
      "learning_rate": 4.850150602409639e-06,
      "loss": 1.8508,
      "step": 199
    },
    {
      "epoch": 0.12048192771084337,
      "grad_norm": 1.0740361213684082,
      "learning_rate": 4.849397590361446e-06,
      "loss": 1.8899,
      "step": 200
    },
    {
      "epoch": 0.1210843373493976,
      "grad_norm": 1.0050240755081177,
      "learning_rate": 4.848644578313253e-06,
      "loss": 1.8798,
      "step": 201
    },
    {
      "epoch": 0.1216867469879518,
      "grad_norm": 1.0541584491729736,
      "learning_rate": 4.84789156626506e-06,
      "loss": 1.9042,
      "step": 202
    },
    {
      "epoch": 0.12228915662650602,
      "grad_norm": 0.9949057102203369,
      "learning_rate": 4.847138554216868e-06,
      "loss": 1.8468,
      "step": 203
    },
    {
      "epoch": 0.12289156626506025,
      "grad_norm": 1.0123581886291504,
      "learning_rate": 4.846385542168675e-06,
      "loss": 1.8818,
      "step": 204
    },
    {
      "epoch": 0.12349397590361445,
      "grad_norm": 0.9042607545852661,
      "learning_rate": 4.845632530120482e-06,
      "loss": 1.815,
      "step": 205
    },
    {
      "epoch": 0.12409638554216867,
      "grad_norm": 1.0103472471237183,
      "learning_rate": 4.84487951807229e-06,
      "loss": 1.8368,
      "step": 206
    },
    {
      "epoch": 0.1246987951807229,
      "grad_norm": 0.9077780246734619,
      "learning_rate": 4.8441265060240965e-06,
      "loss": 1.804,
      "step": 207
    },
    {
      "epoch": 0.12530120481927712,
      "grad_norm": 0.9505817890167236,
      "learning_rate": 4.843373493975904e-06,
      "loss": 1.8615,
      "step": 208
    },
    {
      "epoch": 0.12590361445783133,
      "grad_norm": 0.9575837850570679,
      "learning_rate": 4.842620481927711e-06,
      "loss": 1.856,
      "step": 209
    },
    {
      "epoch": 0.12650602409638553,
      "grad_norm": 0.9176722168922424,
      "learning_rate": 4.841867469879519e-06,
      "loss": 1.8496,
      "step": 210
    },
    {
      "epoch": 0.12710843373493977,
      "grad_norm": 0.9278918504714966,
      "learning_rate": 4.841114457831326e-06,
      "loss": 1.8675,
      "step": 211
    },
    {
      "epoch": 0.12771084337349398,
      "grad_norm": 0.9137035608291626,
      "learning_rate": 4.840361445783133e-06,
      "loss": 1.7916,
      "step": 212
    },
    {
      "epoch": 0.12831325301204818,
      "grad_norm": 0.9672578573226929,
      "learning_rate": 4.839608433734941e-06,
      "loss": 1.8276,
      "step": 213
    },
    {
      "epoch": 0.12891566265060242,
      "grad_norm": 0.8599427342414856,
      "learning_rate": 4.8388554216867476e-06,
      "loss": 1.7928,
      "step": 214
    },
    {
      "epoch": 0.12951807228915663,
      "grad_norm": 0.9550036191940308,
      "learning_rate": 4.8381024096385545e-06,
      "loss": 1.852,
      "step": 215
    },
    {
      "epoch": 0.13012048192771083,
      "grad_norm": 0.8712965250015259,
      "learning_rate": 4.837349397590361e-06,
      "loss": 1.7794,
      "step": 216
    },
    {
      "epoch": 0.13072289156626507,
      "grad_norm": 0.875115692615509,
      "learning_rate": 4.836596385542169e-06,
      "loss": 1.8266,
      "step": 217
    },
    {
      "epoch": 0.13132530120481928,
      "grad_norm": 0.852411687374115,
      "learning_rate": 4.835843373493976e-06,
      "loss": 1.8206,
      "step": 218
    },
    {
      "epoch": 0.13192771084337349,
      "grad_norm": 0.8348486423492432,
      "learning_rate": 4.835090361445783e-06,
      "loss": 1.8134,
      "step": 219
    },
    {
      "epoch": 0.13253012048192772,
      "grad_norm": 0.7793241739273071,
      "learning_rate": 4.834337349397591e-06,
      "loss": 1.7362,
      "step": 220
    },
    {
      "epoch": 0.13313253012048193,
      "grad_norm": 0.8342352509498596,
      "learning_rate": 4.833584337349398e-06,
      "loss": 1.7996,
      "step": 221
    },
    {
      "epoch": 0.13373493975903614,
      "grad_norm": 0.8212642073631287,
      "learning_rate": 4.8328313253012055e-06,
      "loss": 1.799,
      "step": 222
    },
    {
      "epoch": 0.13433734939759037,
      "grad_norm": 0.8465393781661987,
      "learning_rate": 4.832078313253012e-06,
      "loss": 1.7914,
      "step": 223
    },
    {
      "epoch": 0.13493975903614458,
      "grad_norm": 0.7977269291877747,
      "learning_rate": 4.831325301204819e-06,
      "loss": 1.8053,
      "step": 224
    },
    {
      "epoch": 0.1355421686746988,
      "grad_norm": 0.7921637892723083,
      "learning_rate": 4.830572289156627e-06,
      "loss": 1.7695,
      "step": 225
    },
    {
      "epoch": 0.13614457831325302,
      "grad_norm": 0.7832058668136597,
      "learning_rate": 4.829819277108434e-06,
      "loss": 1.799,
      "step": 226
    },
    {
      "epoch": 0.13674698795180723,
      "grad_norm": 0.8296300172805786,
      "learning_rate": 4.829066265060242e-06,
      "loss": 1.7622,
      "step": 227
    },
    {
      "epoch": 0.13734939759036144,
      "grad_norm": 0.7828813195228577,
      "learning_rate": 4.828313253012049e-06,
      "loss": 1.7706,
      "step": 228
    },
    {
      "epoch": 0.13795180722891567,
      "grad_norm": 0.7815297245979309,
      "learning_rate": 4.827560240963856e-06,
      "loss": 1.79,
      "step": 229
    },
    {
      "epoch": 0.13855421686746988,
      "grad_norm": 0.7838123440742493,
      "learning_rate": 4.8268072289156634e-06,
      "loss": 1.789,
      "step": 230
    },
    {
      "epoch": 0.1391566265060241,
      "grad_norm": 0.7792511582374573,
      "learning_rate": 4.82605421686747e-06,
      "loss": 1.7937,
      "step": 231
    },
    {
      "epoch": 0.13975903614457832,
      "grad_norm": 0.8035470843315125,
      "learning_rate": 4.825301204819277e-06,
      "loss": 1.7949,
      "step": 232
    },
    {
      "epoch": 0.14036144578313253,
      "grad_norm": 0.7542542815208435,
      "learning_rate": 4.824548192771085e-06,
      "loss": 1.7282,
      "step": 233
    },
    {
      "epoch": 0.14096385542168674,
      "grad_norm": 0.7674682140350342,
      "learning_rate": 4.823795180722892e-06,
      "loss": 1.7515,
      "step": 234
    },
    {
      "epoch": 0.14156626506024098,
      "grad_norm": 0.7248489260673523,
      "learning_rate": 4.823042168674699e-06,
      "loss": 1.7266,
      "step": 235
    },
    {
      "epoch": 0.14216867469879518,
      "grad_norm": 0.7419578433036804,
      "learning_rate": 4.822289156626506e-06,
      "loss": 1.7683,
      "step": 236
    },
    {
      "epoch": 0.1427710843373494,
      "grad_norm": 0.7516714334487915,
      "learning_rate": 4.821536144578314e-06,
      "loss": 1.7499,
      "step": 237
    },
    {
      "epoch": 0.14337349397590363,
      "grad_norm": 0.7608193755149841,
      "learning_rate": 4.8207831325301205e-06,
      "loss": 1.763,
      "step": 238
    },
    {
      "epoch": 0.14397590361445783,
      "grad_norm": 0.7405287027359009,
      "learning_rate": 4.820030120481928e-06,
      "loss": 1.7826,
      "step": 239
    },
    {
      "epoch": 0.14457831325301204,
      "grad_norm": 0.7617663741111755,
      "learning_rate": 4.819277108433735e-06,
      "loss": 1.7692,
      "step": 240
    },
    {
      "epoch": 0.14518072289156628,
      "grad_norm": 0.7266189455986023,
      "learning_rate": 4.818524096385542e-06,
      "loss": 1.7425,
      "step": 241
    },
    {
      "epoch": 0.14578313253012049,
      "grad_norm": 0.7304509878158569,
      "learning_rate": 4.81777108433735e-06,
      "loss": 1.7665,
      "step": 242
    },
    {
      "epoch": 0.1463855421686747,
      "grad_norm": 0.7530302405357361,
      "learning_rate": 4.817018072289157e-06,
      "loss": 1.7465,
      "step": 243
    },
    {
      "epoch": 0.14698795180722893,
      "grad_norm": 0.748790979385376,
      "learning_rate": 4.816265060240965e-06,
      "loss": 1.7618,
      "step": 244
    },
    {
      "epoch": 0.14759036144578314,
      "grad_norm": 0.7156896591186523,
      "learning_rate": 4.8155120481927715e-06,
      "loss": 1.7582,
      "step": 245
    },
    {
      "epoch": 0.14819277108433734,
      "grad_norm": 0.7198463082313538,
      "learning_rate": 4.814759036144579e-06,
      "loss": 1.7199,
      "step": 246
    },
    {
      "epoch": 0.14879518072289158,
      "grad_norm": 0.7159889936447144,
      "learning_rate": 4.814006024096386e-06,
      "loss": 1.7125,
      "step": 247
    },
    {
      "epoch": 0.1493975903614458,
      "grad_norm": 0.7478316426277161,
      "learning_rate": 4.813253012048193e-06,
      "loss": 1.7325,
      "step": 248
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7034206986427307,
      "learning_rate": 4.8125e-06,
      "loss": 1.6775,
      "step": 249
    },
    {
      "epoch": 0.15060240963855423,
      "grad_norm": 0.7154672741889954,
      "learning_rate": 4.811746987951808e-06,
      "loss": 1.7079,
      "step": 250
    },
    {
      "epoch": 0.15120481927710844,
      "grad_norm": 0.7286857962608337,
      "learning_rate": 4.810993975903615e-06,
      "loss": 1.7452,
      "step": 251
    },
    {
      "epoch": 0.15180722891566265,
      "grad_norm": 0.7306095957756042,
      "learning_rate": 4.810240963855422e-06,
      "loss": 1.7389,
      "step": 252
    },
    {
      "epoch": 0.15240963855421688,
      "grad_norm": 0.7658929824829102,
      "learning_rate": 4.809487951807229e-06,
      "loss": 1.7538,
      "step": 253
    },
    {
      "epoch": 0.1530120481927711,
      "grad_norm": 0.7986821532249451,
      "learning_rate": 4.808734939759036e-06,
      "loss": 1.7607,
      "step": 254
    },
    {
      "epoch": 0.1536144578313253,
      "grad_norm": 0.7916812896728516,
      "learning_rate": 4.807981927710843e-06,
      "loss": 1.7161,
      "step": 255
    },
    {
      "epoch": 0.15421686746987953,
      "grad_norm": 0.9134896397590637,
      "learning_rate": 4.807228915662651e-06,
      "loss": 1.6001,
      "step": 256
    },
    {
      "epoch": 0.15481927710843374,
      "grad_norm": 0.6852250099182129,
      "learning_rate": 4.806475903614458e-06,
      "loss": 1.7377,
      "step": 257
    },
    {
      "epoch": 0.15542168674698795,
      "grad_norm": 0.7006720304489136,
      "learning_rate": 4.805722891566266e-06,
      "loss": 1.6864,
      "step": 258
    },
    {
      "epoch": 0.15602409638554218,
      "grad_norm": 0.6734626293182373,
      "learning_rate": 4.804969879518073e-06,
      "loss": 1.6787,
      "step": 259
    },
    {
      "epoch": 0.1566265060240964,
      "grad_norm": 0.6498069763183594,
      "learning_rate": 4.80421686746988e-06,
      "loss": 1.6754,
      "step": 260
    },
    {
      "epoch": 0.1572289156626506,
      "grad_norm": 0.6874427199363708,
      "learning_rate": 4.803463855421687e-06,
      "loss": 1.6744,
      "step": 261
    },
    {
      "epoch": 0.1578313253012048,
      "grad_norm": 0.737357497215271,
      "learning_rate": 4.802710843373494e-06,
      "loss": 1.7087,
      "step": 262
    },
    {
      "epoch": 0.15843373493975904,
      "grad_norm": 0.6797679662704468,
      "learning_rate": 4.801957831325302e-06,
      "loss": 1.7166,
      "step": 263
    },
    {
      "epoch": 0.15903614457831325,
      "grad_norm": 0.6966806054115295,
      "learning_rate": 4.801204819277109e-06,
      "loss": 1.6967,
      "step": 264
    },
    {
      "epoch": 0.15963855421686746,
      "grad_norm": 0.6827394962310791,
      "learning_rate": 4.800451807228916e-06,
      "loss": 1.6597,
      "step": 265
    },
    {
      "epoch": 0.1602409638554217,
      "grad_norm": 0.7116414904594421,
      "learning_rate": 4.799698795180724e-06,
      "loss": 1.7002,
      "step": 266
    },
    {
      "epoch": 0.1608433734939759,
      "grad_norm": 0.6779251098632812,
      "learning_rate": 4.798945783132531e-06,
      "loss": 1.7055,
      "step": 267
    },
    {
      "epoch": 0.1614457831325301,
      "grad_norm": 0.6708039045333862,
      "learning_rate": 4.798192771084338e-06,
      "loss": 1.6679,
      "step": 268
    },
    {
      "epoch": 0.16204819277108434,
      "grad_norm": 0.6839370727539062,
      "learning_rate": 4.7974397590361445e-06,
      "loss": 1.6921,
      "step": 269
    },
    {
      "epoch": 0.16265060240963855,
      "grad_norm": 0.6977958083152771,
      "learning_rate": 4.796686746987952e-06,
      "loss": 1.6964,
      "step": 270
    },
    {
      "epoch": 0.16325301204819276,
      "grad_norm": 0.6544438004493713,
      "learning_rate": 4.795933734939759e-06,
      "loss": 1.6635,
      "step": 271
    },
    {
      "epoch": 0.163855421686747,
      "grad_norm": 0.6762298345565796,
      "learning_rate": 4.795180722891566e-06,
      "loss": 1.6713,
      "step": 272
    },
    {
      "epoch": 0.1644578313253012,
      "grad_norm": 0.7012321949005127,
      "learning_rate": 4.794427710843374e-06,
      "loss": 1.6868,
      "step": 273
    },
    {
      "epoch": 0.1650602409638554,
      "grad_norm": 0.6606985926628113,
      "learning_rate": 4.793674698795181e-06,
      "loss": 1.6682,
      "step": 274
    },
    {
      "epoch": 0.16566265060240964,
      "grad_norm": 0.6576200127601624,
      "learning_rate": 4.792921686746989e-06,
      "loss": 1.6666,
      "step": 275
    },
    {
      "epoch": 0.16626506024096385,
      "grad_norm": 0.7273927927017212,
      "learning_rate": 4.7921686746987955e-06,
      "loss": 1.6765,
      "step": 276
    },
    {
      "epoch": 0.16686746987951806,
      "grad_norm": 0.6670618057250977,
      "learning_rate": 4.7914156626506025e-06,
      "loss": 1.6845,
      "step": 277
    },
    {
      "epoch": 0.1674698795180723,
      "grad_norm": 0.6406273245811462,
      "learning_rate": 4.79066265060241e-06,
      "loss": 1.6227,
      "step": 278
    },
    {
      "epoch": 0.1680722891566265,
      "grad_norm": 0.6692442297935486,
      "learning_rate": 4.789909638554217e-06,
      "loss": 1.6482,
      "step": 279
    },
    {
      "epoch": 0.1686746987951807,
      "grad_norm": 0.6585025191307068,
      "learning_rate": 4.789156626506025e-06,
      "loss": 1.6574,
      "step": 280
    },
    {
      "epoch": 0.16927710843373495,
      "grad_norm": 0.697080135345459,
      "learning_rate": 4.788403614457832e-06,
      "loss": 1.6336,
      "step": 281
    },
    {
      "epoch": 0.16987951807228915,
      "grad_norm": 0.6588965654373169,
      "learning_rate": 4.787650602409639e-06,
      "loss": 1.6491,
      "step": 282
    },
    {
      "epoch": 0.17048192771084336,
      "grad_norm": 0.6678246259689331,
      "learning_rate": 4.7868975903614465e-06,
      "loss": 1.6352,
      "step": 283
    },
    {
      "epoch": 0.1710843373493976,
      "grad_norm": 0.6675540804862976,
      "learning_rate": 4.7861445783132535e-06,
      "loss": 1.6593,
      "step": 284
    },
    {
      "epoch": 0.1716867469879518,
      "grad_norm": 0.6648253202438354,
      "learning_rate": 4.78539156626506e-06,
      "loss": 1.6625,
      "step": 285
    },
    {
      "epoch": 0.172289156626506,
      "grad_norm": 0.660615861415863,
      "learning_rate": 4.784638554216867e-06,
      "loss": 1.6681,
      "step": 286
    },
    {
      "epoch": 0.17289156626506025,
      "grad_norm": 0.6819944977760315,
      "learning_rate": 4.783885542168675e-06,
      "loss": 1.6714,
      "step": 287
    },
    {
      "epoch": 0.17349397590361446,
      "grad_norm": 0.671136200428009,
      "learning_rate": 4.783132530120482e-06,
      "loss": 1.6377,
      "step": 288
    },
    {
      "epoch": 0.17409638554216866,
      "grad_norm": 0.61184161901474,
      "learning_rate": 4.782379518072289e-06,
      "loss": 1.58,
      "step": 289
    },
    {
      "epoch": 0.1746987951807229,
      "grad_norm": 0.6526268720626831,
      "learning_rate": 4.781626506024097e-06,
      "loss": 1.6385,
      "step": 290
    },
    {
      "epoch": 0.1753012048192771,
      "grad_norm": 0.642365574836731,
      "learning_rate": 4.780873493975904e-06,
      "loss": 1.6191,
      "step": 291
    },
    {
      "epoch": 0.17590361445783131,
      "grad_norm": 0.6718357801437378,
      "learning_rate": 4.780120481927711e-06,
      "loss": 1.6605,
      "step": 292
    },
    {
      "epoch": 0.17650602409638555,
      "grad_norm": 0.6541979312896729,
      "learning_rate": 4.779367469879518e-06,
      "loss": 1.6293,
      "step": 293
    },
    {
      "epoch": 0.17710843373493976,
      "grad_norm": 0.6586394309997559,
      "learning_rate": 4.778614457831326e-06,
      "loss": 1.6176,
      "step": 294
    },
    {
      "epoch": 0.17771084337349397,
      "grad_norm": 0.6500979661941528,
      "learning_rate": 4.777861445783133e-06,
      "loss": 1.6348,
      "step": 295
    },
    {
      "epoch": 0.1783132530120482,
      "grad_norm": 0.6391447186470032,
      "learning_rate": 4.77710843373494e-06,
      "loss": 1.5877,
      "step": 296
    },
    {
      "epoch": 0.1789156626506024,
      "grad_norm": 0.6656926274299622,
      "learning_rate": 4.776355421686748e-06,
      "loss": 1.6451,
      "step": 297
    },
    {
      "epoch": 0.17951807228915662,
      "grad_norm": 0.6461007595062256,
      "learning_rate": 4.775602409638555e-06,
      "loss": 1.6238,
      "step": 298
    },
    {
      "epoch": 0.18012048192771085,
      "grad_norm": 0.6284456849098206,
      "learning_rate": 4.7748493975903624e-06,
      "loss": 1.5773,
      "step": 299
    },
    {
      "epoch": 0.18072289156626506,
      "grad_norm": 0.6400514841079712,
      "learning_rate": 4.774096385542169e-06,
      "loss": 1.6096,
      "step": 300
    },
    {
      "epoch": 0.18132530120481927,
      "grad_norm": 0.6357744336128235,
      "learning_rate": 4.773343373493976e-06,
      "loss": 1.6174,
      "step": 301
    },
    {
      "epoch": 0.1819277108433735,
      "grad_norm": 0.6255476474761963,
      "learning_rate": 4.772590361445783e-06,
      "loss": 1.6065,
      "step": 302
    },
    {
      "epoch": 0.1825301204819277,
      "grad_norm": 0.6425718665122986,
      "learning_rate": 4.771837349397591e-06,
      "loss": 1.5976,
      "step": 303
    },
    {
      "epoch": 0.18313253012048192,
      "grad_norm": 0.5990505218505859,
      "learning_rate": 4.771084337349398e-06,
      "loss": 1.5839,
      "step": 304
    },
    {
      "epoch": 0.18373493975903615,
      "grad_norm": 0.6406679749488831,
      "learning_rate": 4.770331325301205e-06,
      "loss": 1.5903,
      "step": 305
    },
    {
      "epoch": 0.18433734939759036,
      "grad_norm": 0.6475541591644287,
      "learning_rate": 4.769578313253013e-06,
      "loss": 1.6086,
      "step": 306
    },
    {
      "epoch": 0.18493975903614457,
      "grad_norm": 0.6213065385818481,
      "learning_rate": 4.7688253012048195e-06,
      "loss": 1.5811,
      "step": 307
    },
    {
      "epoch": 0.1855421686746988,
      "grad_norm": 0.6599918007850647,
      "learning_rate": 4.7680722891566264e-06,
      "loss": 1.6204,
      "step": 308
    },
    {
      "epoch": 0.186144578313253,
      "grad_norm": 0.7024031281471252,
      "learning_rate": 4.767319277108434e-06,
      "loss": 1.5912,
      "step": 309
    },
    {
      "epoch": 0.18674698795180722,
      "grad_norm": 0.6702051758766174,
      "learning_rate": 4.766566265060241e-06,
      "loss": 1.6281,
      "step": 310
    },
    {
      "epoch": 0.18734939759036146,
      "grad_norm": 0.6451951265335083,
      "learning_rate": 4.765813253012049e-06,
      "loss": 1.5694,
      "step": 311
    },
    {
      "epoch": 0.18795180722891566,
      "grad_norm": 0.6359463930130005,
      "learning_rate": 4.765060240963856e-06,
      "loss": 1.5843,
      "step": 312
    },
    {
      "epoch": 0.18855421686746987,
      "grad_norm": 0.6530444025993347,
      "learning_rate": 4.764307228915663e-06,
      "loss": 1.5817,
      "step": 313
    },
    {
      "epoch": 0.1891566265060241,
      "grad_norm": 0.6461654305458069,
      "learning_rate": 4.7635542168674705e-06,
      "loss": 1.594,
      "step": 314
    },
    {
      "epoch": 0.1897590361445783,
      "grad_norm": 0.6297623515129089,
      "learning_rate": 4.7628012048192775e-06,
      "loss": 1.5633,
      "step": 315
    },
    {
      "epoch": 0.19036144578313252,
      "grad_norm": 0.6362635493278503,
      "learning_rate": 4.762048192771085e-06,
      "loss": 1.5812,
      "step": 316
    },
    {
      "epoch": 0.19096385542168676,
      "grad_norm": 0.6120848059654236,
      "learning_rate": 4.761295180722892e-06,
      "loss": 1.5595,
      "step": 317
    },
    {
      "epoch": 0.19156626506024096,
      "grad_norm": 0.6225551962852478,
      "learning_rate": 4.760542168674699e-06,
      "loss": 1.5783,
      "step": 318
    },
    {
      "epoch": 0.19216867469879517,
      "grad_norm": 0.6688928604125977,
      "learning_rate": 4.759789156626506e-06,
      "loss": 1.5967,
      "step": 319
    },
    {
      "epoch": 0.1927710843373494,
      "grad_norm": 0.6598610281944275,
      "learning_rate": 4.759036144578314e-06,
      "loss": 1.6214,
      "step": 320
    },
    {
      "epoch": 0.19337349397590362,
      "grad_norm": 0.6592398285865784,
      "learning_rate": 4.758283132530121e-06,
      "loss": 1.6104,
      "step": 321
    },
    {
      "epoch": 0.19397590361445782,
      "grad_norm": 0.6635907292366028,
      "learning_rate": 4.757530120481928e-06,
      "loss": 1.5348,
      "step": 322
    },
    {
      "epoch": 0.19457831325301206,
      "grad_norm": 0.6335883736610413,
      "learning_rate": 4.756777108433735e-06,
      "loss": 1.5675,
      "step": 323
    },
    {
      "epoch": 0.19518072289156627,
      "grad_norm": 0.6404081583023071,
      "learning_rate": 4.756024096385542e-06,
      "loss": 1.5806,
      "step": 324
    },
    {
      "epoch": 0.19578313253012047,
      "grad_norm": 0.829918384552002,
      "learning_rate": 4.755271084337349e-06,
      "loss": 1.5913,
      "step": 325
    },
    {
      "epoch": 0.1963855421686747,
      "grad_norm": 0.6443366408348083,
      "learning_rate": 4.754518072289157e-06,
      "loss": 1.5576,
      "step": 326
    },
    {
      "epoch": 0.19698795180722892,
      "grad_norm": 0.6491392850875854,
      "learning_rate": 4.753765060240964e-06,
      "loss": 1.5359,
      "step": 327
    },
    {
      "epoch": 0.19759036144578312,
      "grad_norm": 0.6451538801193237,
      "learning_rate": 4.753012048192772e-06,
      "loss": 1.5618,
      "step": 328
    },
    {
      "epoch": 0.19819277108433736,
      "grad_norm": 0.6561552882194519,
      "learning_rate": 4.752259036144579e-06,
      "loss": 1.5651,
      "step": 329
    },
    {
      "epoch": 0.19879518072289157,
      "grad_norm": 0.6456325054168701,
      "learning_rate": 4.751506024096386e-06,
      "loss": 1.5567,
      "step": 330
    },
    {
      "epoch": 0.19939759036144578,
      "grad_norm": 0.6588553786277771,
      "learning_rate": 4.750753012048193e-06,
      "loss": 1.5959,
      "step": 331
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6509483456611633,
      "learning_rate": 4.75e-06,
      "loss": 1.5742,
      "step": 332
    },
    {
      "epoch": 0.20060240963855422,
      "grad_norm": 0.6219142079353333,
      "learning_rate": 4.749246987951808e-06,
      "loss": 1.5571,
      "step": 333
    },
    {
      "epoch": 0.20120481927710843,
      "grad_norm": 0.6430069208145142,
      "learning_rate": 4.748493975903615e-06,
      "loss": 1.5397,
      "step": 334
    },
    {
      "epoch": 0.20180722891566266,
      "grad_norm": 0.6167206168174744,
      "learning_rate": 4.747740963855422e-06,
      "loss": 1.5558,
      "step": 335
    },
    {
      "epoch": 0.20240963855421687,
      "grad_norm": 0.6544647216796875,
      "learning_rate": 4.74698795180723e-06,
      "loss": 1.5603,
      "step": 336
    },
    {
      "epoch": 0.20301204819277108,
      "grad_norm": 0.684609591960907,
      "learning_rate": 4.746234939759037e-06,
      "loss": 1.525,
      "step": 337
    },
    {
      "epoch": 0.2036144578313253,
      "grad_norm": 0.6527585983276367,
      "learning_rate": 4.7454819277108435e-06,
      "loss": 1.5503,
      "step": 338
    },
    {
      "epoch": 0.20421686746987952,
      "grad_norm": 0.6695069670677185,
      "learning_rate": 4.7447289156626504e-06,
      "loss": 1.5858,
      "step": 339
    },
    {
      "epoch": 0.20481927710843373,
      "grad_norm": 0.6157159805297852,
      "learning_rate": 4.743975903614458e-06,
      "loss": 1.5405,
      "step": 340
    },
    {
      "epoch": 0.20542168674698796,
      "grad_norm": 0.6423202753067017,
      "learning_rate": 4.743222891566265e-06,
      "loss": 1.534,
      "step": 341
    },
    {
      "epoch": 0.20602409638554217,
      "grad_norm": 0.6362714767456055,
      "learning_rate": 4.742469879518073e-06,
      "loss": 1.5294,
      "step": 342
    },
    {
      "epoch": 0.20662650602409638,
      "grad_norm": 0.6461687684059143,
      "learning_rate": 4.74171686746988e-06,
      "loss": 1.5208,
      "step": 343
    },
    {
      "epoch": 0.20722891566265061,
      "grad_norm": 0.6433520913124084,
      "learning_rate": 4.740963855421687e-06,
      "loss": 1.5267,
      "step": 344
    },
    {
      "epoch": 0.20783132530120482,
      "grad_norm": 0.6207682490348816,
      "learning_rate": 4.7402108433734945e-06,
      "loss": 1.5138,
      "step": 345
    },
    {
      "epoch": 0.20843373493975903,
      "grad_norm": 0.6161406636238098,
      "learning_rate": 4.7394578313253014e-06,
      "loss": 1.5034,
      "step": 346
    },
    {
      "epoch": 0.20903614457831327,
      "grad_norm": 0.64574134349823,
      "learning_rate": 4.738704819277109e-06,
      "loss": 1.5531,
      "step": 347
    },
    {
      "epoch": 0.20963855421686747,
      "grad_norm": 0.6376998424530029,
      "learning_rate": 4.737951807228916e-06,
      "loss": 1.5378,
      "step": 348
    },
    {
      "epoch": 0.21024096385542168,
      "grad_norm": 0.5982925891876221,
      "learning_rate": 4.737198795180723e-06,
      "loss": 1.4712,
      "step": 349
    },
    {
      "epoch": 0.21084337349397592,
      "grad_norm": 0.6326965093612671,
      "learning_rate": 4.736445783132531e-06,
      "loss": 1.5181,
      "step": 350
    },
    {
      "epoch": 0.21144578313253012,
      "grad_norm": 0.6496576070785522,
      "learning_rate": 4.735692771084338e-06,
      "loss": 1.5407,
      "step": 351
    },
    {
      "epoch": 0.21204819277108433,
      "grad_norm": 0.6260280013084412,
      "learning_rate": 4.734939759036145e-06,
      "loss": 1.4836,
      "step": 352
    },
    {
      "epoch": 0.21265060240963857,
      "grad_norm": 0.6155536770820618,
      "learning_rate": 4.7341867469879525e-06,
      "loss": 1.5073,
      "step": 353
    },
    {
      "epoch": 0.21325301204819277,
      "grad_norm": 0.6185526847839355,
      "learning_rate": 4.733433734939759e-06,
      "loss": 1.477,
      "step": 354
    },
    {
      "epoch": 0.21385542168674698,
      "grad_norm": 0.6486453413963318,
      "learning_rate": 4.732680722891566e-06,
      "loss": 1.4951,
      "step": 355
    },
    {
      "epoch": 0.21445783132530122,
      "grad_norm": 0.6380505561828613,
      "learning_rate": 4.731927710843373e-06,
      "loss": 1.4814,
      "step": 356
    },
    {
      "epoch": 0.21506024096385543,
      "grad_norm": 0.6255105137825012,
      "learning_rate": 4.731174698795181e-06,
      "loss": 1.4791,
      "step": 357
    },
    {
      "epoch": 0.21566265060240963,
      "grad_norm": 0.6287629008293152,
      "learning_rate": 4.730421686746988e-06,
      "loss": 1.4868,
      "step": 358
    },
    {
      "epoch": 0.21626506024096387,
      "grad_norm": 0.6419431567192078,
      "learning_rate": 4.729668674698796e-06,
      "loss": 1.4912,
      "step": 359
    },
    {
      "epoch": 0.21686746987951808,
      "grad_norm": 0.7530532479286194,
      "learning_rate": 4.728915662650603e-06,
      "loss": 1.5267,
      "step": 360
    },
    {
      "epoch": 0.21746987951807228,
      "grad_norm": 0.7297770380973816,
      "learning_rate": 4.7281626506024096e-06,
      "loss": 1.5409,
      "step": 361
    },
    {
      "epoch": 0.21807228915662652,
      "grad_norm": 0.6409830451011658,
      "learning_rate": 4.727409638554217e-06,
      "loss": 1.4688,
      "step": 362
    },
    {
      "epoch": 0.21867469879518073,
      "grad_norm": 0.6544075012207031,
      "learning_rate": 4.726656626506024e-06,
      "loss": 1.4872,
      "step": 363
    },
    {
      "epoch": 0.21927710843373494,
      "grad_norm": 0.6264719367027283,
      "learning_rate": 4.725903614457832e-06,
      "loss": 1.4943,
      "step": 364
    },
    {
      "epoch": 0.21987951807228914,
      "grad_norm": 0.6438235640525818,
      "learning_rate": 4.725150602409639e-06,
      "loss": 1.4854,
      "step": 365
    },
    {
      "epoch": 0.22048192771084338,
      "grad_norm": 0.6482366919517517,
      "learning_rate": 4.724397590361447e-06,
      "loss": 1.4896,
      "step": 366
    },
    {
      "epoch": 0.22108433734939759,
      "grad_norm": 0.6416745781898499,
      "learning_rate": 4.723644578313254e-06,
      "loss": 1.451,
      "step": 367
    },
    {
      "epoch": 0.2216867469879518,
      "grad_norm": 0.6397807002067566,
      "learning_rate": 4.7228915662650606e-06,
      "loss": 1.4765,
      "step": 368
    },
    {
      "epoch": 0.22228915662650603,
      "grad_norm": 0.6592069864273071,
      "learning_rate": 4.722138554216868e-06,
      "loss": 1.4787,
      "step": 369
    },
    {
      "epoch": 0.22289156626506024,
      "grad_norm": 0.7139462232589722,
      "learning_rate": 4.721385542168675e-06,
      "loss": 1.5071,
      "step": 370
    },
    {
      "epoch": 0.22349397590361444,
      "grad_norm": 0.623958945274353,
      "learning_rate": 4.720632530120482e-06,
      "loss": 1.457,
      "step": 371
    },
    {
      "epoch": 0.22409638554216868,
      "grad_norm": 0.6212629675865173,
      "learning_rate": 4.719879518072289e-06,
      "loss": 1.4666,
      "step": 372
    },
    {
      "epoch": 0.2246987951807229,
      "grad_norm": 0.7842098474502563,
      "learning_rate": 4.719126506024097e-06,
      "loss": 1.4939,
      "step": 373
    },
    {
      "epoch": 0.2253012048192771,
      "grad_norm": 0.6521069407463074,
      "learning_rate": 4.718373493975904e-06,
      "loss": 1.4768,
      "step": 374
    },
    {
      "epoch": 0.22590361445783133,
      "grad_norm": 0.6809759736061096,
      "learning_rate": 4.717620481927711e-06,
      "loss": 1.4788,
      "step": 375
    },
    {
      "epoch": 0.22650602409638554,
      "grad_norm": 0.6498954892158508,
      "learning_rate": 4.7168674698795185e-06,
      "loss": 1.4681,
      "step": 376
    },
    {
      "epoch": 0.22710843373493975,
      "grad_norm": 0.6468263268470764,
      "learning_rate": 4.7161144578313254e-06,
      "loss": 1.4697,
      "step": 377
    },
    {
      "epoch": 0.22771084337349398,
      "grad_norm": 0.6433398127555847,
      "learning_rate": 4.715361445783133e-06,
      "loss": 1.4695,
      "step": 378
    },
    {
      "epoch": 0.2283132530120482,
      "grad_norm": 0.658553957939148,
      "learning_rate": 4.71460843373494e-06,
      "loss": 1.4828,
      "step": 379
    },
    {
      "epoch": 0.2289156626506024,
      "grad_norm": 0.652323842048645,
      "learning_rate": 4.713855421686747e-06,
      "loss": 1.4792,
      "step": 380
    },
    {
      "epoch": 0.22951807228915663,
      "grad_norm": 0.6653844714164734,
      "learning_rate": 4.713102409638555e-06,
      "loss": 1.4792,
      "step": 381
    },
    {
      "epoch": 0.23012048192771084,
      "grad_norm": 0.6484766006469727,
      "learning_rate": 4.712349397590362e-06,
      "loss": 1.4725,
      "step": 382
    },
    {
      "epoch": 0.23072289156626505,
      "grad_norm": 0.6362417936325073,
      "learning_rate": 4.7115963855421695e-06,
      "loss": 1.4438,
      "step": 383
    },
    {
      "epoch": 0.23132530120481928,
      "grad_norm": 0.6443678736686707,
      "learning_rate": 4.7108433734939764e-06,
      "loss": 1.4481,
      "step": 384
    },
    {
      "epoch": 0.2319277108433735,
      "grad_norm": 0.6164745092391968,
      "learning_rate": 4.710090361445783e-06,
      "loss": 1.4363,
      "step": 385
    },
    {
      "epoch": 0.2325301204819277,
      "grad_norm": 0.6805216670036316,
      "learning_rate": 4.709337349397591e-06,
      "loss": 1.478,
      "step": 386
    },
    {
      "epoch": 0.23313253012048193,
      "grad_norm": 0.6527292132377625,
      "learning_rate": 4.708584337349398e-06,
      "loss": 1.45,
      "step": 387
    },
    {
      "epoch": 0.23373493975903614,
      "grad_norm": 0.6436319947242737,
      "learning_rate": 4.707831325301205e-06,
      "loss": 1.4401,
      "step": 388
    },
    {
      "epoch": 0.23433734939759035,
      "grad_norm": 0.6378951668739319,
      "learning_rate": 4.707078313253013e-06,
      "loss": 1.4388,
      "step": 389
    },
    {
      "epoch": 0.23493975903614459,
      "grad_norm": 0.6975602507591248,
      "learning_rate": 4.70632530120482e-06,
      "loss": 1.4458,
      "step": 390
    },
    {
      "epoch": 0.2355421686746988,
      "grad_norm": 0.6798909902572632,
      "learning_rate": 4.705572289156627e-06,
      "loss": 1.4306,
      "step": 391
    },
    {
      "epoch": 0.236144578313253,
      "grad_norm": 0.6244096755981445,
      "learning_rate": 4.7048192771084335e-06,
      "loss": 1.4082,
      "step": 392
    },
    {
      "epoch": 0.23674698795180724,
      "grad_norm": 0.6536766886711121,
      "learning_rate": 4.704066265060241e-06,
      "loss": 1.4142,
      "step": 393
    },
    {
      "epoch": 0.23734939759036144,
      "grad_norm": 0.6715525388717651,
      "learning_rate": 4.703313253012048e-06,
      "loss": 1.4416,
      "step": 394
    },
    {
      "epoch": 0.23795180722891565,
      "grad_norm": 0.6854484677314758,
      "learning_rate": 4.702560240963856e-06,
      "loss": 1.4591,
      "step": 395
    },
    {
      "epoch": 0.2385542168674699,
      "grad_norm": 0.6372882127761841,
      "learning_rate": 4.701807228915663e-06,
      "loss": 1.4125,
      "step": 396
    },
    {
      "epoch": 0.2391566265060241,
      "grad_norm": 0.6718167662620544,
      "learning_rate": 4.70105421686747e-06,
      "loss": 1.4605,
      "step": 397
    },
    {
      "epoch": 0.2397590361445783,
      "grad_norm": 0.665308952331543,
      "learning_rate": 4.700301204819278e-06,
      "loss": 1.4518,
      "step": 398
    },
    {
      "epoch": 0.24036144578313254,
      "grad_norm": 0.6598243117332458,
      "learning_rate": 4.6995481927710846e-06,
      "loss": 1.4508,
      "step": 399
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 0.65450119972229,
      "learning_rate": 4.698795180722892e-06,
      "loss": 1.4276,
      "step": 400
    },
    {
      "epoch": 0.24156626506024095,
      "grad_norm": 0.6503952741622925,
      "learning_rate": 4.698042168674699e-06,
      "loss": 1.419,
      "step": 401
    },
    {
      "epoch": 0.2421686746987952,
      "grad_norm": 0.606131911277771,
      "learning_rate": 4.697289156626507e-06,
      "loss": 1.3597,
      "step": 402
    },
    {
      "epoch": 0.2427710843373494,
      "grad_norm": 0.6401098370552063,
      "learning_rate": 4.696536144578314e-06,
      "loss": 1.363,
      "step": 403
    },
    {
      "epoch": 0.2433734939759036,
      "grad_norm": 0.7056542038917542,
      "learning_rate": 4.695783132530121e-06,
      "loss": 1.4047,
      "step": 404
    },
    {
      "epoch": 0.24397590361445784,
      "grad_norm": 0.6579391360282898,
      "learning_rate": 4.695030120481928e-06,
      "loss": 1.4165,
      "step": 405
    },
    {
      "epoch": 0.24457831325301205,
      "grad_norm": 0.6766225695610046,
      "learning_rate": 4.6942771084337356e-06,
      "loss": 1.428,
      "step": 406
    },
    {
      "epoch": 0.24518072289156626,
      "grad_norm": 0.7448626756668091,
      "learning_rate": 4.6935240963855425e-06,
      "loss": 1.4026,
      "step": 407
    },
    {
      "epoch": 0.2457831325301205,
      "grad_norm": 0.6427358388900757,
      "learning_rate": 4.692771084337349e-06,
      "loss": 1.3784,
      "step": 408
    },
    {
      "epoch": 0.2463855421686747,
      "grad_norm": 0.6683297753334045,
      "learning_rate": 4.692018072289156e-06,
      "loss": 1.3994,
      "step": 409
    },
    {
      "epoch": 0.2469879518072289,
      "grad_norm": 0.6842496395111084,
      "learning_rate": 4.691265060240964e-06,
      "loss": 1.3979,
      "step": 410
    },
    {
      "epoch": 0.24759036144578314,
      "grad_norm": 0.6649302244186401,
      "learning_rate": 4.690512048192771e-06,
      "loss": 1.3698,
      "step": 411
    },
    {
      "epoch": 0.24819277108433735,
      "grad_norm": 0.7221450209617615,
      "learning_rate": 4.689759036144579e-06,
      "loss": 1.4015,
      "step": 412
    },
    {
      "epoch": 0.24879518072289156,
      "grad_norm": 0.6628255248069763,
      "learning_rate": 4.689006024096386e-06,
      "loss": 1.3892,
      "step": 413
    },
    {
      "epoch": 0.2493975903614458,
      "grad_norm": 0.7052865028381348,
      "learning_rate": 4.6882530120481935e-06,
      "loss": 1.4037,
      "step": 414
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6725109815597534,
      "learning_rate": 4.6875000000000004e-06,
      "loss": 1.3813,
      "step": 415
    },
    {
      "epoch": 0.25060240963855424,
      "grad_norm": 0.7037453055381775,
      "learning_rate": 4.686746987951807e-06,
      "loss": 1.4082,
      "step": 416
    },
    {
      "epoch": 0.2512048192771084,
      "grad_norm": 0.682462215423584,
      "learning_rate": 4.685993975903615e-06,
      "loss": 1.3844,
      "step": 417
    },
    {
      "epoch": 0.25180722891566265,
      "grad_norm": 0.6489384770393372,
      "learning_rate": 4.685240963855422e-06,
      "loss": 1.3704,
      "step": 418
    },
    {
      "epoch": 0.2524096385542169,
      "grad_norm": 0.6836550235748291,
      "learning_rate": 4.68448795180723e-06,
      "loss": 1.3628,
      "step": 419
    },
    {
      "epoch": 0.25301204819277107,
      "grad_norm": 0.6634193658828735,
      "learning_rate": 4.683734939759037e-06,
      "loss": 1.3687,
      "step": 420
    },
    {
      "epoch": 0.2536144578313253,
      "grad_norm": 0.6690682172775269,
      "learning_rate": 4.682981927710844e-06,
      "loss": 1.3645,
      "step": 421
    },
    {
      "epoch": 0.25421686746987954,
      "grad_norm": 0.7435281276702881,
      "learning_rate": 4.6822289156626515e-06,
      "loss": 1.4076,
      "step": 422
    },
    {
      "epoch": 0.2548192771084337,
      "grad_norm": 0.6612210869789124,
      "learning_rate": 4.681475903614458e-06,
      "loss": 1.3464,
      "step": 423
    },
    {
      "epoch": 0.25542168674698795,
      "grad_norm": 0.7181046009063721,
      "learning_rate": 4.680722891566265e-06,
      "loss": 1.3975,
      "step": 424
    },
    {
      "epoch": 0.2560240963855422,
      "grad_norm": 0.7023417353630066,
      "learning_rate": 4.679969879518072e-06,
      "loss": 1.3777,
      "step": 425
    },
    {
      "epoch": 0.25662650602409637,
      "grad_norm": 0.7121264338493347,
      "learning_rate": 4.67921686746988e-06,
      "loss": 1.3819,
      "step": 426
    },
    {
      "epoch": 0.2572289156626506,
      "grad_norm": 0.664839506149292,
      "learning_rate": 4.678463855421687e-06,
      "loss": 1.4063,
      "step": 427
    },
    {
      "epoch": 0.25783132530120484,
      "grad_norm": 0.6752731800079346,
      "learning_rate": 4.677710843373494e-06,
      "loss": 1.3606,
      "step": 428
    },
    {
      "epoch": 0.258433734939759,
      "grad_norm": 0.6757628321647644,
      "learning_rate": 4.676957831325302e-06,
      "loss": 1.3312,
      "step": 429
    },
    {
      "epoch": 0.25903614457831325,
      "grad_norm": 0.6671711802482605,
      "learning_rate": 4.6762048192771085e-06,
      "loss": 1.3333,
      "step": 430
    },
    {
      "epoch": 0.2596385542168675,
      "grad_norm": 0.6762487888336182,
      "learning_rate": 4.675451807228916e-06,
      "loss": 1.3519,
      "step": 431
    },
    {
      "epoch": 0.26024096385542167,
      "grad_norm": 0.6368926167488098,
      "learning_rate": 4.674698795180723e-06,
      "loss": 1.3852,
      "step": 432
    },
    {
      "epoch": 0.2608433734939759,
      "grad_norm": 0.7183334231376648,
      "learning_rate": 4.673945783132531e-06,
      "loss": 1.3441,
      "step": 433
    },
    {
      "epoch": 0.26144578313253014,
      "grad_norm": 1.0045826435089111,
      "learning_rate": 4.673192771084338e-06,
      "loss": 1.3471,
      "step": 434
    },
    {
      "epoch": 0.2620481927710843,
      "grad_norm": 0.7425513863563538,
      "learning_rate": 4.672439759036145e-06,
      "loss": 1.3465,
      "step": 435
    },
    {
      "epoch": 0.26265060240963856,
      "grad_norm": 0.6605783104896545,
      "learning_rate": 4.671686746987953e-06,
      "loss": 1.3459,
      "step": 436
    },
    {
      "epoch": 0.2632530120481928,
      "grad_norm": 0.6908897757530212,
      "learning_rate": 4.6709337349397596e-06,
      "loss": 1.3708,
      "step": 437
    },
    {
      "epoch": 0.26385542168674697,
      "grad_norm": 0.7091141939163208,
      "learning_rate": 4.6701807228915665e-06,
      "loss": 1.3439,
      "step": 438
    },
    {
      "epoch": 0.2644578313253012,
      "grad_norm": 0.7621722221374512,
      "learning_rate": 4.669427710843374e-06,
      "loss": 1.3213,
      "step": 439
    },
    {
      "epoch": 0.26506024096385544,
      "grad_norm": 0.7582409381866455,
      "learning_rate": 4.668674698795181e-06,
      "loss": 1.3623,
      "step": 440
    },
    {
      "epoch": 0.2656626506024096,
      "grad_norm": 0.7061888575553894,
      "learning_rate": 4.667921686746988e-06,
      "loss": 1.3331,
      "step": 441
    },
    {
      "epoch": 0.26626506024096386,
      "grad_norm": 0.6889800429344177,
      "learning_rate": 4.667168674698795e-06,
      "loss": 1.3545,
      "step": 442
    },
    {
      "epoch": 0.2668674698795181,
      "grad_norm": 0.6855157613754272,
      "learning_rate": 4.666415662650603e-06,
      "loss": 1.3314,
      "step": 443
    },
    {
      "epoch": 0.2674698795180723,
      "grad_norm": 0.7147547006607056,
      "learning_rate": 4.66566265060241e-06,
      "loss": 1.3596,
      "step": 444
    },
    {
      "epoch": 0.2680722891566265,
      "grad_norm": 0.723124086856842,
      "learning_rate": 4.6649096385542175e-06,
      "loss": 1.3116,
      "step": 445
    },
    {
      "epoch": 0.26867469879518074,
      "grad_norm": 0.7121570706367493,
      "learning_rate": 4.6641566265060244e-06,
      "loss": 1.3487,
      "step": 446
    },
    {
      "epoch": 0.2692771084337349,
      "grad_norm": 0.6966265439987183,
      "learning_rate": 4.663403614457831e-06,
      "loss": 1.3382,
      "step": 447
    },
    {
      "epoch": 0.26987951807228916,
      "grad_norm": 0.73429274559021,
      "learning_rate": 4.662650602409639e-06,
      "loss": 1.3471,
      "step": 448
    },
    {
      "epoch": 0.2704819277108434,
      "grad_norm": 0.6960325241088867,
      "learning_rate": 4.661897590361446e-06,
      "loss": 1.3229,
      "step": 449
    },
    {
      "epoch": 0.2710843373493976,
      "grad_norm": 0.7126370072364807,
      "learning_rate": 4.661144578313254e-06,
      "loss": 1.3231,
      "step": 450
    },
    {
      "epoch": 0.2716867469879518,
      "grad_norm": 0.7032334804534912,
      "learning_rate": 4.660391566265061e-06,
      "loss": 1.3313,
      "step": 451
    },
    {
      "epoch": 0.27228915662650605,
      "grad_norm": 0.7691775560379028,
      "learning_rate": 4.659638554216868e-06,
      "loss": 1.3257,
      "step": 452
    },
    {
      "epoch": 0.2728915662650602,
      "grad_norm": 0.7335044145584106,
      "learning_rate": 4.6588855421686754e-06,
      "loss": 1.3261,
      "step": 453
    },
    {
      "epoch": 0.27349397590361446,
      "grad_norm": 0.700809895992279,
      "learning_rate": 4.658132530120482e-06,
      "loss": 1.3036,
      "step": 454
    },
    {
      "epoch": 0.2740963855421687,
      "grad_norm": 0.6737030148506165,
      "learning_rate": 4.65737951807229e-06,
      "loss": 1.2997,
      "step": 455
    },
    {
      "epoch": 0.2746987951807229,
      "grad_norm": 0.8478635549545288,
      "learning_rate": 4.656626506024097e-06,
      "loss": 1.3218,
      "step": 456
    },
    {
      "epoch": 0.2753012048192771,
      "grad_norm": 0.6802839636802673,
      "learning_rate": 4.655873493975904e-06,
      "loss": 1.294,
      "step": 457
    },
    {
      "epoch": 0.27590361445783135,
      "grad_norm": 0.6938044428825378,
      "learning_rate": 4.655120481927711e-06,
      "loss": 1.3092,
      "step": 458
    },
    {
      "epoch": 0.2765060240963855,
      "grad_norm": 0.7576228380203247,
      "learning_rate": 4.654367469879519e-06,
      "loss": 1.2819,
      "step": 459
    },
    {
      "epoch": 0.27710843373493976,
      "grad_norm": 0.795172929763794,
      "learning_rate": 4.653614457831326e-06,
      "loss": 1.3076,
      "step": 460
    },
    {
      "epoch": 0.277710843373494,
      "grad_norm": 0.7527379393577576,
      "learning_rate": 4.6528614457831325e-06,
      "loss": 1.3194,
      "step": 461
    },
    {
      "epoch": 0.2783132530120482,
      "grad_norm": 0.6936380863189697,
      "learning_rate": 4.65210843373494e-06,
      "loss": 1.2759,
      "step": 462
    },
    {
      "epoch": 0.2789156626506024,
      "grad_norm": 0.7290310263633728,
      "learning_rate": 4.651355421686747e-06,
      "loss": 1.3042,
      "step": 463
    },
    {
      "epoch": 0.27951807228915665,
      "grad_norm": 0.7192020416259766,
      "learning_rate": 4.650602409638554e-06,
      "loss": 1.2775,
      "step": 464
    },
    {
      "epoch": 0.28012048192771083,
      "grad_norm": 0.7727175951004028,
      "learning_rate": 4.649849397590362e-06,
      "loss": 1.3059,
      "step": 465
    },
    {
      "epoch": 0.28072289156626506,
      "grad_norm": 0.7462296485900879,
      "learning_rate": 4.649096385542169e-06,
      "loss": 1.3091,
      "step": 466
    },
    {
      "epoch": 0.2813253012048193,
      "grad_norm": 0.7823005318641663,
      "learning_rate": 4.648343373493977e-06,
      "loss": 1.3072,
      "step": 467
    },
    {
      "epoch": 0.2819277108433735,
      "grad_norm": 0.7252394556999207,
      "learning_rate": 4.6475903614457835e-06,
      "loss": 1.3137,
      "step": 468
    },
    {
      "epoch": 0.2825301204819277,
      "grad_norm": 0.7515267729759216,
      "learning_rate": 4.646837349397591e-06,
      "loss": 1.3118,
      "step": 469
    },
    {
      "epoch": 0.28313253012048195,
      "grad_norm": 0.7366926074028015,
      "learning_rate": 4.646084337349398e-06,
      "loss": 1.2643,
      "step": 470
    },
    {
      "epoch": 0.28373493975903613,
      "grad_norm": 0.899003267288208,
      "learning_rate": 4.645331325301205e-06,
      "loss": 1.2794,
      "step": 471
    },
    {
      "epoch": 0.28433734939759037,
      "grad_norm": 0.7598603367805481,
      "learning_rate": 4.644578313253013e-06,
      "loss": 1.2812,
      "step": 472
    },
    {
      "epoch": 0.2849397590361446,
      "grad_norm": 0.7439104914665222,
      "learning_rate": 4.64382530120482e-06,
      "loss": 1.271,
      "step": 473
    },
    {
      "epoch": 0.2855421686746988,
      "grad_norm": 0.7227540016174316,
      "learning_rate": 4.643072289156627e-06,
      "loss": 1.2725,
      "step": 474
    },
    {
      "epoch": 0.286144578313253,
      "grad_norm": 0.756925642490387,
      "learning_rate": 4.642319277108434e-06,
      "loss": 1.2725,
      "step": 475
    },
    {
      "epoch": 0.28674698795180725,
      "grad_norm": 0.7776544690132141,
      "learning_rate": 4.6415662650602415e-06,
      "loss": 1.267,
      "step": 476
    },
    {
      "epoch": 0.28734939759036143,
      "grad_norm": 0.7618106007575989,
      "learning_rate": 4.640813253012048e-06,
      "loss": 1.2444,
      "step": 477
    },
    {
      "epoch": 0.28795180722891567,
      "grad_norm": 0.7443186044692993,
      "learning_rate": 4.640060240963855e-06,
      "loss": 1.2573,
      "step": 478
    },
    {
      "epoch": 0.2885542168674699,
      "grad_norm": 0.847170889377594,
      "learning_rate": 4.639307228915663e-06,
      "loss": 1.2683,
      "step": 479
    },
    {
      "epoch": 0.2891566265060241,
      "grad_norm": 0.7935969233512878,
      "learning_rate": 4.63855421686747e-06,
      "loss": 1.2703,
      "step": 480
    },
    {
      "epoch": 0.2897590361445783,
      "grad_norm": 0.838478684425354,
      "learning_rate": 4.637801204819278e-06,
      "loss": 1.2397,
      "step": 481
    },
    {
      "epoch": 0.29036144578313255,
      "grad_norm": 0.8000442981719971,
      "learning_rate": 4.637048192771085e-06,
      "loss": 1.2362,
      "step": 482
    },
    {
      "epoch": 0.29096385542168673,
      "grad_norm": 0.7502771615982056,
      "learning_rate": 4.636295180722892e-06,
      "loss": 1.2522,
      "step": 483
    },
    {
      "epoch": 0.29156626506024097,
      "grad_norm": 0.721977949142456,
      "learning_rate": 4.6355421686746994e-06,
      "loss": 1.2276,
      "step": 484
    },
    {
      "epoch": 0.2921686746987952,
      "grad_norm": 0.7902247309684753,
      "learning_rate": 4.634789156626506e-06,
      "loss": 1.2726,
      "step": 485
    },
    {
      "epoch": 0.2927710843373494,
      "grad_norm": 0.8303613066673279,
      "learning_rate": 4.634036144578314e-06,
      "loss": 1.2493,
      "step": 486
    },
    {
      "epoch": 0.2933734939759036,
      "grad_norm": 0.7572912573814392,
      "learning_rate": 4.633283132530121e-06,
      "loss": 1.2372,
      "step": 487
    },
    {
      "epoch": 0.29397590361445786,
      "grad_norm": 0.7693661451339722,
      "learning_rate": 4.632530120481928e-06,
      "loss": 1.236,
      "step": 488
    },
    {
      "epoch": 0.29457831325301204,
      "grad_norm": 0.7457924485206604,
      "learning_rate": 4.631777108433736e-06,
      "loss": 1.2084,
      "step": 489
    },
    {
      "epoch": 0.29518072289156627,
      "grad_norm": 0.7683013677597046,
      "learning_rate": 4.631024096385543e-06,
      "loss": 1.228,
      "step": 490
    },
    {
      "epoch": 0.2957831325301205,
      "grad_norm": 0.7842846512794495,
      "learning_rate": 4.63027108433735e-06,
      "loss": 1.2092,
      "step": 491
    },
    {
      "epoch": 0.2963855421686747,
      "grad_norm": 0.7988995909690857,
      "learning_rate": 4.629518072289157e-06,
      "loss": 1.1987,
      "step": 492
    },
    {
      "epoch": 0.2969879518072289,
      "grad_norm": 0.7974557280540466,
      "learning_rate": 4.628765060240964e-06,
      "loss": 1.2046,
      "step": 493
    },
    {
      "epoch": 0.29759036144578316,
      "grad_norm": 0.8083837032318115,
      "learning_rate": 4.628012048192771e-06,
      "loss": 1.2179,
      "step": 494
    },
    {
      "epoch": 0.29819277108433734,
      "grad_norm": 0.8177149891853333,
      "learning_rate": 4.627259036144578e-06,
      "loss": 1.235,
      "step": 495
    },
    {
      "epoch": 0.2987951807228916,
      "grad_norm": 0.774157702922821,
      "learning_rate": 4.626506024096386e-06,
      "loss": 1.2061,
      "step": 496
    },
    {
      "epoch": 0.2993975903614458,
      "grad_norm": 0.7774245142936707,
      "learning_rate": 4.625753012048193e-06,
      "loss": 1.2128,
      "step": 497
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7715277671813965,
      "learning_rate": 4.625000000000001e-06,
      "loss": 1.2154,
      "step": 498
    },
    {
      "epoch": 0.3006024096385542,
      "grad_norm": 0.7642433047294617,
      "learning_rate": 4.6242469879518075e-06,
      "loss": 1.1755,
      "step": 499
    },
    {
      "epoch": 0.30120481927710846,
      "grad_norm": 0.7985989451408386,
      "learning_rate": 4.6234939759036145e-06,
      "loss": 1.1925,
      "step": 500
    },
    {
      "epoch": 0.30180722891566264,
      "grad_norm": 0.8449245095252991,
      "learning_rate": 4.622740963855422e-06,
      "loss": 1.1925,
      "step": 501
    },
    {
      "epoch": 0.3024096385542169,
      "grad_norm": 0.7987614274024963,
      "learning_rate": 4.621987951807229e-06,
      "loss": 1.2051,
      "step": 502
    },
    {
      "epoch": 0.3030120481927711,
      "grad_norm": 0.8026478886604309,
      "learning_rate": 4.621234939759037e-06,
      "loss": 1.2038,
      "step": 503
    },
    {
      "epoch": 0.3036144578313253,
      "grad_norm": 0.936475932598114,
      "learning_rate": 4.620481927710844e-06,
      "loss": 1.2163,
      "step": 504
    },
    {
      "epoch": 0.3042168674698795,
      "grad_norm": 0.7759738564491272,
      "learning_rate": 4.619728915662652e-06,
      "loss": 1.1716,
      "step": 505
    },
    {
      "epoch": 0.30481927710843376,
      "grad_norm": 0.7715129852294922,
      "learning_rate": 4.6189759036144586e-06,
      "loss": 1.1802,
      "step": 506
    },
    {
      "epoch": 0.30542168674698794,
      "grad_norm": 0.7802460193634033,
      "learning_rate": 4.6182228915662655e-06,
      "loss": 1.1971,
      "step": 507
    },
    {
      "epoch": 0.3060240963855422,
      "grad_norm": 0.7795127630233765,
      "learning_rate": 4.617469879518072e-06,
      "loss": 1.1992,
      "step": 508
    },
    {
      "epoch": 0.3066265060240964,
      "grad_norm": 0.7875553369522095,
      "learning_rate": 4.61671686746988e-06,
      "loss": 1.1441,
      "step": 509
    },
    {
      "epoch": 0.3072289156626506,
      "grad_norm": 0.8119906187057495,
      "learning_rate": 4.615963855421687e-06,
      "loss": 1.1568,
      "step": 510
    },
    {
      "epoch": 0.30783132530120483,
      "grad_norm": 0.79170161485672,
      "learning_rate": 4.615210843373494e-06,
      "loss": 1.1808,
      "step": 511
    },
    {
      "epoch": 0.30843373493975906,
      "grad_norm": 0.8204405903816223,
      "learning_rate": 4.614457831325301e-06,
      "loss": 1.1723,
      "step": 512
    },
    {
      "epoch": 0.30903614457831324,
      "grad_norm": 0.7836465239524841,
      "learning_rate": 4.613704819277109e-06,
      "loss": 1.1588,
      "step": 513
    },
    {
      "epoch": 0.3096385542168675,
      "grad_norm": 0.8192872405052185,
      "learning_rate": 4.612951807228916e-06,
      "loss": 1.1641,
      "step": 514
    },
    {
      "epoch": 0.3102409638554217,
      "grad_norm": 1.1575502157211304,
      "learning_rate": 4.612198795180723e-06,
      "loss": 1.1508,
      "step": 515
    },
    {
      "epoch": 0.3108433734939759,
      "grad_norm": 0.8360119462013245,
      "learning_rate": 4.61144578313253e-06,
      "loss": 1.1599,
      "step": 516
    },
    {
      "epoch": 0.31144578313253013,
      "grad_norm": 0.8230413794517517,
      "learning_rate": 4.610692771084338e-06,
      "loss": 1.1525,
      "step": 517
    },
    {
      "epoch": 0.31204819277108437,
      "grad_norm": 0.794537365436554,
      "learning_rate": 4.609939759036145e-06,
      "loss": 1.1787,
      "step": 518
    },
    {
      "epoch": 0.31265060240963854,
      "grad_norm": 1.0930845737457275,
      "learning_rate": 4.609186746987952e-06,
      "loss": 1.1056,
      "step": 519
    },
    {
      "epoch": 0.3132530120481928,
      "grad_norm": 0.8123249411582947,
      "learning_rate": 4.60843373493976e-06,
      "loss": 1.1547,
      "step": 520
    },
    {
      "epoch": 0.31385542168674696,
      "grad_norm": 0.7511062622070312,
      "learning_rate": 4.607680722891567e-06,
      "loss": 1.1339,
      "step": 521
    },
    {
      "epoch": 0.3144578313253012,
      "grad_norm": 0.8800257444381714,
      "learning_rate": 4.6069277108433744e-06,
      "loss": 1.1551,
      "step": 522
    },
    {
      "epoch": 0.31506024096385543,
      "grad_norm": 0.8391683101654053,
      "learning_rate": 4.606174698795181e-06,
      "loss": 1.1385,
      "step": 523
    },
    {
      "epoch": 0.3156626506024096,
      "grad_norm": 0.8860307335853577,
      "learning_rate": 4.605421686746988e-06,
      "loss": 1.1557,
      "step": 524
    },
    {
      "epoch": 0.31626506024096385,
      "grad_norm": 0.8355449438095093,
      "learning_rate": 4.604668674698796e-06,
      "loss": 1.129,
      "step": 525
    },
    {
      "epoch": 0.3168674698795181,
      "grad_norm": 0.8208494186401367,
      "learning_rate": 4.603915662650603e-06,
      "loss": 1.1232,
      "step": 526
    },
    {
      "epoch": 0.31746987951807226,
      "grad_norm": 0.8163328766822815,
      "learning_rate": 4.60316265060241e-06,
      "loss": 1.1046,
      "step": 527
    },
    {
      "epoch": 0.3180722891566265,
      "grad_norm": 0.8091890811920166,
      "learning_rate": 4.602409638554217e-06,
      "loss": 1.1565,
      "step": 528
    },
    {
      "epoch": 0.31867469879518073,
      "grad_norm": 0.8065326809883118,
      "learning_rate": 4.601656626506025e-06,
      "loss": 1.1008,
      "step": 529
    },
    {
      "epoch": 0.3192771084337349,
      "grad_norm": 0.8265286087989807,
      "learning_rate": 4.6009036144578315e-06,
      "loss": 1.1127,
      "step": 530
    },
    {
      "epoch": 0.31987951807228915,
      "grad_norm": 0.8936268091201782,
      "learning_rate": 4.6001506024096384e-06,
      "loss": 1.1378,
      "step": 531
    },
    {
      "epoch": 0.3204819277108434,
      "grad_norm": 0.8300471901893616,
      "learning_rate": 4.599397590361446e-06,
      "loss": 1.1128,
      "step": 532
    },
    {
      "epoch": 0.32108433734939756,
      "grad_norm": 0.8353710174560547,
      "learning_rate": 4.598644578313253e-06,
      "loss": 1.0873,
      "step": 533
    },
    {
      "epoch": 0.3216867469879518,
      "grad_norm": 0.8373447060585022,
      "learning_rate": 4.597891566265061e-06,
      "loss": 1.1299,
      "step": 534
    },
    {
      "epoch": 0.32228915662650603,
      "grad_norm": 0.8070380091667175,
      "learning_rate": 4.597138554216868e-06,
      "loss": 1.1317,
      "step": 535
    },
    {
      "epoch": 0.3228915662650602,
      "grad_norm": 0.8433580994606018,
      "learning_rate": 4.596385542168675e-06,
      "loss": 1.0959,
      "step": 536
    },
    {
      "epoch": 0.32349397590361445,
      "grad_norm": 0.8714677691459656,
      "learning_rate": 4.5956325301204825e-06,
      "loss": 1.1119,
      "step": 537
    },
    {
      "epoch": 0.3240963855421687,
      "grad_norm": 0.9281489253044128,
      "learning_rate": 4.5948795180722895e-06,
      "loss": 1.1035,
      "step": 538
    },
    {
      "epoch": 0.32469879518072287,
      "grad_norm": 0.963981568813324,
      "learning_rate": 4.594126506024097e-06,
      "loss": 1.0874,
      "step": 539
    },
    {
      "epoch": 0.3253012048192771,
      "grad_norm": 0.8538676500320435,
      "learning_rate": 4.593373493975904e-06,
      "loss": 1.1177,
      "step": 540
    },
    {
      "epoch": 0.32590361445783134,
      "grad_norm": 1.217300534248352,
      "learning_rate": 4.592620481927711e-06,
      "loss": 1.1248,
      "step": 541
    },
    {
      "epoch": 0.3265060240963855,
      "grad_norm": 0.9153752326965332,
      "learning_rate": 4.591867469879519e-06,
      "loss": 1.0635,
      "step": 542
    },
    {
      "epoch": 0.32710843373493975,
      "grad_norm": 0.8561972379684448,
      "learning_rate": 4.591114457831326e-06,
      "loss": 1.0825,
      "step": 543
    },
    {
      "epoch": 0.327710843373494,
      "grad_norm": 0.9268096089363098,
      "learning_rate": 4.590361445783133e-06,
      "loss": 1.0601,
      "step": 544
    },
    {
      "epoch": 0.32831325301204817,
      "grad_norm": 0.8263047933578491,
      "learning_rate": 4.58960843373494e-06,
      "loss": 1.0711,
      "step": 545
    },
    {
      "epoch": 0.3289156626506024,
      "grad_norm": 0.8348627686500549,
      "learning_rate": 4.588855421686747e-06,
      "loss": 1.0768,
      "step": 546
    },
    {
      "epoch": 0.32951807228915664,
      "grad_norm": 0.8844594359397888,
      "learning_rate": 4.588102409638554e-06,
      "loss": 1.098,
      "step": 547
    },
    {
      "epoch": 0.3301204819277108,
      "grad_norm": 0.8970906138420105,
      "learning_rate": 4.587349397590361e-06,
      "loss": 1.0742,
      "step": 548
    },
    {
      "epoch": 0.33072289156626505,
      "grad_norm": 0.8220227360725403,
      "learning_rate": 4.586596385542169e-06,
      "loss": 1.0707,
      "step": 549
    },
    {
      "epoch": 0.3313253012048193,
      "grad_norm": 0.848793625831604,
      "learning_rate": 4.585843373493976e-06,
      "loss": 1.0406,
      "step": 550
    },
    {
      "epoch": 0.33192771084337347,
      "grad_norm": 0.9019021987915039,
      "learning_rate": 4.585090361445784e-06,
      "loss": 1.0939,
      "step": 551
    },
    {
      "epoch": 0.3325301204819277,
      "grad_norm": 0.9108277559280396,
      "learning_rate": 4.584337349397591e-06,
      "loss": 1.0181,
      "step": 552
    },
    {
      "epoch": 0.33313253012048194,
      "grad_norm": 0.9106627702713013,
      "learning_rate": 4.583584337349398e-06,
      "loss": 1.0258,
      "step": 553
    },
    {
      "epoch": 0.3337349397590361,
      "grad_norm": 0.9148174524307251,
      "learning_rate": 4.582831325301205e-06,
      "loss": 1.0757,
      "step": 554
    },
    {
      "epoch": 0.33433734939759036,
      "grad_norm": 0.9404388070106506,
      "learning_rate": 4.582078313253012e-06,
      "loss": 1.02,
      "step": 555
    },
    {
      "epoch": 0.3349397590361446,
      "grad_norm": 0.9330199956893921,
      "learning_rate": 4.58132530120482e-06,
      "loss": 1.0696,
      "step": 556
    },
    {
      "epoch": 0.33554216867469877,
      "grad_norm": 0.872704029083252,
      "learning_rate": 4.580572289156627e-06,
      "loss": 1.0112,
      "step": 557
    },
    {
      "epoch": 0.336144578313253,
      "grad_norm": 0.9114587306976318,
      "learning_rate": 4.579819277108435e-06,
      "loss": 1.0161,
      "step": 558
    },
    {
      "epoch": 0.33674698795180724,
      "grad_norm": 1.0541424751281738,
      "learning_rate": 4.579066265060242e-06,
      "loss": 1.0246,
      "step": 559
    },
    {
      "epoch": 0.3373493975903614,
      "grad_norm": 0.9305897951126099,
      "learning_rate": 4.578313253012049e-06,
      "loss": 1.0096,
      "step": 560
    },
    {
      "epoch": 0.33795180722891566,
      "grad_norm": 1.101534366607666,
      "learning_rate": 4.5775602409638555e-06,
      "loss": 1.0068,
      "step": 561
    },
    {
      "epoch": 0.3385542168674699,
      "grad_norm": 0.9265696406364441,
      "learning_rate": 4.576807228915663e-06,
      "loss": 1.0539,
      "step": 562
    },
    {
      "epoch": 0.3391566265060241,
      "grad_norm": 0.9041746854782104,
      "learning_rate": 4.57605421686747e-06,
      "loss": 1.0164,
      "step": 563
    },
    {
      "epoch": 0.3397590361445783,
      "grad_norm": 0.9439758062362671,
      "learning_rate": 4.575301204819277e-06,
      "loss": 1.0086,
      "step": 564
    },
    {
      "epoch": 0.34036144578313254,
      "grad_norm": 0.9918045997619629,
      "learning_rate": 4.574548192771085e-06,
      "loss": 1.0056,
      "step": 565
    },
    {
      "epoch": 0.3409638554216867,
      "grad_norm": 0.9387204051017761,
      "learning_rate": 4.573795180722892e-06,
      "loss": 0.9728,
      "step": 566
    },
    {
      "epoch": 0.34156626506024096,
      "grad_norm": 0.9380938410758972,
      "learning_rate": 4.573042168674699e-06,
      "loss": 0.9882,
      "step": 567
    },
    {
      "epoch": 0.3421686746987952,
      "grad_norm": 0.9221879243850708,
      "learning_rate": 4.5722891566265065e-06,
      "loss": 1.0003,
      "step": 568
    },
    {
      "epoch": 0.3427710843373494,
      "grad_norm": 0.959180474281311,
      "learning_rate": 4.5715361445783135e-06,
      "loss": 0.9877,
      "step": 569
    },
    {
      "epoch": 0.3433734939759036,
      "grad_norm": 0.908014178276062,
      "learning_rate": 4.570783132530121e-06,
      "loss": 1.0168,
      "step": 570
    },
    {
      "epoch": 0.34397590361445785,
      "grad_norm": 0.9182217717170715,
      "learning_rate": 4.570030120481928e-06,
      "loss": 0.9933,
      "step": 571
    },
    {
      "epoch": 0.344578313253012,
      "grad_norm": 0.8885422348976135,
      "learning_rate": 4.569277108433735e-06,
      "loss": 0.9803,
      "step": 572
    },
    {
      "epoch": 0.34518072289156626,
      "grad_norm": 0.9633075594902039,
      "learning_rate": 4.568524096385543e-06,
      "loss": 0.9624,
      "step": 573
    },
    {
      "epoch": 0.3457831325301205,
      "grad_norm": 0.8849138021469116,
      "learning_rate": 4.56777108433735e-06,
      "loss": 0.9881,
      "step": 574
    },
    {
      "epoch": 0.3463855421686747,
      "grad_norm": 0.8933996558189392,
      "learning_rate": 4.5670180722891575e-06,
      "loss": 0.9633,
      "step": 575
    },
    {
      "epoch": 0.3469879518072289,
      "grad_norm": 0.9244436621665955,
      "learning_rate": 4.5662650602409645e-06,
      "loss": 0.9901,
      "step": 576
    },
    {
      "epoch": 0.34759036144578315,
      "grad_norm": 0.9138057231903076,
      "learning_rate": 4.565512048192771e-06,
      "loss": 0.9645,
      "step": 577
    },
    {
      "epoch": 0.3481927710843373,
      "grad_norm": 0.9953289031982422,
      "learning_rate": 4.564759036144578e-06,
      "loss": 0.9579,
      "step": 578
    },
    {
      "epoch": 0.34879518072289156,
      "grad_norm": 0.9399383068084717,
      "learning_rate": 4.564006024096386e-06,
      "loss": 0.9973,
      "step": 579
    },
    {
      "epoch": 0.3493975903614458,
      "grad_norm": 0.982713520526886,
      "learning_rate": 4.563253012048193e-06,
      "loss": 0.9567,
      "step": 580
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9631641507148743,
      "learning_rate": 4.5625e-06,
      "loss": 0.926,
      "step": 581
    },
    {
      "epoch": 0.3506024096385542,
      "grad_norm": 0.9645606875419617,
      "learning_rate": 4.561746987951808e-06,
      "loss": 0.9863,
      "step": 582
    },
    {
      "epoch": 0.35120481927710845,
      "grad_norm": 0.976893424987793,
      "learning_rate": 4.560993975903615e-06,
      "loss": 0.9265,
      "step": 583
    },
    {
      "epoch": 0.35180722891566263,
      "grad_norm": 0.9919202923774719,
      "learning_rate": 4.5602409638554216e-06,
      "loss": 0.939,
      "step": 584
    },
    {
      "epoch": 0.35240963855421686,
      "grad_norm": 0.9405646920204163,
      "learning_rate": 4.559487951807229e-06,
      "loss": 0.9392,
      "step": 585
    },
    {
      "epoch": 0.3530120481927711,
      "grad_norm": 0.9683030843734741,
      "learning_rate": 4.558734939759036e-06,
      "loss": 0.9401,
      "step": 586
    },
    {
      "epoch": 0.3536144578313253,
      "grad_norm": 0.9618101119995117,
      "learning_rate": 4.557981927710844e-06,
      "loss": 0.9485,
      "step": 587
    },
    {
      "epoch": 0.3542168674698795,
      "grad_norm": 0.988267183303833,
      "learning_rate": 4.557228915662651e-06,
      "loss": 0.9813,
      "step": 588
    },
    {
      "epoch": 0.35481927710843375,
      "grad_norm": 0.9834212064743042,
      "learning_rate": 4.556475903614459e-06,
      "loss": 0.9445,
      "step": 589
    },
    {
      "epoch": 0.35542168674698793,
      "grad_norm": 0.9508017897605896,
      "learning_rate": 4.555722891566266e-06,
      "loss": 0.9281,
      "step": 590
    },
    {
      "epoch": 0.35602409638554217,
      "grad_norm": 1.004608154296875,
      "learning_rate": 4.5549698795180726e-06,
      "loss": 0.9604,
      "step": 591
    },
    {
      "epoch": 0.3566265060240964,
      "grad_norm": 1.0016077756881714,
      "learning_rate": 4.55421686746988e-06,
      "loss": 0.9093,
      "step": 592
    },
    {
      "epoch": 0.3572289156626506,
      "grad_norm": 0.9390355348587036,
      "learning_rate": 4.553463855421687e-06,
      "loss": 0.9473,
      "step": 593
    },
    {
      "epoch": 0.3578313253012048,
      "grad_norm": 1.0279744863510132,
      "learning_rate": 4.552710843373494e-06,
      "loss": 0.9234,
      "step": 594
    },
    {
      "epoch": 0.35843373493975905,
      "grad_norm": 1.098037838935852,
      "learning_rate": 4.551957831325302e-06,
      "loss": 0.874,
      "step": 595
    },
    {
      "epoch": 0.35903614457831323,
      "grad_norm": 0.9620440602302551,
      "learning_rate": 4.551204819277109e-06,
      "loss": 0.8961,
      "step": 596
    },
    {
      "epoch": 0.35963855421686747,
      "grad_norm": 0.962898850440979,
      "learning_rate": 4.550451807228916e-06,
      "loss": 0.9264,
      "step": 597
    },
    {
      "epoch": 0.3602409638554217,
      "grad_norm": 1.0518107414245605,
      "learning_rate": 4.549698795180723e-06,
      "loss": 0.9111,
      "step": 598
    },
    {
      "epoch": 0.3608433734939759,
      "grad_norm": 0.969085693359375,
      "learning_rate": 4.5489457831325305e-06,
      "loss": 0.8656,
      "step": 599
    },
    {
      "epoch": 0.3614457831325301,
      "grad_norm": 1.0729764699935913,
      "learning_rate": 4.5481927710843374e-06,
      "loss": 0.8835,
      "step": 600
    },
    {
      "epoch": 0.36204819277108435,
      "grad_norm": 0.9866555333137512,
      "learning_rate": 4.547439759036145e-06,
      "loss": 0.9002,
      "step": 601
    },
    {
      "epoch": 0.36265060240963853,
      "grad_norm": 0.9489277005195618,
      "learning_rate": 4.546686746987952e-06,
      "loss": 0.9146,
      "step": 602
    },
    {
      "epoch": 0.36325301204819277,
      "grad_norm": 0.9685836434364319,
      "learning_rate": 4.545933734939759e-06,
      "loss": 0.8984,
      "step": 603
    },
    {
      "epoch": 0.363855421686747,
      "grad_norm": 1.012414574623108,
      "learning_rate": 4.545180722891567e-06,
      "loss": 0.8998,
      "step": 604
    },
    {
      "epoch": 0.3644578313253012,
      "grad_norm": 0.9283714890480042,
      "learning_rate": 4.544427710843374e-06,
      "loss": 0.9173,
      "step": 605
    },
    {
      "epoch": 0.3650602409638554,
      "grad_norm": 1.0342031717300415,
      "learning_rate": 4.5436746987951815e-06,
      "loss": 0.8984,
      "step": 606
    },
    {
      "epoch": 0.36566265060240966,
      "grad_norm": 1.0203651189804077,
      "learning_rate": 4.5429216867469885e-06,
      "loss": 0.8753,
      "step": 607
    },
    {
      "epoch": 0.36626506024096384,
      "grad_norm": 0.9535887241363525,
      "learning_rate": 4.542168674698795e-06,
      "loss": 0.8502,
      "step": 608
    },
    {
      "epoch": 0.36686746987951807,
      "grad_norm": 0.9617121815681458,
      "learning_rate": 4.541415662650603e-06,
      "loss": 0.8422,
      "step": 609
    },
    {
      "epoch": 0.3674698795180723,
      "grad_norm": 1.1295785903930664,
      "learning_rate": 4.54066265060241e-06,
      "loss": 0.8227,
      "step": 610
    },
    {
      "epoch": 0.3680722891566265,
      "grad_norm": 0.9491984844207764,
      "learning_rate": 4.539909638554217e-06,
      "loss": 0.8487,
      "step": 611
    },
    {
      "epoch": 0.3686746987951807,
      "grad_norm": 0.9706175923347473,
      "learning_rate": 4.539156626506025e-06,
      "loss": 0.8319,
      "step": 612
    },
    {
      "epoch": 0.36927710843373496,
      "grad_norm": 0.919400691986084,
      "learning_rate": 4.538403614457832e-06,
      "loss": 0.8632,
      "step": 613
    },
    {
      "epoch": 0.36987951807228914,
      "grad_norm": 0.9322134852409363,
      "learning_rate": 4.537650602409639e-06,
      "loss": 0.8609,
      "step": 614
    },
    {
      "epoch": 0.3704819277108434,
      "grad_norm": 0.970780074596405,
      "learning_rate": 4.5368975903614455e-06,
      "loss": 0.8526,
      "step": 615
    },
    {
      "epoch": 0.3710843373493976,
      "grad_norm": 0.9999784827232361,
      "learning_rate": 4.536144578313253e-06,
      "loss": 0.863,
      "step": 616
    },
    {
      "epoch": 0.3716867469879518,
      "grad_norm": 0.957375168800354,
      "learning_rate": 4.53539156626506e-06,
      "loss": 0.8338,
      "step": 617
    },
    {
      "epoch": 0.372289156626506,
      "grad_norm": 0.9888643026351929,
      "learning_rate": 4.534638554216868e-06,
      "loss": 0.8307,
      "step": 618
    },
    {
      "epoch": 0.37289156626506026,
      "grad_norm": 1.1285840272903442,
      "learning_rate": 4.533885542168675e-06,
      "loss": 0.8275,
      "step": 619
    },
    {
      "epoch": 0.37349397590361444,
      "grad_norm": 0.9737631678581238,
      "learning_rate": 4.533132530120482e-06,
      "loss": 0.8364,
      "step": 620
    },
    {
      "epoch": 0.3740963855421687,
      "grad_norm": 1.0187486410140991,
      "learning_rate": 4.53237951807229e-06,
      "loss": 0.8101,
      "step": 621
    },
    {
      "epoch": 0.3746987951807229,
      "grad_norm": 1.1224439144134521,
      "learning_rate": 4.5316265060240966e-06,
      "loss": 0.8386,
      "step": 622
    },
    {
      "epoch": 0.3753012048192771,
      "grad_norm": 1.0057836771011353,
      "learning_rate": 4.530873493975904e-06,
      "loss": 0.8125,
      "step": 623
    },
    {
      "epoch": 0.3759036144578313,
      "grad_norm": 0.9241012334823608,
      "learning_rate": 4.530120481927711e-06,
      "loss": 0.7912,
      "step": 624
    },
    {
      "epoch": 0.37650602409638556,
      "grad_norm": 1.0259642601013184,
      "learning_rate": 4.529367469879519e-06,
      "loss": 0.8048,
      "step": 625
    },
    {
      "epoch": 0.37710843373493974,
      "grad_norm": 0.9782875776290894,
      "learning_rate": 4.528614457831326e-06,
      "loss": 0.797,
      "step": 626
    },
    {
      "epoch": 0.377710843373494,
      "grad_norm": 0.9677438139915466,
      "learning_rate": 4.527861445783133e-06,
      "loss": 0.8065,
      "step": 627
    },
    {
      "epoch": 0.3783132530120482,
      "grad_norm": 1.181806206703186,
      "learning_rate": 4.527108433734941e-06,
      "loss": 0.8327,
      "step": 628
    },
    {
      "epoch": 0.3789156626506024,
      "grad_norm": 0.9669102430343628,
      "learning_rate": 4.526355421686748e-06,
      "loss": 0.8121,
      "step": 629
    },
    {
      "epoch": 0.3795180722891566,
      "grad_norm": 1.0070346593856812,
      "learning_rate": 4.5256024096385545e-06,
      "loss": 0.8125,
      "step": 630
    },
    {
      "epoch": 0.38012048192771086,
      "grad_norm": 0.9802150130271912,
      "learning_rate": 4.5248493975903614e-06,
      "loss": 0.798,
      "step": 631
    },
    {
      "epoch": 0.38072289156626504,
      "grad_norm": 0.9939547181129456,
      "learning_rate": 4.524096385542169e-06,
      "loss": 0.7678,
      "step": 632
    },
    {
      "epoch": 0.3813253012048193,
      "grad_norm": 0.9938790798187256,
      "learning_rate": 4.523343373493976e-06,
      "loss": 0.7828,
      "step": 633
    },
    {
      "epoch": 0.3819277108433735,
      "grad_norm": 0.9847097992897034,
      "learning_rate": 4.522590361445783e-06,
      "loss": 0.7516,
      "step": 634
    },
    {
      "epoch": 0.3825301204819277,
      "grad_norm": 1.0515861511230469,
      "learning_rate": 4.521837349397591e-06,
      "loss": 0.7748,
      "step": 635
    },
    {
      "epoch": 0.38313253012048193,
      "grad_norm": 1.0002471208572388,
      "learning_rate": 4.521084337349398e-06,
      "loss": 0.781,
      "step": 636
    },
    {
      "epoch": 0.38373493975903616,
      "grad_norm": 1.0326029062271118,
      "learning_rate": 4.5203313253012055e-06,
      "loss": 0.7551,
      "step": 637
    },
    {
      "epoch": 0.38433734939759034,
      "grad_norm": 1.0850296020507812,
      "learning_rate": 4.5195783132530124e-06,
      "loss": 0.7555,
      "step": 638
    },
    {
      "epoch": 0.3849397590361446,
      "grad_norm": 1.0035778284072876,
      "learning_rate": 4.518825301204819e-06,
      "loss": 0.7601,
      "step": 639
    },
    {
      "epoch": 0.3855421686746988,
      "grad_norm": 0.9963601231575012,
      "learning_rate": 4.518072289156627e-06,
      "loss": 0.7613,
      "step": 640
    },
    {
      "epoch": 0.386144578313253,
      "grad_norm": 1.0431171655654907,
      "learning_rate": 4.517319277108434e-06,
      "loss": 0.7854,
      "step": 641
    },
    {
      "epoch": 0.38674698795180723,
      "grad_norm": 0.9927381873130798,
      "learning_rate": 4.516566265060242e-06,
      "loss": 0.7691,
      "step": 642
    },
    {
      "epoch": 0.38734939759036147,
      "grad_norm": 1.0342531204223633,
      "learning_rate": 4.515813253012049e-06,
      "loss": 0.7544,
      "step": 643
    },
    {
      "epoch": 0.38795180722891565,
      "grad_norm": 1.0149853229522705,
      "learning_rate": 4.515060240963856e-06,
      "loss": 0.7598,
      "step": 644
    },
    {
      "epoch": 0.3885542168674699,
      "grad_norm": 0.9952117800712585,
      "learning_rate": 4.5143072289156635e-06,
      "loss": 0.7943,
      "step": 645
    },
    {
      "epoch": 0.3891566265060241,
      "grad_norm": 0.9949886798858643,
      "learning_rate": 4.51355421686747e-06,
      "loss": 0.7551,
      "step": 646
    },
    {
      "epoch": 0.3897590361445783,
      "grad_norm": 1.086167573928833,
      "learning_rate": 4.512801204819277e-06,
      "loss": 0.741,
      "step": 647
    },
    {
      "epoch": 0.39036144578313253,
      "grad_norm": 1.1988611221313477,
      "learning_rate": 4.512048192771084e-06,
      "loss": 0.7565,
      "step": 648
    },
    {
      "epoch": 0.39096385542168677,
      "grad_norm": 1.0323466062545776,
      "learning_rate": 4.511295180722892e-06,
      "loss": 0.7126,
      "step": 649
    },
    {
      "epoch": 0.39156626506024095,
      "grad_norm": 0.9905972480773926,
      "learning_rate": 4.510542168674699e-06,
      "loss": 0.7752,
      "step": 650
    },
    {
      "epoch": 0.3921686746987952,
      "grad_norm": 0.984609842300415,
      "learning_rate": 4.509789156626506e-06,
      "loss": 0.74,
      "step": 651
    },
    {
      "epoch": 0.3927710843373494,
      "grad_norm": 1.0333820581436157,
      "learning_rate": 4.509036144578314e-06,
      "loss": 0.7098,
      "step": 652
    },
    {
      "epoch": 0.3933734939759036,
      "grad_norm": 1.0306119918823242,
      "learning_rate": 4.5082831325301206e-06,
      "loss": 0.7288,
      "step": 653
    },
    {
      "epoch": 0.39397590361445783,
      "grad_norm": 0.9868487119674683,
      "learning_rate": 4.507530120481928e-06,
      "loss": 0.7509,
      "step": 654
    },
    {
      "epoch": 0.39457831325301207,
      "grad_norm": 0.9456450939178467,
      "learning_rate": 4.506777108433735e-06,
      "loss": 0.7322,
      "step": 655
    },
    {
      "epoch": 0.39518072289156625,
      "grad_norm": 1.1040544509887695,
      "learning_rate": 4.506024096385542e-06,
      "loss": 0.6939,
      "step": 656
    },
    {
      "epoch": 0.3957831325301205,
      "grad_norm": 1.0201845169067383,
      "learning_rate": 4.50527108433735e-06,
      "loss": 0.7019,
      "step": 657
    },
    {
      "epoch": 0.3963855421686747,
      "grad_norm": 1.083809733390808,
      "learning_rate": 4.504518072289157e-06,
      "loss": 0.7379,
      "step": 658
    },
    {
      "epoch": 0.3969879518072289,
      "grad_norm": 0.976912796497345,
      "learning_rate": 4.503765060240965e-06,
      "loss": 0.7122,
      "step": 659
    },
    {
      "epoch": 0.39759036144578314,
      "grad_norm": 0.9991454482078552,
      "learning_rate": 4.5030120481927716e-06,
      "loss": 0.7655,
      "step": 660
    },
    {
      "epoch": 0.39819277108433737,
      "grad_norm": 0.9785576462745667,
      "learning_rate": 4.502259036144579e-06,
      "loss": 0.7211,
      "step": 661
    },
    {
      "epoch": 0.39879518072289155,
      "grad_norm": 1.0570738315582275,
      "learning_rate": 4.501506024096386e-06,
      "loss": 0.7336,
      "step": 662
    },
    {
      "epoch": 0.3993975903614458,
      "grad_norm": 0.9458779096603394,
      "learning_rate": 4.500753012048193e-06,
      "loss": 0.7477,
      "step": 663
    },
    {
      "epoch": 0.4,
      "grad_norm": 0.9830377101898193,
      "learning_rate": 4.5e-06,
      "loss": 0.7287,
      "step": 664
    },
    {
      "epoch": 0.4006024096385542,
      "grad_norm": 1.0244436264038086,
      "learning_rate": 4.499246987951808e-06,
      "loss": 0.7612,
      "step": 665
    },
    {
      "epoch": 0.40120481927710844,
      "grad_norm": 0.9554290175437927,
      "learning_rate": 4.498493975903615e-06,
      "loss": 0.7803,
      "step": 666
    },
    {
      "epoch": 0.4018072289156627,
      "grad_norm": 0.877579391002655,
      "learning_rate": 4.497740963855422e-06,
      "loss": 0.7402,
      "step": 667
    },
    {
      "epoch": 0.40240963855421685,
      "grad_norm": 0.9879792332649231,
      "learning_rate": 4.496987951807229e-06,
      "loss": 0.758,
      "step": 668
    },
    {
      "epoch": 0.4030120481927711,
      "grad_norm": 1.0020405054092407,
      "learning_rate": 4.4962349397590364e-06,
      "loss": 0.7167,
      "step": 669
    },
    {
      "epoch": 0.4036144578313253,
      "grad_norm": 0.8506149649620056,
      "learning_rate": 4.495481927710843e-06,
      "loss": 0.7331,
      "step": 670
    },
    {
      "epoch": 0.4042168674698795,
      "grad_norm": 0.8942980170249939,
      "learning_rate": 4.494728915662651e-06,
      "loss": 0.6974,
      "step": 671
    },
    {
      "epoch": 0.40481927710843374,
      "grad_norm": 1.0375481843948364,
      "learning_rate": 4.493975903614458e-06,
      "loss": 0.6814,
      "step": 672
    },
    {
      "epoch": 0.405421686746988,
      "grad_norm": 0.9320423007011414,
      "learning_rate": 4.493222891566266e-06,
      "loss": 0.7214,
      "step": 673
    },
    {
      "epoch": 0.40602409638554215,
      "grad_norm": 0.9550923705101013,
      "learning_rate": 4.492469879518073e-06,
      "loss": 0.7069,
      "step": 674
    },
    {
      "epoch": 0.4066265060240964,
      "grad_norm": 0.9613714218139648,
      "learning_rate": 4.49171686746988e-06,
      "loss": 0.6746,
      "step": 675
    },
    {
      "epoch": 0.4072289156626506,
      "grad_norm": 0.9653357267379761,
      "learning_rate": 4.4909638554216874e-06,
      "loss": 0.7179,
      "step": 676
    },
    {
      "epoch": 0.4078313253012048,
      "grad_norm": 0.9436835050582886,
      "learning_rate": 4.490210843373494e-06,
      "loss": 0.6853,
      "step": 677
    },
    {
      "epoch": 0.40843373493975904,
      "grad_norm": 0.8814073204994202,
      "learning_rate": 4.489457831325302e-06,
      "loss": 0.6808,
      "step": 678
    },
    {
      "epoch": 0.4090361445783133,
      "grad_norm": 1.0435870885849,
      "learning_rate": 4.488704819277109e-06,
      "loss": 0.7029,
      "step": 679
    },
    {
      "epoch": 0.40963855421686746,
      "grad_norm": 1.0130159854888916,
      "learning_rate": 4.487951807228916e-06,
      "loss": 0.6854,
      "step": 680
    },
    {
      "epoch": 0.4102409638554217,
      "grad_norm": 0.9990358352661133,
      "learning_rate": 4.487198795180723e-06,
      "loss": 0.6871,
      "step": 681
    },
    {
      "epoch": 0.4108433734939759,
      "grad_norm": 1.0080596208572388,
      "learning_rate": 4.486445783132531e-06,
      "loss": 0.6812,
      "step": 682
    },
    {
      "epoch": 0.4114457831325301,
      "grad_norm": 0.9966175556182861,
      "learning_rate": 4.485692771084338e-06,
      "loss": 0.692,
      "step": 683
    },
    {
      "epoch": 0.41204819277108434,
      "grad_norm": 1.0099101066589355,
      "learning_rate": 4.4849397590361445e-06,
      "loss": 0.7005,
      "step": 684
    },
    {
      "epoch": 0.4126506024096386,
      "grad_norm": 0.8783646821975708,
      "learning_rate": 4.484186746987952e-06,
      "loss": 0.6659,
      "step": 685
    },
    {
      "epoch": 0.41325301204819276,
      "grad_norm": 0.9848851561546326,
      "learning_rate": 4.483433734939759e-06,
      "loss": 0.7148,
      "step": 686
    },
    {
      "epoch": 0.413855421686747,
      "grad_norm": 0.9291229248046875,
      "learning_rate": 4.482680722891566e-06,
      "loss": 0.6947,
      "step": 687
    },
    {
      "epoch": 0.41445783132530123,
      "grad_norm": 0.9552850127220154,
      "learning_rate": 4.481927710843374e-06,
      "loss": 0.6914,
      "step": 688
    },
    {
      "epoch": 0.4150602409638554,
      "grad_norm": 1.6165939569473267,
      "learning_rate": 4.481174698795181e-06,
      "loss": 0.6872,
      "step": 689
    },
    {
      "epoch": 0.41566265060240964,
      "grad_norm": 0.9408247470855713,
      "learning_rate": 4.480421686746989e-06,
      "loss": 0.6915,
      "step": 690
    },
    {
      "epoch": 0.4162650602409639,
      "grad_norm": 0.9832175374031067,
      "learning_rate": 4.4796686746987956e-06,
      "loss": 0.6531,
      "step": 691
    },
    {
      "epoch": 0.41686746987951806,
      "grad_norm": 0.9320594668388367,
      "learning_rate": 4.4789156626506025e-06,
      "loss": 0.6568,
      "step": 692
    },
    {
      "epoch": 0.4174698795180723,
      "grad_norm": 1.1095316410064697,
      "learning_rate": 4.47816265060241e-06,
      "loss": 0.6633,
      "step": 693
    },
    {
      "epoch": 0.41807228915662653,
      "grad_norm": 0.9405596256256104,
      "learning_rate": 4.477409638554217e-06,
      "loss": 0.6959,
      "step": 694
    },
    {
      "epoch": 0.4186746987951807,
      "grad_norm": 0.9901683926582336,
      "learning_rate": 4.476656626506025e-06,
      "loss": 0.6622,
      "step": 695
    },
    {
      "epoch": 0.41927710843373495,
      "grad_norm": 1.0008043050765991,
      "learning_rate": 4.475903614457832e-06,
      "loss": 0.6214,
      "step": 696
    },
    {
      "epoch": 0.4198795180722892,
      "grad_norm": 0.9779519438743591,
      "learning_rate": 4.475150602409639e-06,
      "loss": 0.674,
      "step": 697
    },
    {
      "epoch": 0.42048192771084336,
      "grad_norm": 0.9066988229751587,
      "learning_rate": 4.4743975903614466e-06,
      "loss": 0.6495,
      "step": 698
    },
    {
      "epoch": 0.4210843373493976,
      "grad_norm": 1.0088273286819458,
      "learning_rate": 4.4736445783132535e-06,
      "loss": 0.6462,
      "step": 699
    },
    {
      "epoch": 0.42168674698795183,
      "grad_norm": 0.9917451739311218,
      "learning_rate": 4.47289156626506e-06,
      "loss": 0.6373,
      "step": 700
    },
    {
      "epoch": 0.422289156626506,
      "grad_norm": 0.9690353870391846,
      "learning_rate": 4.472138554216867e-06,
      "loss": 0.6795,
      "step": 701
    },
    {
      "epoch": 0.42289156626506025,
      "grad_norm": 1.0181070566177368,
      "learning_rate": 4.471385542168675e-06,
      "loss": 0.6278,
      "step": 702
    },
    {
      "epoch": 0.4234939759036145,
      "grad_norm": 0.9530130624771118,
      "learning_rate": 4.470632530120482e-06,
      "loss": 0.6549,
      "step": 703
    },
    {
      "epoch": 0.42409638554216866,
      "grad_norm": 0.9008291959762573,
      "learning_rate": 4.469879518072289e-06,
      "loss": 0.6507,
      "step": 704
    },
    {
      "epoch": 0.4246987951807229,
      "grad_norm": 0.9395440220832825,
      "learning_rate": 4.469126506024097e-06,
      "loss": 0.6724,
      "step": 705
    },
    {
      "epoch": 0.42530120481927713,
      "grad_norm": 1.0078351497650146,
      "learning_rate": 4.468373493975904e-06,
      "loss": 0.6332,
      "step": 706
    },
    {
      "epoch": 0.4259036144578313,
      "grad_norm": 1.0122779607772827,
      "learning_rate": 4.4676204819277114e-06,
      "loss": 0.6802,
      "step": 707
    },
    {
      "epoch": 0.42650602409638555,
      "grad_norm": 0.9692552089691162,
      "learning_rate": 4.466867469879518e-06,
      "loss": 0.6274,
      "step": 708
    },
    {
      "epoch": 0.4271084337349398,
      "grad_norm": 0.943323016166687,
      "learning_rate": 4.466114457831326e-06,
      "loss": 0.6186,
      "step": 709
    },
    {
      "epoch": 0.42771084337349397,
      "grad_norm": 1.0794533491134644,
      "learning_rate": 4.465361445783133e-06,
      "loss": 0.6631,
      "step": 710
    },
    {
      "epoch": 0.4283132530120482,
      "grad_norm": 0.9130005240440369,
      "learning_rate": 4.46460843373494e-06,
      "loss": 0.6255,
      "step": 711
    },
    {
      "epoch": 0.42891566265060244,
      "grad_norm": 0.9307296276092529,
      "learning_rate": 4.463855421686748e-06,
      "loss": 0.6364,
      "step": 712
    },
    {
      "epoch": 0.4295180722891566,
      "grad_norm": 0.9065305590629578,
      "learning_rate": 4.463102409638555e-06,
      "loss": 0.6246,
      "step": 713
    },
    {
      "epoch": 0.43012048192771085,
      "grad_norm": 0.9677712321281433,
      "learning_rate": 4.462349397590362e-06,
      "loss": 0.6194,
      "step": 714
    },
    {
      "epoch": 0.4307228915662651,
      "grad_norm": 0.8950340747833252,
      "learning_rate": 4.461596385542169e-06,
      "loss": 0.6367,
      "step": 715
    },
    {
      "epoch": 0.43132530120481927,
      "grad_norm": 0.9786390662193298,
      "learning_rate": 4.460843373493976e-06,
      "loss": 0.5931,
      "step": 716
    },
    {
      "epoch": 0.4319277108433735,
      "grad_norm": 1.0250036716461182,
      "learning_rate": 4.460090361445783e-06,
      "loss": 0.6028,
      "step": 717
    },
    {
      "epoch": 0.43253012048192774,
      "grad_norm": 0.937761127948761,
      "learning_rate": 4.45933734939759e-06,
      "loss": 0.5555,
      "step": 718
    },
    {
      "epoch": 0.4331325301204819,
      "grad_norm": 0.9779691696166992,
      "learning_rate": 4.458584337349398e-06,
      "loss": 0.6021,
      "step": 719
    },
    {
      "epoch": 0.43373493975903615,
      "grad_norm": 0.9344915747642517,
      "learning_rate": 4.457831325301205e-06,
      "loss": 0.6569,
      "step": 720
    },
    {
      "epoch": 0.4343373493975904,
      "grad_norm": 0.9954251646995544,
      "learning_rate": 4.457078313253013e-06,
      "loss": 0.6174,
      "step": 721
    },
    {
      "epoch": 0.43493975903614457,
      "grad_norm": 0.8516242504119873,
      "learning_rate": 4.4563253012048195e-06,
      "loss": 0.6418,
      "step": 722
    },
    {
      "epoch": 0.4355421686746988,
      "grad_norm": 0.9169853329658508,
      "learning_rate": 4.4555722891566265e-06,
      "loss": 0.5812,
      "step": 723
    },
    {
      "epoch": 0.43614457831325304,
      "grad_norm": 1.0424436330795288,
      "learning_rate": 4.454819277108434e-06,
      "loss": 0.6382,
      "step": 724
    },
    {
      "epoch": 0.4367469879518072,
      "grad_norm": 0.99777752161026,
      "learning_rate": 4.454066265060241e-06,
      "loss": 0.578,
      "step": 725
    },
    {
      "epoch": 0.43734939759036146,
      "grad_norm": 0.920998215675354,
      "learning_rate": 4.453313253012049e-06,
      "loss": 0.5899,
      "step": 726
    },
    {
      "epoch": 0.43795180722891563,
      "grad_norm": 0.9298461675643921,
      "learning_rate": 4.452560240963856e-06,
      "loss": 0.6322,
      "step": 727
    },
    {
      "epoch": 0.43855421686746987,
      "grad_norm": 0.9972163438796997,
      "learning_rate": 4.451807228915663e-06,
      "loss": 0.6032,
      "step": 728
    },
    {
      "epoch": 0.4391566265060241,
      "grad_norm": 0.9436771869659424,
      "learning_rate": 4.4510542168674706e-06,
      "loss": 0.5473,
      "step": 729
    },
    {
      "epoch": 0.4397590361445783,
      "grad_norm": 1.0062204599380493,
      "learning_rate": 4.4503012048192775e-06,
      "loss": 0.5798,
      "step": 730
    },
    {
      "epoch": 0.4403614457831325,
      "grad_norm": 0.9378586411476135,
      "learning_rate": 4.449548192771085e-06,
      "loss": 0.5944,
      "step": 731
    },
    {
      "epoch": 0.44096385542168676,
      "grad_norm": 1.0160906314849854,
      "learning_rate": 4.448795180722892e-06,
      "loss": 0.5631,
      "step": 732
    },
    {
      "epoch": 0.44156626506024094,
      "grad_norm": 0.9789966940879822,
      "learning_rate": 4.448042168674699e-06,
      "loss": 0.6433,
      "step": 733
    },
    {
      "epoch": 0.44216867469879517,
      "grad_norm": 0.9005126357078552,
      "learning_rate": 4.447289156626506e-06,
      "loss": 0.585,
      "step": 734
    },
    {
      "epoch": 0.4427710843373494,
      "grad_norm": 0.9871088862419128,
      "learning_rate": 4.446536144578314e-06,
      "loss": 0.5834,
      "step": 735
    },
    {
      "epoch": 0.4433734939759036,
      "grad_norm": 1.0006294250488281,
      "learning_rate": 4.445783132530121e-06,
      "loss": 0.5742,
      "step": 736
    },
    {
      "epoch": 0.4439759036144578,
      "grad_norm": 0.889438271522522,
      "learning_rate": 4.445030120481928e-06,
      "loss": 0.642,
      "step": 737
    },
    {
      "epoch": 0.44457831325301206,
      "grad_norm": 0.8629721999168396,
      "learning_rate": 4.4442771084337354e-06,
      "loss": 0.5846,
      "step": 738
    },
    {
      "epoch": 0.44518072289156624,
      "grad_norm": 1.0041207075119019,
      "learning_rate": 4.443524096385542e-06,
      "loss": 0.5977,
      "step": 739
    },
    {
      "epoch": 0.4457831325301205,
      "grad_norm": 0.9290510416030884,
      "learning_rate": 4.442771084337349e-06,
      "loss": 0.5622,
      "step": 740
    },
    {
      "epoch": 0.4463855421686747,
      "grad_norm": 0.9912819266319275,
      "learning_rate": 4.442018072289157e-06,
      "loss": 0.5261,
      "step": 741
    },
    {
      "epoch": 0.4469879518072289,
      "grad_norm": 0.9195947051048279,
      "learning_rate": 4.441265060240964e-06,
      "loss": 0.5443,
      "step": 742
    },
    {
      "epoch": 0.4475903614457831,
      "grad_norm": 0.8996024131774902,
      "learning_rate": 4.440512048192772e-06,
      "loss": 0.5504,
      "step": 743
    },
    {
      "epoch": 0.44819277108433736,
      "grad_norm": 0.945646345615387,
      "learning_rate": 4.439759036144579e-06,
      "loss": 0.5786,
      "step": 744
    },
    {
      "epoch": 0.44879518072289154,
      "grad_norm": 0.9238427877426147,
      "learning_rate": 4.4390060240963864e-06,
      "loss": 0.5495,
      "step": 745
    },
    {
      "epoch": 0.4493975903614458,
      "grad_norm": 1.047765851020813,
      "learning_rate": 4.438253012048193e-06,
      "loss": 0.5739,
      "step": 746
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9090179800987244,
      "learning_rate": 4.4375e-06,
      "loss": 0.597,
      "step": 747
    },
    {
      "epoch": 0.4506024096385542,
      "grad_norm": 0.9197324514389038,
      "learning_rate": 4.436746987951808e-06,
      "loss": 0.5811,
      "step": 748
    },
    {
      "epoch": 0.4512048192771084,
      "grad_norm": 0.9030837416648865,
      "learning_rate": 4.435993975903615e-06,
      "loss": 0.5578,
      "step": 749
    },
    {
      "epoch": 0.45180722891566266,
      "grad_norm": 0.9160696268081665,
      "learning_rate": 4.435240963855422e-06,
      "loss": 0.4974,
      "step": 750
    },
    {
      "epoch": 0.45240963855421684,
      "grad_norm": 0.9278409481048584,
      "learning_rate": 4.434487951807229e-06,
      "loss": 0.5429,
      "step": 751
    },
    {
      "epoch": 0.4530120481927711,
      "grad_norm": 0.9684813618659973,
      "learning_rate": 4.433734939759037e-06,
      "loss": 0.5843,
      "step": 752
    },
    {
      "epoch": 0.4536144578313253,
      "grad_norm": 0.8796373605728149,
      "learning_rate": 4.4329819277108435e-06,
      "loss": 0.5586,
      "step": 753
    },
    {
      "epoch": 0.4542168674698795,
      "grad_norm": 0.9431066513061523,
      "learning_rate": 4.4322289156626505e-06,
      "loss": 0.513,
      "step": 754
    },
    {
      "epoch": 0.45481927710843373,
      "grad_norm": 0.9364920258522034,
      "learning_rate": 4.431475903614458e-06,
      "loss": 0.6405,
      "step": 755
    },
    {
      "epoch": 0.45542168674698796,
      "grad_norm": 0.860787570476532,
      "learning_rate": 4.430722891566265e-06,
      "loss": 0.5389,
      "step": 756
    },
    {
      "epoch": 0.45602409638554214,
      "grad_norm": 0.8944628238677979,
      "learning_rate": 4.429969879518073e-06,
      "loss": 0.5775,
      "step": 757
    },
    {
      "epoch": 0.4566265060240964,
      "grad_norm": 0.9040141701698303,
      "learning_rate": 4.42921686746988e-06,
      "loss": 0.5221,
      "step": 758
    },
    {
      "epoch": 0.4572289156626506,
      "grad_norm": 1.1182328462600708,
      "learning_rate": 4.428463855421687e-06,
      "loss": 0.5385,
      "step": 759
    },
    {
      "epoch": 0.4578313253012048,
      "grad_norm": 0.9699077606201172,
      "learning_rate": 4.4277108433734945e-06,
      "loss": 0.5664,
      "step": 760
    },
    {
      "epoch": 0.45843373493975903,
      "grad_norm": 0.811103105545044,
      "learning_rate": 4.4269578313253015e-06,
      "loss": 0.547,
      "step": 761
    },
    {
      "epoch": 0.45903614457831327,
      "grad_norm": 0.8763119578361511,
      "learning_rate": 4.426204819277109e-06,
      "loss": 0.5639,
      "step": 762
    },
    {
      "epoch": 0.45963855421686745,
      "grad_norm": 1.029720664024353,
      "learning_rate": 4.425451807228916e-06,
      "loss": 0.515,
      "step": 763
    },
    {
      "epoch": 0.4602409638554217,
      "grad_norm": 0.9936409592628479,
      "learning_rate": 4.424698795180723e-06,
      "loss": 0.5859,
      "step": 764
    },
    {
      "epoch": 0.4608433734939759,
      "grad_norm": 0.9107235074043274,
      "learning_rate": 4.423945783132531e-06,
      "loss": 0.5077,
      "step": 765
    },
    {
      "epoch": 0.4614457831325301,
      "grad_norm": 0.9016269445419312,
      "learning_rate": 4.423192771084338e-06,
      "loss": 0.5535,
      "step": 766
    },
    {
      "epoch": 0.46204819277108433,
      "grad_norm": 0.9680023789405823,
      "learning_rate": 4.422439759036145e-06,
      "loss": 0.5329,
      "step": 767
    },
    {
      "epoch": 0.46265060240963857,
      "grad_norm": 0.9125257730484009,
      "learning_rate": 4.4216867469879525e-06,
      "loss": 0.5685,
      "step": 768
    },
    {
      "epoch": 0.46325301204819275,
      "grad_norm": 0.8962112665176392,
      "learning_rate": 4.420933734939759e-06,
      "loss": 0.5456,
      "step": 769
    },
    {
      "epoch": 0.463855421686747,
      "grad_norm": 1.1933462619781494,
      "learning_rate": 4.420180722891566e-06,
      "loss": 0.5458,
      "step": 770
    },
    {
      "epoch": 0.4644578313253012,
      "grad_norm": 0.9724375605583191,
      "learning_rate": 4.419427710843373e-06,
      "loss": 0.5425,
      "step": 771
    },
    {
      "epoch": 0.4650602409638554,
      "grad_norm": 0.8712671995162964,
      "learning_rate": 4.418674698795181e-06,
      "loss": 0.5442,
      "step": 772
    },
    {
      "epoch": 0.46566265060240963,
      "grad_norm": 0.9080502986907959,
      "learning_rate": 4.417921686746988e-06,
      "loss": 0.51,
      "step": 773
    },
    {
      "epoch": 0.46626506024096387,
      "grad_norm": 0.9123330116271973,
      "learning_rate": 4.417168674698796e-06,
      "loss": 0.4986,
      "step": 774
    },
    {
      "epoch": 0.46686746987951805,
      "grad_norm": 0.9079879522323608,
      "learning_rate": 4.416415662650603e-06,
      "loss": 0.482,
      "step": 775
    },
    {
      "epoch": 0.4674698795180723,
      "grad_norm": 0.8559274077415466,
      "learning_rate": 4.41566265060241e-06,
      "loss": 0.4993,
      "step": 776
    },
    {
      "epoch": 0.4680722891566265,
      "grad_norm": 0.9323950409889221,
      "learning_rate": 4.414909638554217e-06,
      "loss": 0.5288,
      "step": 777
    },
    {
      "epoch": 0.4686746987951807,
      "grad_norm": 0.8708287477493286,
      "learning_rate": 4.414156626506024e-06,
      "loss": 0.5061,
      "step": 778
    },
    {
      "epoch": 0.46927710843373494,
      "grad_norm": 0.871116578578949,
      "learning_rate": 4.413403614457832e-06,
      "loss": 0.4909,
      "step": 779
    },
    {
      "epoch": 0.46987951807228917,
      "grad_norm": 0.8838405013084412,
      "learning_rate": 4.412650602409639e-06,
      "loss": 0.5693,
      "step": 780
    },
    {
      "epoch": 0.47048192771084335,
      "grad_norm": 0.9266073107719421,
      "learning_rate": 4.411897590361447e-06,
      "loss": 0.5046,
      "step": 781
    },
    {
      "epoch": 0.4710843373493976,
      "grad_norm": 0.8655080199241638,
      "learning_rate": 4.411144578313254e-06,
      "loss": 0.4972,
      "step": 782
    },
    {
      "epoch": 0.4716867469879518,
      "grad_norm": 0.9509895443916321,
      "learning_rate": 4.410391566265061e-06,
      "loss": 0.4997,
      "step": 783
    },
    {
      "epoch": 0.472289156626506,
      "grad_norm": 0.8986620903015137,
      "learning_rate": 4.4096385542168675e-06,
      "loss": 0.5084,
      "step": 784
    },
    {
      "epoch": 0.47289156626506024,
      "grad_norm": 0.9372712969779968,
      "learning_rate": 4.408885542168675e-06,
      "loss": 0.4936,
      "step": 785
    },
    {
      "epoch": 0.4734939759036145,
      "grad_norm": 0.8521026372909546,
      "learning_rate": 4.408132530120482e-06,
      "loss": 0.5073,
      "step": 786
    },
    {
      "epoch": 0.47409638554216865,
      "grad_norm": 0.8784803748130798,
      "learning_rate": 4.407379518072289e-06,
      "loss": 0.499,
      "step": 787
    },
    {
      "epoch": 0.4746987951807229,
      "grad_norm": 0.9275217652320862,
      "learning_rate": 4.406626506024096e-06,
      "loss": 0.5246,
      "step": 788
    },
    {
      "epoch": 0.4753012048192771,
      "grad_norm": 0.876923680305481,
      "learning_rate": 4.405873493975904e-06,
      "loss": 0.4873,
      "step": 789
    },
    {
      "epoch": 0.4759036144578313,
      "grad_norm": 0.8721955418586731,
      "learning_rate": 4.405120481927711e-06,
      "loss": 0.4658,
      "step": 790
    },
    {
      "epoch": 0.47650602409638554,
      "grad_norm": 0.8986465334892273,
      "learning_rate": 4.4043674698795185e-06,
      "loss": 0.5235,
      "step": 791
    },
    {
      "epoch": 0.4771084337349398,
      "grad_norm": 0.9452976584434509,
      "learning_rate": 4.4036144578313255e-06,
      "loss": 0.5278,
      "step": 792
    },
    {
      "epoch": 0.47771084337349395,
      "grad_norm": 0.8645633459091187,
      "learning_rate": 4.402861445783133e-06,
      "loss": 0.4777,
      "step": 793
    },
    {
      "epoch": 0.4783132530120482,
      "grad_norm": 0.9630475044250488,
      "learning_rate": 4.40210843373494e-06,
      "loss": 0.5284,
      "step": 794
    },
    {
      "epoch": 0.4789156626506024,
      "grad_norm": 0.8300889134407043,
      "learning_rate": 4.401355421686747e-06,
      "loss": 0.4414,
      "step": 795
    },
    {
      "epoch": 0.4795180722891566,
      "grad_norm": 0.897244393825531,
      "learning_rate": 4.400602409638555e-06,
      "loss": 0.527,
      "step": 796
    },
    {
      "epoch": 0.48012048192771084,
      "grad_norm": 0.9212774038314819,
      "learning_rate": 4.399849397590362e-06,
      "loss": 0.4663,
      "step": 797
    },
    {
      "epoch": 0.4807228915662651,
      "grad_norm": 1.5308340787887573,
      "learning_rate": 4.3990963855421696e-06,
      "loss": 0.554,
      "step": 798
    },
    {
      "epoch": 0.48132530120481926,
      "grad_norm": 1.0316593647003174,
      "learning_rate": 4.3983433734939765e-06,
      "loss": 0.5177,
      "step": 799
    },
    {
      "epoch": 0.4819277108433735,
      "grad_norm": 0.8318576216697693,
      "learning_rate": 4.397590361445783e-06,
      "loss": 0.4574,
      "step": 800
    },
    {
      "epoch": 0.4825301204819277,
      "grad_norm": 0.785359799861908,
      "learning_rate": 4.396837349397591e-06,
      "loss": 0.5224,
      "step": 801
    },
    {
      "epoch": 0.4831325301204819,
      "grad_norm": 0.8361062407493591,
      "learning_rate": 4.396084337349398e-06,
      "loss": 0.4497,
      "step": 802
    },
    {
      "epoch": 0.48373493975903614,
      "grad_norm": 0.900143027305603,
      "learning_rate": 4.395331325301205e-06,
      "loss": 0.465,
      "step": 803
    },
    {
      "epoch": 0.4843373493975904,
      "grad_norm": 0.8827140927314758,
      "learning_rate": 4.394578313253012e-06,
      "loss": 0.4795,
      "step": 804
    },
    {
      "epoch": 0.48493975903614456,
      "grad_norm": 0.8853199481964111,
      "learning_rate": 4.39382530120482e-06,
      "loss": 0.461,
      "step": 805
    },
    {
      "epoch": 0.4855421686746988,
      "grad_norm": 0.8593314290046692,
      "learning_rate": 4.393072289156627e-06,
      "loss": 0.5416,
      "step": 806
    },
    {
      "epoch": 0.48614457831325303,
      "grad_norm": 0.8876661658287048,
      "learning_rate": 4.3923192771084336e-06,
      "loss": 0.5154,
      "step": 807
    },
    {
      "epoch": 0.4867469879518072,
      "grad_norm": 0.8372247815132141,
      "learning_rate": 4.391566265060241e-06,
      "loss": 0.4342,
      "step": 808
    },
    {
      "epoch": 0.48734939759036144,
      "grad_norm": 0.8435972929000854,
      "learning_rate": 4.390813253012048e-06,
      "loss": 0.5251,
      "step": 809
    },
    {
      "epoch": 0.4879518072289157,
      "grad_norm": 0.9273171424865723,
      "learning_rate": 4.390060240963856e-06,
      "loss": 0.4365,
      "step": 810
    },
    {
      "epoch": 0.48855421686746986,
      "grad_norm": 0.903259813785553,
      "learning_rate": 4.389307228915663e-06,
      "loss": 0.4721,
      "step": 811
    },
    {
      "epoch": 0.4891566265060241,
      "grad_norm": 0.8267525434494019,
      "learning_rate": 4.38855421686747e-06,
      "loss": 0.4626,
      "step": 812
    },
    {
      "epoch": 0.48975903614457833,
      "grad_norm": 0.8491689562797546,
      "learning_rate": 4.387801204819278e-06,
      "loss": 0.5043,
      "step": 813
    },
    {
      "epoch": 0.4903614457831325,
      "grad_norm": 0.8502357602119446,
      "learning_rate": 4.387048192771085e-06,
      "loss": 0.4407,
      "step": 814
    },
    {
      "epoch": 0.49096385542168675,
      "grad_norm": 0.8383609652519226,
      "learning_rate": 4.386295180722892e-06,
      "loss": 0.4619,
      "step": 815
    },
    {
      "epoch": 0.491566265060241,
      "grad_norm": 0.9556128978729248,
      "learning_rate": 4.385542168674699e-06,
      "loss": 0.4982,
      "step": 816
    },
    {
      "epoch": 0.49216867469879516,
      "grad_norm": 0.8619638085365295,
      "learning_rate": 4.384789156626506e-06,
      "loss": 0.4701,
      "step": 817
    },
    {
      "epoch": 0.4927710843373494,
      "grad_norm": 0.9183036684989929,
      "learning_rate": 4.384036144578314e-06,
      "loss": 0.5135,
      "step": 818
    },
    {
      "epoch": 0.49337349397590363,
      "grad_norm": 0.8889361619949341,
      "learning_rate": 4.383283132530121e-06,
      "loss": 0.4775,
      "step": 819
    },
    {
      "epoch": 0.4939759036144578,
      "grad_norm": 0.7888558506965637,
      "learning_rate": 4.382530120481928e-06,
      "loss": 0.4469,
      "step": 820
    },
    {
      "epoch": 0.49457831325301205,
      "grad_norm": 0.8945604562759399,
      "learning_rate": 4.381777108433735e-06,
      "loss": 0.4947,
      "step": 821
    },
    {
      "epoch": 0.4951807228915663,
      "grad_norm": 0.9308881163597107,
      "learning_rate": 4.3810240963855425e-06,
      "loss": 0.5346,
      "step": 822
    },
    {
      "epoch": 0.49578313253012046,
      "grad_norm": 0.8991137146949768,
      "learning_rate": 4.3802710843373494e-06,
      "loss": 0.4587,
      "step": 823
    },
    {
      "epoch": 0.4963855421686747,
      "grad_norm": 0.8650689721107483,
      "learning_rate": 4.379518072289156e-06,
      "loss": 0.4449,
      "step": 824
    },
    {
      "epoch": 0.49698795180722893,
      "grad_norm": 0.7826708555221558,
      "learning_rate": 4.378765060240964e-06,
      "loss": 0.4854,
      "step": 825
    },
    {
      "epoch": 0.4975903614457831,
      "grad_norm": 0.846635639667511,
      "learning_rate": 4.378012048192771e-06,
      "loss": 0.5129,
      "step": 826
    },
    {
      "epoch": 0.49819277108433735,
      "grad_norm": 0.839249849319458,
      "learning_rate": 4.377259036144579e-06,
      "loss": 0.4467,
      "step": 827
    },
    {
      "epoch": 0.4987951807228916,
      "grad_norm": 0.8985586166381836,
      "learning_rate": 4.376506024096386e-06,
      "loss": 0.4316,
      "step": 828
    },
    {
      "epoch": 0.49939759036144576,
      "grad_norm": 0.8218884468078613,
      "learning_rate": 4.3757530120481935e-06,
      "loss": 0.4357,
      "step": 829
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.8651209473609924,
      "learning_rate": 4.3750000000000005e-06,
      "loss": 0.4312,
      "step": 830
    },
    {
      "epoch": 0.5006024096385542,
      "grad_norm": 0.8238757252693176,
      "learning_rate": 4.374246987951807e-06,
      "loss": 0.4181,
      "step": 831
    },
    {
      "epoch": 0.5012048192771085,
      "grad_norm": 0.899289608001709,
      "learning_rate": 4.373493975903615e-06,
      "loss": 0.4332,
      "step": 832
    },
    {
      "epoch": 0.5018072289156627,
      "grad_norm": 0.8530382513999939,
      "learning_rate": 4.372740963855422e-06,
      "loss": 0.4145,
      "step": 833
    },
    {
      "epoch": 0.5024096385542168,
      "grad_norm": 0.8259833455085754,
      "learning_rate": 4.37198795180723e-06,
      "loss": 0.449,
      "step": 834
    },
    {
      "epoch": 0.5030120481927711,
      "grad_norm": 0.8372104167938232,
      "learning_rate": 4.371234939759037e-06,
      "loss": 0.4516,
      "step": 835
    },
    {
      "epoch": 0.5036144578313253,
      "grad_norm": 0.8983108997344971,
      "learning_rate": 4.370481927710844e-06,
      "loss": 0.4467,
      "step": 836
    },
    {
      "epoch": 0.5042168674698795,
      "grad_norm": 0.8715597987174988,
      "learning_rate": 4.369728915662651e-06,
      "loss": 0.4118,
      "step": 837
    },
    {
      "epoch": 0.5048192771084338,
      "grad_norm": 0.8441186547279358,
      "learning_rate": 4.368975903614458e-06,
      "loss": 0.4774,
      "step": 838
    },
    {
      "epoch": 0.505421686746988,
      "grad_norm": 0.8388553857803345,
      "learning_rate": 4.368222891566265e-06,
      "loss": 0.4464,
      "step": 839
    },
    {
      "epoch": 0.5060240963855421,
      "grad_norm": 0.7678592801094055,
      "learning_rate": 4.367469879518072e-06,
      "loss": 0.4192,
      "step": 840
    },
    {
      "epoch": 0.5066265060240964,
      "grad_norm": 0.7655641436576843,
      "learning_rate": 4.36671686746988e-06,
      "loss": 0.4317,
      "step": 841
    },
    {
      "epoch": 0.5072289156626506,
      "grad_norm": 0.8410685062408447,
      "learning_rate": 4.365963855421687e-06,
      "loss": 0.4209,
      "step": 842
    },
    {
      "epoch": 0.5078313253012048,
      "grad_norm": 0.8814238905906677,
      "learning_rate": 4.365210843373494e-06,
      "loss": 0.4152,
      "step": 843
    },
    {
      "epoch": 0.5084337349397591,
      "grad_norm": 0.8156286478042603,
      "learning_rate": 4.364457831325302e-06,
      "loss": 0.4294,
      "step": 844
    },
    {
      "epoch": 0.5090361445783133,
      "grad_norm": 0.8003370761871338,
      "learning_rate": 4.3637048192771086e-06,
      "loss": 0.4518,
      "step": 845
    },
    {
      "epoch": 0.5096385542168674,
      "grad_norm": 0.7960193753242493,
      "learning_rate": 4.362951807228916e-06,
      "loss": 0.43,
      "step": 846
    },
    {
      "epoch": 0.5102409638554217,
      "grad_norm": 0.8519753813743591,
      "learning_rate": 4.362198795180723e-06,
      "loss": 0.4401,
      "step": 847
    },
    {
      "epoch": 0.5108433734939759,
      "grad_norm": 0.8265104293823242,
      "learning_rate": 4.361445783132531e-06,
      "loss": 0.4734,
      "step": 848
    },
    {
      "epoch": 0.5114457831325301,
      "grad_norm": 0.8482330441474915,
      "learning_rate": 4.360692771084338e-06,
      "loss": 0.4573,
      "step": 849
    },
    {
      "epoch": 0.5120481927710844,
      "grad_norm": 0.7986993789672852,
      "learning_rate": 4.359939759036145e-06,
      "loss": 0.4304,
      "step": 850
    },
    {
      "epoch": 0.5126506024096386,
      "grad_norm": 0.829521894454956,
      "learning_rate": 4.359186746987953e-06,
      "loss": 0.4495,
      "step": 851
    },
    {
      "epoch": 0.5132530120481927,
      "grad_norm": 0.8475502729415894,
      "learning_rate": 4.35843373493976e-06,
      "loss": 0.4306,
      "step": 852
    },
    {
      "epoch": 0.513855421686747,
      "grad_norm": 0.818935751914978,
      "learning_rate": 4.3576807228915665e-06,
      "loss": 0.4227,
      "step": 853
    },
    {
      "epoch": 0.5144578313253012,
      "grad_norm": 0.8371078968048096,
      "learning_rate": 4.3569277108433734e-06,
      "loss": 0.4514,
      "step": 854
    },
    {
      "epoch": 0.5150602409638554,
      "grad_norm": 0.8844770193099976,
      "learning_rate": 4.356174698795181e-06,
      "loss": 0.4162,
      "step": 855
    },
    {
      "epoch": 0.5156626506024097,
      "grad_norm": 0.8010909557342529,
      "learning_rate": 4.355421686746988e-06,
      "loss": 0.4353,
      "step": 856
    },
    {
      "epoch": 0.5162650602409639,
      "grad_norm": 0.7793331146240234,
      "learning_rate": 4.354668674698795e-06,
      "loss": 0.4004,
      "step": 857
    },
    {
      "epoch": 0.516867469879518,
      "grad_norm": 0.8492479920387268,
      "learning_rate": 4.353915662650603e-06,
      "loss": 0.4524,
      "step": 858
    },
    {
      "epoch": 0.5174698795180723,
      "grad_norm": 0.9664198160171509,
      "learning_rate": 4.35316265060241e-06,
      "loss": 0.4546,
      "step": 859
    },
    {
      "epoch": 0.5180722891566265,
      "grad_norm": 0.8174721598625183,
      "learning_rate": 4.3524096385542175e-06,
      "loss": 0.4017,
      "step": 860
    },
    {
      "epoch": 0.5186746987951807,
      "grad_norm": 0.8000345230102539,
      "learning_rate": 4.3516566265060245e-06,
      "loss": 0.3915,
      "step": 861
    },
    {
      "epoch": 0.519277108433735,
      "grad_norm": 0.8073064088821411,
      "learning_rate": 4.350903614457831e-06,
      "loss": 0.4086,
      "step": 862
    },
    {
      "epoch": 0.5198795180722892,
      "grad_norm": 0.7949256896972656,
      "learning_rate": 4.350150602409639e-06,
      "loss": 0.4068,
      "step": 863
    },
    {
      "epoch": 0.5204819277108433,
      "grad_norm": 0.7876476049423218,
      "learning_rate": 4.349397590361446e-06,
      "loss": 0.4398,
      "step": 864
    },
    {
      "epoch": 0.5210843373493976,
      "grad_norm": 0.8097521662712097,
      "learning_rate": 4.348644578313254e-06,
      "loss": 0.3997,
      "step": 865
    },
    {
      "epoch": 0.5216867469879518,
      "grad_norm": 0.8396500945091248,
      "learning_rate": 4.347891566265061e-06,
      "loss": 0.4223,
      "step": 866
    },
    {
      "epoch": 0.522289156626506,
      "grad_norm": 0.7638972401618958,
      "learning_rate": 4.347138554216868e-06,
      "loss": 0.4742,
      "step": 867
    },
    {
      "epoch": 0.5228915662650603,
      "grad_norm": 0.7966380715370178,
      "learning_rate": 4.3463855421686755e-06,
      "loss": 0.4339,
      "step": 868
    },
    {
      "epoch": 0.5234939759036145,
      "grad_norm": 0.7622591257095337,
      "learning_rate": 4.345632530120482e-06,
      "loss": 0.472,
      "step": 869
    },
    {
      "epoch": 0.5240963855421686,
      "grad_norm": 0.7776954174041748,
      "learning_rate": 4.344879518072289e-06,
      "loss": 0.3648,
      "step": 870
    },
    {
      "epoch": 0.5246987951807229,
      "grad_norm": 0.8573868274688721,
      "learning_rate": 4.344126506024097e-06,
      "loss": 0.4273,
      "step": 871
    },
    {
      "epoch": 0.5253012048192771,
      "grad_norm": 0.8810848593711853,
      "learning_rate": 4.343373493975904e-06,
      "loss": 0.4515,
      "step": 872
    },
    {
      "epoch": 0.5259036144578313,
      "grad_norm": 0.8266674280166626,
      "learning_rate": 4.342620481927711e-06,
      "loss": 0.4184,
      "step": 873
    },
    {
      "epoch": 0.5265060240963856,
      "grad_norm": 0.7836454510688782,
      "learning_rate": 4.341867469879518e-06,
      "loss": 0.4075,
      "step": 874
    },
    {
      "epoch": 0.5271084337349398,
      "grad_norm": 0.7385941743850708,
      "learning_rate": 4.341114457831326e-06,
      "loss": 0.4595,
      "step": 875
    },
    {
      "epoch": 0.5277108433734939,
      "grad_norm": 0.7901641130447388,
      "learning_rate": 4.3403614457831326e-06,
      "loss": 0.4493,
      "step": 876
    },
    {
      "epoch": 0.5283132530120482,
      "grad_norm": 0.7479045391082764,
      "learning_rate": 4.33960843373494e-06,
      "loss": 0.3579,
      "step": 877
    },
    {
      "epoch": 0.5289156626506024,
      "grad_norm": 0.8022544980049133,
      "learning_rate": 4.338855421686747e-06,
      "loss": 0.3896,
      "step": 878
    },
    {
      "epoch": 0.5295180722891566,
      "grad_norm": 0.8185123205184937,
      "learning_rate": 4.338102409638554e-06,
      "loss": 0.447,
      "step": 879
    },
    {
      "epoch": 0.5301204819277109,
      "grad_norm": 0.8169865608215332,
      "learning_rate": 4.337349397590362e-06,
      "loss": 0.4279,
      "step": 880
    },
    {
      "epoch": 0.5307228915662651,
      "grad_norm": 0.8088361620903015,
      "learning_rate": 4.336596385542169e-06,
      "loss": 0.4396,
      "step": 881
    },
    {
      "epoch": 0.5313253012048192,
      "grad_norm": 0.8401119112968445,
      "learning_rate": 4.335843373493977e-06,
      "loss": 0.4006,
      "step": 882
    },
    {
      "epoch": 0.5319277108433735,
      "grad_norm": 0.8571670651435852,
      "learning_rate": 4.3350903614457836e-06,
      "loss": 0.4492,
      "step": 883
    },
    {
      "epoch": 0.5325301204819277,
      "grad_norm": 0.7971510887145996,
      "learning_rate": 4.334337349397591e-06,
      "loss": 0.4395,
      "step": 884
    },
    {
      "epoch": 0.5331325301204819,
      "grad_norm": 0.8040735721588135,
      "learning_rate": 4.333584337349398e-06,
      "loss": 0.3819,
      "step": 885
    },
    {
      "epoch": 0.5337349397590362,
      "grad_norm": 0.7898667454719543,
      "learning_rate": 4.332831325301205e-06,
      "loss": 0.4176,
      "step": 886
    },
    {
      "epoch": 0.5343373493975904,
      "grad_norm": 0.7932963967323303,
      "learning_rate": 4.332078313253012e-06,
      "loss": 0.3567,
      "step": 887
    },
    {
      "epoch": 0.5349397590361445,
      "grad_norm": 0.8073636889457703,
      "learning_rate": 4.33132530120482e-06,
      "loss": 0.4313,
      "step": 888
    },
    {
      "epoch": 0.5355421686746988,
      "grad_norm": 0.726006805896759,
      "learning_rate": 4.330572289156627e-06,
      "loss": 0.3913,
      "step": 889
    },
    {
      "epoch": 0.536144578313253,
      "grad_norm": 0.8472052812576294,
      "learning_rate": 4.329819277108434e-06,
      "loss": 0.3992,
      "step": 890
    },
    {
      "epoch": 0.5367469879518072,
      "grad_norm": 0.8237423300743103,
      "learning_rate": 4.329066265060241e-06,
      "loss": 0.438,
      "step": 891
    },
    {
      "epoch": 0.5373493975903615,
      "grad_norm": 0.8357053995132446,
      "learning_rate": 4.3283132530120484e-06,
      "loss": 0.3825,
      "step": 892
    },
    {
      "epoch": 0.5379518072289157,
      "grad_norm": 0.7606215476989746,
      "learning_rate": 4.327560240963855e-06,
      "loss": 0.4078,
      "step": 893
    },
    {
      "epoch": 0.5385542168674698,
      "grad_norm": 0.8142374753952026,
      "learning_rate": 4.326807228915663e-06,
      "loss": 0.423,
      "step": 894
    },
    {
      "epoch": 0.5391566265060241,
      "grad_norm": 0.7939624786376953,
      "learning_rate": 4.32605421686747e-06,
      "loss": 0.4351,
      "step": 895
    },
    {
      "epoch": 0.5397590361445783,
      "grad_norm": 0.6977701187133789,
      "learning_rate": 4.325301204819278e-06,
      "loss": 0.395,
      "step": 896
    },
    {
      "epoch": 0.5403614457831325,
      "grad_norm": 0.8009588122367859,
      "learning_rate": 4.324548192771085e-06,
      "loss": 0.3854,
      "step": 897
    },
    {
      "epoch": 0.5409638554216868,
      "grad_norm": 0.8048933148384094,
      "learning_rate": 4.323795180722892e-06,
      "loss": 0.4036,
      "step": 898
    },
    {
      "epoch": 0.541566265060241,
      "grad_norm": 0.7233434915542603,
      "learning_rate": 4.3230421686746995e-06,
      "loss": 0.4306,
      "step": 899
    },
    {
      "epoch": 0.5421686746987951,
      "grad_norm": 0.7529335021972656,
      "learning_rate": 4.322289156626506e-06,
      "loss": 0.4377,
      "step": 900
    },
    {
      "epoch": 0.5427710843373494,
      "grad_norm": 0.7765246033668518,
      "learning_rate": 4.321536144578314e-06,
      "loss": 0.4116,
      "step": 901
    },
    {
      "epoch": 0.5433734939759036,
      "grad_norm": 0.7744295597076416,
      "learning_rate": 4.320783132530121e-06,
      "loss": 0.3805,
      "step": 902
    },
    {
      "epoch": 0.5439759036144578,
      "grad_norm": 0.8364754319190979,
      "learning_rate": 4.320030120481928e-06,
      "loss": 0.4078,
      "step": 903
    },
    {
      "epoch": 0.5445783132530121,
      "grad_norm": 0.8348791003227234,
      "learning_rate": 4.319277108433736e-06,
      "loss": 0.45,
      "step": 904
    },
    {
      "epoch": 0.5451807228915663,
      "grad_norm": 0.7692778706550598,
      "learning_rate": 4.318524096385543e-06,
      "loss": 0.4167,
      "step": 905
    },
    {
      "epoch": 0.5457831325301205,
      "grad_norm": 0.7611362934112549,
      "learning_rate": 4.31777108433735e-06,
      "loss": 0.4337,
      "step": 906
    },
    {
      "epoch": 0.5463855421686747,
      "grad_norm": 0.7576718926429749,
      "learning_rate": 4.3170180722891565e-06,
      "loss": 0.4157,
      "step": 907
    },
    {
      "epoch": 0.5469879518072289,
      "grad_norm": 0.7705451846122742,
      "learning_rate": 4.316265060240964e-06,
      "loss": 0.3569,
      "step": 908
    },
    {
      "epoch": 0.5475903614457831,
      "grad_norm": 4.315168857574463,
      "learning_rate": 4.315512048192771e-06,
      "loss": 0.5013,
      "step": 909
    },
    {
      "epoch": 0.5481927710843374,
      "grad_norm": 0.8412376642227173,
      "learning_rate": 4.314759036144578e-06,
      "loss": 0.3898,
      "step": 910
    },
    {
      "epoch": 0.5487951807228916,
      "grad_norm": 0.7682619690895081,
      "learning_rate": 4.314006024096386e-06,
      "loss": 0.3907,
      "step": 911
    },
    {
      "epoch": 0.5493975903614458,
      "grad_norm": 0.7069816589355469,
      "learning_rate": 4.313253012048193e-06,
      "loss": 0.3979,
      "step": 912
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7971832752227783,
      "learning_rate": 4.312500000000001e-06,
      "loss": 0.404,
      "step": 913
    },
    {
      "epoch": 0.5506024096385542,
      "grad_norm": 1.9294850826263428,
      "learning_rate": 4.3117469879518076e-06,
      "loss": 0.4829,
      "step": 914
    },
    {
      "epoch": 0.5512048192771084,
      "grad_norm": 0.8267315030097961,
      "learning_rate": 4.3109939759036145e-06,
      "loss": 0.452,
      "step": 915
    },
    {
      "epoch": 0.5518072289156627,
      "grad_norm": 0.8068246245384216,
      "learning_rate": 4.310240963855422e-06,
      "loss": 0.382,
      "step": 916
    },
    {
      "epoch": 0.5524096385542169,
      "grad_norm": 0.831504225730896,
      "learning_rate": 4.309487951807229e-06,
      "loss": 0.4938,
      "step": 917
    },
    {
      "epoch": 0.553012048192771,
      "grad_norm": 0.7440221309661865,
      "learning_rate": 4.308734939759037e-06,
      "loss": 0.3758,
      "step": 918
    },
    {
      "epoch": 0.5536144578313253,
      "grad_norm": 0.8431599736213684,
      "learning_rate": 4.307981927710844e-06,
      "loss": 0.3886,
      "step": 919
    },
    {
      "epoch": 0.5542168674698795,
      "grad_norm": 0.8180341124534607,
      "learning_rate": 4.307228915662651e-06,
      "loss": 0.4134,
      "step": 920
    },
    {
      "epoch": 0.5548192771084337,
      "grad_norm": 0.7903769016265869,
      "learning_rate": 4.306475903614459e-06,
      "loss": 0.4007,
      "step": 921
    },
    {
      "epoch": 0.555421686746988,
      "grad_norm": 0.7334953546524048,
      "learning_rate": 4.3057228915662655e-06,
      "loss": 0.4247,
      "step": 922
    },
    {
      "epoch": 0.5560240963855422,
      "grad_norm": 0.7574230432510376,
      "learning_rate": 4.3049698795180724e-06,
      "loss": 0.3726,
      "step": 923
    },
    {
      "epoch": 0.5566265060240964,
      "grad_norm": 0.8313443064689636,
      "learning_rate": 4.304216867469879e-06,
      "loss": 0.3802,
      "step": 924
    },
    {
      "epoch": 0.5572289156626506,
      "grad_norm": 0.8252736926078796,
      "learning_rate": 4.303463855421687e-06,
      "loss": 0.3955,
      "step": 925
    },
    {
      "epoch": 0.5578313253012048,
      "grad_norm": 0.756425142288208,
      "learning_rate": 4.302710843373494e-06,
      "loss": 0.3647,
      "step": 926
    },
    {
      "epoch": 0.558433734939759,
      "grad_norm": 0.7799807190895081,
      "learning_rate": 4.301957831325301e-06,
      "loss": 0.3606,
      "step": 927
    },
    {
      "epoch": 0.5590361445783133,
      "grad_norm": 0.7825757265090942,
      "learning_rate": 4.301204819277109e-06,
      "loss": 0.3925,
      "step": 928
    },
    {
      "epoch": 0.5596385542168675,
      "grad_norm": 0.7923397421836853,
      "learning_rate": 4.300451807228916e-06,
      "loss": 0.3761,
      "step": 929
    },
    {
      "epoch": 0.5602409638554217,
      "grad_norm": 0.7975937128067017,
      "learning_rate": 4.2996987951807234e-06,
      "loss": 0.3594,
      "step": 930
    },
    {
      "epoch": 0.560843373493976,
      "grad_norm": 0.7704777121543884,
      "learning_rate": 4.29894578313253e-06,
      "loss": 0.3476,
      "step": 931
    },
    {
      "epoch": 0.5614457831325301,
      "grad_norm": 0.7414358258247375,
      "learning_rate": 4.298192771084338e-06,
      "loss": 0.3777,
      "step": 932
    },
    {
      "epoch": 0.5620481927710843,
      "grad_norm": 0.7355138063430786,
      "learning_rate": 4.297439759036145e-06,
      "loss": 0.3918,
      "step": 933
    },
    {
      "epoch": 0.5626506024096386,
      "grad_norm": 0.7713682651519775,
      "learning_rate": 4.296686746987952e-06,
      "loss": 0.3657,
      "step": 934
    },
    {
      "epoch": 0.5632530120481928,
      "grad_norm": 0.7218055725097656,
      "learning_rate": 4.29593373493976e-06,
      "loss": 0.3643,
      "step": 935
    },
    {
      "epoch": 0.563855421686747,
      "grad_norm": 0.7480095028877258,
      "learning_rate": 4.295180722891567e-06,
      "loss": 0.3316,
      "step": 936
    },
    {
      "epoch": 0.5644578313253013,
      "grad_norm": 0.7294235229492188,
      "learning_rate": 4.2944277108433745e-06,
      "loss": 0.3549,
      "step": 937
    },
    {
      "epoch": 0.5650602409638554,
      "grad_norm": 0.8008028268814087,
      "learning_rate": 4.293674698795181e-06,
      "loss": 0.3503,
      "step": 938
    },
    {
      "epoch": 0.5656626506024096,
      "grad_norm": 0.806866466999054,
      "learning_rate": 4.292921686746988e-06,
      "loss": 0.355,
      "step": 939
    },
    {
      "epoch": 0.5662650602409639,
      "grad_norm": 0.7996290326118469,
      "learning_rate": 4.292168674698795e-06,
      "loss": 0.4023,
      "step": 940
    },
    {
      "epoch": 0.5668674698795181,
      "grad_norm": 0.7068387866020203,
      "learning_rate": 4.291415662650603e-06,
      "loss": 0.3938,
      "step": 941
    },
    {
      "epoch": 0.5674698795180723,
      "grad_norm": 1.0710734128952026,
      "learning_rate": 4.29066265060241e-06,
      "loss": 0.3771,
      "step": 942
    },
    {
      "epoch": 0.5680722891566266,
      "grad_norm": 0.7710971832275391,
      "learning_rate": 4.289909638554217e-06,
      "loss": 0.3812,
      "step": 943
    },
    {
      "epoch": 0.5686746987951807,
      "grad_norm": 0.7914687395095825,
      "learning_rate": 4.289156626506025e-06,
      "loss": 0.3928,
      "step": 944
    },
    {
      "epoch": 0.5692771084337349,
      "grad_norm": 0.7704615592956543,
      "learning_rate": 4.2884036144578316e-06,
      "loss": 0.3692,
      "step": 945
    },
    {
      "epoch": 0.5698795180722892,
      "grad_norm": 0.7417771816253662,
      "learning_rate": 4.2876506024096385e-06,
      "loss": 0.405,
      "step": 946
    },
    {
      "epoch": 0.5704819277108434,
      "grad_norm": 0.7705473899841309,
      "learning_rate": 4.286897590361446e-06,
      "loss": 0.4091,
      "step": 947
    },
    {
      "epoch": 0.5710843373493976,
      "grad_norm": 0.7784224152565002,
      "learning_rate": 4.286144578313253e-06,
      "loss": 0.3471,
      "step": 948
    },
    {
      "epoch": 0.5716867469879519,
      "grad_norm": 0.8063245415687561,
      "learning_rate": 4.285391566265061e-06,
      "loss": 0.4306,
      "step": 949
    },
    {
      "epoch": 0.572289156626506,
      "grad_norm": 0.7977460622787476,
      "learning_rate": 4.284638554216868e-06,
      "loss": 0.3737,
      "step": 950
    },
    {
      "epoch": 0.5728915662650602,
      "grad_norm": 0.7328252196311951,
      "learning_rate": 4.283885542168675e-06,
      "loss": 0.3707,
      "step": 951
    },
    {
      "epoch": 0.5734939759036145,
      "grad_norm": 0.7227932214736938,
      "learning_rate": 4.2831325301204826e-06,
      "loss": 0.3394,
      "step": 952
    },
    {
      "epoch": 0.5740963855421687,
      "grad_norm": 0.7435798645019531,
      "learning_rate": 4.2823795180722895e-06,
      "loss": 0.3483,
      "step": 953
    },
    {
      "epoch": 0.5746987951807229,
      "grad_norm": 0.7096930742263794,
      "learning_rate": 4.281626506024097e-06,
      "loss": 0.3788,
      "step": 954
    },
    {
      "epoch": 0.5753012048192772,
      "grad_norm": 0.7445315718650818,
      "learning_rate": 4.280873493975904e-06,
      "loss": 0.3734,
      "step": 955
    },
    {
      "epoch": 0.5759036144578313,
      "grad_norm": 0.7313184142112732,
      "learning_rate": 4.280120481927711e-06,
      "loss": 0.3307,
      "step": 956
    },
    {
      "epoch": 0.5765060240963855,
      "grad_norm": 0.8035340905189514,
      "learning_rate": 4.279367469879518e-06,
      "loss": 0.3393,
      "step": 957
    },
    {
      "epoch": 0.5771084337349398,
      "grad_norm": 0.7038957476615906,
      "learning_rate": 4.278614457831326e-06,
      "loss": 0.3846,
      "step": 958
    },
    {
      "epoch": 0.577710843373494,
      "grad_norm": 0.6692425608634949,
      "learning_rate": 4.277861445783133e-06,
      "loss": 0.3385,
      "step": 959
    },
    {
      "epoch": 0.5783132530120482,
      "grad_norm": 0.7419648766517639,
      "learning_rate": 4.27710843373494e-06,
      "loss": 0.387,
      "step": 960
    },
    {
      "epoch": 0.5789156626506025,
      "grad_norm": 0.8434422016143799,
      "learning_rate": 4.2763554216867474e-06,
      "loss": 0.3789,
      "step": 961
    },
    {
      "epoch": 0.5795180722891566,
      "grad_norm": 0.71660977602005,
      "learning_rate": 4.275602409638554e-06,
      "loss": 0.3894,
      "step": 962
    },
    {
      "epoch": 0.5801204819277108,
      "grad_norm": 0.7434622049331665,
      "learning_rate": 4.274849397590361e-06,
      "loss": 0.3518,
      "step": 963
    },
    {
      "epoch": 0.5807228915662651,
      "grad_norm": 0.7609408497810364,
      "learning_rate": 4.274096385542169e-06,
      "loss": 0.3681,
      "step": 964
    },
    {
      "epoch": 0.5813253012048193,
      "grad_norm": 0.6996928453445435,
      "learning_rate": 4.273343373493976e-06,
      "loss": 0.3634,
      "step": 965
    },
    {
      "epoch": 0.5819277108433735,
      "grad_norm": 0.7500999569892883,
      "learning_rate": 4.272590361445784e-06,
      "loss": 0.3647,
      "step": 966
    },
    {
      "epoch": 0.5825301204819278,
      "grad_norm": 0.672360360622406,
      "learning_rate": 4.271837349397591e-06,
      "loss": 0.3799,
      "step": 967
    },
    {
      "epoch": 0.5831325301204819,
      "grad_norm": 0.7159790992736816,
      "learning_rate": 4.2710843373493984e-06,
      "loss": 0.3405,
      "step": 968
    },
    {
      "epoch": 0.5837349397590361,
      "grad_norm": 0.7717326283454895,
      "learning_rate": 4.270331325301205e-06,
      "loss": 0.4065,
      "step": 969
    },
    {
      "epoch": 0.5843373493975904,
      "grad_norm": 0.6975754499435425,
      "learning_rate": 4.269578313253012e-06,
      "loss": 0.3674,
      "step": 970
    },
    {
      "epoch": 0.5849397590361446,
      "grad_norm": 0.6191722750663757,
      "learning_rate": 4.26882530120482e-06,
      "loss": 0.3654,
      "step": 971
    },
    {
      "epoch": 0.5855421686746988,
      "grad_norm": 0.7361752986907959,
      "learning_rate": 4.268072289156627e-06,
      "loss": 0.4072,
      "step": 972
    },
    {
      "epoch": 0.5861445783132531,
      "grad_norm": 0.7437025904655457,
      "learning_rate": 4.267319277108434e-06,
      "loss": 0.3474,
      "step": 973
    },
    {
      "epoch": 0.5867469879518072,
      "grad_norm": 0.9859191179275513,
      "learning_rate": 4.266566265060242e-06,
      "loss": 0.3884,
      "step": 974
    },
    {
      "epoch": 0.5873493975903614,
      "grad_norm": 0.7379528880119324,
      "learning_rate": 4.265813253012049e-06,
      "loss": 0.3959,
      "step": 975
    },
    {
      "epoch": 0.5879518072289157,
      "grad_norm": 0.6736807227134705,
      "learning_rate": 4.2650602409638555e-06,
      "loss": 0.4062,
      "step": 976
    },
    {
      "epoch": 0.5885542168674699,
      "grad_norm": 0.7174250483512878,
      "learning_rate": 4.2643072289156625e-06,
      "loss": 0.3559,
      "step": 977
    },
    {
      "epoch": 0.5891566265060241,
      "grad_norm": 0.7445334196090698,
      "learning_rate": 4.26355421686747e-06,
      "loss": 0.3721,
      "step": 978
    },
    {
      "epoch": 0.5897590361445784,
      "grad_norm": 0.6853645443916321,
      "learning_rate": 4.262801204819277e-06,
      "loss": 0.3231,
      "step": 979
    },
    {
      "epoch": 0.5903614457831325,
      "grad_norm": 0.7564582228660583,
      "learning_rate": 4.262048192771085e-06,
      "loss": 0.3753,
      "step": 980
    },
    {
      "epoch": 0.5909638554216867,
      "grad_norm": 0.7529146075248718,
      "learning_rate": 4.261295180722892e-06,
      "loss": 0.3854,
      "step": 981
    },
    {
      "epoch": 0.591566265060241,
      "grad_norm": 0.7169272899627686,
      "learning_rate": 4.260542168674699e-06,
      "loss": 0.3677,
      "step": 982
    },
    {
      "epoch": 0.5921686746987952,
      "grad_norm": 0.7944785952568054,
      "learning_rate": 4.2597891566265066e-06,
      "loss": 0.3435,
      "step": 983
    },
    {
      "epoch": 0.5927710843373494,
      "grad_norm": 0.7797319889068604,
      "learning_rate": 4.2590361445783135e-06,
      "loss": 0.3864,
      "step": 984
    },
    {
      "epoch": 0.5933734939759037,
      "grad_norm": 0.725689709186554,
      "learning_rate": 4.258283132530121e-06,
      "loss": 0.3542,
      "step": 985
    },
    {
      "epoch": 0.5939759036144578,
      "grad_norm": 0.6821196675300598,
      "learning_rate": 4.257530120481928e-06,
      "loss": 0.3686,
      "step": 986
    },
    {
      "epoch": 0.594578313253012,
      "grad_norm": 0.7773293256759644,
      "learning_rate": 4.256777108433735e-06,
      "loss": 0.3639,
      "step": 987
    },
    {
      "epoch": 0.5951807228915663,
      "grad_norm": 0.6714105010032654,
      "learning_rate": 4.256024096385543e-06,
      "loss": 0.3535,
      "step": 988
    },
    {
      "epoch": 0.5957831325301205,
      "grad_norm": 1.0115476846694946,
      "learning_rate": 4.25527108433735e-06,
      "loss": 0.3749,
      "step": 989
    },
    {
      "epoch": 0.5963855421686747,
      "grad_norm": 0.6596676707267761,
      "learning_rate": 4.254518072289157e-06,
      "loss": 0.3466,
      "step": 990
    },
    {
      "epoch": 0.596987951807229,
      "grad_norm": 0.6764962673187256,
      "learning_rate": 4.2537650602409645e-06,
      "loss": 0.3686,
      "step": 991
    },
    {
      "epoch": 0.5975903614457831,
      "grad_norm": 0.7789087891578674,
      "learning_rate": 4.253012048192771e-06,
      "loss": 0.3443,
      "step": 992
    },
    {
      "epoch": 0.5981927710843373,
      "grad_norm": 0.6915074586868286,
      "learning_rate": 4.252259036144578e-06,
      "loss": 0.3934,
      "step": 993
    },
    {
      "epoch": 0.5987951807228916,
      "grad_norm": 0.6859859824180603,
      "learning_rate": 4.251506024096385e-06,
      "loss": 0.3677,
      "step": 994
    },
    {
      "epoch": 0.5993975903614458,
      "grad_norm": 0.6384007334709167,
      "learning_rate": 4.250753012048193e-06,
      "loss": 0.3387,
      "step": 995
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7972452640533447,
      "learning_rate": 4.25e-06,
      "loss": 0.3479,
      "step": 996
    },
    {
      "epoch": 0.6006024096385543,
      "grad_norm": 0.7143418788909912,
      "learning_rate": 4.249246987951808e-06,
      "loss": 0.3802,
      "step": 997
    },
    {
      "epoch": 0.6012048192771084,
      "grad_norm": 0.7030960917472839,
      "learning_rate": 4.248493975903615e-06,
      "loss": 0.3669,
      "step": 998
    },
    {
      "epoch": 0.6018072289156626,
      "grad_norm": 0.7782144546508789,
      "learning_rate": 4.247740963855422e-06,
      "loss": 0.3559,
      "step": 999
    },
    {
      "epoch": 0.6024096385542169,
      "grad_norm": 0.7781561613082886,
      "learning_rate": 4.246987951807229e-06,
      "loss": 0.3272,
      "step": 1000
    },
    {
      "epoch": 0.6030120481927711,
      "grad_norm": 0.7029792070388794,
      "learning_rate": 4.246234939759036e-06,
      "loss": 0.3626,
      "step": 1001
    },
    {
      "epoch": 0.6036144578313253,
      "grad_norm": 0.8206674456596375,
      "learning_rate": 4.245481927710844e-06,
      "loss": 0.401,
      "step": 1002
    },
    {
      "epoch": 0.6042168674698796,
      "grad_norm": 0.777209460735321,
      "learning_rate": 4.244728915662651e-06,
      "loss": 0.3997,
      "step": 1003
    },
    {
      "epoch": 0.6048192771084338,
      "grad_norm": 0.7077927589416504,
      "learning_rate": 4.243975903614459e-06,
      "loss": 0.3044,
      "step": 1004
    },
    {
      "epoch": 0.6054216867469879,
      "grad_norm": 0.7602314949035645,
      "learning_rate": 4.243222891566266e-06,
      "loss": 0.352,
      "step": 1005
    },
    {
      "epoch": 0.6060240963855422,
      "grad_norm": 0.7351922988891602,
      "learning_rate": 4.242469879518073e-06,
      "loss": 0.3322,
      "step": 1006
    },
    {
      "epoch": 0.6066265060240964,
      "grad_norm": 0.7000468373298645,
      "learning_rate": 4.24171686746988e-06,
      "loss": 0.3976,
      "step": 1007
    },
    {
      "epoch": 0.6072289156626506,
      "grad_norm": 0.6801012754440308,
      "learning_rate": 4.240963855421687e-06,
      "loss": 0.3772,
      "step": 1008
    },
    {
      "epoch": 0.6078313253012049,
      "grad_norm": 0.6733007431030273,
      "learning_rate": 4.240210843373494e-06,
      "loss": 0.379,
      "step": 1009
    },
    {
      "epoch": 0.608433734939759,
      "grad_norm": 0.746812105178833,
      "learning_rate": 4.239457831325301e-06,
      "loss": 0.3456,
      "step": 1010
    },
    {
      "epoch": 0.6090361445783132,
      "grad_norm": 0.6872010827064514,
      "learning_rate": 4.238704819277109e-06,
      "loss": 0.3365,
      "step": 1011
    },
    {
      "epoch": 0.6096385542168675,
      "grad_norm": 0.6772070527076721,
      "learning_rate": 4.237951807228916e-06,
      "loss": 0.3365,
      "step": 1012
    },
    {
      "epoch": 0.6102409638554217,
      "grad_norm": 0.7157016396522522,
      "learning_rate": 4.237198795180723e-06,
      "loss": 0.3906,
      "step": 1013
    },
    {
      "epoch": 0.6108433734939759,
      "grad_norm": 0.6758989691734314,
      "learning_rate": 4.2364457831325305e-06,
      "loss": 0.274,
      "step": 1014
    },
    {
      "epoch": 0.6114457831325302,
      "grad_norm": 0.7036014199256897,
      "learning_rate": 4.2356927710843375e-06,
      "loss": 0.3127,
      "step": 1015
    },
    {
      "epoch": 0.6120481927710844,
      "grad_norm": 0.6943942308425903,
      "learning_rate": 4.234939759036145e-06,
      "loss": 0.3453,
      "step": 1016
    },
    {
      "epoch": 0.6126506024096385,
      "grad_norm": 0.7896462678909302,
      "learning_rate": 4.234186746987952e-06,
      "loss": 0.3552,
      "step": 1017
    },
    {
      "epoch": 0.6132530120481928,
      "grad_norm": 0.6845191717147827,
      "learning_rate": 4.233433734939759e-06,
      "loss": 0.3616,
      "step": 1018
    },
    {
      "epoch": 0.613855421686747,
      "grad_norm": 0.6497243046760559,
      "learning_rate": 4.232680722891567e-06,
      "loss": 0.3255,
      "step": 1019
    },
    {
      "epoch": 0.6144578313253012,
      "grad_norm": 0.7155961394309998,
      "learning_rate": 4.231927710843374e-06,
      "loss": 0.3412,
      "step": 1020
    },
    {
      "epoch": 0.6150602409638555,
      "grad_norm": 0.743620753288269,
      "learning_rate": 4.2311746987951816e-06,
      "loss": 0.3698,
      "step": 1021
    },
    {
      "epoch": 0.6156626506024097,
      "grad_norm": 0.6765284538269043,
      "learning_rate": 4.2304216867469885e-06,
      "loss": 0.2969,
      "step": 1022
    },
    {
      "epoch": 0.6162650602409638,
      "grad_norm": 0.670057475566864,
      "learning_rate": 4.229668674698795e-06,
      "loss": 0.3982,
      "step": 1023
    },
    {
      "epoch": 0.6168674698795181,
      "grad_norm": 0.7183547616004944,
      "learning_rate": 4.228915662650603e-06,
      "loss": 0.3037,
      "step": 1024
    },
    {
      "epoch": 0.6174698795180723,
      "grad_norm": 0.7418147921562195,
      "learning_rate": 4.22816265060241e-06,
      "loss": 0.3699,
      "step": 1025
    },
    {
      "epoch": 0.6180722891566265,
      "grad_norm": 0.6746722459793091,
      "learning_rate": 4.227409638554217e-06,
      "loss": 0.3377,
      "step": 1026
    },
    {
      "epoch": 0.6186746987951808,
      "grad_norm": 0.652052104473114,
      "learning_rate": 4.226656626506024e-06,
      "loss": 0.3989,
      "step": 1027
    },
    {
      "epoch": 0.619277108433735,
      "grad_norm": 0.714030921459198,
      "learning_rate": 4.225903614457832e-06,
      "loss": 0.3822,
      "step": 1028
    },
    {
      "epoch": 0.6198795180722891,
      "grad_norm": 0.7113739848136902,
      "learning_rate": 4.225150602409639e-06,
      "loss": 0.3894,
      "step": 1029
    },
    {
      "epoch": 0.6204819277108434,
      "grad_norm": 0.6580613255500793,
      "learning_rate": 4.2243975903614456e-06,
      "loss": 0.3304,
      "step": 1030
    },
    {
      "epoch": 0.6210843373493976,
      "grad_norm": 0.6946856379508972,
      "learning_rate": 4.223644578313253e-06,
      "loss": 0.3022,
      "step": 1031
    },
    {
      "epoch": 0.6216867469879518,
      "grad_norm": 0.6940138339996338,
      "learning_rate": 4.22289156626506e-06,
      "loss": 0.3031,
      "step": 1032
    },
    {
      "epoch": 0.6222891566265061,
      "grad_norm": 0.6886828541755676,
      "learning_rate": 4.222138554216868e-06,
      "loss": 0.3478,
      "step": 1033
    },
    {
      "epoch": 0.6228915662650603,
      "grad_norm": 0.7083032727241516,
      "learning_rate": 4.221385542168675e-06,
      "loss": 0.3554,
      "step": 1034
    },
    {
      "epoch": 0.6234939759036144,
      "grad_norm": 0.6513544321060181,
      "learning_rate": 4.220632530120482e-06,
      "loss": 0.3838,
      "step": 1035
    },
    {
      "epoch": 0.6240963855421687,
      "grad_norm": 0.7648593187332153,
      "learning_rate": 4.21987951807229e-06,
      "loss": 0.3185,
      "step": 1036
    },
    {
      "epoch": 0.6246987951807229,
      "grad_norm": 0.7226129174232483,
      "learning_rate": 4.219126506024097e-06,
      "loss": 0.3383,
      "step": 1037
    },
    {
      "epoch": 0.6253012048192771,
      "grad_norm": 0.6883175373077393,
      "learning_rate": 4.218373493975904e-06,
      "loss": 0.369,
      "step": 1038
    },
    {
      "epoch": 0.6259036144578313,
      "grad_norm": 0.7176735997200012,
      "learning_rate": 4.217620481927711e-06,
      "loss": 0.3428,
      "step": 1039
    },
    {
      "epoch": 0.6265060240963856,
      "grad_norm": 0.6760815382003784,
      "learning_rate": 4.216867469879519e-06,
      "loss": 0.3126,
      "step": 1040
    },
    {
      "epoch": 0.6271084337349397,
      "grad_norm": 0.7809283137321472,
      "learning_rate": 4.216114457831326e-06,
      "loss": 0.3902,
      "step": 1041
    },
    {
      "epoch": 0.6277108433734939,
      "grad_norm": 0.693533718585968,
      "learning_rate": 4.215361445783133e-06,
      "loss": 0.3144,
      "step": 1042
    },
    {
      "epoch": 0.6283132530120482,
      "grad_norm": 0.6808416843414307,
      "learning_rate": 4.21460843373494e-06,
      "loss": 0.3377,
      "step": 1043
    },
    {
      "epoch": 0.6289156626506024,
      "grad_norm": 0.7449379563331604,
      "learning_rate": 4.213855421686748e-06,
      "loss": 0.3527,
      "step": 1044
    },
    {
      "epoch": 0.6295180722891566,
      "grad_norm": 0.7878081798553467,
      "learning_rate": 4.2131024096385545e-06,
      "loss": 0.39,
      "step": 1045
    },
    {
      "epoch": 0.6301204819277109,
      "grad_norm": 0.6536931991577148,
      "learning_rate": 4.2123493975903615e-06,
      "loss": 0.328,
      "step": 1046
    },
    {
      "epoch": 0.630722891566265,
      "grad_norm": 0.6915048956871033,
      "learning_rate": 4.211596385542168e-06,
      "loss": 0.3341,
      "step": 1047
    },
    {
      "epoch": 0.6313253012048192,
      "grad_norm": 0.6676458120346069,
      "learning_rate": 4.210843373493976e-06,
      "loss": 0.2822,
      "step": 1048
    },
    {
      "epoch": 0.6319277108433735,
      "grad_norm": 0.6868332028388977,
      "learning_rate": 4.210090361445783e-06,
      "loss": 0.3516,
      "step": 1049
    },
    {
      "epoch": 0.6325301204819277,
      "grad_norm": 0.6932550668716431,
      "learning_rate": 4.209337349397591e-06,
      "loss": 0.3046,
      "step": 1050
    },
    {
      "epoch": 0.6331325301204819,
      "grad_norm": 0.6924625039100647,
      "learning_rate": 4.208584337349398e-06,
      "loss": 0.3336,
      "step": 1051
    },
    {
      "epoch": 0.6337349397590362,
      "grad_norm": 0.6451301574707031,
      "learning_rate": 4.2078313253012055e-06,
      "loss": 0.2989,
      "step": 1052
    },
    {
      "epoch": 0.6343373493975903,
      "grad_norm": 0.6550989747047424,
      "learning_rate": 4.2070783132530125e-06,
      "loss": 0.313,
      "step": 1053
    },
    {
      "epoch": 0.6349397590361445,
      "grad_norm": 0.6595355868339539,
      "learning_rate": 4.206325301204819e-06,
      "loss": 0.3384,
      "step": 1054
    },
    {
      "epoch": 0.6355421686746988,
      "grad_norm": 0.6261127591133118,
      "learning_rate": 4.205572289156627e-06,
      "loss": 0.316,
      "step": 1055
    },
    {
      "epoch": 0.636144578313253,
      "grad_norm": 0.6545342206954956,
      "learning_rate": 4.204819277108434e-06,
      "loss": 0.3547,
      "step": 1056
    },
    {
      "epoch": 0.6367469879518072,
      "grad_norm": 0.6626054048538208,
      "learning_rate": 4.204066265060242e-06,
      "loss": 0.3209,
      "step": 1057
    },
    {
      "epoch": 0.6373493975903615,
      "grad_norm": 0.6778848767280579,
      "learning_rate": 4.203313253012049e-06,
      "loss": 0.3131,
      "step": 1058
    },
    {
      "epoch": 0.6379518072289156,
      "grad_norm": 0.7069299817085266,
      "learning_rate": 4.202560240963856e-06,
      "loss": 0.3474,
      "step": 1059
    },
    {
      "epoch": 0.6385542168674698,
      "grad_norm": 0.6784418225288391,
      "learning_rate": 4.201807228915663e-06,
      "loss": 0.3105,
      "step": 1060
    },
    {
      "epoch": 0.6391566265060241,
      "grad_norm": 0.696437418460846,
      "learning_rate": 4.20105421686747e-06,
      "loss": 0.3723,
      "step": 1061
    },
    {
      "epoch": 0.6397590361445783,
      "grad_norm": 0.8004807829856873,
      "learning_rate": 4.200301204819277e-06,
      "loss": 0.3416,
      "step": 1062
    },
    {
      "epoch": 0.6403614457831325,
      "grad_norm": 0.7302642464637756,
      "learning_rate": 4.199548192771084e-06,
      "loss": 0.3102,
      "step": 1063
    },
    {
      "epoch": 0.6409638554216868,
      "grad_norm": 0.6766858100891113,
      "learning_rate": 4.198795180722892e-06,
      "loss": 0.3493,
      "step": 1064
    },
    {
      "epoch": 0.641566265060241,
      "grad_norm": 0.6763878464698792,
      "learning_rate": 4.198042168674699e-06,
      "loss": 0.313,
      "step": 1065
    },
    {
      "epoch": 0.6421686746987951,
      "grad_norm": 0.7035558819770813,
      "learning_rate": 4.197289156626506e-06,
      "loss": 0.3309,
      "step": 1066
    },
    {
      "epoch": 0.6427710843373494,
      "grad_norm": 0.7089851498603821,
      "learning_rate": 4.196536144578314e-06,
      "loss": 0.3277,
      "step": 1067
    },
    {
      "epoch": 0.6433734939759036,
      "grad_norm": 0.6647509336471558,
      "learning_rate": 4.195783132530121e-06,
      "loss": 0.3452,
      "step": 1068
    },
    {
      "epoch": 0.6439759036144578,
      "grad_norm": 0.6854298114776611,
      "learning_rate": 4.195030120481928e-06,
      "loss": 0.3048,
      "step": 1069
    },
    {
      "epoch": 0.6445783132530121,
      "grad_norm": 0.6603912711143494,
      "learning_rate": 4.194277108433735e-06,
      "loss": 0.3199,
      "step": 1070
    },
    {
      "epoch": 0.6451807228915662,
      "grad_norm": 0.6995744705200195,
      "learning_rate": 4.193524096385542e-06,
      "loss": 0.3009,
      "step": 1071
    },
    {
      "epoch": 0.6457831325301204,
      "grad_norm": 0.70346599817276,
      "learning_rate": 4.19277108433735e-06,
      "loss": 0.3732,
      "step": 1072
    },
    {
      "epoch": 0.6463855421686747,
      "grad_norm": 0.6439405679702759,
      "learning_rate": 4.192018072289157e-06,
      "loss": 0.3556,
      "step": 1073
    },
    {
      "epoch": 0.6469879518072289,
      "grad_norm": 0.65443354845047,
      "learning_rate": 4.191265060240965e-06,
      "loss": 0.3123,
      "step": 1074
    },
    {
      "epoch": 0.6475903614457831,
      "grad_norm": 0.6255698204040527,
      "learning_rate": 4.190512048192772e-06,
      "loss": 0.3273,
      "step": 1075
    },
    {
      "epoch": 0.6481927710843374,
      "grad_norm": 0.6877039670944214,
      "learning_rate": 4.1897590361445785e-06,
      "loss": 0.2985,
      "step": 1076
    },
    {
      "epoch": 0.6487951807228916,
      "grad_norm": 0.6268601417541504,
      "learning_rate": 4.189006024096386e-06,
      "loss": 0.3029,
      "step": 1077
    },
    {
      "epoch": 0.6493975903614457,
      "grad_norm": 0.6810986399650574,
      "learning_rate": 4.188253012048193e-06,
      "loss": 0.3206,
      "step": 1078
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.7084299921989441,
      "learning_rate": 4.1875e-06,
      "loss": 0.335,
      "step": 1079
    },
    {
      "epoch": 0.6506024096385542,
      "grad_norm": 0.8337351083755493,
      "learning_rate": 4.186746987951807e-06,
      "loss": 0.3475,
      "step": 1080
    },
    {
      "epoch": 0.6512048192771084,
      "grad_norm": 0.9058039784431458,
      "learning_rate": 4.185993975903615e-06,
      "loss": 0.3735,
      "step": 1081
    },
    {
      "epoch": 0.6518072289156627,
      "grad_norm": 0.8393770456314087,
      "learning_rate": 4.185240963855422e-06,
      "loss": 0.4093,
      "step": 1082
    },
    {
      "epoch": 0.6524096385542169,
      "grad_norm": 0.8646925091743469,
      "learning_rate": 4.184487951807229e-06,
      "loss": 0.3268,
      "step": 1083
    },
    {
      "epoch": 0.653012048192771,
      "grad_norm": 0.8454601764678955,
      "learning_rate": 4.1837349397590365e-06,
      "loss": 0.3609,
      "step": 1084
    },
    {
      "epoch": 0.6536144578313253,
      "grad_norm": 0.74372798204422,
      "learning_rate": 4.182981927710843e-06,
      "loss": 0.3601,
      "step": 1085
    },
    {
      "epoch": 0.6542168674698795,
      "grad_norm": 0.7892573475837708,
      "learning_rate": 4.182228915662651e-06,
      "loss": 0.4099,
      "step": 1086
    },
    {
      "epoch": 0.6548192771084337,
      "grad_norm": 0.756250262260437,
      "learning_rate": 4.181475903614458e-06,
      "loss": 0.4141,
      "step": 1087
    },
    {
      "epoch": 0.655421686746988,
      "grad_norm": 0.7410038113594055,
      "learning_rate": 4.180722891566266e-06,
      "loss": 0.4716,
      "step": 1088
    },
    {
      "epoch": 0.6560240963855422,
      "grad_norm": 0.8193921446800232,
      "learning_rate": 4.179969879518073e-06,
      "loss": 0.3939,
      "step": 1089
    },
    {
      "epoch": 0.6566265060240963,
      "grad_norm": 0.829695999622345,
      "learning_rate": 4.17921686746988e-06,
      "loss": 0.3326,
      "step": 1090
    },
    {
      "epoch": 0.6572289156626506,
      "grad_norm": 0.7578059434890747,
      "learning_rate": 4.1784638554216875e-06,
      "loss": 0.3661,
      "step": 1091
    },
    {
      "epoch": 0.6578313253012048,
      "grad_norm": 0.7890134453773499,
      "learning_rate": 4.177710843373494e-06,
      "loss": 0.3775,
      "step": 1092
    },
    {
      "epoch": 0.658433734939759,
      "grad_norm": 0.7565470337867737,
      "learning_rate": 4.176957831325302e-06,
      "loss": 0.4088,
      "step": 1093
    },
    {
      "epoch": 0.6590361445783133,
      "grad_norm": 0.7307422757148743,
      "learning_rate": 4.176204819277109e-06,
      "loss": 0.4021,
      "step": 1094
    },
    {
      "epoch": 0.6596385542168675,
      "grad_norm": 0.807192325592041,
      "learning_rate": 4.175451807228916e-06,
      "loss": 0.3572,
      "step": 1095
    },
    {
      "epoch": 0.6602409638554216,
      "grad_norm": 0.7733858823776245,
      "learning_rate": 4.174698795180723e-06,
      "loss": 0.3502,
      "step": 1096
    },
    {
      "epoch": 0.6608433734939759,
      "grad_norm": 0.7308663725852966,
      "learning_rate": 4.17394578313253e-06,
      "loss": 0.3302,
      "step": 1097
    },
    {
      "epoch": 0.6614457831325301,
      "grad_norm": 0.7004818320274353,
      "learning_rate": 4.173192771084338e-06,
      "loss": 0.386,
      "step": 1098
    },
    {
      "epoch": 0.6620481927710843,
      "grad_norm": 0.7053731679916382,
      "learning_rate": 4.1724397590361446e-06,
      "loss": 0.3731,
      "step": 1099
    },
    {
      "epoch": 0.6626506024096386,
      "grad_norm": 0.696440577507019,
      "learning_rate": 4.171686746987952e-06,
      "loss": 0.37,
      "step": 1100
    },
    {
      "epoch": 0.6632530120481928,
      "grad_norm": 0.7520250082015991,
      "learning_rate": 4.170933734939759e-06,
      "loss": 0.3468,
      "step": 1101
    },
    {
      "epoch": 0.6638554216867469,
      "grad_norm": 0.7111615538597107,
      "learning_rate": 4.170180722891566e-06,
      "loss": 0.3994,
      "step": 1102
    },
    {
      "epoch": 0.6644578313253012,
      "grad_norm": 0.7460950613021851,
      "learning_rate": 4.169427710843374e-06,
      "loss": 0.363,
      "step": 1103
    },
    {
      "epoch": 0.6650602409638554,
      "grad_norm": 0.7063286304473877,
      "learning_rate": 4.168674698795181e-06,
      "loss": 0.3828,
      "step": 1104
    },
    {
      "epoch": 0.6656626506024096,
      "grad_norm": 0.7418696284294128,
      "learning_rate": 4.167921686746989e-06,
      "loss": 0.3591,
      "step": 1105
    },
    {
      "epoch": 0.6662650602409639,
      "grad_norm": 0.6723604202270508,
      "learning_rate": 4.167168674698796e-06,
      "loss": 0.3364,
      "step": 1106
    },
    {
      "epoch": 0.6668674698795181,
      "grad_norm": 0.7255706191062927,
      "learning_rate": 4.1664156626506025e-06,
      "loss": 0.3851,
      "step": 1107
    },
    {
      "epoch": 0.6674698795180722,
      "grad_norm": 0.7266241908073425,
      "learning_rate": 4.16566265060241e-06,
      "loss": 0.4126,
      "step": 1108
    },
    {
      "epoch": 0.6680722891566265,
      "grad_norm": 0.6823615431785583,
      "learning_rate": 4.164909638554217e-06,
      "loss": 0.3126,
      "step": 1109
    },
    {
      "epoch": 0.6686746987951807,
      "grad_norm": 0.778885543346405,
      "learning_rate": 4.164156626506025e-06,
      "loss": 0.4113,
      "step": 1110
    },
    {
      "epoch": 0.6692771084337349,
      "grad_norm": 0.7855172157287598,
      "learning_rate": 4.163403614457832e-06,
      "loss": 0.3496,
      "step": 1111
    },
    {
      "epoch": 0.6698795180722892,
      "grad_norm": 0.6871347427368164,
      "learning_rate": 4.162650602409639e-06,
      "loss": 0.3885,
      "step": 1112
    },
    {
      "epoch": 0.6704819277108434,
      "grad_norm": 0.7277586460113525,
      "learning_rate": 4.161897590361446e-06,
      "loss": 0.3714,
      "step": 1113
    },
    {
      "epoch": 0.6710843373493975,
      "grad_norm": 0.7606149911880493,
      "learning_rate": 4.1611445783132535e-06,
      "loss": 0.3092,
      "step": 1114
    },
    {
      "epoch": 0.6716867469879518,
      "grad_norm": 0.670769214630127,
      "learning_rate": 4.1603915662650604e-06,
      "loss": 0.4058,
      "step": 1115
    },
    {
      "epoch": 0.672289156626506,
      "grad_norm": 0.6900104284286499,
      "learning_rate": 4.159638554216867e-06,
      "loss": 0.409,
      "step": 1116
    },
    {
      "epoch": 0.6728915662650602,
      "grad_norm": 0.7318465113639832,
      "learning_rate": 4.158885542168675e-06,
      "loss": 0.3566,
      "step": 1117
    },
    {
      "epoch": 0.6734939759036145,
      "grad_norm": 0.6790814995765686,
      "learning_rate": 4.158132530120482e-06,
      "loss": 0.3671,
      "step": 1118
    },
    {
      "epoch": 0.6740963855421687,
      "grad_norm": 0.6595885753631592,
      "learning_rate": 4.157379518072289e-06,
      "loss": 0.3269,
      "step": 1119
    },
    {
      "epoch": 0.6746987951807228,
      "grad_norm": 0.6600633263587952,
      "learning_rate": 4.156626506024097e-06,
      "loss": 0.4118,
      "step": 1120
    },
    {
      "epoch": 0.6753012048192771,
      "grad_norm": 0.7100929617881775,
      "learning_rate": 4.155873493975904e-06,
      "loss": 0.3744,
      "step": 1121
    },
    {
      "epoch": 0.6759036144578313,
      "grad_norm": 0.6811153888702393,
      "learning_rate": 4.1551204819277115e-06,
      "loss": 0.3597,
      "step": 1122
    },
    {
      "epoch": 0.6765060240963855,
      "grad_norm": 0.6813244819641113,
      "learning_rate": 4.154367469879518e-06,
      "loss": 0.365,
      "step": 1123
    },
    {
      "epoch": 0.6771084337349398,
      "grad_norm": 1.015429973602295,
      "learning_rate": 4.153614457831326e-06,
      "loss": 0.3578,
      "step": 1124
    },
    {
      "epoch": 0.677710843373494,
      "grad_norm": 0.7641411423683167,
      "learning_rate": 4.152861445783133e-06,
      "loss": 0.3867,
      "step": 1125
    },
    {
      "epoch": 0.6783132530120481,
      "grad_norm": 0.6677541136741638,
      "learning_rate": 4.15210843373494e-06,
      "loss": 0.3365,
      "step": 1126
    },
    {
      "epoch": 0.6789156626506024,
      "grad_norm": 0.7072002291679382,
      "learning_rate": 4.151355421686748e-06,
      "loss": 0.3471,
      "step": 1127
    },
    {
      "epoch": 0.6795180722891566,
      "grad_norm": 0.7066214084625244,
      "learning_rate": 4.150602409638555e-06,
      "loss": 0.3671,
      "step": 1128
    },
    {
      "epoch": 0.6801204819277108,
      "grad_norm": 0.6892730593681335,
      "learning_rate": 4.149849397590362e-06,
      "loss": 0.3155,
      "step": 1129
    },
    {
      "epoch": 0.6807228915662651,
      "grad_norm": 0.7690296173095703,
      "learning_rate": 4.149096385542169e-06,
      "loss": 0.3431,
      "step": 1130
    },
    {
      "epoch": 0.6813253012048193,
      "grad_norm": 0.7405403852462769,
      "learning_rate": 4.148343373493976e-06,
      "loss": 0.4033,
      "step": 1131
    },
    {
      "epoch": 0.6819277108433734,
      "grad_norm": 0.6929907202720642,
      "learning_rate": 4.147590361445783e-06,
      "loss": 0.3994,
      "step": 1132
    },
    {
      "epoch": 0.6825301204819277,
      "grad_norm": 0.6948909759521484,
      "learning_rate": 4.14683734939759e-06,
      "loss": 0.3513,
      "step": 1133
    },
    {
      "epoch": 0.6831325301204819,
      "grad_norm": 0.7331668138504028,
      "learning_rate": 4.146084337349398e-06,
      "loss": 0.3418,
      "step": 1134
    },
    {
      "epoch": 0.6837349397590361,
      "grad_norm": 0.7278557419776917,
      "learning_rate": 4.145331325301205e-06,
      "loss": 0.3969,
      "step": 1135
    },
    {
      "epoch": 0.6843373493975904,
      "grad_norm": 0.7604015469551086,
      "learning_rate": 4.144578313253013e-06,
      "loss": 0.389,
      "step": 1136
    },
    {
      "epoch": 0.6849397590361446,
      "grad_norm": 0.6164882779121399,
      "learning_rate": 4.1438253012048196e-06,
      "loss": 0.3412,
      "step": 1137
    },
    {
      "epoch": 0.6855421686746987,
      "grad_norm": 0.6567646265029907,
      "learning_rate": 4.1430722891566265e-06,
      "loss": 0.3479,
      "step": 1138
    },
    {
      "epoch": 0.686144578313253,
      "grad_norm": 0.751112163066864,
      "learning_rate": 4.142319277108434e-06,
      "loss": 0.3833,
      "step": 1139
    },
    {
      "epoch": 0.6867469879518072,
      "grad_norm": 0.7280837297439575,
      "learning_rate": 4.141566265060241e-06,
      "loss": 0.3462,
      "step": 1140
    },
    {
      "epoch": 0.6873493975903614,
      "grad_norm": 0.7169371247291565,
      "learning_rate": 4.140813253012049e-06,
      "loss": 0.3274,
      "step": 1141
    },
    {
      "epoch": 0.6879518072289157,
      "grad_norm": 0.7110101580619812,
      "learning_rate": 4.140060240963856e-06,
      "loss": 0.3015,
      "step": 1142
    },
    {
      "epoch": 0.6885542168674699,
      "grad_norm": 0.9400873184204102,
      "learning_rate": 4.139307228915663e-06,
      "loss": 0.3982,
      "step": 1143
    },
    {
      "epoch": 0.689156626506024,
      "grad_norm": 0.6203580498695374,
      "learning_rate": 4.138554216867471e-06,
      "loss": 0.3072,
      "step": 1144
    },
    {
      "epoch": 0.6897590361445783,
      "grad_norm": 0.7553263306617737,
      "learning_rate": 4.1378012048192775e-06,
      "loss": 0.3164,
      "step": 1145
    },
    {
      "epoch": 0.6903614457831325,
      "grad_norm": 1.0292719602584839,
      "learning_rate": 4.1370481927710844e-06,
      "loss": 0.3628,
      "step": 1146
    },
    {
      "epoch": 0.6909638554216867,
      "grad_norm": 0.6488680839538574,
      "learning_rate": 4.136295180722892e-06,
      "loss": 0.3104,
      "step": 1147
    },
    {
      "epoch": 0.691566265060241,
      "grad_norm": 0.6610344052314758,
      "learning_rate": 4.135542168674699e-06,
      "loss": 0.3491,
      "step": 1148
    },
    {
      "epoch": 0.6921686746987952,
      "grad_norm": 0.7640371322631836,
      "learning_rate": 4.134789156626506e-06,
      "loss": 0.3505,
      "step": 1149
    },
    {
      "epoch": 0.6927710843373494,
      "grad_norm": 0.620290994644165,
      "learning_rate": 4.134036144578313e-06,
      "loss": 0.3782,
      "step": 1150
    },
    {
      "epoch": 0.6933734939759036,
      "grad_norm": 0.6953434944152832,
      "learning_rate": 4.133283132530121e-06,
      "loss": 0.3064,
      "step": 1151
    },
    {
      "epoch": 0.6939759036144578,
      "grad_norm": 0.7066259980201721,
      "learning_rate": 4.132530120481928e-06,
      "loss": 0.3342,
      "step": 1152
    },
    {
      "epoch": 0.694578313253012,
      "grad_norm": 0.6773651242256165,
      "learning_rate": 4.1317771084337355e-06,
      "loss": 0.3597,
      "step": 1153
    },
    {
      "epoch": 0.6951807228915663,
      "grad_norm": 0.7076932787895203,
      "learning_rate": 4.131024096385542e-06,
      "loss": 0.3609,
      "step": 1154
    },
    {
      "epoch": 0.6957831325301205,
      "grad_norm": 0.7089959979057312,
      "learning_rate": 4.130271084337349e-06,
      "loss": 0.3563,
      "step": 1155
    },
    {
      "epoch": 0.6963855421686747,
      "grad_norm": 0.6806254386901855,
      "learning_rate": 4.129518072289157e-06,
      "loss": 0.3526,
      "step": 1156
    },
    {
      "epoch": 0.696987951807229,
      "grad_norm": 0.7032434940338135,
      "learning_rate": 4.128765060240964e-06,
      "loss": 0.403,
      "step": 1157
    },
    {
      "epoch": 0.6975903614457831,
      "grad_norm": 0.7432276010513306,
      "learning_rate": 4.128012048192772e-06,
      "loss": 0.3602,
      "step": 1158
    },
    {
      "epoch": 0.6981927710843373,
      "grad_norm": 0.7304036021232605,
      "learning_rate": 4.127259036144579e-06,
      "loss": 0.3009,
      "step": 1159
    },
    {
      "epoch": 0.6987951807228916,
      "grad_norm": 0.7010596394538879,
      "learning_rate": 4.1265060240963865e-06,
      "loss": 0.3872,
      "step": 1160
    },
    {
      "epoch": 0.6993975903614458,
      "grad_norm": 0.6451774835586548,
      "learning_rate": 4.125753012048193e-06,
      "loss": 0.3303,
      "step": 1161
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.7344850897789001,
      "learning_rate": 4.125e-06,
      "loss": 0.3365,
      "step": 1162
    },
    {
      "epoch": 0.7006024096385542,
      "grad_norm": 0.6735291481018066,
      "learning_rate": 4.124246987951808e-06,
      "loss": 0.3422,
      "step": 1163
    },
    {
      "epoch": 0.7012048192771084,
      "grad_norm": 0.7351776957511902,
      "learning_rate": 4.123493975903615e-06,
      "loss": 0.3286,
      "step": 1164
    },
    {
      "epoch": 0.7018072289156626,
      "grad_norm": 0.7131130695343018,
      "learning_rate": 4.122740963855422e-06,
      "loss": 0.3224,
      "step": 1165
    },
    {
      "epoch": 0.7024096385542169,
      "grad_norm": 0.721572995185852,
      "learning_rate": 4.121987951807229e-06,
      "loss": 0.4132,
      "step": 1166
    },
    {
      "epoch": 0.7030120481927711,
      "grad_norm": 0.6213558316230774,
      "learning_rate": 4.121234939759037e-06,
      "loss": 0.3347,
      "step": 1167
    },
    {
      "epoch": 0.7036144578313253,
      "grad_norm": 0.6109111905097961,
      "learning_rate": 4.1204819277108436e-06,
      "loss": 0.3366,
      "step": 1168
    },
    {
      "epoch": 0.7042168674698795,
      "grad_norm": 0.7020894885063171,
      "learning_rate": 4.1197289156626505e-06,
      "loss": 0.2927,
      "step": 1169
    },
    {
      "epoch": 0.7048192771084337,
      "grad_norm": 0.6216098666191101,
      "learning_rate": 4.118975903614458e-06,
      "loss": 0.3395,
      "step": 1170
    },
    {
      "epoch": 0.7054216867469879,
      "grad_norm": 0.7292430400848389,
      "learning_rate": 4.118222891566265e-06,
      "loss": 0.3357,
      "step": 1171
    },
    {
      "epoch": 0.7060240963855422,
      "grad_norm": 0.623601496219635,
      "learning_rate": 4.117469879518073e-06,
      "loss": 0.3507,
      "step": 1172
    },
    {
      "epoch": 0.7066265060240964,
      "grad_norm": 0.7319486737251282,
      "learning_rate": 4.11671686746988e-06,
      "loss": 0.3318,
      "step": 1173
    },
    {
      "epoch": 0.7072289156626506,
      "grad_norm": 0.6480372548103333,
      "learning_rate": 4.115963855421687e-06,
      "loss": 0.3055,
      "step": 1174
    },
    {
      "epoch": 0.7078313253012049,
      "grad_norm": 0.6781510710716248,
      "learning_rate": 4.1152108433734946e-06,
      "loss": 0.2998,
      "step": 1175
    },
    {
      "epoch": 0.708433734939759,
      "grad_norm": 0.6410520672798157,
      "learning_rate": 4.1144578313253015e-06,
      "loss": 0.3968,
      "step": 1176
    },
    {
      "epoch": 0.7090361445783132,
      "grad_norm": 0.6358199715614319,
      "learning_rate": 4.113704819277109e-06,
      "loss": 0.34,
      "step": 1177
    },
    {
      "epoch": 0.7096385542168675,
      "grad_norm": 0.7137256264686584,
      "learning_rate": 4.112951807228916e-06,
      "loss": 0.3963,
      "step": 1178
    },
    {
      "epoch": 0.7102409638554217,
      "grad_norm": 0.6148025393486023,
      "learning_rate": 4.112198795180723e-06,
      "loss": 0.3359,
      "step": 1179
    },
    {
      "epoch": 0.7108433734939759,
      "grad_norm": 0.6833720803260803,
      "learning_rate": 4.111445783132531e-06,
      "loss": 0.3038,
      "step": 1180
    },
    {
      "epoch": 0.7114457831325302,
      "grad_norm": 0.652373194694519,
      "learning_rate": 4.110692771084338e-06,
      "loss": 0.3189,
      "step": 1181
    },
    {
      "epoch": 0.7120481927710843,
      "grad_norm": 0.6954135298728943,
      "learning_rate": 4.109939759036145e-06,
      "loss": 0.3747,
      "step": 1182
    },
    {
      "epoch": 0.7126506024096385,
      "grad_norm": 0.6136237382888794,
      "learning_rate": 4.109186746987952e-06,
      "loss": 0.3256,
      "step": 1183
    },
    {
      "epoch": 0.7132530120481928,
      "grad_norm": 0.6680583357810974,
      "learning_rate": 4.1084337349397594e-06,
      "loss": 0.3209,
      "step": 1184
    },
    {
      "epoch": 0.713855421686747,
      "grad_norm": 0.6853963732719421,
      "learning_rate": 4.107680722891566e-06,
      "loss": 0.3427,
      "step": 1185
    },
    {
      "epoch": 0.7144578313253012,
      "grad_norm": 0.7339667677879333,
      "learning_rate": 4.106927710843373e-06,
      "loss": 0.3551,
      "step": 1186
    },
    {
      "epoch": 0.7150602409638555,
      "grad_norm": 0.6828790307044983,
      "learning_rate": 4.106174698795181e-06,
      "loss": 0.3298,
      "step": 1187
    },
    {
      "epoch": 0.7156626506024096,
      "grad_norm": 0.6640404462814331,
      "learning_rate": 4.105421686746988e-06,
      "loss": 0.3413,
      "step": 1188
    },
    {
      "epoch": 0.7162650602409638,
      "grad_norm": 0.6555465459823608,
      "learning_rate": 4.104668674698796e-06,
      "loss": 0.3568,
      "step": 1189
    },
    {
      "epoch": 0.7168674698795181,
      "grad_norm": 0.6330344676971436,
      "learning_rate": 4.103915662650603e-06,
      "loss": 0.3785,
      "step": 1190
    },
    {
      "epoch": 0.7174698795180723,
      "grad_norm": 0.7714635133743286,
      "learning_rate": 4.10316265060241e-06,
      "loss": 0.3351,
      "step": 1191
    },
    {
      "epoch": 0.7180722891566265,
      "grad_norm": 0.5968729257583618,
      "learning_rate": 4.102409638554217e-06,
      "loss": 0.3414,
      "step": 1192
    },
    {
      "epoch": 0.7186746987951808,
      "grad_norm": 0.701184868812561,
      "learning_rate": 4.101656626506024e-06,
      "loss": 0.3549,
      "step": 1193
    },
    {
      "epoch": 0.7192771084337349,
      "grad_norm": 0.7470781207084656,
      "learning_rate": 4.100903614457832e-06,
      "loss": 0.3848,
      "step": 1194
    },
    {
      "epoch": 0.7198795180722891,
      "grad_norm": 0.6938418745994568,
      "learning_rate": 4.100150602409639e-06,
      "loss": 0.3468,
      "step": 1195
    },
    {
      "epoch": 0.7204819277108434,
      "grad_norm": 0.7974057793617249,
      "learning_rate": 4.099397590361447e-06,
      "loss": 0.3347,
      "step": 1196
    },
    {
      "epoch": 0.7210843373493976,
      "grad_norm": 0.6201475858688354,
      "learning_rate": 4.098644578313254e-06,
      "loss": 0.35,
      "step": 1197
    },
    {
      "epoch": 0.7216867469879518,
      "grad_norm": 0.6616216897964478,
      "learning_rate": 4.097891566265061e-06,
      "loss": 0.3663,
      "step": 1198
    },
    {
      "epoch": 0.7222891566265061,
      "grad_norm": 0.6222080588340759,
      "learning_rate": 4.0971385542168675e-06,
      "loss": 0.3827,
      "step": 1199
    },
    {
      "epoch": 0.7228915662650602,
      "grad_norm": 0.7219311594963074,
      "learning_rate": 4.096385542168675e-06,
      "loss": 0.3148,
      "step": 1200
    },
    {
      "epoch": 0.7234939759036144,
      "grad_norm": 0.6741011142730713,
      "learning_rate": 4.095632530120482e-06,
      "loss": 0.2849,
      "step": 1201
    },
    {
      "epoch": 0.7240963855421687,
      "grad_norm": 0.5965597033500671,
      "learning_rate": 4.094879518072289e-06,
      "loss": 0.35,
      "step": 1202
    },
    {
      "epoch": 0.7246987951807229,
      "grad_norm": 0.668911874294281,
      "learning_rate": 4.094126506024096e-06,
      "loss": 0.3449,
      "step": 1203
    },
    {
      "epoch": 0.7253012048192771,
      "grad_norm": 0.7351496815681458,
      "learning_rate": 4.093373493975904e-06,
      "loss": 0.3032,
      "step": 1204
    },
    {
      "epoch": 0.7259036144578314,
      "grad_norm": 0.734277069568634,
      "learning_rate": 4.092620481927711e-06,
      "loss": 0.3129,
      "step": 1205
    },
    {
      "epoch": 0.7265060240963855,
      "grad_norm": 0.6762212514877319,
      "learning_rate": 4.0918674698795186e-06,
      "loss": 0.3445,
      "step": 1206
    },
    {
      "epoch": 0.7271084337349397,
      "grad_norm": 0.6043711304664612,
      "learning_rate": 4.0911144578313255e-06,
      "loss": 0.302,
      "step": 1207
    },
    {
      "epoch": 0.727710843373494,
      "grad_norm": 0.7071713805198669,
      "learning_rate": 4.090361445783133e-06,
      "loss": 0.3625,
      "step": 1208
    },
    {
      "epoch": 0.7283132530120482,
      "grad_norm": 0.6860135793685913,
      "learning_rate": 4.08960843373494e-06,
      "loss": 0.3121,
      "step": 1209
    },
    {
      "epoch": 0.7289156626506024,
      "grad_norm": 0.6108654141426086,
      "learning_rate": 4.088855421686747e-06,
      "loss": 0.343,
      "step": 1210
    },
    {
      "epoch": 0.7295180722891567,
      "grad_norm": 0.6414788961410522,
      "learning_rate": 4.088102409638555e-06,
      "loss": 0.3439,
      "step": 1211
    },
    {
      "epoch": 0.7301204819277108,
      "grad_norm": 0.7130690813064575,
      "learning_rate": 4.087349397590362e-06,
      "loss": 0.2978,
      "step": 1212
    },
    {
      "epoch": 0.730722891566265,
      "grad_norm": 0.6224998831748962,
      "learning_rate": 4.08659638554217e-06,
      "loss": 0.3222,
      "step": 1213
    },
    {
      "epoch": 0.7313253012048193,
      "grad_norm": 0.8036806583404541,
      "learning_rate": 4.0858433734939765e-06,
      "loss": 0.3328,
      "step": 1214
    },
    {
      "epoch": 0.7319277108433735,
      "grad_norm": 0.6677924394607544,
      "learning_rate": 4.0850903614457834e-06,
      "loss": 0.3764,
      "step": 1215
    },
    {
      "epoch": 0.7325301204819277,
      "grad_norm": 0.668714165687561,
      "learning_rate": 4.08433734939759e-06,
      "loss": 0.3109,
      "step": 1216
    },
    {
      "epoch": 0.733132530120482,
      "grad_norm": 0.6950169205665588,
      "learning_rate": 4.083584337349398e-06,
      "loss": 0.3176,
      "step": 1217
    },
    {
      "epoch": 0.7337349397590361,
      "grad_norm": 0.6632584929466248,
      "learning_rate": 4.082831325301205e-06,
      "loss": 0.2972,
      "step": 1218
    },
    {
      "epoch": 0.7343373493975903,
      "grad_norm": 0.5953941941261292,
      "learning_rate": 4.082078313253012e-06,
      "loss": 0.3168,
      "step": 1219
    },
    {
      "epoch": 0.7349397590361446,
      "grad_norm": 0.6645527482032776,
      "learning_rate": 4.08132530120482e-06,
      "loss": 0.2851,
      "step": 1220
    },
    {
      "epoch": 0.7355421686746988,
      "grad_norm": 0.60289067029953,
      "learning_rate": 4.080572289156627e-06,
      "loss": 0.3366,
      "step": 1221
    },
    {
      "epoch": 0.736144578313253,
      "grad_norm": 0.5942919850349426,
      "learning_rate": 4.079819277108434e-06,
      "loss": 0.3299,
      "step": 1222
    },
    {
      "epoch": 0.7367469879518073,
      "grad_norm": 0.6865565776824951,
      "learning_rate": 4.079066265060241e-06,
      "loss": 0.346,
      "step": 1223
    },
    {
      "epoch": 0.7373493975903614,
      "grad_norm": 0.6602187752723694,
      "learning_rate": 4.078313253012048e-06,
      "loss": 0.3096,
      "step": 1224
    },
    {
      "epoch": 0.7379518072289156,
      "grad_norm": 0.6692097187042236,
      "learning_rate": 4.077560240963856e-06,
      "loss": 0.3027,
      "step": 1225
    },
    {
      "epoch": 0.7385542168674699,
      "grad_norm": 0.6158462762832642,
      "learning_rate": 4.076807228915663e-06,
      "loss": 0.3304,
      "step": 1226
    },
    {
      "epoch": 0.7391566265060241,
      "grad_norm": 0.5837892889976501,
      "learning_rate": 4.07605421686747e-06,
      "loss": 0.3737,
      "step": 1227
    },
    {
      "epoch": 0.7397590361445783,
      "grad_norm": 0.6340808868408203,
      "learning_rate": 4.075301204819278e-06,
      "loss": 0.3235,
      "step": 1228
    },
    {
      "epoch": 0.7403614457831326,
      "grad_norm": 0.6484788656234741,
      "learning_rate": 4.074548192771085e-06,
      "loss": 0.3505,
      "step": 1229
    },
    {
      "epoch": 0.7409638554216867,
      "grad_norm": 0.6695238351821899,
      "learning_rate": 4.073795180722892e-06,
      "loss": 0.2948,
      "step": 1230
    },
    {
      "epoch": 0.7415662650602409,
      "grad_norm": 0.7171471118927002,
      "learning_rate": 4.073042168674699e-06,
      "loss": 0.2863,
      "step": 1231
    },
    {
      "epoch": 0.7421686746987952,
      "grad_norm": 0.6523705720901489,
      "learning_rate": 4.072289156626506e-06,
      "loss": 0.3555,
      "step": 1232
    },
    {
      "epoch": 0.7427710843373494,
      "grad_norm": 0.6911658048629761,
      "learning_rate": 4.071536144578314e-06,
      "loss": 0.3182,
      "step": 1233
    },
    {
      "epoch": 0.7433734939759036,
      "grad_norm": 0.6740326285362244,
      "learning_rate": 4.070783132530121e-06,
      "loss": 0.3447,
      "step": 1234
    },
    {
      "epoch": 0.7439759036144579,
      "grad_norm": 0.6500383019447327,
      "learning_rate": 4.070030120481928e-06,
      "loss": 0.3325,
      "step": 1235
    },
    {
      "epoch": 0.744578313253012,
      "grad_norm": 0.6544352173805237,
      "learning_rate": 4.069277108433735e-06,
      "loss": 0.355,
      "step": 1236
    },
    {
      "epoch": 0.7451807228915662,
      "grad_norm": 0.6897818446159363,
      "learning_rate": 4.0685240963855426e-06,
      "loss": 0.3739,
      "step": 1237
    },
    {
      "epoch": 0.7457831325301205,
      "grad_norm": 0.6634519696235657,
      "learning_rate": 4.0677710843373495e-06,
      "loss": 0.3493,
      "step": 1238
    },
    {
      "epoch": 0.7463855421686747,
      "grad_norm": 0.6979337334632874,
      "learning_rate": 4.067018072289156e-06,
      "loss": 0.3073,
      "step": 1239
    },
    {
      "epoch": 0.7469879518072289,
      "grad_norm": 0.6326096057891846,
      "learning_rate": 4.066265060240964e-06,
      "loss": 0.3461,
      "step": 1240
    },
    {
      "epoch": 0.7475903614457832,
      "grad_norm": 0.6902734637260437,
      "learning_rate": 4.065512048192771e-06,
      "loss": 0.3577,
      "step": 1241
    },
    {
      "epoch": 0.7481927710843373,
      "grad_norm": 0.6940042972564697,
      "learning_rate": 4.064759036144579e-06,
      "loss": 0.2946,
      "step": 1242
    },
    {
      "epoch": 0.7487951807228915,
      "grad_norm": 0.6150743365287781,
      "learning_rate": 4.064006024096386e-06,
      "loss": 0.2932,
      "step": 1243
    },
    {
      "epoch": 0.7493975903614458,
      "grad_norm": 0.658450186252594,
      "learning_rate": 4.0632530120481936e-06,
      "loss": 0.352,
      "step": 1244
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6391847729682922,
      "learning_rate": 4.0625000000000005e-06,
      "loss": 0.3485,
      "step": 1245
    },
    {
      "epoch": 0.7506024096385542,
      "grad_norm": 0.6489208936691284,
      "learning_rate": 4.061746987951807e-06,
      "loss": 0.2848,
      "step": 1246
    },
    {
      "epoch": 0.7512048192771085,
      "grad_norm": 0.6270966529846191,
      "learning_rate": 4.060993975903615e-06,
      "loss": 0.3369,
      "step": 1247
    },
    {
      "epoch": 0.7518072289156627,
      "grad_norm": 0.6907310485839844,
      "learning_rate": 4.060240963855422e-06,
      "loss": 0.3489,
      "step": 1248
    },
    {
      "epoch": 0.7524096385542168,
      "grad_norm": 1.1850091218948364,
      "learning_rate": 4.059487951807229e-06,
      "loss": 0.3561,
      "step": 1249
    },
    {
      "epoch": 0.7530120481927711,
      "grad_norm": 0.7083243727684021,
      "learning_rate": 4.058734939759037e-06,
      "loss": 0.3195,
      "step": 1250
    },
    {
      "epoch": 0.7536144578313253,
      "grad_norm": 0.5743643641471863,
      "learning_rate": 4.057981927710844e-06,
      "loss": 0.3168,
      "step": 1251
    },
    {
      "epoch": 0.7542168674698795,
      "grad_norm": 0.6494764685630798,
      "learning_rate": 4.057228915662651e-06,
      "loss": 0.2677,
      "step": 1252
    },
    {
      "epoch": 0.7548192771084338,
      "grad_norm": 0.7561531662940979,
      "learning_rate": 4.056475903614458e-06,
      "loss": 0.3795,
      "step": 1253
    },
    {
      "epoch": 0.755421686746988,
      "grad_norm": 0.6723291873931885,
      "learning_rate": 4.055722891566265e-06,
      "loss": 0.3302,
      "step": 1254
    },
    {
      "epoch": 0.7560240963855421,
      "grad_norm": 0.6667733788490295,
      "learning_rate": 4.054969879518072e-06,
      "loss": 0.2821,
      "step": 1255
    },
    {
      "epoch": 0.7566265060240964,
      "grad_norm": 0.7143755555152893,
      "learning_rate": 4.05421686746988e-06,
      "loss": 0.3104,
      "step": 1256
    },
    {
      "epoch": 0.7572289156626506,
      "grad_norm": 0.6921657919883728,
      "learning_rate": 4.053463855421687e-06,
      "loss": 0.3804,
      "step": 1257
    },
    {
      "epoch": 0.7578313253012048,
      "grad_norm": 0.669330358505249,
      "learning_rate": 4.052710843373494e-06,
      "loss": 0.3321,
      "step": 1258
    },
    {
      "epoch": 0.7584337349397591,
      "grad_norm": 0.6456053853034973,
      "learning_rate": 4.051957831325302e-06,
      "loss": 0.3194,
      "step": 1259
    },
    {
      "epoch": 0.7590361445783133,
      "grad_norm": 0.6776100397109985,
      "learning_rate": 4.051204819277109e-06,
      "loss": 0.359,
      "step": 1260
    },
    {
      "epoch": 0.7596385542168674,
      "grad_norm": 0.6884143352508545,
      "learning_rate": 4.050451807228916e-06,
      "loss": 0.2858,
      "step": 1261
    },
    {
      "epoch": 0.7602409638554217,
      "grad_norm": 0.6576393246650696,
      "learning_rate": 4.049698795180723e-06,
      "loss": 0.2583,
      "step": 1262
    },
    {
      "epoch": 0.7608433734939759,
      "grad_norm": 0.6169259548187256,
      "learning_rate": 4.048945783132531e-06,
      "loss": 0.3293,
      "step": 1263
    },
    {
      "epoch": 0.7614457831325301,
      "grad_norm": 0.7015711665153503,
      "learning_rate": 4.048192771084338e-06,
      "loss": 0.3093,
      "step": 1264
    },
    {
      "epoch": 0.7620481927710844,
      "grad_norm": 0.7525081038475037,
      "learning_rate": 4.047439759036145e-06,
      "loss": 0.3532,
      "step": 1265
    },
    {
      "epoch": 0.7626506024096386,
      "grad_norm": 0.6522400975227356,
      "learning_rate": 4.046686746987953e-06,
      "loss": 0.3476,
      "step": 1266
    },
    {
      "epoch": 0.7632530120481927,
      "grad_norm": 0.664547860622406,
      "learning_rate": 4.04593373493976e-06,
      "loss": 0.3235,
      "step": 1267
    },
    {
      "epoch": 0.763855421686747,
      "grad_norm": 0.7088428735733032,
      "learning_rate": 4.0451807228915665e-06,
      "loss": 0.357,
      "step": 1268
    },
    {
      "epoch": 0.7644578313253012,
      "grad_norm": 0.7161743640899658,
      "learning_rate": 4.0444277108433735e-06,
      "loss": 0.3788,
      "step": 1269
    },
    {
      "epoch": 0.7650602409638554,
      "grad_norm": 0.708991289138794,
      "learning_rate": 4.043674698795181e-06,
      "loss": 0.3961,
      "step": 1270
    },
    {
      "epoch": 0.7656626506024097,
      "grad_norm": 0.5819255709648132,
      "learning_rate": 4.042921686746988e-06,
      "loss": 0.3212,
      "step": 1271
    },
    {
      "epoch": 0.7662650602409639,
      "grad_norm": 0.6390199065208435,
      "learning_rate": 4.042168674698795e-06,
      "loss": 0.285,
      "step": 1272
    },
    {
      "epoch": 0.766867469879518,
      "grad_norm": 0.6281388401985168,
      "learning_rate": 4.041415662650603e-06,
      "loss": 0.308,
      "step": 1273
    },
    {
      "epoch": 0.7674698795180723,
      "grad_norm": 0.6146369576454163,
      "learning_rate": 4.04066265060241e-06,
      "loss": 0.2811,
      "step": 1274
    },
    {
      "epoch": 0.7680722891566265,
      "grad_norm": 0.6472655534744263,
      "learning_rate": 4.0399096385542176e-06,
      "loss": 0.3232,
      "step": 1275
    },
    {
      "epoch": 0.7686746987951807,
      "grad_norm": 0.6446939706802368,
      "learning_rate": 4.0391566265060245e-06,
      "loss": 0.3973,
      "step": 1276
    },
    {
      "epoch": 0.769277108433735,
      "grad_norm": 0.7459872364997864,
      "learning_rate": 4.038403614457831e-06,
      "loss": 0.2581,
      "step": 1277
    },
    {
      "epoch": 0.7698795180722892,
      "grad_norm": 0.5861269235610962,
      "learning_rate": 4.037650602409639e-06,
      "loss": 0.3359,
      "step": 1278
    },
    {
      "epoch": 0.7704819277108433,
      "grad_norm": 0.7208502888679504,
      "learning_rate": 4.036897590361446e-06,
      "loss": 0.2926,
      "step": 1279
    },
    {
      "epoch": 0.7710843373493976,
      "grad_norm": 0.6178955435752869,
      "learning_rate": 4.036144578313254e-06,
      "loss": 0.3464,
      "step": 1280
    },
    {
      "epoch": 0.7716867469879518,
      "grad_norm": 0.5934728384017944,
      "learning_rate": 4.035391566265061e-06,
      "loss": 0.3292,
      "step": 1281
    },
    {
      "epoch": 0.772289156626506,
      "grad_norm": 0.6801672577857971,
      "learning_rate": 4.034638554216868e-06,
      "loss": 0.2986,
      "step": 1282
    },
    {
      "epoch": 0.7728915662650603,
      "grad_norm": 0.6871153116226196,
      "learning_rate": 4.0338855421686755e-06,
      "loss": 0.3455,
      "step": 1283
    },
    {
      "epoch": 0.7734939759036145,
      "grad_norm": 0.6208491325378418,
      "learning_rate": 4.033132530120482e-06,
      "loss": 0.372,
      "step": 1284
    },
    {
      "epoch": 0.7740963855421686,
      "grad_norm": 0.7075480222702026,
      "learning_rate": 4.032379518072289e-06,
      "loss": 0.3297,
      "step": 1285
    },
    {
      "epoch": 0.7746987951807229,
      "grad_norm": 0.635271430015564,
      "learning_rate": 4.031626506024096e-06,
      "loss": 0.3145,
      "step": 1286
    },
    {
      "epoch": 0.7753012048192771,
      "grad_norm": 0.6504743099212646,
      "learning_rate": 4.030873493975904e-06,
      "loss": 0.3371,
      "step": 1287
    },
    {
      "epoch": 0.7759036144578313,
      "grad_norm": 0.602141797542572,
      "learning_rate": 4.030120481927711e-06,
      "loss": 0.3452,
      "step": 1288
    },
    {
      "epoch": 0.7765060240963856,
      "grad_norm": 0.8488123416900635,
      "learning_rate": 4.029367469879518e-06,
      "loss": 0.3245,
      "step": 1289
    },
    {
      "epoch": 0.7771084337349398,
      "grad_norm": 0.6632486581802368,
      "learning_rate": 4.028614457831326e-06,
      "loss": 0.3245,
      "step": 1290
    },
    {
      "epoch": 0.7777108433734939,
      "grad_norm": 0.7756630778312683,
      "learning_rate": 4.027861445783133e-06,
      "loss": 0.422,
      "step": 1291
    },
    {
      "epoch": 0.7783132530120482,
      "grad_norm": 0.6919595003128052,
      "learning_rate": 4.02710843373494e-06,
      "loss": 0.364,
      "step": 1292
    },
    {
      "epoch": 0.7789156626506024,
      "grad_norm": 0.6849520802497864,
      "learning_rate": 4.026355421686747e-06,
      "loss": 0.3094,
      "step": 1293
    },
    {
      "epoch": 0.7795180722891566,
      "grad_norm": 0.5789428949356079,
      "learning_rate": 4.025602409638554e-06,
      "loss": 0.3474,
      "step": 1294
    },
    {
      "epoch": 0.7801204819277109,
      "grad_norm": 0.6602098941802979,
      "learning_rate": 4.024849397590362e-06,
      "loss": 0.3607,
      "step": 1295
    },
    {
      "epoch": 0.7807228915662651,
      "grad_norm": 0.6475358009338379,
      "learning_rate": 4.024096385542169e-06,
      "loss": 0.3581,
      "step": 1296
    },
    {
      "epoch": 0.7813253012048192,
      "grad_norm": 0.651212751865387,
      "learning_rate": 4.023343373493977e-06,
      "loss": 0.3652,
      "step": 1297
    },
    {
      "epoch": 0.7819277108433735,
      "grad_norm": 0.6652516722679138,
      "learning_rate": 4.022590361445784e-06,
      "loss": 0.3228,
      "step": 1298
    },
    {
      "epoch": 0.7825301204819277,
      "grad_norm": 0.6539467573165894,
      "learning_rate": 4.021837349397591e-06,
      "loss": 0.3486,
      "step": 1299
    },
    {
      "epoch": 0.7831325301204819,
      "grad_norm": 0.6533969640731812,
      "learning_rate": 4.021084337349398e-06,
      "loss": 0.2901,
      "step": 1300
    },
    {
      "epoch": 0.7837349397590362,
      "grad_norm": 0.634690523147583,
      "learning_rate": 4.020331325301205e-06,
      "loss": 0.3735,
      "step": 1301
    },
    {
      "epoch": 0.7843373493975904,
      "grad_norm": 0.7488970756530762,
      "learning_rate": 4.019578313253012e-06,
      "loss": 0.36,
      "step": 1302
    },
    {
      "epoch": 0.7849397590361445,
      "grad_norm": 0.5960925221443176,
      "learning_rate": 4.01882530120482e-06,
      "loss": 0.358,
      "step": 1303
    },
    {
      "epoch": 0.7855421686746988,
      "grad_norm": 0.5976033806800842,
      "learning_rate": 4.018072289156627e-06,
      "loss": 0.3669,
      "step": 1304
    },
    {
      "epoch": 0.786144578313253,
      "grad_norm": 0.6645509600639343,
      "learning_rate": 4.017319277108434e-06,
      "loss": 0.3086,
      "step": 1305
    },
    {
      "epoch": 0.7867469879518072,
      "grad_norm": 0.6560782194137573,
      "learning_rate": 4.016566265060241e-06,
      "loss": 0.3251,
      "step": 1306
    },
    {
      "epoch": 0.7873493975903615,
      "grad_norm": 0.676472544670105,
      "learning_rate": 4.0158132530120485e-06,
      "loss": 0.3553,
      "step": 1307
    },
    {
      "epoch": 0.7879518072289157,
      "grad_norm": 0.681889533996582,
      "learning_rate": 4.015060240963855e-06,
      "loss": 0.3449,
      "step": 1308
    },
    {
      "epoch": 0.7885542168674698,
      "grad_norm": 0.6473820209503174,
      "learning_rate": 4.014307228915663e-06,
      "loss": 0.2772,
      "step": 1309
    },
    {
      "epoch": 0.7891566265060241,
      "grad_norm": 0.6822525262832642,
      "learning_rate": 4.01355421686747e-06,
      "loss": 0.35,
      "step": 1310
    },
    {
      "epoch": 0.7897590361445783,
      "grad_norm": 0.6748459339141846,
      "learning_rate": 4.012801204819278e-06,
      "loss": 0.2929,
      "step": 1311
    },
    {
      "epoch": 0.7903614457831325,
      "grad_norm": 0.7833793759346008,
      "learning_rate": 4.012048192771085e-06,
      "loss": 0.3312,
      "step": 1312
    },
    {
      "epoch": 0.7909638554216868,
      "grad_norm": 0.6330089569091797,
      "learning_rate": 4.011295180722892e-06,
      "loss": 0.296,
      "step": 1313
    },
    {
      "epoch": 0.791566265060241,
      "grad_norm": 0.6290909051895142,
      "learning_rate": 4.0105421686746995e-06,
      "loss": 0.2916,
      "step": 1314
    },
    {
      "epoch": 0.7921686746987951,
      "grad_norm": 0.621932864189148,
      "learning_rate": 4.009789156626506e-06,
      "loss": 0.3011,
      "step": 1315
    },
    {
      "epoch": 0.7927710843373494,
      "grad_norm": 0.5920501947402954,
      "learning_rate": 4.009036144578314e-06,
      "loss": 0.3105,
      "step": 1316
    },
    {
      "epoch": 0.7933734939759036,
      "grad_norm": 0.6105424761772156,
      "learning_rate": 4.008283132530121e-06,
      "loss": 0.3182,
      "step": 1317
    },
    {
      "epoch": 0.7939759036144578,
      "grad_norm": 0.6443378925323486,
      "learning_rate": 4.007530120481928e-06,
      "loss": 0.2722,
      "step": 1318
    },
    {
      "epoch": 0.7945783132530121,
      "grad_norm": 0.7080325484275818,
      "learning_rate": 4.006777108433735e-06,
      "loss": 0.3306,
      "step": 1319
    },
    {
      "epoch": 0.7951807228915663,
      "grad_norm": 0.6527564525604248,
      "learning_rate": 4.006024096385543e-06,
      "loss": 0.274,
      "step": 1320
    },
    {
      "epoch": 0.7957831325301205,
      "grad_norm": 0.7242480516433716,
      "learning_rate": 4.00527108433735e-06,
      "loss": 0.4003,
      "step": 1321
    },
    {
      "epoch": 0.7963855421686747,
      "grad_norm": 0.5978679060935974,
      "learning_rate": 4.0045180722891566e-06,
      "loss": 0.2801,
      "step": 1322
    },
    {
      "epoch": 0.7969879518072289,
      "grad_norm": 0.6306935548782349,
      "learning_rate": 4.003765060240964e-06,
      "loss": 0.3421,
      "step": 1323
    },
    {
      "epoch": 0.7975903614457831,
      "grad_norm": 0.6691349744796753,
      "learning_rate": 4.003012048192771e-06,
      "loss": 0.3128,
      "step": 1324
    },
    {
      "epoch": 0.7981927710843374,
      "grad_norm": 0.647977888584137,
      "learning_rate": 4.002259036144578e-06,
      "loss": 0.3286,
      "step": 1325
    },
    {
      "epoch": 0.7987951807228916,
      "grad_norm": 1.184637427330017,
      "learning_rate": 4.001506024096386e-06,
      "loss": 0.2958,
      "step": 1326
    },
    {
      "epoch": 0.7993975903614458,
      "grad_norm": 0.6447247862815857,
      "learning_rate": 4.000753012048193e-06,
      "loss": 0.2963,
      "step": 1327
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6623203158378601,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.2928,
      "step": 1328
    },
    {
      "epoch": 0.8006024096385542,
      "grad_norm": 0.6198915243148804,
      "learning_rate": 3.999246987951808e-06,
      "loss": 0.3408,
      "step": 1329
    },
    {
      "epoch": 0.8012048192771084,
      "grad_norm": 0.6455022096633911,
      "learning_rate": 3.9984939759036145e-06,
      "loss": 0.2948,
      "step": 1330
    },
    {
      "epoch": 0.8018072289156627,
      "grad_norm": 0.6096243262290955,
      "learning_rate": 3.997740963855422e-06,
      "loss": 0.2973,
      "step": 1331
    },
    {
      "epoch": 0.8024096385542169,
      "grad_norm": 0.6551714539527893,
      "learning_rate": 3.996987951807229e-06,
      "loss": 0.303,
      "step": 1332
    },
    {
      "epoch": 0.803012048192771,
      "grad_norm": 0.5947499871253967,
      "learning_rate": 3.996234939759037e-06,
      "loss": 0.3789,
      "step": 1333
    },
    {
      "epoch": 0.8036144578313253,
      "grad_norm": 0.6945600509643555,
      "learning_rate": 3.995481927710844e-06,
      "loss": 0.3604,
      "step": 1334
    },
    {
      "epoch": 0.8042168674698795,
      "grad_norm": 0.6528960466384888,
      "learning_rate": 3.994728915662651e-06,
      "loss": 0.315,
      "step": 1335
    },
    {
      "epoch": 0.8048192771084337,
      "grad_norm": 0.6938419342041016,
      "learning_rate": 3.993975903614459e-06,
      "loss": 0.3623,
      "step": 1336
    },
    {
      "epoch": 0.805421686746988,
      "grad_norm": 0.7271010875701904,
      "learning_rate": 3.9932228915662655e-06,
      "loss": 0.3815,
      "step": 1337
    },
    {
      "epoch": 0.8060240963855422,
      "grad_norm": 0.6007196307182312,
      "learning_rate": 3.9924698795180725e-06,
      "loss": 0.3279,
      "step": 1338
    },
    {
      "epoch": 0.8066265060240964,
      "grad_norm": 0.6569790244102478,
      "learning_rate": 3.991716867469879e-06,
      "loss": 0.3464,
      "step": 1339
    },
    {
      "epoch": 0.8072289156626506,
      "grad_norm": 0.5715174078941345,
      "learning_rate": 3.990963855421687e-06,
      "loss": 0.3426,
      "step": 1340
    },
    {
      "epoch": 0.8078313253012048,
      "grad_norm": 0.6090062260627747,
      "learning_rate": 3.990210843373494e-06,
      "loss": 0.2965,
      "step": 1341
    },
    {
      "epoch": 0.808433734939759,
      "grad_norm": 0.6832830309867859,
      "learning_rate": 3.989457831325301e-06,
      "loss": 0.3576,
      "step": 1342
    },
    {
      "epoch": 0.8090361445783133,
      "grad_norm": 0.5756262540817261,
      "learning_rate": 3.988704819277109e-06,
      "loss": 0.338,
      "step": 1343
    },
    {
      "epoch": 0.8096385542168675,
      "grad_norm": 0.7121894359588623,
      "learning_rate": 3.987951807228916e-06,
      "loss": 0.3454,
      "step": 1344
    },
    {
      "epoch": 0.8102409638554217,
      "grad_norm": 0.6715471148490906,
      "learning_rate": 3.9871987951807235e-06,
      "loss": 0.3194,
      "step": 1345
    },
    {
      "epoch": 0.810843373493976,
      "grad_norm": 0.6128184795379639,
      "learning_rate": 3.98644578313253e-06,
      "loss": 0.3511,
      "step": 1346
    },
    {
      "epoch": 0.8114457831325301,
      "grad_norm": 0.5705967545509338,
      "learning_rate": 3.985692771084338e-06,
      "loss": 0.3222,
      "step": 1347
    },
    {
      "epoch": 0.8120481927710843,
      "grad_norm": 0.8676145672798157,
      "learning_rate": 3.984939759036145e-06,
      "loss": 0.3241,
      "step": 1348
    },
    {
      "epoch": 0.8126506024096386,
      "grad_norm": 0.6677693724632263,
      "learning_rate": 3.984186746987952e-06,
      "loss": 0.3147,
      "step": 1349
    },
    {
      "epoch": 0.8132530120481928,
      "grad_norm": 0.6343680620193481,
      "learning_rate": 3.98343373493976e-06,
      "loss": 0.2766,
      "step": 1350
    },
    {
      "epoch": 0.813855421686747,
      "grad_norm": 0.6380179524421692,
      "learning_rate": 3.982680722891567e-06,
      "loss": 0.3411,
      "step": 1351
    },
    {
      "epoch": 0.8144578313253013,
      "grad_norm": 0.7448874711990356,
      "learning_rate": 3.981927710843374e-06,
      "loss": 0.2714,
      "step": 1352
    },
    {
      "epoch": 0.8150602409638554,
      "grad_norm": 0.5817899703979492,
      "learning_rate": 3.981174698795181e-06,
      "loss": 0.3023,
      "step": 1353
    },
    {
      "epoch": 0.8156626506024096,
      "grad_norm": 0.6787431240081787,
      "learning_rate": 3.980421686746988e-06,
      "loss": 0.3128,
      "step": 1354
    },
    {
      "epoch": 0.8162650602409639,
      "grad_norm": 0.6568396687507629,
      "learning_rate": 3.979668674698795e-06,
      "loss": 0.335,
      "step": 1355
    },
    {
      "epoch": 0.8168674698795181,
      "grad_norm": 0.6983189582824707,
      "learning_rate": 3.978915662650602e-06,
      "loss": 0.3446,
      "step": 1356
    },
    {
      "epoch": 0.8174698795180723,
      "grad_norm": 0.6015532612800598,
      "learning_rate": 3.97816265060241e-06,
      "loss": 0.3109,
      "step": 1357
    },
    {
      "epoch": 0.8180722891566266,
      "grad_norm": 0.5914849638938904,
      "learning_rate": 3.977409638554217e-06,
      "loss": 0.3249,
      "step": 1358
    },
    {
      "epoch": 0.8186746987951807,
      "grad_norm": 0.71555095911026,
      "learning_rate": 3.976656626506025e-06,
      "loss": 0.3231,
      "step": 1359
    },
    {
      "epoch": 0.8192771084337349,
      "grad_norm": 0.5725877285003662,
      "learning_rate": 3.975903614457832e-06,
      "loss": 0.3187,
      "step": 1360
    },
    {
      "epoch": 0.8198795180722892,
      "grad_norm": 0.5875887274742126,
      "learning_rate": 3.9751506024096385e-06,
      "loss": 0.3259,
      "step": 1361
    },
    {
      "epoch": 0.8204819277108434,
      "grad_norm": 0.6685592532157898,
      "learning_rate": 3.974397590361446e-06,
      "loss": 0.3446,
      "step": 1362
    },
    {
      "epoch": 0.8210843373493976,
      "grad_norm": 0.7394621968269348,
      "learning_rate": 3.973644578313253e-06,
      "loss": 0.2938,
      "step": 1363
    },
    {
      "epoch": 0.8216867469879519,
      "grad_norm": 0.6172720193862915,
      "learning_rate": 3.972891566265061e-06,
      "loss": 0.333,
      "step": 1364
    },
    {
      "epoch": 0.822289156626506,
      "grad_norm": 0.7247864007949829,
      "learning_rate": 3.972138554216868e-06,
      "loss": 0.3935,
      "step": 1365
    },
    {
      "epoch": 0.8228915662650602,
      "grad_norm": 0.6079726815223694,
      "learning_rate": 3.971385542168675e-06,
      "loss": 0.3449,
      "step": 1366
    },
    {
      "epoch": 0.8234939759036145,
      "grad_norm": 0.7315145134925842,
      "learning_rate": 3.970632530120483e-06,
      "loss": 0.2951,
      "step": 1367
    },
    {
      "epoch": 0.8240963855421687,
      "grad_norm": 0.6590251326560974,
      "learning_rate": 3.9698795180722895e-06,
      "loss": 0.3207,
      "step": 1368
    },
    {
      "epoch": 0.8246987951807229,
      "grad_norm": 0.5693491101264954,
      "learning_rate": 3.969126506024097e-06,
      "loss": 0.325,
      "step": 1369
    },
    {
      "epoch": 0.8253012048192772,
      "grad_norm": 0.6153811812400818,
      "learning_rate": 3.968373493975904e-06,
      "loss": 0.3441,
      "step": 1370
    },
    {
      "epoch": 0.8259036144578313,
      "grad_norm": 0.655285120010376,
      "learning_rate": 3.967620481927711e-06,
      "loss": 0.2918,
      "step": 1371
    },
    {
      "epoch": 0.8265060240963855,
      "grad_norm": 0.6623290181159973,
      "learning_rate": 3.966867469879518e-06,
      "loss": 0.3043,
      "step": 1372
    },
    {
      "epoch": 0.8271084337349398,
      "grad_norm": 0.6748846769332886,
      "learning_rate": 3.966114457831326e-06,
      "loss": 0.3411,
      "step": 1373
    },
    {
      "epoch": 0.827710843373494,
      "grad_norm": 0.6094885468482971,
      "learning_rate": 3.965361445783133e-06,
      "loss": 0.333,
      "step": 1374
    },
    {
      "epoch": 0.8283132530120482,
      "grad_norm": 0.6256977915763855,
      "learning_rate": 3.96460843373494e-06,
      "loss": 0.318,
      "step": 1375
    },
    {
      "epoch": 0.8289156626506025,
      "grad_norm": 0.6513076424598694,
      "learning_rate": 3.9638554216867475e-06,
      "loss": 0.2965,
      "step": 1376
    },
    {
      "epoch": 0.8295180722891566,
      "grad_norm": 0.6324112415313721,
      "learning_rate": 3.963102409638554e-06,
      "loss": 0.3367,
      "step": 1377
    },
    {
      "epoch": 0.8301204819277108,
      "grad_norm": 0.6135618090629578,
      "learning_rate": 3.962349397590361e-06,
      "loss": 0.3314,
      "step": 1378
    },
    {
      "epoch": 0.8307228915662651,
      "grad_norm": 0.5613499283790588,
      "learning_rate": 3.961596385542169e-06,
      "loss": 0.346,
      "step": 1379
    },
    {
      "epoch": 0.8313253012048193,
      "grad_norm": 0.6173573732376099,
      "learning_rate": 3.960843373493976e-06,
      "loss": 0.3029,
      "step": 1380
    },
    {
      "epoch": 0.8319277108433735,
      "grad_norm": 0.709518551826477,
      "learning_rate": 3.960090361445784e-06,
      "loss": 0.3342,
      "step": 1381
    },
    {
      "epoch": 0.8325301204819278,
      "grad_norm": 0.5617232918739319,
      "learning_rate": 3.959337349397591e-06,
      "loss": 0.3292,
      "step": 1382
    },
    {
      "epoch": 0.8331325301204819,
      "grad_norm": 0.5836560726165771,
      "learning_rate": 3.9585843373493985e-06,
      "loss": 0.2966,
      "step": 1383
    },
    {
      "epoch": 0.8337349397590361,
      "grad_norm": 0.6304729580879211,
      "learning_rate": 3.957831325301205e-06,
      "loss": 0.2599,
      "step": 1384
    },
    {
      "epoch": 0.8343373493975904,
      "grad_norm": 0.6626138091087341,
      "learning_rate": 3.957078313253012e-06,
      "loss": 0.3094,
      "step": 1385
    },
    {
      "epoch": 0.8349397590361446,
      "grad_norm": 0.6060118079185486,
      "learning_rate": 3.95632530120482e-06,
      "loss": 0.3356,
      "step": 1386
    },
    {
      "epoch": 0.8355421686746988,
      "grad_norm": 0.6764475703239441,
      "learning_rate": 3.955572289156627e-06,
      "loss": 0.3664,
      "step": 1387
    },
    {
      "epoch": 0.8361445783132531,
      "grad_norm": 0.6757855415344238,
      "learning_rate": 3.954819277108434e-06,
      "loss": 0.2997,
      "step": 1388
    },
    {
      "epoch": 0.8367469879518072,
      "grad_norm": 0.6430056095123291,
      "learning_rate": 3.954066265060241e-06,
      "loss": 0.3638,
      "step": 1389
    },
    {
      "epoch": 0.8373493975903614,
      "grad_norm": 0.5622665286064148,
      "learning_rate": 3.953313253012049e-06,
      "loss": 0.2752,
      "step": 1390
    },
    {
      "epoch": 0.8379518072289157,
      "grad_norm": 0.5215542316436768,
      "learning_rate": 3.9525602409638556e-06,
      "loss": 0.2612,
      "step": 1391
    },
    {
      "epoch": 0.8385542168674699,
      "grad_norm": 0.6023708581924438,
      "learning_rate": 3.9518072289156625e-06,
      "loss": 0.2939,
      "step": 1392
    },
    {
      "epoch": 0.8391566265060241,
      "grad_norm": 0.7536341547966003,
      "learning_rate": 3.95105421686747e-06,
      "loss": 0.3409,
      "step": 1393
    },
    {
      "epoch": 0.8397590361445784,
      "grad_norm": 0.6905057430267334,
      "learning_rate": 3.950301204819277e-06,
      "loss": 0.3499,
      "step": 1394
    },
    {
      "epoch": 0.8403614457831325,
      "grad_norm": 0.6328054070472717,
      "learning_rate": 3.949548192771085e-06,
      "loss": 0.357,
      "step": 1395
    },
    {
      "epoch": 0.8409638554216867,
      "grad_norm": 0.6260149478912354,
      "learning_rate": 3.948795180722892e-06,
      "loss": 0.2755,
      "step": 1396
    },
    {
      "epoch": 0.841566265060241,
      "grad_norm": 0.6167488694190979,
      "learning_rate": 3.948042168674699e-06,
      "loss": 0.3269,
      "step": 1397
    },
    {
      "epoch": 0.8421686746987952,
      "grad_norm": 0.6073984503746033,
      "learning_rate": 3.947289156626507e-06,
      "loss": 0.2726,
      "step": 1398
    },
    {
      "epoch": 0.8427710843373494,
      "grad_norm": 0.6297515034675598,
      "learning_rate": 3.9465361445783135e-06,
      "loss": 0.3181,
      "step": 1399
    },
    {
      "epoch": 0.8433734939759037,
      "grad_norm": 0.6830478310585022,
      "learning_rate": 3.945783132530121e-06,
      "loss": 0.34,
      "step": 1400
    },
    {
      "epoch": 0.8439759036144578,
      "grad_norm": 0.7903813123703003,
      "learning_rate": 3.945030120481928e-06,
      "loss": 0.3874,
      "step": 1401
    },
    {
      "epoch": 0.844578313253012,
      "grad_norm": 0.6101157069206238,
      "learning_rate": 3.944277108433735e-06,
      "loss": 0.3254,
      "step": 1402
    },
    {
      "epoch": 0.8451807228915663,
      "grad_norm": 0.6501947641372681,
      "learning_rate": 3.943524096385543e-06,
      "loss": 0.2942,
      "step": 1403
    },
    {
      "epoch": 0.8457831325301205,
      "grad_norm": 0.6793314814567566,
      "learning_rate": 3.94277108433735e-06,
      "loss": 0.349,
      "step": 1404
    },
    {
      "epoch": 0.8463855421686747,
      "grad_norm": 0.619828462600708,
      "learning_rate": 3.942018072289157e-06,
      "loss": 0.332,
      "step": 1405
    },
    {
      "epoch": 0.846987951807229,
      "grad_norm": 0.6303223967552185,
      "learning_rate": 3.9412650602409645e-06,
      "loss": 0.3127,
      "step": 1406
    },
    {
      "epoch": 0.8475903614457831,
      "grad_norm": 0.6433241963386536,
      "learning_rate": 3.9405120481927714e-06,
      "loss": 0.3411,
      "step": 1407
    },
    {
      "epoch": 0.8481927710843373,
      "grad_norm": 0.6163122653961182,
      "learning_rate": 3.939759036144578e-06,
      "loss": 0.2907,
      "step": 1408
    },
    {
      "epoch": 0.8487951807228916,
      "grad_norm": 0.6196736097335815,
      "learning_rate": 3.939006024096385e-06,
      "loss": 0.3351,
      "step": 1409
    },
    {
      "epoch": 0.8493975903614458,
      "grad_norm": 0.654933512210846,
      "learning_rate": 3.938253012048193e-06,
      "loss": 0.3459,
      "step": 1410
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.6690235733985901,
      "learning_rate": 3.9375e-06,
      "loss": 0.2788,
      "step": 1411
    },
    {
      "epoch": 0.8506024096385543,
      "grad_norm": 0.6596876382827759,
      "learning_rate": 3.936746987951808e-06,
      "loss": 0.328,
      "step": 1412
    },
    {
      "epoch": 0.8512048192771084,
      "grad_norm": 0.6434564590454102,
      "learning_rate": 3.935993975903615e-06,
      "loss": 0.292,
      "step": 1413
    },
    {
      "epoch": 0.8518072289156626,
      "grad_norm": 0.5759883522987366,
      "learning_rate": 3.935240963855422e-06,
      "loss": 0.3483,
      "step": 1414
    },
    {
      "epoch": 0.8524096385542169,
      "grad_norm": 0.5891191959381104,
      "learning_rate": 3.934487951807229e-06,
      "loss": 0.2698,
      "step": 1415
    },
    {
      "epoch": 0.8530120481927711,
      "grad_norm": 0.6757310628890991,
      "learning_rate": 3.933734939759036e-06,
      "loss": 0.3457,
      "step": 1416
    },
    {
      "epoch": 0.8536144578313253,
      "grad_norm": 0.5630702972412109,
      "learning_rate": 3.932981927710844e-06,
      "loss": 0.2926,
      "step": 1417
    },
    {
      "epoch": 0.8542168674698796,
      "grad_norm": 0.5957810282707214,
      "learning_rate": 3.932228915662651e-06,
      "loss": 0.2979,
      "step": 1418
    },
    {
      "epoch": 0.8548192771084338,
      "grad_norm": 0.5499871373176575,
      "learning_rate": 3.931475903614459e-06,
      "loss": 0.3069,
      "step": 1419
    },
    {
      "epoch": 0.8554216867469879,
      "grad_norm": 0.6242157816886902,
      "learning_rate": 3.930722891566266e-06,
      "loss": 0.3463,
      "step": 1420
    },
    {
      "epoch": 0.8560240963855422,
      "grad_norm": 0.6204714179039001,
      "learning_rate": 3.929969879518073e-06,
      "loss": 0.2832,
      "step": 1421
    },
    {
      "epoch": 0.8566265060240964,
      "grad_norm": 0.5853444933891296,
      "learning_rate": 3.9292168674698796e-06,
      "loss": 0.292,
      "step": 1422
    },
    {
      "epoch": 0.8572289156626506,
      "grad_norm": 0.5995053648948669,
      "learning_rate": 3.928463855421687e-06,
      "loss": 0.2993,
      "step": 1423
    },
    {
      "epoch": 0.8578313253012049,
      "grad_norm": 0.6134621500968933,
      "learning_rate": 3.927710843373494e-06,
      "loss": 0.3116,
      "step": 1424
    },
    {
      "epoch": 0.858433734939759,
      "grad_norm": 0.6084901094436646,
      "learning_rate": 3.926957831325301e-06,
      "loss": 0.3154,
      "step": 1425
    },
    {
      "epoch": 0.8590361445783132,
      "grad_norm": 0.6178888082504272,
      "learning_rate": 3.926204819277108e-06,
      "loss": 0.3145,
      "step": 1426
    },
    {
      "epoch": 0.8596385542168675,
      "grad_norm": 0.7113654613494873,
      "learning_rate": 3.925451807228916e-06,
      "loss": 0.3173,
      "step": 1427
    },
    {
      "epoch": 0.8602409638554217,
      "grad_norm": 0.6048520803451538,
      "learning_rate": 3.924698795180723e-06,
      "loss": 0.3081,
      "step": 1428
    },
    {
      "epoch": 0.8608433734939759,
      "grad_norm": 0.6564222574234009,
      "learning_rate": 3.9239457831325306e-06,
      "loss": 0.3449,
      "step": 1429
    },
    {
      "epoch": 0.8614457831325302,
      "grad_norm": 0.6237884163856506,
      "learning_rate": 3.9231927710843375e-06,
      "loss": 0.3189,
      "step": 1430
    },
    {
      "epoch": 0.8620481927710844,
      "grad_norm": 0.6884970664978027,
      "learning_rate": 3.922439759036145e-06,
      "loss": 0.3466,
      "step": 1431
    },
    {
      "epoch": 0.8626506024096385,
      "grad_norm": 0.5881276726722717,
      "learning_rate": 3.921686746987952e-06,
      "loss": 0.2845,
      "step": 1432
    },
    {
      "epoch": 0.8632530120481928,
      "grad_norm": 0.5654270052909851,
      "learning_rate": 3.920933734939759e-06,
      "loss": 0.2871,
      "step": 1433
    },
    {
      "epoch": 0.863855421686747,
      "grad_norm": 0.5755783915519714,
      "learning_rate": 3.920180722891567e-06,
      "loss": 0.2818,
      "step": 1434
    },
    {
      "epoch": 0.8644578313253012,
      "grad_norm": 0.6721832752227783,
      "learning_rate": 3.919427710843374e-06,
      "loss": 0.3472,
      "step": 1435
    },
    {
      "epoch": 0.8650602409638555,
      "grad_norm": 0.7769577503204346,
      "learning_rate": 3.918674698795182e-06,
      "loss": 0.3726,
      "step": 1436
    },
    {
      "epoch": 0.8656626506024097,
      "grad_norm": 0.6263464689254761,
      "learning_rate": 3.9179216867469885e-06,
      "loss": 0.3302,
      "step": 1437
    },
    {
      "epoch": 0.8662650602409638,
      "grad_norm": 0.6821962594985962,
      "learning_rate": 3.9171686746987954e-06,
      "loss": 0.3463,
      "step": 1438
    },
    {
      "epoch": 0.8668674698795181,
      "grad_norm": 0.6285779476165771,
      "learning_rate": 3.916415662650603e-06,
      "loss": 0.3091,
      "step": 1439
    },
    {
      "epoch": 0.8674698795180723,
      "grad_norm": 0.6422539949417114,
      "learning_rate": 3.91566265060241e-06,
      "loss": 0.3631,
      "step": 1440
    },
    {
      "epoch": 0.8680722891566265,
      "grad_norm": 0.6092469096183777,
      "learning_rate": 3.914909638554217e-06,
      "loss": 0.2627,
      "step": 1441
    },
    {
      "epoch": 0.8686746987951808,
      "grad_norm": 0.5948477387428284,
      "learning_rate": 3.914156626506024e-06,
      "loss": 0.3732,
      "step": 1442
    },
    {
      "epoch": 0.869277108433735,
      "grad_norm": 0.6237130165100098,
      "learning_rate": 3.913403614457832e-06,
      "loss": 0.2781,
      "step": 1443
    },
    {
      "epoch": 0.8698795180722891,
      "grad_norm": 0.6364349722862244,
      "learning_rate": 3.912650602409639e-06,
      "loss": 0.2676,
      "step": 1444
    },
    {
      "epoch": 0.8704819277108434,
      "grad_norm": 0.5893974900245667,
      "learning_rate": 3.911897590361446e-06,
      "loss": 0.2849,
      "step": 1445
    },
    {
      "epoch": 0.8710843373493976,
      "grad_norm": 0.5950419902801514,
      "learning_rate": 3.911144578313253e-06,
      "loss": 0.2899,
      "step": 1446
    },
    {
      "epoch": 0.8716867469879518,
      "grad_norm": 0.6617782115936279,
      "learning_rate": 3.91039156626506e-06,
      "loss": 0.3489,
      "step": 1447
    },
    {
      "epoch": 0.8722891566265061,
      "grad_norm": 0.6698896884918213,
      "learning_rate": 3.909638554216868e-06,
      "loss": 0.3248,
      "step": 1448
    },
    {
      "epoch": 0.8728915662650603,
      "grad_norm": 0.6757217049598694,
      "learning_rate": 3.908885542168675e-06,
      "loss": 0.2985,
      "step": 1449
    },
    {
      "epoch": 0.8734939759036144,
      "grad_norm": 0.7296745181083679,
      "learning_rate": 3.908132530120482e-06,
      "loss": 0.3857,
      "step": 1450
    },
    {
      "epoch": 0.8740963855421687,
      "grad_norm": 0.6538490653038025,
      "learning_rate": 3.90737951807229e-06,
      "loss": 0.3054,
      "step": 1451
    },
    {
      "epoch": 0.8746987951807229,
      "grad_norm": 0.5825758576393127,
      "learning_rate": 3.906626506024097e-06,
      "loss": 0.33,
      "step": 1452
    },
    {
      "epoch": 0.8753012048192771,
      "grad_norm": 0.6469640731811523,
      "learning_rate": 3.905873493975904e-06,
      "loss": 0.2929,
      "step": 1453
    },
    {
      "epoch": 0.8759036144578313,
      "grad_norm": 0.6048181056976318,
      "learning_rate": 3.905120481927711e-06,
      "loss": 0.313,
      "step": 1454
    },
    {
      "epoch": 0.8765060240963856,
      "grad_norm": 0.630557119846344,
      "learning_rate": 3.904367469879518e-06,
      "loss": 0.3538,
      "step": 1455
    },
    {
      "epoch": 0.8771084337349397,
      "grad_norm": 0.6541991829872131,
      "learning_rate": 3.903614457831326e-06,
      "loss": 0.2826,
      "step": 1456
    },
    {
      "epoch": 0.8777108433734939,
      "grad_norm": 0.6044911742210388,
      "learning_rate": 3.902861445783133e-06,
      "loss": 0.3152,
      "step": 1457
    },
    {
      "epoch": 0.8783132530120482,
      "grad_norm": 0.6428477764129639,
      "learning_rate": 3.90210843373494e-06,
      "loss": 0.2684,
      "step": 1458
    },
    {
      "epoch": 0.8789156626506024,
      "grad_norm": 0.5537837147712708,
      "learning_rate": 3.901355421686747e-06,
      "loss": 0.2658,
      "step": 1459
    },
    {
      "epoch": 0.8795180722891566,
      "grad_norm": 0.5673262476921082,
      "learning_rate": 3.9006024096385546e-06,
      "loss": 0.361,
      "step": 1460
    },
    {
      "epoch": 0.8801204819277109,
      "grad_norm": 0.5812801122665405,
      "learning_rate": 3.8998493975903615e-06,
      "loss": 0.3244,
      "step": 1461
    },
    {
      "epoch": 0.880722891566265,
      "grad_norm": 0.5421818494796753,
      "learning_rate": 3.899096385542168e-06,
      "loss": 0.313,
      "step": 1462
    },
    {
      "epoch": 0.8813253012048192,
      "grad_norm": 0.7199039459228516,
      "learning_rate": 3.898343373493976e-06,
      "loss": 0.3481,
      "step": 1463
    },
    {
      "epoch": 0.8819277108433735,
      "grad_norm": 0.6445140838623047,
      "learning_rate": 3.897590361445783e-06,
      "loss": 0.3176,
      "step": 1464
    },
    {
      "epoch": 0.8825301204819277,
      "grad_norm": 0.6591705083847046,
      "learning_rate": 3.896837349397591e-06,
      "loss": 0.3707,
      "step": 1465
    },
    {
      "epoch": 0.8831325301204819,
      "grad_norm": 0.6226058006286621,
      "learning_rate": 3.896084337349398e-06,
      "loss": 0.3364,
      "step": 1466
    },
    {
      "epoch": 0.8837349397590362,
      "grad_norm": 0.6748546957969666,
      "learning_rate": 3.8953313253012056e-06,
      "loss": 0.3015,
      "step": 1467
    },
    {
      "epoch": 0.8843373493975903,
      "grad_norm": 0.5864818096160889,
      "learning_rate": 3.8945783132530125e-06,
      "loss": 0.3022,
      "step": 1468
    },
    {
      "epoch": 0.8849397590361445,
      "grad_norm": 0.5625417232513428,
      "learning_rate": 3.8938253012048194e-06,
      "loss": 0.2888,
      "step": 1469
    },
    {
      "epoch": 0.8855421686746988,
      "grad_norm": 0.6721621155738831,
      "learning_rate": 3.893072289156627e-06,
      "loss": 0.3815,
      "step": 1470
    },
    {
      "epoch": 0.886144578313253,
      "grad_norm": 0.6444303393363953,
      "learning_rate": 3.892319277108434e-06,
      "loss": 0.2902,
      "step": 1471
    },
    {
      "epoch": 0.8867469879518072,
      "grad_norm": 0.6529662013053894,
      "learning_rate": 3.891566265060242e-06,
      "loss": 0.3363,
      "step": 1472
    },
    {
      "epoch": 0.8873493975903615,
      "grad_norm": 0.5869300365447998,
      "learning_rate": 3.890813253012049e-06,
      "loss": 0.3277,
      "step": 1473
    },
    {
      "epoch": 0.8879518072289156,
      "grad_norm": 0.6133694648742676,
      "learning_rate": 3.890060240963856e-06,
      "loss": 0.3269,
      "step": 1474
    },
    {
      "epoch": 0.8885542168674698,
      "grad_norm": 0.7123200297355652,
      "learning_rate": 3.889307228915663e-06,
      "loss": 0.3393,
      "step": 1475
    },
    {
      "epoch": 0.8891566265060241,
      "grad_norm": 0.5997908115386963,
      "learning_rate": 3.8885542168674704e-06,
      "loss": 0.3349,
      "step": 1476
    },
    {
      "epoch": 0.8897590361445783,
      "grad_norm": 0.6404901146888733,
      "learning_rate": 3.887801204819277e-06,
      "loss": 0.3321,
      "step": 1477
    },
    {
      "epoch": 0.8903614457831325,
      "grad_norm": 0.5983113646507263,
      "learning_rate": 3.887048192771084e-06,
      "loss": 0.3016,
      "step": 1478
    },
    {
      "epoch": 0.8909638554216868,
      "grad_norm": 0.5430082082748413,
      "learning_rate": 3.886295180722892e-06,
      "loss": 0.2703,
      "step": 1479
    },
    {
      "epoch": 0.891566265060241,
      "grad_norm": 0.6811428666114807,
      "learning_rate": 3.885542168674699e-06,
      "loss": 0.3653,
      "step": 1480
    },
    {
      "epoch": 0.8921686746987951,
      "grad_norm": 0.6260882019996643,
      "learning_rate": 3.884789156626506e-06,
      "loss": 0.3122,
      "step": 1481
    },
    {
      "epoch": 0.8927710843373494,
      "grad_norm": 0.5989213585853577,
      "learning_rate": 3.884036144578314e-06,
      "loss": 0.3018,
      "step": 1482
    },
    {
      "epoch": 0.8933734939759036,
      "grad_norm": 0.6583399176597595,
      "learning_rate": 3.883283132530121e-06,
      "loss": 0.3049,
      "step": 1483
    },
    {
      "epoch": 0.8939759036144578,
      "grad_norm": 0.6526419520378113,
      "learning_rate": 3.882530120481928e-06,
      "loss": 0.2812,
      "step": 1484
    },
    {
      "epoch": 0.8945783132530121,
      "grad_norm": 0.5724244117736816,
      "learning_rate": 3.881777108433735e-06,
      "loss": 0.3446,
      "step": 1485
    },
    {
      "epoch": 0.8951807228915662,
      "grad_norm": 0.5562093257904053,
      "learning_rate": 3.881024096385542e-06,
      "loss": 0.2929,
      "step": 1486
    },
    {
      "epoch": 0.8957831325301204,
      "grad_norm": 0.6325515508651733,
      "learning_rate": 3.88027108433735e-06,
      "loss": 0.2777,
      "step": 1487
    },
    {
      "epoch": 0.8963855421686747,
      "grad_norm": 0.619558572769165,
      "learning_rate": 3.879518072289157e-06,
      "loss": 0.2945,
      "step": 1488
    },
    {
      "epoch": 0.8969879518072289,
      "grad_norm": 0.6351866126060486,
      "learning_rate": 3.878765060240965e-06,
      "loss": 0.3876,
      "step": 1489
    },
    {
      "epoch": 0.8975903614457831,
      "grad_norm": 0.6049681305885315,
      "learning_rate": 3.878012048192772e-06,
      "loss": 0.3077,
      "step": 1490
    },
    {
      "epoch": 0.8981927710843374,
      "grad_norm": 0.6105822324752808,
      "learning_rate": 3.8772590361445785e-06,
      "loss": 0.2467,
      "step": 1491
    },
    {
      "epoch": 0.8987951807228916,
      "grad_norm": 0.5921570062637329,
      "learning_rate": 3.8765060240963855e-06,
      "loss": 0.3187,
      "step": 1492
    },
    {
      "epoch": 0.8993975903614457,
      "grad_norm": 0.5715286135673523,
      "learning_rate": 3.875753012048193e-06,
      "loss": 0.3295,
      "step": 1493
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.679085373878479,
      "learning_rate": 3.875e-06,
      "loss": 0.324,
      "step": 1494
    },
    {
      "epoch": 0.9006024096385542,
      "grad_norm": 0.5913132429122925,
      "learning_rate": 3.874246987951807e-06,
      "loss": 0.3314,
      "step": 1495
    },
    {
      "epoch": 0.9012048192771084,
      "grad_norm": 0.5846433639526367,
      "learning_rate": 3.873493975903615e-06,
      "loss": 0.2943,
      "step": 1496
    },
    {
      "epoch": 0.9018072289156627,
      "grad_norm": 0.581974446773529,
      "learning_rate": 3.872740963855422e-06,
      "loss": 0.3164,
      "step": 1497
    },
    {
      "epoch": 0.9024096385542169,
      "grad_norm": 0.5888330936431885,
      "learning_rate": 3.871987951807229e-06,
      "loss": 0.3557,
      "step": 1498
    },
    {
      "epoch": 0.903012048192771,
      "grad_norm": 0.5957286357879639,
      "learning_rate": 3.8712349397590365e-06,
      "loss": 0.3254,
      "step": 1499
    },
    {
      "epoch": 0.9036144578313253,
      "grad_norm": 0.6183656454086304,
      "learning_rate": 3.870481927710843e-06,
      "loss": 0.3752,
      "step": 1500
    },
    {
      "epoch": 0.9042168674698795,
      "grad_norm": 0.6683447360992432,
      "learning_rate": 3.869728915662651e-06,
      "loss": 0.3253,
      "step": 1501
    },
    {
      "epoch": 0.9048192771084337,
      "grad_norm": 0.6463075876235962,
      "learning_rate": 3.868975903614458e-06,
      "loss": 0.3134,
      "step": 1502
    },
    {
      "epoch": 0.905421686746988,
      "grad_norm": 0.5957850217819214,
      "learning_rate": 3.868222891566266e-06,
      "loss": 0.3079,
      "step": 1503
    },
    {
      "epoch": 0.9060240963855422,
      "grad_norm": 0.6379228830337524,
      "learning_rate": 3.867469879518073e-06,
      "loss": 0.3179,
      "step": 1504
    },
    {
      "epoch": 0.9066265060240963,
      "grad_norm": 0.5929701328277588,
      "learning_rate": 3.86671686746988e-06,
      "loss": 0.2868,
      "step": 1505
    },
    {
      "epoch": 0.9072289156626506,
      "grad_norm": 0.6923640966415405,
      "learning_rate": 3.8659638554216875e-06,
      "loss": 0.3871,
      "step": 1506
    },
    {
      "epoch": 0.9078313253012048,
      "grad_norm": 0.6090556383132935,
      "learning_rate": 3.8652108433734944e-06,
      "loss": 0.321,
      "step": 1507
    },
    {
      "epoch": 0.908433734939759,
      "grad_norm": 0.6507430672645569,
      "learning_rate": 3.864457831325301e-06,
      "loss": 0.3266,
      "step": 1508
    },
    {
      "epoch": 0.9090361445783133,
      "grad_norm": 0.6598023772239685,
      "learning_rate": 3.863704819277109e-06,
      "loss": 0.2792,
      "step": 1509
    },
    {
      "epoch": 0.9096385542168675,
      "grad_norm": 0.6596893072128296,
      "learning_rate": 3.862951807228916e-06,
      "loss": 0.2762,
      "step": 1510
    },
    {
      "epoch": 0.9102409638554216,
      "grad_norm": 0.6119979619979858,
      "learning_rate": 3.862198795180723e-06,
      "loss": 0.3281,
      "step": 1511
    },
    {
      "epoch": 0.9108433734939759,
      "grad_norm": 0.5859057903289795,
      "learning_rate": 3.86144578313253e-06,
      "loss": 0.2657,
      "step": 1512
    },
    {
      "epoch": 0.9114457831325301,
      "grad_norm": 0.6372591853141785,
      "learning_rate": 3.860692771084338e-06,
      "loss": 0.2885,
      "step": 1513
    },
    {
      "epoch": 0.9120481927710843,
      "grad_norm": 0.616199791431427,
      "learning_rate": 3.859939759036145e-06,
      "loss": 0.3024,
      "step": 1514
    },
    {
      "epoch": 0.9126506024096386,
      "grad_norm": 0.6273398995399475,
      "learning_rate": 3.859186746987952e-06,
      "loss": 0.2957,
      "step": 1515
    },
    {
      "epoch": 0.9132530120481928,
      "grad_norm": 0.5773645639419556,
      "learning_rate": 3.858433734939759e-06,
      "loss": 0.2893,
      "step": 1516
    },
    {
      "epoch": 0.9138554216867469,
      "grad_norm": 0.5950593948364258,
      "learning_rate": 3.857680722891566e-06,
      "loss": 0.2872,
      "step": 1517
    },
    {
      "epoch": 0.9144578313253012,
      "grad_norm": 0.6240668892860413,
      "learning_rate": 3.856927710843374e-06,
      "loss": 0.3351,
      "step": 1518
    },
    {
      "epoch": 0.9150602409638554,
      "grad_norm": 0.5925419926643372,
      "learning_rate": 3.856174698795181e-06,
      "loss": 0.3134,
      "step": 1519
    },
    {
      "epoch": 0.9156626506024096,
      "grad_norm": 0.6849952936172485,
      "learning_rate": 3.855421686746989e-06,
      "loss": 0.3156,
      "step": 1520
    },
    {
      "epoch": 0.9162650602409639,
      "grad_norm": 0.5960055589675903,
      "learning_rate": 3.854668674698796e-06,
      "loss": 0.3143,
      "step": 1521
    },
    {
      "epoch": 0.9168674698795181,
      "grad_norm": 0.5648604035377502,
      "learning_rate": 3.8539156626506025e-06,
      "loss": 0.2982,
      "step": 1522
    },
    {
      "epoch": 0.9174698795180722,
      "grad_norm": 0.6444298624992371,
      "learning_rate": 3.85316265060241e-06,
      "loss": 0.2838,
      "step": 1523
    },
    {
      "epoch": 0.9180722891566265,
      "grad_norm": 0.6052560806274414,
      "learning_rate": 3.852409638554217e-06,
      "loss": 0.3151,
      "step": 1524
    },
    {
      "epoch": 0.9186746987951807,
      "grad_norm": 0.5851566195487976,
      "learning_rate": 3.851656626506024e-06,
      "loss": 0.3146,
      "step": 1525
    },
    {
      "epoch": 0.9192771084337349,
      "grad_norm": 0.6157030463218689,
      "learning_rate": 3.850903614457832e-06,
      "loss": 0.2879,
      "step": 1526
    },
    {
      "epoch": 0.9198795180722892,
      "grad_norm": 0.5989096760749817,
      "learning_rate": 3.850150602409639e-06,
      "loss": 0.3028,
      "step": 1527
    },
    {
      "epoch": 0.9204819277108434,
      "grad_norm": 0.5804506540298462,
      "learning_rate": 3.849397590361446e-06,
      "loss": 0.2998,
      "step": 1528
    },
    {
      "epoch": 0.9210843373493975,
      "grad_norm": 0.6003552079200745,
      "learning_rate": 3.848644578313253e-06,
      "loss": 0.273,
      "step": 1529
    },
    {
      "epoch": 0.9216867469879518,
      "grad_norm": 0.6949920058250427,
      "learning_rate": 3.8478915662650605e-06,
      "loss": 0.3089,
      "step": 1530
    },
    {
      "epoch": 0.922289156626506,
      "grad_norm": 0.6303969025611877,
      "learning_rate": 3.847138554216867e-06,
      "loss": 0.3403,
      "step": 1531
    },
    {
      "epoch": 0.9228915662650602,
      "grad_norm": 0.6089457869529724,
      "learning_rate": 3.846385542168675e-06,
      "loss": 0.2744,
      "step": 1532
    },
    {
      "epoch": 0.9234939759036145,
      "grad_norm": 0.6227356791496277,
      "learning_rate": 3.845632530120482e-06,
      "loss": 0.2546,
      "step": 1533
    },
    {
      "epoch": 0.9240963855421687,
      "grad_norm": 0.6822543144226074,
      "learning_rate": 3.844879518072289e-06,
      "loss": 0.251,
      "step": 1534
    },
    {
      "epoch": 0.9246987951807228,
      "grad_norm": 0.5985514521598816,
      "learning_rate": 3.844126506024097e-06,
      "loss": 0.3064,
      "step": 1535
    },
    {
      "epoch": 0.9253012048192771,
      "grad_norm": 0.5865997076034546,
      "learning_rate": 3.843373493975904e-06,
      "loss": 0.3325,
      "step": 1536
    },
    {
      "epoch": 0.9259036144578313,
      "grad_norm": 0.6580799221992493,
      "learning_rate": 3.8426204819277115e-06,
      "loss": 0.2492,
      "step": 1537
    },
    {
      "epoch": 0.9265060240963855,
      "grad_norm": 0.6335626840591431,
      "learning_rate": 3.841867469879518e-06,
      "loss": 0.263,
      "step": 1538
    },
    {
      "epoch": 0.9271084337349398,
      "grad_norm": 0.6081291437149048,
      "learning_rate": 3.841114457831326e-06,
      "loss": 0.3283,
      "step": 1539
    },
    {
      "epoch": 0.927710843373494,
      "grad_norm": 0.6659252047538757,
      "learning_rate": 3.840361445783133e-06,
      "loss": 0.2611,
      "step": 1540
    },
    {
      "epoch": 0.9283132530120481,
      "grad_norm": 0.5848076939582825,
      "learning_rate": 3.83960843373494e-06,
      "loss": 0.3023,
      "step": 1541
    },
    {
      "epoch": 0.9289156626506024,
      "grad_norm": 0.5407769680023193,
      "learning_rate": 3.838855421686748e-06,
      "loss": 0.2494,
      "step": 1542
    },
    {
      "epoch": 0.9295180722891566,
      "grad_norm": 0.7843824028968811,
      "learning_rate": 3.838102409638555e-06,
      "loss": 0.3291,
      "step": 1543
    },
    {
      "epoch": 0.9301204819277108,
      "grad_norm": 0.7609158158302307,
      "learning_rate": 3.837349397590362e-06,
      "loss": 0.3184,
      "step": 1544
    },
    {
      "epoch": 0.9307228915662651,
      "grad_norm": 0.5524119138717651,
      "learning_rate": 3.836596385542169e-06,
      "loss": 0.256,
      "step": 1545
    },
    {
      "epoch": 0.9313253012048193,
      "grad_norm": 0.55179762840271,
      "learning_rate": 3.835843373493976e-06,
      "loss": 0.3001,
      "step": 1546
    },
    {
      "epoch": 0.9319277108433734,
      "grad_norm": 0.6495732069015503,
      "learning_rate": 3.835090361445783e-06,
      "loss": 0.3171,
      "step": 1547
    },
    {
      "epoch": 0.9325301204819277,
      "grad_norm": 0.610310971736908,
      "learning_rate": 3.83433734939759e-06,
      "loss": 0.2965,
      "step": 1548
    },
    {
      "epoch": 0.9331325301204819,
      "grad_norm": 0.5891467928886414,
      "learning_rate": 3.833584337349398e-06,
      "loss": 0.2966,
      "step": 1549
    },
    {
      "epoch": 0.9337349397590361,
      "grad_norm": 0.5972080826759338,
      "learning_rate": 3.832831325301205e-06,
      "loss": 0.2395,
      "step": 1550
    },
    {
      "epoch": 0.9343373493975904,
      "grad_norm": 0.5893555879592896,
      "learning_rate": 3.832078313253013e-06,
      "loss": 0.2452,
      "step": 1551
    },
    {
      "epoch": 0.9349397590361446,
      "grad_norm": 0.5661063194274902,
      "learning_rate": 3.83132530120482e-06,
      "loss": 0.3265,
      "step": 1552
    },
    {
      "epoch": 0.9355421686746987,
      "grad_norm": 0.6463367342948914,
      "learning_rate": 3.8305722891566265e-06,
      "loss": 0.3172,
      "step": 1553
    },
    {
      "epoch": 0.936144578313253,
      "grad_norm": 0.5575387477874756,
      "learning_rate": 3.829819277108434e-06,
      "loss": 0.2853,
      "step": 1554
    },
    {
      "epoch": 0.9367469879518072,
      "grad_norm": 0.6367904543876648,
      "learning_rate": 3.829066265060241e-06,
      "loss": 0.2671,
      "step": 1555
    },
    {
      "epoch": 0.9373493975903614,
      "grad_norm": 0.5370010733604431,
      "learning_rate": 3.828313253012049e-06,
      "loss": 0.2489,
      "step": 1556
    },
    {
      "epoch": 0.9379518072289157,
      "grad_norm": 0.6039838194847107,
      "learning_rate": 3.827560240963856e-06,
      "loss": 0.2907,
      "step": 1557
    },
    {
      "epoch": 0.9385542168674699,
      "grad_norm": 0.5508047938346863,
      "learning_rate": 3.826807228915663e-06,
      "loss": 0.241,
      "step": 1558
    },
    {
      "epoch": 0.939156626506024,
      "grad_norm": 0.6745787262916565,
      "learning_rate": 3.826054216867471e-06,
      "loss": 0.2605,
      "step": 1559
    },
    {
      "epoch": 0.9397590361445783,
      "grad_norm": 0.5981773138046265,
      "learning_rate": 3.8253012048192775e-06,
      "loss": 0.3568,
      "step": 1560
    },
    {
      "epoch": 0.9403614457831325,
      "grad_norm": 0.6590654253959656,
      "learning_rate": 3.8245481927710845e-06,
      "loss": 0.3527,
      "step": 1561
    },
    {
      "epoch": 0.9409638554216867,
      "grad_norm": 0.630463719367981,
      "learning_rate": 3.823795180722891e-06,
      "loss": 0.3011,
      "step": 1562
    },
    {
      "epoch": 0.941566265060241,
      "grad_norm": 0.6156840920448303,
      "learning_rate": 3.823042168674699e-06,
      "loss": 0.2993,
      "step": 1563
    },
    {
      "epoch": 0.9421686746987952,
      "grad_norm": 0.5556546449661255,
      "learning_rate": 3.822289156626506e-06,
      "loss": 0.3157,
      "step": 1564
    },
    {
      "epoch": 0.9427710843373494,
      "grad_norm": 0.5959848761558533,
      "learning_rate": 3.821536144578313e-06,
      "loss": 0.251,
      "step": 1565
    },
    {
      "epoch": 0.9433734939759036,
      "grad_norm": 0.6050891280174255,
      "learning_rate": 3.820783132530121e-06,
      "loss": 0.2312,
      "step": 1566
    },
    {
      "epoch": 0.9439759036144578,
      "grad_norm": 0.6471617817878723,
      "learning_rate": 3.820030120481928e-06,
      "loss": 0.3423,
      "step": 1567
    },
    {
      "epoch": 0.944578313253012,
      "grad_norm": 0.6996471285820007,
      "learning_rate": 3.8192771084337355e-06,
      "loss": 0.2993,
      "step": 1568
    },
    {
      "epoch": 0.9451807228915663,
      "grad_norm": 0.6312844753265381,
      "learning_rate": 3.818524096385542e-06,
      "loss": 0.2518,
      "step": 1569
    },
    {
      "epoch": 0.9457831325301205,
      "grad_norm": 0.7280901074409485,
      "learning_rate": 3.817771084337349e-06,
      "loss": 0.2789,
      "step": 1570
    },
    {
      "epoch": 0.9463855421686747,
      "grad_norm": 0.7090468406677246,
      "learning_rate": 3.817018072289157e-06,
      "loss": 0.3174,
      "step": 1571
    },
    {
      "epoch": 0.946987951807229,
      "grad_norm": 0.6445513963699341,
      "learning_rate": 3.816265060240964e-06,
      "loss": 0.2992,
      "step": 1572
    },
    {
      "epoch": 0.9475903614457831,
      "grad_norm": 0.5494645237922668,
      "learning_rate": 3.815512048192772e-06,
      "loss": 0.2507,
      "step": 1573
    },
    {
      "epoch": 0.9481927710843373,
      "grad_norm": 0.658787190914154,
      "learning_rate": 3.814759036144579e-06,
      "loss": 0.25,
      "step": 1574
    },
    {
      "epoch": 0.9487951807228916,
      "grad_norm": 0.5917454957962036,
      "learning_rate": 3.814006024096386e-06,
      "loss": 0.3256,
      "step": 1575
    },
    {
      "epoch": 0.9493975903614458,
      "grad_norm": 0.5925835371017456,
      "learning_rate": 3.813253012048193e-06,
      "loss": 0.2335,
      "step": 1576
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.6157392263412476,
      "learning_rate": 3.8125e-06,
      "loss": 0.2763,
      "step": 1577
    },
    {
      "epoch": 0.9506024096385542,
      "grad_norm": 0.6403539180755615,
      "learning_rate": 3.8117469879518077e-06,
      "loss": 0.3398,
      "step": 1578
    },
    {
      "epoch": 0.9512048192771084,
      "grad_norm": 0.5745186805725098,
      "learning_rate": 3.8109939759036146e-06,
      "loss": 0.3078,
      "step": 1579
    },
    {
      "epoch": 0.9518072289156626,
      "grad_norm": 0.7184597849845886,
      "learning_rate": 3.8102409638554224e-06,
      "loss": 0.342,
      "step": 1580
    },
    {
      "epoch": 0.9524096385542169,
      "grad_norm": 0.6140404343605042,
      "learning_rate": 3.8094879518072293e-06,
      "loss": 0.3059,
      "step": 1581
    },
    {
      "epoch": 0.9530120481927711,
      "grad_norm": 0.7262964248657227,
      "learning_rate": 3.8087349397590362e-06,
      "loss": 0.3436,
      "step": 1582
    },
    {
      "epoch": 0.9536144578313253,
      "grad_norm": 0.6389098763465881,
      "learning_rate": 3.8079819277108436e-06,
      "loss": 0.2604,
      "step": 1583
    },
    {
      "epoch": 0.9542168674698795,
      "grad_norm": 0.5756064057350159,
      "learning_rate": 3.807228915662651e-06,
      "loss": 0.305,
      "step": 1584
    },
    {
      "epoch": 0.9548192771084337,
      "grad_norm": 0.5967796444892883,
      "learning_rate": 3.8064759036144583e-06,
      "loss": 0.3023,
      "step": 1585
    },
    {
      "epoch": 0.9554216867469879,
      "grad_norm": 0.6227566599845886,
      "learning_rate": 3.805722891566265e-06,
      "loss": 0.3345,
      "step": 1586
    },
    {
      "epoch": 0.9560240963855422,
      "grad_norm": 0.5670056343078613,
      "learning_rate": 3.804969879518073e-06,
      "loss": 0.2721,
      "step": 1587
    },
    {
      "epoch": 0.9566265060240964,
      "grad_norm": 0.6315850019454956,
      "learning_rate": 3.80421686746988e-06,
      "loss": 0.3042,
      "step": 1588
    },
    {
      "epoch": 0.9572289156626506,
      "grad_norm": 0.6250851154327393,
      "learning_rate": 3.803463855421687e-06,
      "loss": 0.3225,
      "step": 1589
    },
    {
      "epoch": 0.9578313253012049,
      "grad_norm": 0.6011967658996582,
      "learning_rate": 3.802710843373494e-06,
      "loss": 0.2829,
      "step": 1590
    },
    {
      "epoch": 0.958433734939759,
      "grad_norm": 0.6307382583618164,
      "learning_rate": 3.8019578313253015e-06,
      "loss": 0.3226,
      "step": 1591
    },
    {
      "epoch": 0.9590361445783132,
      "grad_norm": 0.6146103143692017,
      "learning_rate": 3.801204819277109e-06,
      "loss": 0.2977,
      "step": 1592
    },
    {
      "epoch": 0.9596385542168675,
      "grad_norm": 0.5792640447616577,
      "learning_rate": 3.800451807228916e-06,
      "loss": 0.262,
      "step": 1593
    },
    {
      "epoch": 0.9602409638554217,
      "grad_norm": 0.5917128324508667,
      "learning_rate": 3.7996987951807227e-06,
      "loss": 0.2577,
      "step": 1594
    },
    {
      "epoch": 0.9608433734939759,
      "grad_norm": 0.6446192264556885,
      "learning_rate": 3.7989457831325305e-06,
      "loss": 0.2948,
      "step": 1595
    },
    {
      "epoch": 0.9614457831325302,
      "grad_norm": 0.5938743948936462,
      "learning_rate": 3.7981927710843374e-06,
      "loss": 0.2994,
      "step": 1596
    },
    {
      "epoch": 0.9620481927710843,
      "grad_norm": 0.5280167460441589,
      "learning_rate": 3.797439759036145e-06,
      "loss": 0.2922,
      "step": 1597
    },
    {
      "epoch": 0.9626506024096385,
      "grad_norm": 0.607342541217804,
      "learning_rate": 3.796686746987952e-06,
      "loss": 0.2967,
      "step": 1598
    },
    {
      "epoch": 0.9632530120481928,
      "grad_norm": 0.6202962398529053,
      "learning_rate": 3.7959337349397595e-06,
      "loss": 0.2805,
      "step": 1599
    },
    {
      "epoch": 0.963855421686747,
      "grad_norm": 0.6688748598098755,
      "learning_rate": 3.7951807228915664e-06,
      "loss": 0.3156,
      "step": 1600
    },
    {
      "epoch": 0.9644578313253012,
      "grad_norm": 0.6333670020103455,
      "learning_rate": 3.7944277108433737e-06,
      "loss": 0.2688,
      "step": 1601
    },
    {
      "epoch": 0.9650602409638555,
      "grad_norm": 0.6280812621116638,
      "learning_rate": 3.793674698795181e-06,
      "loss": 0.3216,
      "step": 1602
    },
    {
      "epoch": 0.9656626506024096,
      "grad_norm": 0.5876431465148926,
      "learning_rate": 3.792921686746988e-06,
      "loss": 0.2755,
      "step": 1603
    },
    {
      "epoch": 0.9662650602409638,
      "grad_norm": 0.7993011474609375,
      "learning_rate": 3.7921686746987958e-06,
      "loss": 0.361,
      "step": 1604
    },
    {
      "epoch": 0.9668674698795181,
      "grad_norm": 0.6021096110343933,
      "learning_rate": 3.7914156626506027e-06,
      "loss": 0.3333,
      "step": 1605
    },
    {
      "epoch": 0.9674698795180723,
      "grad_norm": 0.7371551394462585,
      "learning_rate": 3.7906626506024096e-06,
      "loss": 0.3076,
      "step": 1606
    },
    {
      "epoch": 0.9680722891566265,
      "grad_norm": 0.6577703356742859,
      "learning_rate": 3.7899096385542174e-06,
      "loss": 0.2893,
      "step": 1607
    },
    {
      "epoch": 0.9686746987951808,
      "grad_norm": 0.632206916809082,
      "learning_rate": 3.7891566265060243e-06,
      "loss": 0.3651,
      "step": 1608
    },
    {
      "epoch": 0.9692771084337349,
      "grad_norm": 0.6699337363243103,
      "learning_rate": 3.7884036144578317e-06,
      "loss": 0.3747,
      "step": 1609
    },
    {
      "epoch": 0.9698795180722891,
      "grad_norm": 0.5883642435073853,
      "learning_rate": 3.7876506024096386e-06,
      "loss": 0.2837,
      "step": 1610
    },
    {
      "epoch": 0.9704819277108434,
      "grad_norm": 0.5976810455322266,
      "learning_rate": 3.7868975903614464e-06,
      "loss": 0.2812,
      "step": 1611
    },
    {
      "epoch": 0.9710843373493976,
      "grad_norm": 0.6341924071311951,
      "learning_rate": 3.7861445783132533e-06,
      "loss": 0.3056,
      "step": 1612
    },
    {
      "epoch": 0.9716867469879518,
      "grad_norm": 0.5735381841659546,
      "learning_rate": 3.7853915662650602e-06,
      "loss": 0.3272,
      "step": 1613
    },
    {
      "epoch": 0.9722891566265061,
      "grad_norm": 0.6011747121810913,
      "learning_rate": 3.784638554216868e-06,
      "loss": 0.2576,
      "step": 1614
    },
    {
      "epoch": 0.9728915662650602,
      "grad_norm": 0.5634291768074036,
      "learning_rate": 3.783885542168675e-06,
      "loss": 0.2389,
      "step": 1615
    },
    {
      "epoch": 0.9734939759036144,
      "grad_norm": 0.6676355004310608,
      "learning_rate": 3.7831325301204823e-06,
      "loss": 0.3348,
      "step": 1616
    },
    {
      "epoch": 0.9740963855421687,
      "grad_norm": 0.5721951723098755,
      "learning_rate": 3.7823795180722896e-06,
      "loss": 0.2981,
      "step": 1617
    },
    {
      "epoch": 0.9746987951807229,
      "grad_norm": 0.5959210395812988,
      "learning_rate": 3.7816265060240965e-06,
      "loss": 0.3139,
      "step": 1618
    },
    {
      "epoch": 0.9753012048192771,
      "grad_norm": 0.5500622391700745,
      "learning_rate": 3.780873493975904e-06,
      "loss": 0.2901,
      "step": 1619
    },
    {
      "epoch": 0.9759036144578314,
      "grad_norm": 0.5967771410942078,
      "learning_rate": 3.780120481927711e-06,
      "loss": 0.2725,
      "step": 1620
    },
    {
      "epoch": 0.9765060240963855,
      "grad_norm": 0.5813080072402954,
      "learning_rate": 3.7793674698795186e-06,
      "loss": 0.2704,
      "step": 1621
    },
    {
      "epoch": 0.9771084337349397,
      "grad_norm": 0.5886262059211731,
      "learning_rate": 3.7786144578313255e-06,
      "loss": 0.2801,
      "step": 1622
    },
    {
      "epoch": 0.977710843373494,
      "grad_norm": 0.6181700229644775,
      "learning_rate": 3.777861445783133e-06,
      "loss": 0.3379,
      "step": 1623
    },
    {
      "epoch": 0.9783132530120482,
      "grad_norm": 0.5530874729156494,
      "learning_rate": 3.7771084337349402e-06,
      "loss": 0.2716,
      "step": 1624
    },
    {
      "epoch": 0.9789156626506024,
      "grad_norm": 0.6875714063644409,
      "learning_rate": 3.776355421686747e-06,
      "loss": 0.292,
      "step": 1625
    },
    {
      "epoch": 0.9795180722891567,
      "grad_norm": 0.6063216924667358,
      "learning_rate": 3.7756024096385545e-06,
      "loss": 0.3122,
      "step": 1626
    },
    {
      "epoch": 0.9801204819277108,
      "grad_norm": 0.5745726823806763,
      "learning_rate": 3.7748493975903614e-06,
      "loss": 0.3166,
      "step": 1627
    },
    {
      "epoch": 0.980722891566265,
      "grad_norm": 0.5848833322525024,
      "learning_rate": 3.774096385542169e-06,
      "loss": 0.3523,
      "step": 1628
    },
    {
      "epoch": 0.9813253012048193,
      "grad_norm": 0.6367623805999756,
      "learning_rate": 3.773343373493976e-06,
      "loss": 0.2615,
      "step": 1629
    },
    {
      "epoch": 0.9819277108433735,
      "grad_norm": 0.5850533246994019,
      "learning_rate": 3.772590361445783e-06,
      "loss": 0.3568,
      "step": 1630
    },
    {
      "epoch": 0.9825301204819277,
      "grad_norm": 0.5900455713272095,
      "learning_rate": 3.771837349397591e-06,
      "loss": 0.3082,
      "step": 1631
    },
    {
      "epoch": 0.983132530120482,
      "grad_norm": 0.5823172330856323,
      "learning_rate": 3.7710843373493977e-06,
      "loss": 0.2533,
      "step": 1632
    },
    {
      "epoch": 0.9837349397590361,
      "grad_norm": 0.5458715558052063,
      "learning_rate": 3.770331325301205e-06,
      "loss": 0.2571,
      "step": 1633
    },
    {
      "epoch": 0.9843373493975903,
      "grad_norm": 0.5506874322891235,
      "learning_rate": 3.7695783132530124e-06,
      "loss": 0.3174,
      "step": 1634
    },
    {
      "epoch": 0.9849397590361446,
      "grad_norm": 0.6973297595977783,
      "learning_rate": 3.7688253012048198e-06,
      "loss": 0.3253,
      "step": 1635
    },
    {
      "epoch": 0.9855421686746988,
      "grad_norm": 0.6870803833007812,
      "learning_rate": 3.7680722891566267e-06,
      "loss": 0.3547,
      "step": 1636
    },
    {
      "epoch": 0.986144578313253,
      "grad_norm": 0.6447876691818237,
      "learning_rate": 3.7673192771084336e-06,
      "loss": 0.3459,
      "step": 1637
    },
    {
      "epoch": 0.9867469879518073,
      "grad_norm": 0.6234835386276245,
      "learning_rate": 3.7665662650602414e-06,
      "loss": 0.3602,
      "step": 1638
    },
    {
      "epoch": 0.9873493975903614,
      "grad_norm": 0.5762210488319397,
      "learning_rate": 3.7658132530120483e-06,
      "loss": 0.319,
      "step": 1639
    },
    {
      "epoch": 0.9879518072289156,
      "grad_norm": 0.6055479645729065,
      "learning_rate": 3.765060240963856e-06,
      "loss": 0.2783,
      "step": 1640
    },
    {
      "epoch": 0.9885542168674699,
      "grad_norm": 0.6299756765365601,
      "learning_rate": 3.764307228915663e-06,
      "loss": 0.3216,
      "step": 1641
    },
    {
      "epoch": 0.9891566265060241,
      "grad_norm": 0.571439802646637,
      "learning_rate": 3.76355421686747e-06,
      "loss": 0.2519,
      "step": 1642
    },
    {
      "epoch": 0.9897590361445783,
      "grad_norm": 0.5919230580329895,
      "learning_rate": 3.7628012048192773e-06,
      "loss": 0.3674,
      "step": 1643
    },
    {
      "epoch": 0.9903614457831326,
      "grad_norm": 0.5681582689285278,
      "learning_rate": 3.7620481927710846e-06,
      "loss": 0.2773,
      "step": 1644
    },
    {
      "epoch": 0.9909638554216867,
      "grad_norm": 0.6884616017341614,
      "learning_rate": 3.761295180722892e-06,
      "loss": 0.3365,
      "step": 1645
    },
    {
      "epoch": 0.9915662650602409,
      "grad_norm": 0.5909954309463501,
      "learning_rate": 3.760542168674699e-06,
      "loss": 0.3163,
      "step": 1646
    },
    {
      "epoch": 0.9921686746987952,
      "grad_norm": 0.6184477210044861,
      "learning_rate": 3.7597891566265067e-06,
      "loss": 0.3144,
      "step": 1647
    },
    {
      "epoch": 0.9927710843373494,
      "grad_norm": 0.6468328833580017,
      "learning_rate": 3.7590361445783136e-06,
      "loss": 0.2941,
      "step": 1648
    },
    {
      "epoch": 0.9933734939759036,
      "grad_norm": 0.5764317512512207,
      "learning_rate": 3.7582831325301205e-06,
      "loss": 0.2965,
      "step": 1649
    },
    {
      "epoch": 0.9939759036144579,
      "grad_norm": 0.55708909034729,
      "learning_rate": 3.7575301204819283e-06,
      "loss": 0.3124,
      "step": 1650
    },
    {
      "epoch": 0.994578313253012,
      "grad_norm": 0.7150825262069702,
      "learning_rate": 3.7567771084337352e-06,
      "loss": 0.2556,
      "step": 1651
    },
    {
      "epoch": 0.9951807228915662,
      "grad_norm": 0.6136308908462524,
      "learning_rate": 3.7560240963855426e-06,
      "loss": 0.2947,
      "step": 1652
    },
    {
      "epoch": 0.9957831325301205,
      "grad_norm": 0.6352315545082092,
      "learning_rate": 3.7552710843373495e-06,
      "loss": 0.3087,
      "step": 1653
    },
    {
      "epoch": 0.9963855421686747,
      "grad_norm": 0.6244986653327942,
      "learning_rate": 3.754518072289157e-06,
      "loss": 0.2647,
      "step": 1654
    },
    {
      "epoch": 0.9969879518072289,
      "grad_norm": 0.6941857933998108,
      "learning_rate": 3.753765060240964e-06,
      "loss": 0.3691,
      "step": 1655
    },
    {
      "epoch": 0.9975903614457832,
      "grad_norm": 0.5844574570655823,
      "learning_rate": 3.753012048192771e-06,
      "loss": 0.3044,
      "step": 1656
    },
    {
      "epoch": 0.9981927710843373,
      "grad_norm": 0.6328081488609314,
      "learning_rate": 3.752259036144579e-06,
      "loss": 0.2582,
      "step": 1657
    },
    {
      "epoch": 0.9987951807228915,
      "grad_norm": 0.5432482361793518,
      "learning_rate": 3.751506024096386e-06,
      "loss": 0.2819,
      "step": 1658
    },
    {
      "epoch": 0.9993975903614458,
      "grad_norm": 0.5651382803916931,
      "learning_rate": 3.750753012048193e-06,
      "loss": 0.2639,
      "step": 1659
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.755142331123352,
      "learning_rate": 3.7500000000000005e-06,
      "loss": 0.3525,
      "step": 1660
    },
    {
      "epoch": 1.0006024096385542,
      "grad_norm": 3.682429075241089,
      "learning_rate": 3.7492469879518074e-06,
      "loss": 0.2269,
      "step": 1661
    },
    {
      "epoch": 1.0012048192771084,
      "grad_norm": 0.8089621067047119,
      "learning_rate": 3.748493975903615e-06,
      "loss": 0.2289,
      "step": 1662
    },
    {
      "epoch": 1.0018072289156625,
      "grad_norm": 0.7217946648597717,
      "learning_rate": 3.7477409638554217e-06,
      "loss": 0.2078,
      "step": 1663
    },
    {
      "epoch": 1.002409638554217,
      "grad_norm": 0.7014015913009644,
      "learning_rate": 3.7469879518072295e-06,
      "loss": 0.2587,
      "step": 1664
    },
    {
      "epoch": 1.0030120481927711,
      "grad_norm": 0.7653942108154297,
      "learning_rate": 3.7462349397590364e-06,
      "loss": 0.2546,
      "step": 1665
    },
    {
      "epoch": 1.0036144578313253,
      "grad_norm": 0.7229559421539307,
      "learning_rate": 3.7454819277108438e-06,
      "loss": 0.2413,
      "step": 1666
    },
    {
      "epoch": 1.0042168674698795,
      "grad_norm": 0.6342668533325195,
      "learning_rate": 3.744728915662651e-06,
      "loss": 0.2419,
      "step": 1667
    },
    {
      "epoch": 1.0048192771084337,
      "grad_norm": 0.674233078956604,
      "learning_rate": 3.743975903614458e-06,
      "loss": 0.2559,
      "step": 1668
    },
    {
      "epoch": 1.0054216867469878,
      "grad_norm": 0.6595813632011414,
      "learning_rate": 3.7432228915662654e-06,
      "loss": 0.2694,
      "step": 1669
    },
    {
      "epoch": 1.0060240963855422,
      "grad_norm": 0.6970639824867249,
      "learning_rate": 3.7424698795180723e-06,
      "loss": 0.2045,
      "step": 1670
    },
    {
      "epoch": 1.0066265060240964,
      "grad_norm": 0.7269514203071594,
      "learning_rate": 3.74171686746988e-06,
      "loss": 0.2333,
      "step": 1671
    },
    {
      "epoch": 1.0072289156626506,
      "grad_norm": 0.6308314204216003,
      "learning_rate": 3.740963855421687e-06,
      "loss": 0.2484,
      "step": 1672
    },
    {
      "epoch": 1.0078313253012048,
      "grad_norm": 0.5617812871932983,
      "learning_rate": 3.740210843373494e-06,
      "loss": 0.2499,
      "step": 1673
    },
    {
      "epoch": 1.008433734939759,
      "grad_norm": 0.5916188359260559,
      "learning_rate": 3.7394578313253017e-06,
      "loss": 0.1994,
      "step": 1674
    },
    {
      "epoch": 1.0090361445783131,
      "grad_norm": 0.6025798320770264,
      "learning_rate": 3.7387048192771086e-06,
      "loss": 0.247,
      "step": 1675
    },
    {
      "epoch": 1.0096385542168675,
      "grad_norm": 0.632921040058136,
      "learning_rate": 3.737951807228916e-06,
      "loss": 0.1992,
      "step": 1676
    },
    {
      "epoch": 1.0102409638554217,
      "grad_norm": 0.6674412488937378,
      "learning_rate": 3.7371987951807233e-06,
      "loss": 0.2462,
      "step": 1677
    },
    {
      "epoch": 1.010843373493976,
      "grad_norm": 0.6459711790084839,
      "learning_rate": 3.7364457831325307e-06,
      "loss": 0.2566,
      "step": 1678
    },
    {
      "epoch": 1.01144578313253,
      "grad_norm": 0.6809744238853455,
      "learning_rate": 3.7356927710843376e-06,
      "loss": 0.2635,
      "step": 1679
    },
    {
      "epoch": 1.0120481927710843,
      "grad_norm": 0.5825527906417847,
      "learning_rate": 3.7349397590361445e-06,
      "loss": 0.2182,
      "step": 1680
    },
    {
      "epoch": 1.0126506024096384,
      "grad_norm": 0.6239136457443237,
      "learning_rate": 3.7341867469879523e-06,
      "loss": 0.2273,
      "step": 1681
    },
    {
      "epoch": 1.0132530120481928,
      "grad_norm": 0.709055483341217,
      "learning_rate": 3.7334337349397592e-06,
      "loss": 0.2376,
      "step": 1682
    },
    {
      "epoch": 1.013855421686747,
      "grad_norm": 0.5895212888717651,
      "learning_rate": 3.732680722891567e-06,
      "loss": 0.2736,
      "step": 1683
    },
    {
      "epoch": 1.0144578313253012,
      "grad_norm": 0.5896808505058289,
      "learning_rate": 3.731927710843374e-06,
      "loss": 0.2237,
      "step": 1684
    },
    {
      "epoch": 1.0150602409638554,
      "grad_norm": 0.5976539850234985,
      "learning_rate": 3.731174698795181e-06,
      "loss": 0.2394,
      "step": 1685
    },
    {
      "epoch": 1.0156626506024096,
      "grad_norm": 0.6108614802360535,
      "learning_rate": 3.730421686746988e-06,
      "loss": 0.2491,
      "step": 1686
    },
    {
      "epoch": 1.0162650602409637,
      "grad_norm": 0.5859647989273071,
      "learning_rate": 3.7296686746987955e-06,
      "loss": 0.288,
      "step": 1687
    },
    {
      "epoch": 1.0168674698795181,
      "grad_norm": 0.5983594655990601,
      "learning_rate": 3.728915662650603e-06,
      "loss": 0.2042,
      "step": 1688
    },
    {
      "epoch": 1.0174698795180723,
      "grad_norm": 0.5650344491004944,
      "learning_rate": 3.72816265060241e-06,
      "loss": 0.2182,
      "step": 1689
    },
    {
      "epoch": 1.0180722891566265,
      "grad_norm": 0.6606049537658691,
      "learning_rate": 3.7274096385542176e-06,
      "loss": 0.2013,
      "step": 1690
    },
    {
      "epoch": 1.0186746987951807,
      "grad_norm": 0.548340380191803,
      "learning_rate": 3.7266566265060245e-06,
      "loss": 0.2016,
      "step": 1691
    },
    {
      "epoch": 1.0192771084337349,
      "grad_norm": 0.5426768660545349,
      "learning_rate": 3.7259036144578314e-06,
      "loss": 0.2075,
      "step": 1692
    },
    {
      "epoch": 1.019879518072289,
      "grad_norm": 0.5818175077438354,
      "learning_rate": 3.725150602409639e-06,
      "loss": 0.2289,
      "step": 1693
    },
    {
      "epoch": 1.0204819277108435,
      "grad_norm": 0.5542164444923401,
      "learning_rate": 3.724397590361446e-06,
      "loss": 0.2438,
      "step": 1694
    },
    {
      "epoch": 1.0210843373493976,
      "grad_norm": 0.6699300408363342,
      "learning_rate": 3.7236445783132535e-06,
      "loss": 0.2175,
      "step": 1695
    },
    {
      "epoch": 1.0216867469879518,
      "grad_norm": 0.6514788269996643,
      "learning_rate": 3.7228915662650604e-06,
      "loss": 0.2354,
      "step": 1696
    },
    {
      "epoch": 1.022289156626506,
      "grad_norm": 0.557043731212616,
      "learning_rate": 3.7221385542168677e-06,
      "loss": 0.2384,
      "step": 1697
    },
    {
      "epoch": 1.0228915662650602,
      "grad_norm": 0.5443658828735352,
      "learning_rate": 3.721385542168675e-06,
      "loss": 0.2826,
      "step": 1698
    },
    {
      "epoch": 1.0234939759036144,
      "grad_norm": 0.5525484085083008,
      "learning_rate": 3.720632530120482e-06,
      "loss": 0.2298,
      "step": 1699
    },
    {
      "epoch": 1.0240963855421688,
      "grad_norm": 0.5539202094078064,
      "learning_rate": 3.71987951807229e-06,
      "loss": 0.1952,
      "step": 1700
    },
    {
      "epoch": 1.024698795180723,
      "grad_norm": 0.6447116732597351,
      "learning_rate": 3.7191265060240967e-06,
      "loss": 0.2154,
      "step": 1701
    },
    {
      "epoch": 1.0253012048192771,
      "grad_norm": 0.5565518736839294,
      "learning_rate": 3.718373493975904e-06,
      "loss": 0.2283,
      "step": 1702
    },
    {
      "epoch": 1.0259036144578313,
      "grad_norm": 0.6029331684112549,
      "learning_rate": 3.717620481927711e-06,
      "loss": 0.2069,
      "step": 1703
    },
    {
      "epoch": 1.0265060240963855,
      "grad_norm": 0.5556853413581848,
      "learning_rate": 3.7168674698795183e-06,
      "loss": 0.2613,
      "step": 1704
    },
    {
      "epoch": 1.0271084337349397,
      "grad_norm": 0.5362416505813599,
      "learning_rate": 3.7161144578313257e-06,
      "loss": 0.2209,
      "step": 1705
    },
    {
      "epoch": 1.027710843373494,
      "grad_norm": 0.5702952742576599,
      "learning_rate": 3.7153614457831326e-06,
      "loss": 0.2633,
      "step": 1706
    },
    {
      "epoch": 1.0283132530120482,
      "grad_norm": 0.6237788200378418,
      "learning_rate": 3.7146084337349404e-06,
      "loss": 0.2032,
      "step": 1707
    },
    {
      "epoch": 1.0289156626506024,
      "grad_norm": 0.5755114555358887,
      "learning_rate": 3.7138554216867473e-06,
      "loss": 0.2092,
      "step": 1708
    },
    {
      "epoch": 1.0295180722891566,
      "grad_norm": 0.5700615644454956,
      "learning_rate": 3.7131024096385542e-06,
      "loss": 0.2191,
      "step": 1709
    },
    {
      "epoch": 1.0301204819277108,
      "grad_norm": 0.5802331566810608,
      "learning_rate": 3.712349397590362e-06,
      "loss": 0.2237,
      "step": 1710
    },
    {
      "epoch": 1.030722891566265,
      "grad_norm": 0.6114622950553894,
      "learning_rate": 3.711596385542169e-06,
      "loss": 0.2206,
      "step": 1711
    },
    {
      "epoch": 1.0313253012048194,
      "grad_norm": 0.693122923374176,
      "learning_rate": 3.7108433734939763e-06,
      "loss": 0.222,
      "step": 1712
    },
    {
      "epoch": 1.0319277108433735,
      "grad_norm": 0.5026407837867737,
      "learning_rate": 3.710090361445783e-06,
      "loss": 0.2225,
      "step": 1713
    },
    {
      "epoch": 1.0325301204819277,
      "grad_norm": 0.6691126823425293,
      "learning_rate": 3.709337349397591e-06,
      "loss": 0.2374,
      "step": 1714
    },
    {
      "epoch": 1.033132530120482,
      "grad_norm": 0.5494688153266907,
      "learning_rate": 3.708584337349398e-06,
      "loss": 0.1979,
      "step": 1715
    },
    {
      "epoch": 1.033734939759036,
      "grad_norm": 0.5538400411605835,
      "learning_rate": 3.707831325301205e-06,
      "loss": 0.2477,
      "step": 1716
    },
    {
      "epoch": 1.0343373493975903,
      "grad_norm": 0.49045097827911377,
      "learning_rate": 3.7070783132530126e-06,
      "loss": 0.1861,
      "step": 1717
    },
    {
      "epoch": 1.0349397590361447,
      "grad_norm": 0.5960314869880676,
      "learning_rate": 3.7063253012048195e-06,
      "loss": 0.2497,
      "step": 1718
    },
    {
      "epoch": 1.0355421686746988,
      "grad_norm": 0.8326551914215088,
      "learning_rate": 3.705572289156627e-06,
      "loss": 0.1993,
      "step": 1719
    },
    {
      "epoch": 1.036144578313253,
      "grad_norm": 0.5574325919151306,
      "learning_rate": 3.7048192771084342e-06,
      "loss": 0.212,
      "step": 1720
    },
    {
      "epoch": 1.0367469879518072,
      "grad_norm": 0.5816483497619629,
      "learning_rate": 3.704066265060241e-06,
      "loss": 0.2098,
      "step": 1721
    },
    {
      "epoch": 1.0373493975903614,
      "grad_norm": 0.5598804950714111,
      "learning_rate": 3.7033132530120485e-06,
      "loss": 0.216,
      "step": 1722
    },
    {
      "epoch": 1.0379518072289156,
      "grad_norm": 0.5230050683021545,
      "learning_rate": 3.7025602409638554e-06,
      "loss": 0.2126,
      "step": 1723
    },
    {
      "epoch": 1.03855421686747,
      "grad_norm": 0.5548938512802124,
      "learning_rate": 3.701807228915663e-06,
      "loss": 0.2865,
      "step": 1724
    },
    {
      "epoch": 1.0391566265060241,
      "grad_norm": 0.548706591129303,
      "learning_rate": 3.70105421686747e-06,
      "loss": 0.2081,
      "step": 1725
    },
    {
      "epoch": 1.0397590361445783,
      "grad_norm": 0.5844424962997437,
      "learning_rate": 3.700301204819278e-06,
      "loss": 0.2029,
      "step": 1726
    },
    {
      "epoch": 1.0403614457831325,
      "grad_norm": 0.5211962461471558,
      "learning_rate": 3.699548192771085e-06,
      "loss": 0.2393,
      "step": 1727
    },
    {
      "epoch": 1.0409638554216867,
      "grad_norm": 0.6109213829040527,
      "learning_rate": 3.6987951807228917e-06,
      "loss": 0.2057,
      "step": 1728
    },
    {
      "epoch": 1.0415662650602409,
      "grad_norm": 0.590556263923645,
      "learning_rate": 3.698042168674699e-06,
      "loss": 0.2414,
      "step": 1729
    },
    {
      "epoch": 1.0421686746987953,
      "grad_norm": 0.5430604815483093,
      "learning_rate": 3.6972891566265064e-06,
      "loss": 0.1821,
      "step": 1730
    },
    {
      "epoch": 1.0427710843373494,
      "grad_norm": 0.6353957056999207,
      "learning_rate": 3.6965361445783138e-06,
      "loss": 0.2724,
      "step": 1731
    },
    {
      "epoch": 1.0433734939759036,
      "grad_norm": 0.5019156336784363,
      "learning_rate": 3.6957831325301207e-06,
      "loss": 0.2009,
      "step": 1732
    },
    {
      "epoch": 1.0439759036144578,
      "grad_norm": 0.6726574897766113,
      "learning_rate": 3.6950301204819276e-06,
      "loss": 0.2285,
      "step": 1733
    },
    {
      "epoch": 1.044578313253012,
      "grad_norm": 0.5562721490859985,
      "learning_rate": 3.6942771084337354e-06,
      "loss": 0.2377,
      "step": 1734
    },
    {
      "epoch": 1.0451807228915662,
      "grad_norm": 0.5435733795166016,
      "learning_rate": 3.6935240963855423e-06,
      "loss": 0.2314,
      "step": 1735
    },
    {
      "epoch": 1.0457831325301206,
      "grad_norm": 0.5964382886886597,
      "learning_rate": 3.6927710843373497e-06,
      "loss": 0.2153,
      "step": 1736
    },
    {
      "epoch": 1.0463855421686747,
      "grad_norm": 0.601382851600647,
      "learning_rate": 3.692018072289157e-06,
      "loss": 0.2324,
      "step": 1737
    },
    {
      "epoch": 1.046987951807229,
      "grad_norm": 0.5120938420295715,
      "learning_rate": 3.6912650602409644e-06,
      "loss": 0.2217,
      "step": 1738
    },
    {
      "epoch": 1.047590361445783,
      "grad_norm": 0.5467737317085266,
      "learning_rate": 3.6905120481927713e-06,
      "loss": 0.2138,
      "step": 1739
    },
    {
      "epoch": 1.0481927710843373,
      "grad_norm": 0.5883811712265015,
      "learning_rate": 3.6897590361445782e-06,
      "loss": 0.2391,
      "step": 1740
    },
    {
      "epoch": 1.0487951807228915,
      "grad_norm": 0.4764343202114105,
      "learning_rate": 3.689006024096386e-06,
      "loss": 0.1956,
      "step": 1741
    },
    {
      "epoch": 1.0493975903614459,
      "grad_norm": 0.5365676283836365,
      "learning_rate": 3.688253012048193e-06,
      "loss": 0.2004,
      "step": 1742
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.5650360584259033,
      "learning_rate": 3.6875000000000007e-06,
      "loss": 0.2054,
      "step": 1743
    },
    {
      "epoch": 1.0506024096385542,
      "grad_norm": 0.6048312783241272,
      "learning_rate": 3.6867469879518076e-06,
      "loss": 0.249,
      "step": 1744
    },
    {
      "epoch": 1.0512048192771084,
      "grad_norm": 0.52236407995224,
      "learning_rate": 3.6859939759036145e-06,
      "loss": 0.2327,
      "step": 1745
    },
    {
      "epoch": 1.0518072289156626,
      "grad_norm": 0.5647371411323547,
      "learning_rate": 3.685240963855422e-06,
      "loss": 0.2029,
      "step": 1746
    },
    {
      "epoch": 1.0524096385542168,
      "grad_norm": 0.5125499963760376,
      "learning_rate": 3.6844879518072292e-06,
      "loss": 0.2366,
      "step": 1747
    },
    {
      "epoch": 1.0530120481927712,
      "grad_norm": 0.5556437969207764,
      "learning_rate": 3.6837349397590366e-06,
      "loss": 0.1821,
      "step": 1748
    },
    {
      "epoch": 1.0536144578313253,
      "grad_norm": 0.5665019154548645,
      "learning_rate": 3.6829819277108435e-06,
      "loss": 0.2568,
      "step": 1749
    },
    {
      "epoch": 1.0542168674698795,
      "grad_norm": 0.5712198615074158,
      "learning_rate": 3.6822289156626513e-06,
      "loss": 0.1922,
      "step": 1750
    },
    {
      "epoch": 1.0548192771084337,
      "grad_norm": 0.5691561102867126,
      "learning_rate": 3.681475903614458e-06,
      "loss": 0.2028,
      "step": 1751
    },
    {
      "epoch": 1.0554216867469879,
      "grad_norm": 0.5214918255805969,
      "learning_rate": 3.680722891566265e-06,
      "loss": 0.2404,
      "step": 1752
    },
    {
      "epoch": 1.056024096385542,
      "grad_norm": 0.5064054131507874,
      "learning_rate": 3.679969879518073e-06,
      "loss": 0.2143,
      "step": 1753
    },
    {
      "epoch": 1.0566265060240965,
      "grad_norm": 0.6498476266860962,
      "learning_rate": 3.67921686746988e-06,
      "loss": 0.2475,
      "step": 1754
    },
    {
      "epoch": 1.0572289156626506,
      "grad_norm": 0.5558440089225769,
      "learning_rate": 3.678463855421687e-06,
      "loss": 0.2106,
      "step": 1755
    },
    {
      "epoch": 1.0578313253012048,
      "grad_norm": 0.5598900318145752,
      "learning_rate": 3.677710843373494e-06,
      "loss": 0.2098,
      "step": 1756
    },
    {
      "epoch": 1.058433734939759,
      "grad_norm": 0.5919363498687744,
      "learning_rate": 3.6769578313253015e-06,
      "loss": 0.2154,
      "step": 1757
    },
    {
      "epoch": 1.0590361445783132,
      "grad_norm": 0.5803930759429932,
      "learning_rate": 3.676204819277109e-06,
      "loss": 0.2204,
      "step": 1758
    },
    {
      "epoch": 1.0596385542168674,
      "grad_norm": 0.5121732950210571,
      "learning_rate": 3.6754518072289157e-06,
      "loss": 0.2172,
      "step": 1759
    },
    {
      "epoch": 1.0602409638554218,
      "grad_norm": 0.5391303300857544,
      "learning_rate": 3.6746987951807235e-06,
      "loss": 0.217,
      "step": 1760
    },
    {
      "epoch": 1.060843373493976,
      "grad_norm": 0.5283318161964417,
      "learning_rate": 3.6739457831325304e-06,
      "loss": 0.1974,
      "step": 1761
    },
    {
      "epoch": 1.0614457831325301,
      "grad_norm": 0.6236312389373779,
      "learning_rate": 3.6731927710843378e-06,
      "loss": 0.2559,
      "step": 1762
    },
    {
      "epoch": 1.0620481927710843,
      "grad_norm": 0.5630884170532227,
      "learning_rate": 3.672439759036145e-06,
      "loss": 0.2297,
      "step": 1763
    },
    {
      "epoch": 1.0626506024096385,
      "grad_norm": 0.5159754157066345,
      "learning_rate": 3.671686746987952e-06,
      "loss": 0.201,
      "step": 1764
    },
    {
      "epoch": 1.0632530120481927,
      "grad_norm": 0.5524258613586426,
      "learning_rate": 3.6709337349397594e-06,
      "loss": 0.1837,
      "step": 1765
    },
    {
      "epoch": 1.063855421686747,
      "grad_norm": 0.6258929967880249,
      "learning_rate": 3.6701807228915663e-06,
      "loss": 0.2554,
      "step": 1766
    },
    {
      "epoch": 1.0644578313253013,
      "grad_norm": 1.7559295892715454,
      "learning_rate": 3.669427710843374e-06,
      "loss": 0.1944,
      "step": 1767
    },
    {
      "epoch": 1.0650602409638554,
      "grad_norm": 0.654379665851593,
      "learning_rate": 3.668674698795181e-06,
      "loss": 0.2818,
      "step": 1768
    },
    {
      "epoch": 1.0656626506024096,
      "grad_norm": 0.5732917785644531,
      "learning_rate": 3.667921686746988e-06,
      "loss": 0.193,
      "step": 1769
    },
    {
      "epoch": 1.0662650602409638,
      "grad_norm": 0.46946293115615845,
      "learning_rate": 3.6671686746987957e-06,
      "loss": 0.1891,
      "step": 1770
    },
    {
      "epoch": 1.066867469879518,
      "grad_norm": 0.6063389182090759,
      "learning_rate": 3.6664156626506026e-06,
      "loss": 0.2304,
      "step": 1771
    },
    {
      "epoch": 1.0674698795180724,
      "grad_norm": 0.6524973511695862,
      "learning_rate": 3.66566265060241e-06,
      "loss": 0.2236,
      "step": 1772
    },
    {
      "epoch": 1.0680722891566266,
      "grad_norm": 0.6011930704116821,
      "learning_rate": 3.664909638554217e-06,
      "loss": 0.231,
      "step": 1773
    },
    {
      "epoch": 1.0686746987951807,
      "grad_norm": 0.5619028210639954,
      "learning_rate": 3.6641566265060247e-06,
      "loss": 0.1989,
      "step": 1774
    },
    {
      "epoch": 1.069277108433735,
      "grad_norm": 0.5216304063796997,
      "learning_rate": 3.6634036144578316e-06,
      "loss": 0.193,
      "step": 1775
    },
    {
      "epoch": 1.069879518072289,
      "grad_norm": 0.5231562256813049,
      "learning_rate": 3.6626506024096385e-06,
      "loss": 0.203,
      "step": 1776
    },
    {
      "epoch": 1.0704819277108433,
      "grad_norm": 0.5360733270645142,
      "learning_rate": 3.6618975903614463e-06,
      "loss": 0.1979,
      "step": 1777
    },
    {
      "epoch": 1.0710843373493977,
      "grad_norm": 0.7406540513038635,
      "learning_rate": 3.6611445783132532e-06,
      "loss": 0.2825,
      "step": 1778
    },
    {
      "epoch": 1.0716867469879519,
      "grad_norm": 0.5543988943099976,
      "learning_rate": 3.6603915662650606e-06,
      "loss": 0.2046,
      "step": 1779
    },
    {
      "epoch": 1.072289156626506,
      "grad_norm": 0.5250633358955383,
      "learning_rate": 3.659638554216868e-06,
      "loss": 0.2462,
      "step": 1780
    },
    {
      "epoch": 1.0728915662650602,
      "grad_norm": 0.5597975850105286,
      "learning_rate": 3.658885542168675e-06,
      "loss": 0.2546,
      "step": 1781
    },
    {
      "epoch": 1.0734939759036144,
      "grad_norm": 0.6029123067855835,
      "learning_rate": 3.658132530120482e-06,
      "loss": 0.2039,
      "step": 1782
    },
    {
      "epoch": 1.0740963855421686,
      "grad_norm": 0.6014850735664368,
      "learning_rate": 3.657379518072289e-06,
      "loss": 0.2233,
      "step": 1783
    },
    {
      "epoch": 1.074698795180723,
      "grad_norm": 0.621392011642456,
      "learning_rate": 3.656626506024097e-06,
      "loss": 0.1801,
      "step": 1784
    },
    {
      "epoch": 1.0753012048192772,
      "grad_norm": 0.5427227020263672,
      "learning_rate": 3.655873493975904e-06,
      "loss": 0.1834,
      "step": 1785
    },
    {
      "epoch": 1.0759036144578313,
      "grad_norm": 0.5464897155761719,
      "learning_rate": 3.6551204819277116e-06,
      "loss": 0.2349,
      "step": 1786
    },
    {
      "epoch": 1.0765060240963855,
      "grad_norm": 0.5688543319702148,
      "learning_rate": 3.6543674698795185e-06,
      "loss": 0.2509,
      "step": 1787
    },
    {
      "epoch": 1.0771084337349397,
      "grad_norm": 0.5134186744689941,
      "learning_rate": 3.6536144578313254e-06,
      "loss": 0.1878,
      "step": 1788
    },
    {
      "epoch": 1.0777108433734939,
      "grad_norm": 0.5217296481132507,
      "learning_rate": 3.652861445783133e-06,
      "loss": 0.2489,
      "step": 1789
    },
    {
      "epoch": 1.0783132530120483,
      "grad_norm": 0.5175790190696716,
      "learning_rate": 3.65210843373494e-06,
      "loss": 0.2491,
      "step": 1790
    },
    {
      "epoch": 1.0789156626506025,
      "grad_norm": 0.639116108417511,
      "learning_rate": 3.6513554216867475e-06,
      "loss": 0.2301,
      "step": 1791
    },
    {
      "epoch": 1.0795180722891566,
      "grad_norm": 0.5586652159690857,
      "learning_rate": 3.6506024096385544e-06,
      "loss": 0.2268,
      "step": 1792
    },
    {
      "epoch": 1.0801204819277108,
      "grad_norm": 0.5601426362991333,
      "learning_rate": 3.6498493975903613e-06,
      "loss": 0.1985,
      "step": 1793
    },
    {
      "epoch": 1.080722891566265,
      "grad_norm": 0.6134166717529297,
      "learning_rate": 3.649096385542169e-06,
      "loss": 0.2024,
      "step": 1794
    },
    {
      "epoch": 1.0813253012048192,
      "grad_norm": 0.5200001001358032,
      "learning_rate": 3.648343373493976e-06,
      "loss": 0.1861,
      "step": 1795
    },
    {
      "epoch": 1.0819277108433736,
      "grad_norm": 0.612591564655304,
      "learning_rate": 3.647590361445784e-06,
      "loss": 0.2466,
      "step": 1796
    },
    {
      "epoch": 1.0825301204819278,
      "grad_norm": 0.5435926914215088,
      "learning_rate": 3.6468373493975907e-06,
      "loss": 0.2425,
      "step": 1797
    },
    {
      "epoch": 1.083132530120482,
      "grad_norm": 0.589712917804718,
      "learning_rate": 3.646084337349398e-06,
      "loss": 0.2009,
      "step": 1798
    },
    {
      "epoch": 1.0837349397590361,
      "grad_norm": 0.5020521283149719,
      "learning_rate": 3.645331325301205e-06,
      "loss": 0.2317,
      "step": 1799
    },
    {
      "epoch": 1.0843373493975903,
      "grad_norm": 0.4948910176753998,
      "learning_rate": 3.6445783132530124e-06,
      "loss": 0.2128,
      "step": 1800
    },
    {
      "epoch": 1.0849397590361445,
      "grad_norm": 0.5278297662734985,
      "learning_rate": 3.6438253012048197e-06,
      "loss": 0.1952,
      "step": 1801
    },
    {
      "epoch": 1.0855421686746989,
      "grad_norm": 0.5590835213661194,
      "learning_rate": 3.6430722891566266e-06,
      "loss": 0.2115,
      "step": 1802
    },
    {
      "epoch": 1.086144578313253,
      "grad_norm": 0.5663595199584961,
      "learning_rate": 3.6423192771084344e-06,
      "loss": 0.2062,
      "step": 1803
    },
    {
      "epoch": 1.0867469879518072,
      "grad_norm": 0.511968195438385,
      "learning_rate": 3.6415662650602413e-06,
      "loss": 0.2157,
      "step": 1804
    },
    {
      "epoch": 1.0873493975903614,
      "grad_norm": 0.551673412322998,
      "learning_rate": 3.6408132530120482e-06,
      "loss": 0.1983,
      "step": 1805
    },
    {
      "epoch": 1.0879518072289156,
      "grad_norm": 0.5991960167884827,
      "learning_rate": 3.6400602409638556e-06,
      "loss": 0.1977,
      "step": 1806
    },
    {
      "epoch": 1.0885542168674698,
      "grad_norm": 0.5168616771697998,
      "learning_rate": 3.639307228915663e-06,
      "loss": 0.209,
      "step": 1807
    },
    {
      "epoch": 1.0891566265060242,
      "grad_norm": 0.6214616894721985,
      "learning_rate": 3.6385542168674703e-06,
      "loss": 0.2125,
      "step": 1808
    },
    {
      "epoch": 1.0897590361445784,
      "grad_norm": 0.5322622656822205,
      "learning_rate": 3.6378012048192772e-06,
      "loss": 0.1946,
      "step": 1809
    },
    {
      "epoch": 1.0903614457831325,
      "grad_norm": 0.6226611137390137,
      "learning_rate": 3.637048192771085e-06,
      "loss": 0.2187,
      "step": 1810
    },
    {
      "epoch": 1.0909638554216867,
      "grad_norm": 0.6335646510124207,
      "learning_rate": 3.636295180722892e-06,
      "loss": 0.2297,
      "step": 1811
    },
    {
      "epoch": 1.091566265060241,
      "grad_norm": 0.5199056267738342,
      "learning_rate": 3.635542168674699e-06,
      "loss": 0.2249,
      "step": 1812
    },
    {
      "epoch": 1.092168674698795,
      "grad_norm": 0.6119028925895691,
      "learning_rate": 3.6347891566265066e-06,
      "loss": 0.1934,
      "step": 1813
    },
    {
      "epoch": 1.0927710843373495,
      "grad_norm": 0.4678422510623932,
      "learning_rate": 3.6340361445783135e-06,
      "loss": 0.1995,
      "step": 1814
    },
    {
      "epoch": 1.0933734939759037,
      "grad_norm": 0.677707314491272,
      "learning_rate": 3.633283132530121e-06,
      "loss": 0.2702,
      "step": 1815
    },
    {
      "epoch": 1.0939759036144578,
      "grad_norm": 0.7639368772506714,
      "learning_rate": 3.632530120481928e-06,
      "loss": 0.2412,
      "step": 1816
    },
    {
      "epoch": 1.094578313253012,
      "grad_norm": 0.5093151330947876,
      "learning_rate": 3.631777108433735e-06,
      "loss": 0.1989,
      "step": 1817
    },
    {
      "epoch": 1.0951807228915662,
      "grad_norm": 0.5163976550102234,
      "learning_rate": 3.6310240963855425e-06,
      "loss": 0.1899,
      "step": 1818
    },
    {
      "epoch": 1.0957831325301204,
      "grad_norm": 0.4829656481742859,
      "learning_rate": 3.6302710843373494e-06,
      "loss": 0.2104,
      "step": 1819
    },
    {
      "epoch": 1.0963855421686748,
      "grad_norm": 0.5184393525123596,
      "learning_rate": 3.629518072289157e-06,
      "loss": 0.1996,
      "step": 1820
    },
    {
      "epoch": 1.096987951807229,
      "grad_norm": 0.5530661344528198,
      "learning_rate": 3.628765060240964e-06,
      "loss": 0.1829,
      "step": 1821
    },
    {
      "epoch": 1.0975903614457831,
      "grad_norm": 0.5485884547233582,
      "learning_rate": 3.6280120481927715e-06,
      "loss": 0.2112,
      "step": 1822
    },
    {
      "epoch": 1.0981927710843373,
      "grad_norm": 0.5202689170837402,
      "learning_rate": 3.627259036144579e-06,
      "loss": 0.2152,
      "step": 1823
    },
    {
      "epoch": 1.0987951807228915,
      "grad_norm": 0.4731758236885071,
      "learning_rate": 3.6265060240963857e-06,
      "loss": 0.191,
      "step": 1824
    },
    {
      "epoch": 1.0993975903614457,
      "grad_norm": 0.5479321479797363,
      "learning_rate": 3.625753012048193e-06,
      "loss": 0.2459,
      "step": 1825
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.545063316822052,
      "learning_rate": 3.625e-06,
      "loss": 0.2058,
      "step": 1826
    },
    {
      "epoch": 1.1006024096385543,
      "grad_norm": 0.6152647137641907,
      "learning_rate": 3.624246987951808e-06,
      "loss": 0.2421,
      "step": 1827
    },
    {
      "epoch": 1.1012048192771084,
      "grad_norm": 0.5197845101356506,
      "learning_rate": 3.6234939759036147e-06,
      "loss": 0.1891,
      "step": 1828
    },
    {
      "epoch": 1.1018072289156626,
      "grad_norm": 0.6107365489006042,
      "learning_rate": 3.6227409638554216e-06,
      "loss": 0.2199,
      "step": 1829
    },
    {
      "epoch": 1.1024096385542168,
      "grad_norm": 0.5565663576126099,
      "learning_rate": 3.6219879518072294e-06,
      "loss": 0.204,
      "step": 1830
    },
    {
      "epoch": 1.103012048192771,
      "grad_norm": 0.5208209156990051,
      "learning_rate": 3.6212349397590363e-06,
      "loss": 0.1879,
      "step": 1831
    },
    {
      "epoch": 1.1036144578313254,
      "grad_norm": 0.4886201322078705,
      "learning_rate": 3.6204819277108437e-06,
      "loss": 0.2004,
      "step": 1832
    },
    {
      "epoch": 1.1042168674698796,
      "grad_norm": 0.6147620677947998,
      "learning_rate": 3.619728915662651e-06,
      "loss": 0.2029,
      "step": 1833
    },
    {
      "epoch": 1.1048192771084338,
      "grad_norm": 0.580737292766571,
      "learning_rate": 3.6189759036144584e-06,
      "loss": 0.2175,
      "step": 1834
    },
    {
      "epoch": 1.105421686746988,
      "grad_norm": 0.546844482421875,
      "learning_rate": 3.6182228915662653e-06,
      "loss": 0.2209,
      "step": 1835
    },
    {
      "epoch": 1.106024096385542,
      "grad_norm": 0.6143650412559509,
      "learning_rate": 3.6174698795180722e-06,
      "loss": 0.1799,
      "step": 1836
    },
    {
      "epoch": 1.1066265060240963,
      "grad_norm": 0.45633575320243835,
      "learning_rate": 3.61671686746988e-06,
      "loss": 0.1927,
      "step": 1837
    },
    {
      "epoch": 1.1072289156626507,
      "grad_norm": 0.6047266125679016,
      "learning_rate": 3.615963855421687e-06,
      "loss": 0.2293,
      "step": 1838
    },
    {
      "epoch": 1.1078313253012049,
      "grad_norm": 0.493065744638443,
      "learning_rate": 3.6152108433734943e-06,
      "loss": 0.1468,
      "step": 1839
    },
    {
      "epoch": 1.108433734939759,
      "grad_norm": 0.4926621913909912,
      "learning_rate": 3.6144578313253016e-06,
      "loss": 0.1941,
      "step": 1840
    },
    {
      "epoch": 1.1090361445783132,
      "grad_norm": 0.5101581811904907,
      "learning_rate": 3.6137048192771086e-06,
      "loss": 0.2234,
      "step": 1841
    },
    {
      "epoch": 1.1096385542168674,
      "grad_norm": 0.7441114783287048,
      "learning_rate": 3.612951807228916e-06,
      "loss": 0.1898,
      "step": 1842
    },
    {
      "epoch": 1.1102409638554216,
      "grad_norm": 0.5849472284317017,
      "learning_rate": 3.612198795180723e-06,
      "loss": 0.2204,
      "step": 1843
    },
    {
      "epoch": 1.110843373493976,
      "grad_norm": 0.5584914088249207,
      "learning_rate": 3.6114457831325306e-06,
      "loss": 0.2318,
      "step": 1844
    },
    {
      "epoch": 1.1114457831325302,
      "grad_norm": 0.622622013092041,
      "learning_rate": 3.6106927710843375e-06,
      "loss": 0.2333,
      "step": 1845
    },
    {
      "epoch": 1.1120481927710844,
      "grad_norm": 0.5674509406089783,
      "learning_rate": 3.6099397590361453e-06,
      "loss": 0.2034,
      "step": 1846
    },
    {
      "epoch": 1.1126506024096385,
      "grad_norm": 0.5270935893058777,
      "learning_rate": 3.6091867469879522e-06,
      "loss": 0.1764,
      "step": 1847
    },
    {
      "epoch": 1.1132530120481927,
      "grad_norm": 0.5128425359725952,
      "learning_rate": 3.608433734939759e-06,
      "loss": 0.2302,
      "step": 1848
    },
    {
      "epoch": 1.113855421686747,
      "grad_norm": 0.5393211245536804,
      "learning_rate": 3.6076807228915665e-06,
      "loss": 0.2352,
      "step": 1849
    },
    {
      "epoch": 1.1144578313253013,
      "grad_norm": 0.6072893142700195,
      "learning_rate": 3.606927710843374e-06,
      "loss": 0.2156,
      "step": 1850
    },
    {
      "epoch": 1.1150602409638555,
      "grad_norm": 0.5471010208129883,
      "learning_rate": 3.606174698795181e-06,
      "loss": 0.1467,
      "step": 1851
    },
    {
      "epoch": 1.1156626506024097,
      "grad_norm": 0.6086395382881165,
      "learning_rate": 3.605421686746988e-06,
      "loss": 0.2342,
      "step": 1852
    },
    {
      "epoch": 1.1162650602409638,
      "grad_norm": 0.5952566266059875,
      "learning_rate": 3.604668674698795e-06,
      "loss": 0.2464,
      "step": 1853
    },
    {
      "epoch": 1.116867469879518,
      "grad_norm": 0.5360123515129089,
      "learning_rate": 3.603915662650603e-06,
      "loss": 0.2014,
      "step": 1854
    },
    {
      "epoch": 1.1174698795180722,
      "grad_norm": 0.6594963669776917,
      "learning_rate": 3.6031626506024097e-06,
      "loss": 0.2132,
      "step": 1855
    },
    {
      "epoch": 1.1180722891566266,
      "grad_norm": 0.6136143803596497,
      "learning_rate": 3.6024096385542175e-06,
      "loss": 0.2341,
      "step": 1856
    },
    {
      "epoch": 1.1186746987951808,
      "grad_norm": 0.5493417978286743,
      "learning_rate": 3.6016566265060244e-06,
      "loss": 0.1921,
      "step": 1857
    },
    {
      "epoch": 1.119277108433735,
      "grad_norm": 0.6594560742378235,
      "learning_rate": 3.6009036144578318e-06,
      "loss": 0.2308,
      "step": 1858
    },
    {
      "epoch": 1.1198795180722891,
      "grad_norm": 0.5561659336090088,
      "learning_rate": 3.6001506024096387e-06,
      "loss": 0.2061,
      "step": 1859
    },
    {
      "epoch": 1.1204819277108433,
      "grad_norm": 0.5507648587226868,
      "learning_rate": 3.599397590361446e-06,
      "loss": 0.1748,
      "step": 1860
    },
    {
      "epoch": 1.1210843373493975,
      "grad_norm": 0.5417376160621643,
      "learning_rate": 3.5986445783132534e-06,
      "loss": 0.2257,
      "step": 1861
    },
    {
      "epoch": 1.121686746987952,
      "grad_norm": 0.6299105882644653,
      "learning_rate": 3.5978915662650603e-06,
      "loss": 0.2112,
      "step": 1862
    },
    {
      "epoch": 1.122289156626506,
      "grad_norm": 0.6291981339454651,
      "learning_rate": 3.597138554216868e-06,
      "loss": 0.2826,
      "step": 1863
    },
    {
      "epoch": 1.1228915662650603,
      "grad_norm": 0.548258900642395,
      "learning_rate": 3.596385542168675e-06,
      "loss": 0.1763,
      "step": 1864
    },
    {
      "epoch": 1.1234939759036144,
      "grad_norm": 0.5288527607917786,
      "learning_rate": 3.595632530120482e-06,
      "loss": 0.2186,
      "step": 1865
    },
    {
      "epoch": 1.1240963855421686,
      "grad_norm": 0.4447050094604492,
      "learning_rate": 3.5948795180722897e-06,
      "loss": 0.1927,
      "step": 1866
    },
    {
      "epoch": 1.1246987951807228,
      "grad_norm": 0.6181941032409668,
      "learning_rate": 3.5941265060240966e-06,
      "loss": 0.2191,
      "step": 1867
    },
    {
      "epoch": 1.1253012048192772,
      "grad_norm": 0.5281643271446228,
      "learning_rate": 3.593373493975904e-06,
      "loss": 0.2096,
      "step": 1868
    },
    {
      "epoch": 1.1259036144578314,
      "grad_norm": 0.5254058241844177,
      "learning_rate": 3.592620481927711e-06,
      "loss": 0.1771,
      "step": 1869
    },
    {
      "epoch": 1.1265060240963856,
      "grad_norm": 0.5919300317764282,
      "learning_rate": 3.5918674698795187e-06,
      "loss": 0.2165,
      "step": 1870
    },
    {
      "epoch": 1.1271084337349397,
      "grad_norm": 0.462715744972229,
      "learning_rate": 3.5911144578313256e-06,
      "loss": 0.1882,
      "step": 1871
    },
    {
      "epoch": 1.127710843373494,
      "grad_norm": 0.5933997631072998,
      "learning_rate": 3.5903614457831325e-06,
      "loss": 0.2341,
      "step": 1872
    },
    {
      "epoch": 1.128313253012048,
      "grad_norm": 0.5154777765274048,
      "learning_rate": 3.5896084337349403e-06,
      "loss": 0.22,
      "step": 1873
    },
    {
      "epoch": 1.1289156626506025,
      "grad_norm": 0.5031237602233887,
      "learning_rate": 3.5888554216867472e-06,
      "loss": 0.1891,
      "step": 1874
    },
    {
      "epoch": 1.1295180722891567,
      "grad_norm": 0.5020487308502197,
      "learning_rate": 3.5881024096385546e-06,
      "loss": 0.1832,
      "step": 1875
    },
    {
      "epoch": 1.1301204819277109,
      "grad_norm": 0.442329466342926,
      "learning_rate": 3.5873493975903615e-06,
      "loss": 0.1894,
      "step": 1876
    },
    {
      "epoch": 1.130722891566265,
      "grad_norm": 0.4854069650173187,
      "learning_rate": 3.586596385542169e-06,
      "loss": 0.202,
      "step": 1877
    },
    {
      "epoch": 1.1313253012048192,
      "grad_norm": 0.48691514134407043,
      "learning_rate": 3.585843373493976e-06,
      "loss": 0.2049,
      "step": 1878
    },
    {
      "epoch": 1.1319277108433734,
      "grad_norm": 0.5710991621017456,
      "learning_rate": 3.585090361445783e-06,
      "loss": 0.2134,
      "step": 1879
    },
    {
      "epoch": 1.1325301204819278,
      "grad_norm": 0.549748420715332,
      "learning_rate": 3.584337349397591e-06,
      "loss": 0.2074,
      "step": 1880
    },
    {
      "epoch": 1.133132530120482,
      "grad_norm": 0.5841948986053467,
      "learning_rate": 3.583584337349398e-06,
      "loss": 0.1964,
      "step": 1881
    },
    {
      "epoch": 1.1337349397590362,
      "grad_norm": 0.5336557626724243,
      "learning_rate": 3.582831325301205e-06,
      "loss": 0.2151,
      "step": 1882
    },
    {
      "epoch": 1.1343373493975903,
      "grad_norm": 0.545261025428772,
      "learning_rate": 3.5820783132530125e-06,
      "loss": 0.1946,
      "step": 1883
    },
    {
      "epoch": 1.1349397590361445,
      "grad_norm": 0.5881248712539673,
      "learning_rate": 3.5813253012048195e-06,
      "loss": 0.2326,
      "step": 1884
    },
    {
      "epoch": 1.1355421686746987,
      "grad_norm": 0.5740397572517395,
      "learning_rate": 3.580572289156627e-06,
      "loss": 0.1831,
      "step": 1885
    },
    {
      "epoch": 1.136144578313253,
      "grad_norm": 0.6324855089187622,
      "learning_rate": 3.5798192771084337e-06,
      "loss": 0.2215,
      "step": 1886
    },
    {
      "epoch": 1.1367469879518073,
      "grad_norm": 0.5584884285926819,
      "learning_rate": 3.5790662650602415e-06,
      "loss": 0.173,
      "step": 1887
    },
    {
      "epoch": 1.1373493975903615,
      "grad_norm": 0.49513188004493713,
      "learning_rate": 3.5783132530120484e-06,
      "loss": 0.2087,
      "step": 1888
    },
    {
      "epoch": 1.1379518072289156,
      "grad_norm": 0.5903423428535461,
      "learning_rate": 3.5775602409638553e-06,
      "loss": 0.2559,
      "step": 1889
    },
    {
      "epoch": 1.1385542168674698,
      "grad_norm": 0.5191819667816162,
      "learning_rate": 3.576807228915663e-06,
      "loss": 0.2029,
      "step": 1890
    },
    {
      "epoch": 1.139156626506024,
      "grad_norm": 0.6689732074737549,
      "learning_rate": 3.57605421686747e-06,
      "loss": 0.1583,
      "step": 1891
    },
    {
      "epoch": 1.1397590361445784,
      "grad_norm": 0.49895408749580383,
      "learning_rate": 3.5753012048192774e-06,
      "loss": 0.1563,
      "step": 1892
    },
    {
      "epoch": 1.1403614457831326,
      "grad_norm": 0.5549566745758057,
      "learning_rate": 3.5745481927710847e-06,
      "loss": 0.201,
      "step": 1893
    },
    {
      "epoch": 1.1409638554216868,
      "grad_norm": 0.648867130279541,
      "learning_rate": 3.573795180722892e-06,
      "loss": 0.2503,
      "step": 1894
    },
    {
      "epoch": 1.141566265060241,
      "grad_norm": 0.5101909637451172,
      "learning_rate": 3.573042168674699e-06,
      "loss": 0.2075,
      "step": 1895
    },
    {
      "epoch": 1.1421686746987951,
      "grad_norm": 0.5916838049888611,
      "learning_rate": 3.572289156626506e-06,
      "loss": 0.2162,
      "step": 1896
    },
    {
      "epoch": 1.1427710843373493,
      "grad_norm": 0.6414032578468323,
      "learning_rate": 3.5715361445783137e-06,
      "loss": 0.1755,
      "step": 1897
    },
    {
      "epoch": 1.1433734939759037,
      "grad_norm": 0.5182886719703674,
      "learning_rate": 3.5707831325301206e-06,
      "loss": 0.2245,
      "step": 1898
    },
    {
      "epoch": 1.143975903614458,
      "grad_norm": 0.6015724539756775,
      "learning_rate": 3.5700301204819284e-06,
      "loss": 0.2275,
      "step": 1899
    },
    {
      "epoch": 1.144578313253012,
      "grad_norm": 0.4962620139122009,
      "learning_rate": 3.5692771084337353e-06,
      "loss": 0.201,
      "step": 1900
    },
    {
      "epoch": 1.1451807228915662,
      "grad_norm": 0.5721278190612793,
      "learning_rate": 3.5685240963855423e-06,
      "loss": 0.1776,
      "step": 1901
    },
    {
      "epoch": 1.1457831325301204,
      "grad_norm": 0.5762523412704468,
      "learning_rate": 3.5677710843373496e-06,
      "loss": 0.1985,
      "step": 1902
    },
    {
      "epoch": 1.1463855421686746,
      "grad_norm": 0.5256364345550537,
      "learning_rate": 3.567018072289157e-06,
      "loss": 0.1945,
      "step": 1903
    },
    {
      "epoch": 1.146987951807229,
      "grad_norm": 0.5551699995994568,
      "learning_rate": 3.5662650602409643e-06,
      "loss": 0.1615,
      "step": 1904
    },
    {
      "epoch": 1.1475903614457832,
      "grad_norm": 0.6125929355621338,
      "learning_rate": 3.5655120481927712e-06,
      "loss": 0.2137,
      "step": 1905
    },
    {
      "epoch": 1.1481927710843374,
      "grad_norm": 0.6089499592781067,
      "learning_rate": 3.564759036144579e-06,
      "loss": 0.225,
      "step": 1906
    },
    {
      "epoch": 1.1487951807228916,
      "grad_norm": 0.49503055214881897,
      "learning_rate": 3.564006024096386e-06,
      "loss": 0.1823,
      "step": 1907
    },
    {
      "epoch": 1.1493975903614457,
      "grad_norm": 0.5597626566886902,
      "learning_rate": 3.563253012048193e-06,
      "loss": 0.1735,
      "step": 1908
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.5795822739601135,
      "learning_rate": 3.5625e-06,
      "loss": 0.2164,
      "step": 1909
    },
    {
      "epoch": 1.1506024096385543,
      "grad_norm": 0.5436074137687683,
      "learning_rate": 3.5617469879518075e-06,
      "loss": 0.1945,
      "step": 1910
    },
    {
      "epoch": 1.1512048192771085,
      "grad_norm": 0.5303271412849426,
      "learning_rate": 3.560993975903615e-06,
      "loss": 0.191,
      "step": 1911
    },
    {
      "epoch": 1.1518072289156627,
      "grad_norm": 0.5595015287399292,
      "learning_rate": 3.560240963855422e-06,
      "loss": 0.1693,
      "step": 1912
    },
    {
      "epoch": 1.1524096385542169,
      "grad_norm": 0.5316839814186096,
      "learning_rate": 3.5594879518072287e-06,
      "loss": 0.2067,
      "step": 1913
    },
    {
      "epoch": 1.153012048192771,
      "grad_norm": 0.5498919486999512,
      "learning_rate": 3.5587349397590365e-06,
      "loss": 0.218,
      "step": 1914
    },
    {
      "epoch": 1.1536144578313252,
      "grad_norm": 0.49968379735946655,
      "learning_rate": 3.5579819277108434e-06,
      "loss": 0.1812,
      "step": 1915
    },
    {
      "epoch": 1.1542168674698796,
      "grad_norm": 0.5469430088996887,
      "learning_rate": 3.557228915662651e-06,
      "loss": 0.2014,
      "step": 1916
    },
    {
      "epoch": 1.1548192771084338,
      "grad_norm": 0.6559925079345703,
      "learning_rate": 3.556475903614458e-06,
      "loss": 0.2712,
      "step": 1917
    },
    {
      "epoch": 1.155421686746988,
      "grad_norm": 0.5759490728378296,
      "learning_rate": 3.5557228915662655e-06,
      "loss": 0.2032,
      "step": 1918
    },
    {
      "epoch": 1.1560240963855422,
      "grad_norm": 0.5231872797012329,
      "learning_rate": 3.5549698795180724e-06,
      "loss": 0.1975,
      "step": 1919
    },
    {
      "epoch": 1.1566265060240963,
      "grad_norm": 0.5655622482299805,
      "learning_rate": 3.5542168674698798e-06,
      "loss": 0.2108,
      "step": 1920
    },
    {
      "epoch": 1.1572289156626505,
      "grad_norm": 0.5696512460708618,
      "learning_rate": 3.553463855421687e-06,
      "loss": 0.1818,
      "step": 1921
    },
    {
      "epoch": 1.157831325301205,
      "grad_norm": 0.5212115049362183,
      "learning_rate": 3.552710843373494e-06,
      "loss": 0.1681,
      "step": 1922
    },
    {
      "epoch": 1.158433734939759,
      "grad_norm": 0.5141005516052246,
      "learning_rate": 3.551957831325302e-06,
      "loss": 0.1758,
      "step": 1923
    },
    {
      "epoch": 1.1590361445783133,
      "grad_norm": 0.5276519060134888,
      "learning_rate": 3.5512048192771087e-06,
      "loss": 0.2146,
      "step": 1924
    },
    {
      "epoch": 1.1596385542168675,
      "grad_norm": 0.6281647682189941,
      "learning_rate": 3.5504518072289157e-06,
      "loss": 0.1944,
      "step": 1925
    },
    {
      "epoch": 1.1602409638554216,
      "grad_norm": 0.49461856484413147,
      "learning_rate": 3.5496987951807234e-06,
      "loss": 0.1722,
      "step": 1926
    },
    {
      "epoch": 1.1608433734939758,
      "grad_norm": 0.589397668838501,
      "learning_rate": 3.5489457831325303e-06,
      "loss": 0.2155,
      "step": 1927
    },
    {
      "epoch": 1.16144578313253,
      "grad_norm": 0.6089430451393127,
      "learning_rate": 3.5481927710843377e-06,
      "loss": 0.1691,
      "step": 1928
    },
    {
      "epoch": 1.1620481927710844,
      "grad_norm": 0.6749926209449768,
      "learning_rate": 3.5474397590361446e-06,
      "loss": 0.2065,
      "step": 1929
    },
    {
      "epoch": 1.1626506024096386,
      "grad_norm": 0.49523094296455383,
      "learning_rate": 3.5466867469879524e-06,
      "loss": 0.2094,
      "step": 1930
    },
    {
      "epoch": 1.1632530120481928,
      "grad_norm": 0.5332591533660889,
      "learning_rate": 3.5459337349397593e-06,
      "loss": 0.1871,
      "step": 1931
    },
    {
      "epoch": 1.163855421686747,
      "grad_norm": 1.0723916292190552,
      "learning_rate": 3.5451807228915662e-06,
      "loss": 0.1823,
      "step": 1932
    },
    {
      "epoch": 1.1644578313253011,
      "grad_norm": 0.6538950800895691,
      "learning_rate": 3.544427710843374e-06,
      "loss": 0.167,
      "step": 1933
    },
    {
      "epoch": 1.1650602409638555,
      "grad_norm": 0.5729124546051025,
      "learning_rate": 3.543674698795181e-06,
      "loss": 0.1811,
      "step": 1934
    },
    {
      "epoch": 1.1656626506024097,
      "grad_norm": 0.5077425241470337,
      "learning_rate": 3.5429216867469883e-06,
      "loss": 0.1855,
      "step": 1935
    },
    {
      "epoch": 1.1662650602409639,
      "grad_norm": 0.5408572554588318,
      "learning_rate": 3.5421686746987956e-06,
      "loss": 0.1888,
      "step": 1936
    },
    {
      "epoch": 1.166867469879518,
      "grad_norm": 0.5160971283912659,
      "learning_rate": 3.5414156626506026e-06,
      "loss": 0.1987,
      "step": 1937
    },
    {
      "epoch": 1.1674698795180722,
      "grad_norm": 0.5545939803123474,
      "learning_rate": 3.54066265060241e-06,
      "loss": 0.2427,
      "step": 1938
    },
    {
      "epoch": 1.1680722891566264,
      "grad_norm": 0.7454066872596741,
      "learning_rate": 3.539909638554217e-06,
      "loss": 0.2282,
      "step": 1939
    },
    {
      "epoch": 1.1686746987951806,
      "grad_norm": 0.594551146030426,
      "learning_rate": 3.5391566265060246e-06,
      "loss": 0.2314,
      "step": 1940
    },
    {
      "epoch": 1.169277108433735,
      "grad_norm": 0.5335832834243774,
      "learning_rate": 3.5384036144578315e-06,
      "loss": 0.1725,
      "step": 1941
    },
    {
      "epoch": 1.1698795180722892,
      "grad_norm": 0.6524441838264465,
      "learning_rate": 3.537650602409639e-06,
      "loss": 0.2302,
      "step": 1942
    },
    {
      "epoch": 1.1704819277108434,
      "grad_norm": 0.526018500328064,
      "learning_rate": 3.5368975903614462e-06,
      "loss": 0.1661,
      "step": 1943
    },
    {
      "epoch": 1.1710843373493975,
      "grad_norm": 0.5828050374984741,
      "learning_rate": 3.536144578313253e-06,
      "loss": 0.23,
      "step": 1944
    },
    {
      "epoch": 1.1716867469879517,
      "grad_norm": 0.49693763256073,
      "learning_rate": 3.5353915662650605e-06,
      "loss": 0.1976,
      "step": 1945
    },
    {
      "epoch": 1.1722891566265061,
      "grad_norm": 0.5429035425186157,
      "learning_rate": 3.5346385542168674e-06,
      "loss": 0.2001,
      "step": 1946
    },
    {
      "epoch": 1.1728915662650603,
      "grad_norm": 0.5698562264442444,
      "learning_rate": 3.533885542168675e-06,
      "loss": 0.2151,
      "step": 1947
    },
    {
      "epoch": 1.1734939759036145,
      "grad_norm": 0.5490821599960327,
      "learning_rate": 3.533132530120482e-06,
      "loss": 0.1714,
      "step": 1948
    },
    {
      "epoch": 1.1740963855421687,
      "grad_norm": 0.7078816294670105,
      "learning_rate": 3.532379518072289e-06,
      "loss": 0.2265,
      "step": 1949
    },
    {
      "epoch": 1.1746987951807228,
      "grad_norm": 0.6217227578163147,
      "learning_rate": 3.531626506024097e-06,
      "loss": 0.2403,
      "step": 1950
    },
    {
      "epoch": 1.175301204819277,
      "grad_norm": 0.4804859161376953,
      "learning_rate": 3.5308734939759037e-06,
      "loss": 0.1725,
      "step": 1951
    },
    {
      "epoch": 1.1759036144578312,
      "grad_norm": 0.592829704284668,
      "learning_rate": 3.530120481927711e-06,
      "loss": 0.2152,
      "step": 1952
    },
    {
      "epoch": 1.1765060240963856,
      "grad_norm": 0.6480600833892822,
      "learning_rate": 3.5293674698795184e-06,
      "loss": 0.2014,
      "step": 1953
    },
    {
      "epoch": 1.1771084337349398,
      "grad_norm": 0.5059494376182556,
      "learning_rate": 3.528614457831326e-06,
      "loss": 0.2054,
      "step": 1954
    },
    {
      "epoch": 1.177710843373494,
      "grad_norm": 0.5291392803192139,
      "learning_rate": 3.5278614457831327e-06,
      "loss": 0.176,
      "step": 1955
    },
    {
      "epoch": 1.1783132530120481,
      "grad_norm": 0.5788876414299011,
      "learning_rate": 3.5271084337349396e-06,
      "loss": 0.1821,
      "step": 1956
    },
    {
      "epoch": 1.1789156626506023,
      "grad_norm": 0.5763813257217407,
      "learning_rate": 3.5263554216867474e-06,
      "loss": 0.1715,
      "step": 1957
    },
    {
      "epoch": 1.1795180722891567,
      "grad_norm": 0.6382805705070496,
      "learning_rate": 3.5256024096385543e-06,
      "loss": 0.1944,
      "step": 1958
    },
    {
      "epoch": 1.180120481927711,
      "grad_norm": 0.6820279955863953,
      "learning_rate": 3.524849397590362e-06,
      "loss": 0.235,
      "step": 1959
    },
    {
      "epoch": 1.180722891566265,
      "grad_norm": 0.6487861275672913,
      "learning_rate": 3.524096385542169e-06,
      "loss": 0.2123,
      "step": 1960
    },
    {
      "epoch": 1.1813253012048193,
      "grad_norm": 0.7665185928344727,
      "learning_rate": 3.523343373493976e-06,
      "loss": 0.233,
      "step": 1961
    },
    {
      "epoch": 1.1819277108433734,
      "grad_norm": 0.566963791847229,
      "learning_rate": 3.5225903614457833e-06,
      "loss": 0.2219,
      "step": 1962
    },
    {
      "epoch": 1.1825301204819276,
      "grad_norm": 0.5464989542961121,
      "learning_rate": 3.5218373493975907e-06,
      "loss": 0.1938,
      "step": 1963
    },
    {
      "epoch": 1.1831325301204818,
      "grad_norm": 0.6851610541343689,
      "learning_rate": 3.521084337349398e-06,
      "loss": 0.2283,
      "step": 1964
    },
    {
      "epoch": 1.1837349397590362,
      "grad_norm": 0.6378297805786133,
      "learning_rate": 3.520331325301205e-06,
      "loss": 0.1842,
      "step": 1965
    },
    {
      "epoch": 1.1843373493975904,
      "grad_norm": 0.4829069674015045,
      "learning_rate": 3.5195783132530127e-06,
      "loss": 0.171,
      "step": 1966
    },
    {
      "epoch": 1.1849397590361446,
      "grad_norm": 0.6376652717590332,
      "learning_rate": 3.5188253012048196e-06,
      "loss": 0.2319,
      "step": 1967
    },
    {
      "epoch": 1.1855421686746987,
      "grad_norm": 0.4854018986225128,
      "learning_rate": 3.5180722891566266e-06,
      "loss": 0.1876,
      "step": 1968
    },
    {
      "epoch": 1.186144578313253,
      "grad_norm": 0.5374605059623718,
      "learning_rate": 3.5173192771084343e-06,
      "loss": 0.2043,
      "step": 1969
    },
    {
      "epoch": 1.1867469879518073,
      "grad_norm": 0.6472627520561218,
      "learning_rate": 3.5165662650602412e-06,
      "loss": 0.1986,
      "step": 1970
    },
    {
      "epoch": 1.1873493975903615,
      "grad_norm": 0.5081651210784912,
      "learning_rate": 3.5158132530120486e-06,
      "loss": 0.1855,
      "step": 1971
    },
    {
      "epoch": 1.1879518072289157,
      "grad_norm": 0.5475043654441833,
      "learning_rate": 3.5150602409638555e-06,
      "loss": 0.231,
      "step": 1972
    },
    {
      "epoch": 1.1885542168674699,
      "grad_norm": 0.4800876975059509,
      "learning_rate": 3.514307228915663e-06,
      "loss": 0.1766,
      "step": 1973
    },
    {
      "epoch": 1.189156626506024,
      "grad_norm": 0.5352328419685364,
      "learning_rate": 3.5135542168674702e-06,
      "loss": 0.1987,
      "step": 1974
    },
    {
      "epoch": 1.1897590361445782,
      "grad_norm": 0.5762553811073303,
      "learning_rate": 3.512801204819277e-06,
      "loss": 0.1944,
      "step": 1975
    },
    {
      "epoch": 1.1903614457831324,
      "grad_norm": 0.591858446598053,
      "learning_rate": 3.512048192771085e-06,
      "loss": 0.21,
      "step": 1976
    },
    {
      "epoch": 1.1909638554216868,
      "grad_norm": 0.5059669613838196,
      "learning_rate": 3.511295180722892e-06,
      "loss": 0.1953,
      "step": 1977
    },
    {
      "epoch": 1.191566265060241,
      "grad_norm": 0.5858803391456604,
      "learning_rate": 3.510542168674699e-06,
      "loss": 0.2727,
      "step": 1978
    },
    {
      "epoch": 1.1921686746987952,
      "grad_norm": 0.5097799301147461,
      "learning_rate": 3.509789156626506e-06,
      "loss": 0.1984,
      "step": 1979
    },
    {
      "epoch": 1.1927710843373494,
      "grad_norm": 0.5265614986419678,
      "learning_rate": 3.5090361445783135e-06,
      "loss": 0.1874,
      "step": 1980
    },
    {
      "epoch": 1.1933734939759035,
      "grad_norm": 0.5082537531852722,
      "learning_rate": 3.508283132530121e-06,
      "loss": 0.1561,
      "step": 1981
    },
    {
      "epoch": 1.193975903614458,
      "grad_norm": 0.5257648229598999,
      "learning_rate": 3.5075301204819277e-06,
      "loss": 0.1995,
      "step": 1982
    },
    {
      "epoch": 1.1945783132530121,
      "grad_norm": 0.5525598526000977,
      "learning_rate": 3.5067771084337355e-06,
      "loss": 0.1801,
      "step": 1983
    },
    {
      "epoch": 1.1951807228915663,
      "grad_norm": 0.5618653893470764,
      "learning_rate": 3.5060240963855424e-06,
      "loss": 0.1947,
      "step": 1984
    },
    {
      "epoch": 1.1957831325301205,
      "grad_norm": 0.5438174605369568,
      "learning_rate": 3.5052710843373494e-06,
      "loss": 0.2057,
      "step": 1985
    },
    {
      "epoch": 1.1963855421686747,
      "grad_norm": 0.5722221732139587,
      "learning_rate": 3.504518072289157e-06,
      "loss": 0.2087,
      "step": 1986
    },
    {
      "epoch": 1.1969879518072288,
      "grad_norm": 0.8246344923973083,
      "learning_rate": 3.503765060240964e-06,
      "loss": 0.1752,
      "step": 1987
    },
    {
      "epoch": 1.197590361445783,
      "grad_norm": 0.49938246607780457,
      "learning_rate": 3.5030120481927714e-06,
      "loss": 0.1811,
      "step": 1988
    },
    {
      "epoch": 1.1981927710843374,
      "grad_norm": 0.527503252029419,
      "learning_rate": 3.5022590361445783e-06,
      "loss": 0.1904,
      "step": 1989
    },
    {
      "epoch": 1.1987951807228916,
      "grad_norm": 0.5989700555801392,
      "learning_rate": 3.501506024096386e-06,
      "loss": 0.1696,
      "step": 1990
    },
    {
      "epoch": 1.1993975903614458,
      "grad_norm": 0.6636907458305359,
      "learning_rate": 3.500753012048193e-06,
      "loss": 0.2268,
      "step": 1991
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5235297679901123,
      "learning_rate": 3.5e-06,
      "loss": 0.1848,
      "step": 1992
    },
    {
      "epoch": 1.2006024096385541,
      "grad_norm": 0.5358487963676453,
      "learning_rate": 3.4992469879518077e-06,
      "loss": 0.1777,
      "step": 1993
    },
    {
      "epoch": 1.2012048192771085,
      "grad_norm": 0.5964338183403015,
      "learning_rate": 3.4984939759036146e-06,
      "loss": 0.155,
      "step": 1994
    },
    {
      "epoch": 1.2018072289156627,
      "grad_norm": 0.5987383723258972,
      "learning_rate": 3.497740963855422e-06,
      "loss": 0.2364,
      "step": 1995
    },
    {
      "epoch": 1.202409638554217,
      "grad_norm": 0.49309486150741577,
      "learning_rate": 3.4969879518072293e-06,
      "loss": 0.1803,
      "step": 1996
    },
    {
      "epoch": 1.203012048192771,
      "grad_norm": 0.5305241942405701,
      "learning_rate": 3.4962349397590363e-06,
      "loss": 0.1905,
      "step": 1997
    },
    {
      "epoch": 1.2036144578313253,
      "grad_norm": 0.5221091508865356,
      "learning_rate": 3.4954819277108436e-06,
      "loss": 0.1593,
      "step": 1998
    },
    {
      "epoch": 1.2042168674698794,
      "grad_norm": 0.7129871249198914,
      "learning_rate": 3.4947289156626505e-06,
      "loss": 0.2293,
      "step": 1999
    },
    {
      "epoch": 1.2048192771084336,
      "grad_norm": 0.566684365272522,
      "learning_rate": 3.4939759036144583e-06,
      "loss": 0.229,
      "step": 2000
    },
    {
      "epoch": 1.205421686746988,
      "grad_norm": 0.5027257204055786,
      "learning_rate": 3.4932228915662652e-06,
      "loss": 0.1622,
      "step": 2001
    },
    {
      "epoch": 1.2060240963855422,
      "grad_norm": 0.5336820483207703,
      "learning_rate": 3.492469879518073e-06,
      "loss": 0.184,
      "step": 2002
    },
    {
      "epoch": 1.2066265060240964,
      "grad_norm": 0.5603446364402771,
      "learning_rate": 3.49171686746988e-06,
      "loss": 0.1699,
      "step": 2003
    },
    {
      "epoch": 1.2072289156626506,
      "grad_norm": 0.551873505115509,
      "learning_rate": 3.490963855421687e-06,
      "loss": 0.2063,
      "step": 2004
    },
    {
      "epoch": 1.2078313253012047,
      "grad_norm": 0.5386224985122681,
      "learning_rate": 3.490210843373494e-06,
      "loss": 0.2194,
      "step": 2005
    },
    {
      "epoch": 1.2084337349397591,
      "grad_norm": 0.49124616384506226,
      "learning_rate": 3.4894578313253016e-06,
      "loss": 0.199,
      "step": 2006
    },
    {
      "epoch": 1.2090361445783133,
      "grad_norm": 0.6588746309280396,
      "learning_rate": 3.488704819277109e-06,
      "loss": 0.224,
      "step": 2007
    },
    {
      "epoch": 1.2096385542168675,
      "grad_norm": 0.6315617561340332,
      "learning_rate": 3.487951807228916e-06,
      "loss": 0.2083,
      "step": 2008
    },
    {
      "epoch": 1.2102409638554217,
      "grad_norm": 0.5864002108573914,
      "learning_rate": 3.4871987951807228e-06,
      "loss": 0.2136,
      "step": 2009
    },
    {
      "epoch": 1.2108433734939759,
      "grad_norm": 0.6202021837234497,
      "learning_rate": 3.4864457831325305e-06,
      "loss": 0.1894,
      "step": 2010
    },
    {
      "epoch": 1.21144578313253,
      "grad_norm": 0.5165697932243347,
      "learning_rate": 3.4856927710843374e-06,
      "loss": 0.1703,
      "step": 2011
    },
    {
      "epoch": 1.2120481927710842,
      "grad_norm": 0.4667876958847046,
      "learning_rate": 3.484939759036145e-06,
      "loss": 0.19,
      "step": 2012
    },
    {
      "epoch": 1.2126506024096386,
      "grad_norm": 1.9636179208755493,
      "learning_rate": 3.484186746987952e-06,
      "loss": 0.2376,
      "step": 2013
    },
    {
      "epoch": 1.2132530120481928,
      "grad_norm": 0.5170804262161255,
      "learning_rate": 3.4834337349397595e-06,
      "loss": 0.1832,
      "step": 2014
    },
    {
      "epoch": 1.213855421686747,
      "grad_norm": 0.5270323753356934,
      "learning_rate": 3.4826807228915664e-06,
      "loss": 0.1795,
      "step": 2015
    },
    {
      "epoch": 1.2144578313253012,
      "grad_norm": 0.505857527256012,
      "learning_rate": 3.4819277108433733e-06,
      "loss": 0.1837,
      "step": 2016
    },
    {
      "epoch": 1.2150602409638553,
      "grad_norm": 0.506352961063385,
      "learning_rate": 3.481174698795181e-06,
      "loss": 0.2131,
      "step": 2017
    },
    {
      "epoch": 1.2156626506024097,
      "grad_norm": 0.5400320291519165,
      "learning_rate": 3.480421686746988e-06,
      "loss": 0.1754,
      "step": 2018
    },
    {
      "epoch": 1.216265060240964,
      "grad_norm": 0.5884819626808167,
      "learning_rate": 3.479668674698796e-06,
      "loss": 0.1845,
      "step": 2019
    },
    {
      "epoch": 1.216867469879518,
      "grad_norm": 0.49675416946411133,
      "learning_rate": 3.4789156626506027e-06,
      "loss": 0.1849,
      "step": 2020
    },
    {
      "epoch": 1.2174698795180723,
      "grad_norm": 0.5540309548377991,
      "learning_rate": 3.4781626506024097e-06,
      "loss": 0.1853,
      "step": 2021
    },
    {
      "epoch": 1.2180722891566265,
      "grad_norm": 0.5081053972244263,
      "learning_rate": 3.477409638554217e-06,
      "loss": 0.174,
      "step": 2022
    },
    {
      "epoch": 1.2186746987951806,
      "grad_norm": 0.640505313873291,
      "learning_rate": 3.4766566265060244e-06,
      "loss": 0.1783,
      "step": 2023
    },
    {
      "epoch": 1.2192771084337348,
      "grad_norm": 0.5178796648979187,
      "learning_rate": 3.4759036144578317e-06,
      "loss": 0.1982,
      "step": 2024
    },
    {
      "epoch": 1.2198795180722892,
      "grad_norm": 0.5717410445213318,
      "learning_rate": 3.4751506024096386e-06,
      "loss": 0.1956,
      "step": 2025
    },
    {
      "epoch": 1.2204819277108434,
      "grad_norm": 0.4947965145111084,
      "learning_rate": 3.4743975903614464e-06,
      "loss": 0.1932,
      "step": 2026
    },
    {
      "epoch": 1.2210843373493976,
      "grad_norm": 0.7319088578224182,
      "learning_rate": 3.4736445783132533e-06,
      "loss": 0.1987,
      "step": 2027
    },
    {
      "epoch": 1.2216867469879518,
      "grad_norm": 0.5266297459602356,
      "learning_rate": 3.4728915662650603e-06,
      "loss": 0.1686,
      "step": 2028
    },
    {
      "epoch": 1.222289156626506,
      "grad_norm": 0.5348855257034302,
      "learning_rate": 3.472138554216868e-06,
      "loss": 0.1989,
      "step": 2029
    },
    {
      "epoch": 1.2228915662650603,
      "grad_norm": 0.5318905115127563,
      "learning_rate": 3.471385542168675e-06,
      "loss": 0.1457,
      "step": 2030
    },
    {
      "epoch": 1.2234939759036145,
      "grad_norm": 0.573626697063446,
      "learning_rate": 3.4706325301204823e-06,
      "loss": 0.2304,
      "step": 2031
    },
    {
      "epoch": 1.2240963855421687,
      "grad_norm": 0.6625629663467407,
      "learning_rate": 3.4698795180722892e-06,
      "loss": 0.227,
      "step": 2032
    },
    {
      "epoch": 1.2246987951807229,
      "grad_norm": 0.5488986968994141,
      "learning_rate": 3.4691265060240966e-06,
      "loss": 0.1623,
      "step": 2033
    },
    {
      "epoch": 1.225301204819277,
      "grad_norm": 0.5410126447677612,
      "learning_rate": 3.468373493975904e-06,
      "loss": 0.1802,
      "step": 2034
    },
    {
      "epoch": 1.2259036144578312,
      "grad_norm": 0.54860919713974,
      "learning_rate": 3.467620481927711e-06,
      "loss": 0.1626,
      "step": 2035
    },
    {
      "epoch": 1.2265060240963854,
      "grad_norm": 0.511529266834259,
      "learning_rate": 3.4668674698795186e-06,
      "loss": 0.175,
      "step": 2036
    },
    {
      "epoch": 1.2271084337349398,
      "grad_norm": 0.63193279504776,
      "learning_rate": 3.4661144578313255e-06,
      "loss": 0.1999,
      "step": 2037
    },
    {
      "epoch": 1.227710843373494,
      "grad_norm": 0.5086508989334106,
      "learning_rate": 3.465361445783133e-06,
      "loss": 0.2125,
      "step": 2038
    },
    {
      "epoch": 1.2283132530120482,
      "grad_norm": 0.5907111167907715,
      "learning_rate": 3.4646084337349402e-06,
      "loss": 0.1995,
      "step": 2039
    },
    {
      "epoch": 1.2289156626506024,
      "grad_norm": 0.46994540095329285,
      "learning_rate": 3.463855421686747e-06,
      "loss": 0.1816,
      "step": 2040
    },
    {
      "epoch": 1.2295180722891565,
      "grad_norm": 0.5413877964019775,
      "learning_rate": 3.4631024096385545e-06,
      "loss": 0.1647,
      "step": 2041
    },
    {
      "epoch": 1.230120481927711,
      "grad_norm": 0.5616759657859802,
      "learning_rate": 3.4623493975903614e-06,
      "loss": 0.164,
      "step": 2042
    },
    {
      "epoch": 1.2307228915662651,
      "grad_norm": 0.5076655745506287,
      "learning_rate": 3.461596385542169e-06,
      "loss": 0.1885,
      "step": 2043
    },
    {
      "epoch": 1.2313253012048193,
      "grad_norm": 0.4956022799015045,
      "learning_rate": 3.460843373493976e-06,
      "loss": 0.1851,
      "step": 2044
    },
    {
      "epoch": 1.2319277108433735,
      "grad_norm": 0.8074221611022949,
      "learning_rate": 3.460090361445783e-06,
      "loss": 0.2587,
      "step": 2045
    },
    {
      "epoch": 1.2325301204819277,
      "grad_norm": 0.5549473762512207,
      "learning_rate": 3.459337349397591e-06,
      "loss": 0.1668,
      "step": 2046
    },
    {
      "epoch": 1.2331325301204819,
      "grad_norm": 0.5937731862068176,
      "learning_rate": 3.4585843373493978e-06,
      "loss": 0.1681,
      "step": 2047
    },
    {
      "epoch": 1.233734939759036,
      "grad_norm": 0.5434519052505493,
      "learning_rate": 3.457831325301205e-06,
      "loss": 0.1909,
      "step": 2048
    },
    {
      "epoch": 1.2343373493975904,
      "grad_norm": 0.4919790029525757,
      "learning_rate": 3.4570783132530125e-06,
      "loss": 0.1945,
      "step": 2049
    },
    {
      "epoch": 1.2349397590361446,
      "grad_norm": 0.48983415961265564,
      "learning_rate": 3.45632530120482e-06,
      "loss": 0.1651,
      "step": 2050
    },
    {
      "epoch": 1.2355421686746988,
      "grad_norm": 0.4640762209892273,
      "learning_rate": 3.4555722891566267e-06,
      "loss": 0.1551,
      "step": 2051
    },
    {
      "epoch": 1.236144578313253,
      "grad_norm": 0.4593769907951355,
      "learning_rate": 3.4548192771084337e-06,
      "loss": 0.1777,
      "step": 2052
    },
    {
      "epoch": 1.2367469879518072,
      "grad_norm": 0.6285004615783691,
      "learning_rate": 3.4540662650602414e-06,
      "loss": 0.1592,
      "step": 2053
    },
    {
      "epoch": 1.2373493975903616,
      "grad_norm": 0.5281915664672852,
      "learning_rate": 3.4533132530120483e-06,
      "loss": 0.1739,
      "step": 2054
    },
    {
      "epoch": 1.2379518072289157,
      "grad_norm": 0.514384388923645,
      "learning_rate": 3.4525602409638557e-06,
      "loss": 0.1285,
      "step": 2055
    },
    {
      "epoch": 1.23855421686747,
      "grad_norm": 0.6282324194908142,
      "learning_rate": 3.451807228915663e-06,
      "loss": 0.2379,
      "step": 2056
    },
    {
      "epoch": 1.239156626506024,
      "grad_norm": 0.7121535539627075,
      "learning_rate": 3.45105421686747e-06,
      "loss": 0.2158,
      "step": 2057
    },
    {
      "epoch": 1.2397590361445783,
      "grad_norm": 0.6527960300445557,
      "learning_rate": 3.4503012048192773e-06,
      "loss": 0.2162,
      "step": 2058
    },
    {
      "epoch": 1.2403614457831325,
      "grad_norm": 0.5944370627403259,
      "learning_rate": 3.4495481927710842e-06,
      "loss": 0.1997,
      "step": 2059
    },
    {
      "epoch": 1.2409638554216866,
      "grad_norm": 0.5252578258514404,
      "learning_rate": 3.448795180722892e-06,
      "loss": 0.197,
      "step": 2060
    },
    {
      "epoch": 1.241566265060241,
      "grad_norm": 0.49121811985969543,
      "learning_rate": 3.448042168674699e-06,
      "loss": 0.1878,
      "step": 2061
    },
    {
      "epoch": 1.2421686746987952,
      "grad_norm": 0.5226405262947083,
      "learning_rate": 3.4472891566265067e-06,
      "loss": 0.2021,
      "step": 2062
    },
    {
      "epoch": 1.2427710843373494,
      "grad_norm": 0.5183724164962769,
      "learning_rate": 3.4465361445783136e-06,
      "loss": 0.1971,
      "step": 2063
    },
    {
      "epoch": 1.2433734939759036,
      "grad_norm": 0.655110776424408,
      "learning_rate": 3.4457831325301206e-06,
      "loss": 0.173,
      "step": 2064
    },
    {
      "epoch": 1.2439759036144578,
      "grad_norm": 0.577189564704895,
      "learning_rate": 3.445030120481928e-06,
      "loss": 0.1904,
      "step": 2065
    },
    {
      "epoch": 1.2445783132530122,
      "grad_norm": 0.5206546187400818,
      "learning_rate": 3.4442771084337353e-06,
      "loss": 0.1691,
      "step": 2066
    },
    {
      "epoch": 1.2451807228915663,
      "grad_norm": 0.5676747560501099,
      "learning_rate": 3.4435240963855426e-06,
      "loss": 0.1846,
      "step": 2067
    },
    {
      "epoch": 1.2457831325301205,
      "grad_norm": 0.5205522775650024,
      "learning_rate": 3.4427710843373495e-06,
      "loss": 0.224,
      "step": 2068
    },
    {
      "epoch": 1.2463855421686747,
      "grad_norm": 0.667288601398468,
      "learning_rate": 3.4420180722891565e-06,
      "loss": 0.1608,
      "step": 2069
    },
    {
      "epoch": 1.2469879518072289,
      "grad_norm": 0.46559491753578186,
      "learning_rate": 3.4412650602409642e-06,
      "loss": 0.1512,
      "step": 2070
    },
    {
      "epoch": 1.247590361445783,
      "grad_norm": 0.5428875088691711,
      "learning_rate": 3.440512048192771e-06,
      "loss": 0.1745,
      "step": 2071
    },
    {
      "epoch": 1.2481927710843372,
      "grad_norm": 0.5235571265220642,
      "learning_rate": 3.439759036144579e-06,
      "loss": 0.1621,
      "step": 2072
    },
    {
      "epoch": 1.2487951807228916,
      "grad_norm": 0.5188626050949097,
      "learning_rate": 3.439006024096386e-06,
      "loss": 0.1995,
      "step": 2073
    },
    {
      "epoch": 1.2493975903614458,
      "grad_norm": 0.5661240220069885,
      "learning_rate": 3.438253012048193e-06,
      "loss": 0.2264,
      "step": 2074
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.4507361650466919,
      "learning_rate": 3.4375e-06,
      "loss": 0.1808,
      "step": 2075
    },
    {
      "epoch": 1.2506024096385542,
      "grad_norm": 0.5471200942993164,
      "learning_rate": 3.4367469879518075e-06,
      "loss": 0.2073,
      "step": 2076
    },
    {
      "epoch": 1.2512048192771084,
      "grad_norm": 0.5378449559211731,
      "learning_rate": 3.435993975903615e-06,
      "loss": 0.1737,
      "step": 2077
    },
    {
      "epoch": 1.2518072289156628,
      "grad_norm": 0.5201603174209595,
      "learning_rate": 3.4352409638554217e-06,
      "loss": 0.1959,
      "step": 2078
    },
    {
      "epoch": 1.252409638554217,
      "grad_norm": 0.6184002161026001,
      "learning_rate": 3.4344879518072295e-06,
      "loss": 0.2115,
      "step": 2079
    },
    {
      "epoch": 1.2530120481927711,
      "grad_norm": 0.5666934847831726,
      "learning_rate": 3.4337349397590364e-06,
      "loss": 0.2125,
      "step": 2080
    },
    {
      "epoch": 1.2536144578313253,
      "grad_norm": 0.5966998934745789,
      "learning_rate": 3.432981927710844e-06,
      "loss": 0.1935,
      "step": 2081
    },
    {
      "epoch": 1.2542168674698795,
      "grad_norm": 0.5349613428115845,
      "learning_rate": 3.432228915662651e-06,
      "loss": 0.1652,
      "step": 2082
    },
    {
      "epoch": 1.2548192771084337,
      "grad_norm": 0.6118955612182617,
      "learning_rate": 3.431475903614458e-06,
      "loss": 0.1789,
      "step": 2083
    },
    {
      "epoch": 1.2554216867469878,
      "grad_norm": 0.5855635404586792,
      "learning_rate": 3.4307228915662654e-06,
      "loss": 0.1917,
      "step": 2084
    },
    {
      "epoch": 1.2560240963855422,
      "grad_norm": 0.4786226451396942,
      "learning_rate": 3.4299698795180723e-06,
      "loss": 0.1567,
      "step": 2085
    },
    {
      "epoch": 1.2566265060240964,
      "grad_norm": 0.5095004439353943,
      "learning_rate": 3.42921686746988e-06,
      "loss": 0.1694,
      "step": 2086
    },
    {
      "epoch": 1.2572289156626506,
      "grad_norm": 0.5765605568885803,
      "learning_rate": 3.428463855421687e-06,
      "loss": 0.2117,
      "step": 2087
    },
    {
      "epoch": 1.2578313253012048,
      "grad_norm": 0.5075222253799438,
      "learning_rate": 3.427710843373494e-06,
      "loss": 0.1724,
      "step": 2088
    },
    {
      "epoch": 1.258433734939759,
      "grad_norm": 0.4704013168811798,
      "learning_rate": 3.4269578313253017e-06,
      "loss": 0.1889,
      "step": 2089
    },
    {
      "epoch": 1.2590361445783134,
      "grad_norm": 0.5587189793586731,
      "learning_rate": 3.4262048192771087e-06,
      "loss": 0.1858,
      "step": 2090
    },
    {
      "epoch": 1.2596385542168675,
      "grad_norm": 0.674243152141571,
      "learning_rate": 3.425451807228916e-06,
      "loss": 0.2655,
      "step": 2091
    },
    {
      "epoch": 1.2602409638554217,
      "grad_norm": 0.5330110788345337,
      "learning_rate": 3.424698795180723e-06,
      "loss": 0.2632,
      "step": 2092
    },
    {
      "epoch": 1.260843373493976,
      "grad_norm": 0.5680592060089111,
      "learning_rate": 3.4239457831325307e-06,
      "loss": 0.2026,
      "step": 2093
    },
    {
      "epoch": 1.26144578313253,
      "grad_norm": 0.7726593017578125,
      "learning_rate": 3.4231927710843376e-06,
      "loss": 0.2396,
      "step": 2094
    },
    {
      "epoch": 1.2620481927710843,
      "grad_norm": 0.5687814354896545,
      "learning_rate": 3.4224397590361445e-06,
      "loss": 0.1946,
      "step": 2095
    },
    {
      "epoch": 1.2626506024096384,
      "grad_norm": 0.6184002757072449,
      "learning_rate": 3.4216867469879523e-06,
      "loss": 0.2078,
      "step": 2096
    },
    {
      "epoch": 1.2632530120481928,
      "grad_norm": 0.667843759059906,
      "learning_rate": 3.4209337349397592e-06,
      "loss": 0.2136,
      "step": 2097
    },
    {
      "epoch": 1.263855421686747,
      "grad_norm": 0.5536073446273804,
      "learning_rate": 3.4201807228915666e-06,
      "loss": 0.1483,
      "step": 2098
    },
    {
      "epoch": 1.2644578313253012,
      "grad_norm": 0.668016254901886,
      "learning_rate": 3.419427710843374e-06,
      "loss": 0.1912,
      "step": 2099
    },
    {
      "epoch": 1.2650602409638554,
      "grad_norm": 0.5392707586288452,
      "learning_rate": 3.418674698795181e-06,
      "loss": 0.1617,
      "step": 2100
    },
    {
      "epoch": 1.2656626506024096,
      "grad_norm": 0.5766004323959351,
      "learning_rate": 3.4179216867469882e-06,
      "loss": 0.1833,
      "step": 2101
    },
    {
      "epoch": 1.266265060240964,
      "grad_norm": 0.5845787525177002,
      "learning_rate": 3.417168674698795e-06,
      "loss": 0.1697,
      "step": 2102
    },
    {
      "epoch": 1.2668674698795181,
      "grad_norm": 0.48986831307411194,
      "learning_rate": 3.416415662650603e-06,
      "loss": 0.1732,
      "step": 2103
    },
    {
      "epoch": 1.2674698795180723,
      "grad_norm": 0.5496456027030945,
      "learning_rate": 3.41566265060241e-06,
      "loss": 0.1952,
      "step": 2104
    },
    {
      "epoch": 1.2680722891566265,
      "grad_norm": 0.4306708574295044,
      "learning_rate": 3.4149096385542176e-06,
      "loss": 0.1649,
      "step": 2105
    },
    {
      "epoch": 1.2686746987951807,
      "grad_norm": 0.5257024765014648,
      "learning_rate": 3.4141566265060245e-06,
      "loss": 0.1645,
      "step": 2106
    },
    {
      "epoch": 1.2692771084337349,
      "grad_norm": 0.516545295715332,
      "learning_rate": 3.4134036144578315e-06,
      "loss": 0.18,
      "step": 2107
    },
    {
      "epoch": 1.269879518072289,
      "grad_norm": 0.6146030426025391,
      "learning_rate": 3.412650602409639e-06,
      "loss": 0.1767,
      "step": 2108
    },
    {
      "epoch": 1.2704819277108435,
      "grad_norm": 0.5883327722549438,
      "learning_rate": 3.411897590361446e-06,
      "loss": 0.2019,
      "step": 2109
    },
    {
      "epoch": 1.2710843373493976,
      "grad_norm": 0.5514212846755981,
      "learning_rate": 3.4111445783132535e-06,
      "loss": 0.1853,
      "step": 2110
    },
    {
      "epoch": 1.2716867469879518,
      "grad_norm": 0.7831593155860901,
      "learning_rate": 3.4103915662650604e-06,
      "loss": 0.2048,
      "step": 2111
    },
    {
      "epoch": 1.272289156626506,
      "grad_norm": 0.47827187180519104,
      "learning_rate": 3.4096385542168674e-06,
      "loss": 0.1424,
      "step": 2112
    },
    {
      "epoch": 1.2728915662650602,
      "grad_norm": 0.5727556347846985,
      "learning_rate": 3.408885542168675e-06,
      "loss": 0.1478,
      "step": 2113
    },
    {
      "epoch": 1.2734939759036146,
      "grad_norm": 0.5810121297836304,
      "learning_rate": 3.408132530120482e-06,
      "loss": 0.1694,
      "step": 2114
    },
    {
      "epoch": 1.2740963855421688,
      "grad_norm": 0.611139714717865,
      "learning_rate": 3.40737951807229e-06,
      "loss": 0.2132,
      "step": 2115
    },
    {
      "epoch": 1.274698795180723,
      "grad_norm": 0.5133015513420105,
      "learning_rate": 3.4066265060240967e-06,
      "loss": 0.1419,
      "step": 2116
    },
    {
      "epoch": 1.2753012048192771,
      "grad_norm": 0.5122745037078857,
      "learning_rate": 3.405873493975904e-06,
      "loss": 0.1774,
      "step": 2117
    },
    {
      "epoch": 1.2759036144578313,
      "grad_norm": 0.744608998298645,
      "learning_rate": 3.405120481927711e-06,
      "loss": 0.1743,
      "step": 2118
    },
    {
      "epoch": 1.2765060240963855,
      "grad_norm": 0.6098641753196716,
      "learning_rate": 3.4043674698795184e-06,
      "loss": 0.2324,
      "step": 2119
    },
    {
      "epoch": 1.2771084337349397,
      "grad_norm": 0.6228651404380798,
      "learning_rate": 3.4036144578313257e-06,
      "loss": 0.1992,
      "step": 2120
    },
    {
      "epoch": 1.277710843373494,
      "grad_norm": 0.4854845702648163,
      "learning_rate": 3.4028614457831326e-06,
      "loss": 0.1879,
      "step": 2121
    },
    {
      "epoch": 1.2783132530120482,
      "grad_norm": 0.6942290663719177,
      "learning_rate": 3.4021084337349404e-06,
      "loss": 0.2632,
      "step": 2122
    },
    {
      "epoch": 1.2789156626506024,
      "grad_norm": 0.5013685822486877,
      "learning_rate": 3.4013554216867473e-06,
      "loss": 0.1817,
      "step": 2123
    },
    {
      "epoch": 1.2795180722891566,
      "grad_norm": 1.883759617805481,
      "learning_rate": 3.4006024096385543e-06,
      "loss": 0.2558,
      "step": 2124
    },
    {
      "epoch": 1.2801204819277108,
      "grad_norm": 0.5437043309211731,
      "learning_rate": 3.3998493975903616e-06,
      "loss": 0.1906,
      "step": 2125
    },
    {
      "epoch": 1.2807228915662652,
      "grad_norm": 0.5605877637863159,
      "learning_rate": 3.399096385542169e-06,
      "loss": 0.1567,
      "step": 2126
    },
    {
      "epoch": 1.2813253012048194,
      "grad_norm": 0.5379285216331482,
      "learning_rate": 3.3983433734939763e-06,
      "loss": 0.1731,
      "step": 2127
    },
    {
      "epoch": 1.2819277108433735,
      "grad_norm": 0.5361435413360596,
      "learning_rate": 3.3975903614457832e-06,
      "loss": 0.2267,
      "step": 2128
    },
    {
      "epoch": 1.2825301204819277,
      "grad_norm": 0.5992897748947144,
      "learning_rate": 3.396837349397591e-06,
      "loss": 0.1891,
      "step": 2129
    },
    {
      "epoch": 1.283132530120482,
      "grad_norm": 0.6660718321800232,
      "learning_rate": 3.396084337349398e-06,
      "loss": 0.1877,
      "step": 2130
    },
    {
      "epoch": 1.283734939759036,
      "grad_norm": 0.7120959758758545,
      "learning_rate": 3.395331325301205e-06,
      "loss": 0.2567,
      "step": 2131
    },
    {
      "epoch": 1.2843373493975903,
      "grad_norm": 0.5371782779693604,
      "learning_rate": 3.3945783132530126e-06,
      "loss": 0.1817,
      "step": 2132
    },
    {
      "epoch": 1.2849397590361447,
      "grad_norm": 0.6051875948905945,
      "learning_rate": 3.3938253012048196e-06,
      "loss": 0.1562,
      "step": 2133
    },
    {
      "epoch": 1.2855421686746988,
      "grad_norm": 0.5196647047996521,
      "learning_rate": 3.393072289156627e-06,
      "loss": 0.186,
      "step": 2134
    },
    {
      "epoch": 1.286144578313253,
      "grad_norm": 0.6107714176177979,
      "learning_rate": 3.392319277108434e-06,
      "loss": 0.1825,
      "step": 2135
    },
    {
      "epoch": 1.2867469879518072,
      "grad_norm": 0.6754962801933289,
      "learning_rate": 3.391566265060241e-06,
      "loss": 0.2027,
      "step": 2136
    },
    {
      "epoch": 1.2873493975903614,
      "grad_norm": 0.5472583174705505,
      "learning_rate": 3.3908132530120485e-06,
      "loss": 0.1573,
      "step": 2137
    },
    {
      "epoch": 1.2879518072289158,
      "grad_norm": 0.7558913230895996,
      "learning_rate": 3.3900602409638554e-06,
      "loss": 0.163,
      "step": 2138
    },
    {
      "epoch": 1.28855421686747,
      "grad_norm": 0.7022694945335388,
      "learning_rate": 3.3893072289156632e-06,
      "loss": 0.2164,
      "step": 2139
    },
    {
      "epoch": 1.2891566265060241,
      "grad_norm": 0.5935182571411133,
      "learning_rate": 3.38855421686747e-06,
      "loss": 0.1685,
      "step": 2140
    },
    {
      "epoch": 1.2897590361445783,
      "grad_norm": 0.602767288684845,
      "learning_rate": 3.3878012048192775e-06,
      "loss": 0.1551,
      "step": 2141
    },
    {
      "epoch": 1.2903614457831325,
      "grad_norm": 0.4788340926170349,
      "learning_rate": 3.387048192771085e-06,
      "loss": 0.1338,
      "step": 2142
    },
    {
      "epoch": 1.2909638554216867,
      "grad_norm": 0.5429083108901978,
      "learning_rate": 3.3862951807228918e-06,
      "loss": 0.1633,
      "step": 2143
    },
    {
      "epoch": 1.2915662650602409,
      "grad_norm": 0.5388569235801697,
      "learning_rate": 3.385542168674699e-06,
      "loss": 0.176,
      "step": 2144
    },
    {
      "epoch": 1.2921686746987953,
      "grad_norm": 0.589313268661499,
      "learning_rate": 3.384789156626506e-06,
      "loss": 0.1978,
      "step": 2145
    },
    {
      "epoch": 1.2927710843373494,
      "grad_norm": 0.4964272975921631,
      "learning_rate": 3.384036144578314e-06,
      "loss": 0.1528,
      "step": 2146
    },
    {
      "epoch": 1.2933734939759036,
      "grad_norm": 0.596347451210022,
      "learning_rate": 3.3832831325301207e-06,
      "loss": 0.1899,
      "step": 2147
    },
    {
      "epoch": 1.2939759036144578,
      "grad_norm": 0.6365231871604919,
      "learning_rate": 3.3825301204819277e-06,
      "loss": 0.1484,
      "step": 2148
    },
    {
      "epoch": 1.294578313253012,
      "grad_norm": 0.5206013321876526,
      "learning_rate": 3.3817771084337354e-06,
      "loss": 0.1846,
      "step": 2149
    },
    {
      "epoch": 1.2951807228915664,
      "grad_norm": 0.44337308406829834,
      "learning_rate": 3.3810240963855424e-06,
      "loss": 0.1644,
      "step": 2150
    },
    {
      "epoch": 1.2957831325301206,
      "grad_norm": 0.5668488144874573,
      "learning_rate": 3.3802710843373497e-06,
      "loss": 0.1818,
      "step": 2151
    },
    {
      "epoch": 1.2963855421686747,
      "grad_norm": 0.5619881749153137,
      "learning_rate": 3.379518072289157e-06,
      "loss": 0.1773,
      "step": 2152
    },
    {
      "epoch": 1.296987951807229,
      "grad_norm": 0.5181629657745361,
      "learning_rate": 3.3787650602409644e-06,
      "loss": 0.1849,
      "step": 2153
    },
    {
      "epoch": 1.297590361445783,
      "grad_norm": 0.5281833410263062,
      "learning_rate": 3.3780120481927713e-06,
      "loss": 0.1584,
      "step": 2154
    },
    {
      "epoch": 1.2981927710843373,
      "grad_norm": 0.5555201172828674,
      "learning_rate": 3.3772590361445783e-06,
      "loss": 0.1703,
      "step": 2155
    },
    {
      "epoch": 1.2987951807228915,
      "grad_norm": 0.503372073173523,
      "learning_rate": 3.376506024096386e-06,
      "loss": 0.1463,
      "step": 2156
    },
    {
      "epoch": 1.2993975903614459,
      "grad_norm": 0.5091266632080078,
      "learning_rate": 3.375753012048193e-06,
      "loss": 0.1566,
      "step": 2157
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6406832933425903,
      "learning_rate": 3.3750000000000003e-06,
      "loss": 0.217,
      "step": 2158
    },
    {
      "epoch": 1.3006024096385542,
      "grad_norm": 0.48010513186454773,
      "learning_rate": 3.3742469879518076e-06,
      "loss": 0.1742,
      "step": 2159
    },
    {
      "epoch": 1.3012048192771084,
      "grad_norm": 0.6406087279319763,
      "learning_rate": 3.3734939759036146e-06,
      "loss": 0.1569,
      "step": 2160
    },
    {
      "epoch": 1.3018072289156626,
      "grad_norm": 0.5154339671134949,
      "learning_rate": 3.372740963855422e-06,
      "loss": 0.1873,
      "step": 2161
    },
    {
      "epoch": 1.302409638554217,
      "grad_norm": 0.5456888675689697,
      "learning_rate": 3.371987951807229e-06,
      "loss": 0.1686,
      "step": 2162
    },
    {
      "epoch": 1.3030120481927712,
      "grad_norm": 0.49647966027259827,
      "learning_rate": 3.3712349397590366e-06,
      "loss": 0.1606,
      "step": 2163
    },
    {
      "epoch": 1.3036144578313253,
      "grad_norm": 0.605360746383667,
      "learning_rate": 3.3704819277108435e-06,
      "loss": 0.1555,
      "step": 2164
    },
    {
      "epoch": 1.3042168674698795,
      "grad_norm": 0.5829284191131592,
      "learning_rate": 3.3697289156626513e-06,
      "loss": 0.1886,
      "step": 2165
    },
    {
      "epoch": 1.3048192771084337,
      "grad_norm": 0.581522524356842,
      "learning_rate": 3.3689759036144582e-06,
      "loss": 0.1747,
      "step": 2166
    },
    {
      "epoch": 1.3054216867469879,
      "grad_norm": 0.5146368741989136,
      "learning_rate": 3.368222891566265e-06,
      "loss": 0.2091,
      "step": 2167
    },
    {
      "epoch": 1.306024096385542,
      "grad_norm": 0.49202945828437805,
      "learning_rate": 3.3674698795180725e-06,
      "loss": 0.152,
      "step": 2168
    },
    {
      "epoch": 1.3066265060240965,
      "grad_norm": 0.5238866209983826,
      "learning_rate": 3.36671686746988e-06,
      "loss": 0.1729,
      "step": 2169
    },
    {
      "epoch": 1.3072289156626506,
      "grad_norm": 0.4734799265861511,
      "learning_rate": 3.365963855421687e-06,
      "loss": 0.166,
      "step": 2170
    },
    {
      "epoch": 1.3078313253012048,
      "grad_norm": 0.643515408039093,
      "learning_rate": 3.365210843373494e-06,
      "loss": 0.172,
      "step": 2171
    },
    {
      "epoch": 1.308433734939759,
      "grad_norm": 0.5047248601913452,
      "learning_rate": 3.364457831325301e-06,
      "loss": 0.1452,
      "step": 2172
    },
    {
      "epoch": 1.3090361445783132,
      "grad_norm": 0.5271421670913696,
      "learning_rate": 3.363704819277109e-06,
      "loss": 0.1785,
      "step": 2173
    },
    {
      "epoch": 1.3096385542168676,
      "grad_norm": 0.5980762839317322,
      "learning_rate": 3.3629518072289158e-06,
      "loss": 0.2067,
      "step": 2174
    },
    {
      "epoch": 1.3102409638554218,
      "grad_norm": 0.6243571639060974,
      "learning_rate": 3.3621987951807235e-06,
      "loss": 0.1307,
      "step": 2175
    },
    {
      "epoch": 1.310843373493976,
      "grad_norm": 0.5563721656799316,
      "learning_rate": 3.3614457831325305e-06,
      "loss": 0.1661,
      "step": 2176
    },
    {
      "epoch": 1.3114457831325301,
      "grad_norm": 0.5488357543945312,
      "learning_rate": 3.360692771084338e-06,
      "loss": 0.1657,
      "step": 2177
    },
    {
      "epoch": 1.3120481927710843,
      "grad_norm": 0.8202099800109863,
      "learning_rate": 3.3599397590361447e-06,
      "loss": 0.2424,
      "step": 2178
    },
    {
      "epoch": 1.3126506024096385,
      "grad_norm": 0.5357338190078735,
      "learning_rate": 3.359186746987952e-06,
      "loss": 0.1579,
      "step": 2179
    },
    {
      "epoch": 1.3132530120481927,
      "grad_norm": 0.49430370330810547,
      "learning_rate": 3.3584337349397594e-06,
      "loss": 0.1638,
      "step": 2180
    },
    {
      "epoch": 1.313855421686747,
      "grad_norm": 0.5670992136001587,
      "learning_rate": 3.3576807228915663e-06,
      "loss": 0.2204,
      "step": 2181
    },
    {
      "epoch": 1.3144578313253013,
      "grad_norm": 0.7420284152030945,
      "learning_rate": 3.356927710843374e-06,
      "loss": 0.2807,
      "step": 2182
    },
    {
      "epoch": 1.3150602409638554,
      "grad_norm": 0.574572741985321,
      "learning_rate": 3.356174698795181e-06,
      "loss": 0.1761,
      "step": 2183
    },
    {
      "epoch": 1.3156626506024096,
      "grad_norm": 0.5503410696983337,
      "learning_rate": 3.355421686746988e-06,
      "loss": 0.1706,
      "step": 2184
    },
    {
      "epoch": 1.3162650602409638,
      "grad_norm": 0.6639564633369446,
      "learning_rate": 3.3546686746987957e-06,
      "loss": 0.1694,
      "step": 2185
    },
    {
      "epoch": 1.3168674698795182,
      "grad_norm": 0.5059716701507568,
      "learning_rate": 3.3539156626506027e-06,
      "loss": 0.1667,
      "step": 2186
    },
    {
      "epoch": 1.3174698795180722,
      "grad_norm": 0.6077408790588379,
      "learning_rate": 3.35316265060241e-06,
      "loss": 0.1355,
      "step": 2187
    },
    {
      "epoch": 1.3180722891566266,
      "grad_norm": 0.6733371615409851,
      "learning_rate": 3.352409638554217e-06,
      "loss": 0.2339,
      "step": 2188
    },
    {
      "epoch": 1.3186746987951807,
      "grad_norm": 0.5906296968460083,
      "learning_rate": 3.3516566265060247e-06,
      "loss": 0.1704,
      "step": 2189
    },
    {
      "epoch": 1.319277108433735,
      "grad_norm": 0.6016967296600342,
      "learning_rate": 3.3509036144578316e-06,
      "loss": 0.167,
      "step": 2190
    },
    {
      "epoch": 1.319879518072289,
      "grad_norm": 0.554623007774353,
      "learning_rate": 3.3501506024096386e-06,
      "loss": 0.1958,
      "step": 2191
    },
    {
      "epoch": 1.3204819277108433,
      "grad_norm": 0.5470228791236877,
      "learning_rate": 3.3493975903614463e-06,
      "loss": 0.1894,
      "step": 2192
    },
    {
      "epoch": 1.3210843373493977,
      "grad_norm": 0.5349432826042175,
      "learning_rate": 3.3486445783132533e-06,
      "loss": 0.1422,
      "step": 2193
    },
    {
      "epoch": 1.3216867469879519,
      "grad_norm": 0.6682852506637573,
      "learning_rate": 3.3478915662650606e-06,
      "loss": 0.2461,
      "step": 2194
    },
    {
      "epoch": 1.322289156626506,
      "grad_norm": 0.74764484167099,
      "learning_rate": 3.3471385542168675e-06,
      "loss": 0.2347,
      "step": 2195
    },
    {
      "epoch": 1.3228915662650602,
      "grad_norm": 0.4956698417663574,
      "learning_rate": 3.346385542168675e-06,
      "loss": 0.1781,
      "step": 2196
    },
    {
      "epoch": 1.3234939759036144,
      "grad_norm": 0.6969807744026184,
      "learning_rate": 3.3456325301204822e-06,
      "loss": 0.1927,
      "step": 2197
    },
    {
      "epoch": 1.3240963855421688,
      "grad_norm": 0.5850124955177307,
      "learning_rate": 3.344879518072289e-06,
      "loss": 0.1897,
      "step": 2198
    },
    {
      "epoch": 1.3246987951807228,
      "grad_norm": 0.5282861590385437,
      "learning_rate": 3.344126506024097e-06,
      "loss": 0.1837,
      "step": 2199
    },
    {
      "epoch": 1.3253012048192772,
      "grad_norm": 0.5373172163963318,
      "learning_rate": 3.343373493975904e-06,
      "loss": 0.1983,
      "step": 2200
    },
    {
      "epoch": 1.3259036144578313,
      "grad_norm": 0.5930917263031006,
      "learning_rate": 3.342620481927711e-06,
      "loss": 0.221,
      "step": 2201
    },
    {
      "epoch": 1.3265060240963855,
      "grad_norm": 0.5156784653663635,
      "learning_rate": 3.3418674698795185e-06,
      "loss": 0.1517,
      "step": 2202
    },
    {
      "epoch": 1.3271084337349397,
      "grad_norm": 0.4850652813911438,
      "learning_rate": 3.3411144578313255e-06,
      "loss": 0.1521,
      "step": 2203
    },
    {
      "epoch": 1.3277108433734939,
      "grad_norm": 0.5000749230384827,
      "learning_rate": 3.340361445783133e-06,
      "loss": 0.1538,
      "step": 2204
    },
    {
      "epoch": 1.3283132530120483,
      "grad_norm": 0.6857423186302185,
      "learning_rate": 3.3396084337349397e-06,
      "loss": 0.1956,
      "step": 2205
    },
    {
      "epoch": 1.3289156626506025,
      "grad_norm": 0.7424781918525696,
      "learning_rate": 3.3388554216867475e-06,
      "loss": 0.2152,
      "step": 2206
    },
    {
      "epoch": 1.3295180722891566,
      "grad_norm": 0.647637665271759,
      "learning_rate": 3.3381024096385544e-06,
      "loss": 0.1907,
      "step": 2207
    },
    {
      "epoch": 1.3301204819277108,
      "grad_norm": 0.5324402451515198,
      "learning_rate": 3.3373493975903614e-06,
      "loss": 0.176,
      "step": 2208
    },
    {
      "epoch": 1.330722891566265,
      "grad_norm": 0.6220030188560486,
      "learning_rate": 3.336596385542169e-06,
      "loss": 0.2329,
      "step": 2209
    },
    {
      "epoch": 1.3313253012048194,
      "grad_norm": 0.7915921807289124,
      "learning_rate": 3.335843373493976e-06,
      "loss": 0.2484,
      "step": 2210
    },
    {
      "epoch": 1.3319277108433734,
      "grad_norm": 0.7340859770774841,
      "learning_rate": 3.3350903614457834e-06,
      "loss": 0.2115,
      "step": 2211
    },
    {
      "epoch": 1.3325301204819278,
      "grad_norm": 0.47415891289711,
      "learning_rate": 3.3343373493975908e-06,
      "loss": 0.1616,
      "step": 2212
    },
    {
      "epoch": 1.333132530120482,
      "grad_norm": 0.5226338505744934,
      "learning_rate": 3.333584337349398e-06,
      "loss": 0.1609,
      "step": 2213
    },
    {
      "epoch": 1.3337349397590361,
      "grad_norm": 0.6079832315444946,
      "learning_rate": 3.332831325301205e-06,
      "loss": 0.2606,
      "step": 2214
    },
    {
      "epoch": 1.3343373493975903,
      "grad_norm": 0.5670235753059387,
      "learning_rate": 3.332078313253012e-06,
      "loss": 0.1575,
      "step": 2215
    },
    {
      "epoch": 1.3349397590361445,
      "grad_norm": 0.6825467348098755,
      "learning_rate": 3.3313253012048197e-06,
      "loss": 0.2107,
      "step": 2216
    },
    {
      "epoch": 1.3355421686746989,
      "grad_norm": 0.5398300886154175,
      "learning_rate": 3.3305722891566267e-06,
      "loss": 0.1759,
      "step": 2217
    },
    {
      "epoch": 1.336144578313253,
      "grad_norm": 0.5281935334205627,
      "learning_rate": 3.3298192771084344e-06,
      "loss": 0.1541,
      "step": 2218
    },
    {
      "epoch": 1.3367469879518072,
      "grad_norm": 0.7330154180526733,
      "learning_rate": 3.3290662650602413e-06,
      "loss": 0.137,
      "step": 2219
    },
    {
      "epoch": 1.3373493975903614,
      "grad_norm": 0.5017758011817932,
      "learning_rate": 3.3283132530120483e-06,
      "loss": 0.1537,
      "step": 2220
    },
    {
      "epoch": 1.3379518072289156,
      "grad_norm": 0.5040852427482605,
      "learning_rate": 3.3275602409638556e-06,
      "loss": 0.1589,
      "step": 2221
    },
    {
      "epoch": 1.33855421686747,
      "grad_norm": 0.6951150298118591,
      "learning_rate": 3.326807228915663e-06,
      "loss": 0.1733,
      "step": 2222
    },
    {
      "epoch": 1.339156626506024,
      "grad_norm": 0.5143887996673584,
      "learning_rate": 3.3260542168674703e-06,
      "loss": 0.165,
      "step": 2223
    },
    {
      "epoch": 1.3397590361445784,
      "grad_norm": 0.515010416507721,
      "learning_rate": 3.3253012048192772e-06,
      "loss": 0.15,
      "step": 2224
    },
    {
      "epoch": 1.3403614457831325,
      "grad_norm": 0.6152586936950684,
      "learning_rate": 3.324548192771085e-06,
      "loss": 0.1292,
      "step": 2225
    },
    {
      "epoch": 1.3409638554216867,
      "grad_norm": 0.6351519823074341,
      "learning_rate": 3.323795180722892e-06,
      "loss": 0.1552,
      "step": 2226
    },
    {
      "epoch": 1.341566265060241,
      "grad_norm": 0.575268030166626,
      "learning_rate": 3.323042168674699e-06,
      "loss": 0.1729,
      "step": 2227
    },
    {
      "epoch": 1.342168674698795,
      "grad_norm": 0.5039752125740051,
      "learning_rate": 3.3222891566265062e-06,
      "loss": 0.1792,
      "step": 2228
    },
    {
      "epoch": 1.3427710843373495,
      "grad_norm": 0.4718587100505829,
      "learning_rate": 3.3215361445783136e-06,
      "loss": 0.1616,
      "step": 2229
    },
    {
      "epoch": 1.3433734939759037,
      "grad_norm": 0.6412846446037292,
      "learning_rate": 3.320783132530121e-06,
      "loss": 0.2337,
      "step": 2230
    },
    {
      "epoch": 1.3439759036144578,
      "grad_norm": 0.5858207941055298,
      "learning_rate": 3.320030120481928e-06,
      "loss": 0.155,
      "step": 2231
    },
    {
      "epoch": 1.344578313253012,
      "grad_norm": 0.5365334153175354,
      "learning_rate": 3.3192771084337348e-06,
      "loss": 0.1726,
      "step": 2232
    },
    {
      "epoch": 1.3451807228915662,
      "grad_norm": 0.5851777195930481,
      "learning_rate": 3.3185240963855425e-06,
      "loss": 0.1571,
      "step": 2233
    },
    {
      "epoch": 1.3457831325301206,
      "grad_norm": 0.6707894802093506,
      "learning_rate": 3.3177710843373495e-06,
      "loss": 0.2207,
      "step": 2234
    },
    {
      "epoch": 1.3463855421686746,
      "grad_norm": 0.6431352496147156,
      "learning_rate": 3.3170180722891572e-06,
      "loss": 0.1718,
      "step": 2235
    },
    {
      "epoch": 1.346987951807229,
      "grad_norm": 0.6190375089645386,
      "learning_rate": 3.316265060240964e-06,
      "loss": 0.1958,
      "step": 2236
    },
    {
      "epoch": 1.3475903614457831,
      "grad_norm": 0.5993242263793945,
      "learning_rate": 3.3155120481927715e-06,
      "loss": 0.1763,
      "step": 2237
    },
    {
      "epoch": 1.3481927710843373,
      "grad_norm": 0.5045005083084106,
      "learning_rate": 3.3147590361445784e-06,
      "loss": 0.1951,
      "step": 2238
    },
    {
      "epoch": 1.3487951807228915,
      "grad_norm": 0.947117805480957,
      "learning_rate": 3.3140060240963858e-06,
      "loss": 0.2493,
      "step": 2239
    },
    {
      "epoch": 1.3493975903614457,
      "grad_norm": 0.6054317951202393,
      "learning_rate": 3.313253012048193e-06,
      "loss": 0.2048,
      "step": 2240
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.538395345211029,
      "learning_rate": 3.3125e-06,
      "loss": 0.1609,
      "step": 2241
    },
    {
      "epoch": 1.3506024096385543,
      "grad_norm": 0.5942561030387878,
      "learning_rate": 3.311746987951808e-06,
      "loss": 0.2151,
      "step": 2242
    },
    {
      "epoch": 1.3512048192771084,
      "grad_norm": 0.5490365624427795,
      "learning_rate": 3.3109939759036147e-06,
      "loss": 0.1227,
      "step": 2243
    },
    {
      "epoch": 1.3518072289156626,
      "grad_norm": 0.49288228154182434,
      "learning_rate": 3.3102409638554217e-06,
      "loss": 0.1234,
      "step": 2244
    },
    {
      "epoch": 1.3524096385542168,
      "grad_norm": 0.5418455600738525,
      "learning_rate": 3.3094879518072294e-06,
      "loss": 0.1821,
      "step": 2245
    },
    {
      "epoch": 1.3530120481927712,
      "grad_norm": 0.5807535648345947,
      "learning_rate": 3.3087349397590364e-06,
      "loss": 0.1536,
      "step": 2246
    },
    {
      "epoch": 1.3536144578313252,
      "grad_norm": 0.5197765827178955,
      "learning_rate": 3.3079819277108437e-06,
      "loss": 0.1565,
      "step": 2247
    },
    {
      "epoch": 1.3542168674698796,
      "grad_norm": 0.6518658995628357,
      "learning_rate": 3.3072289156626506e-06,
      "loss": 0.2101,
      "step": 2248
    },
    {
      "epoch": 1.3548192771084338,
      "grad_norm": 0.5480747222900391,
      "learning_rate": 3.3064759036144584e-06,
      "loss": 0.2191,
      "step": 2249
    },
    {
      "epoch": 1.355421686746988,
      "grad_norm": 0.5727200508117676,
      "learning_rate": 3.3057228915662653e-06,
      "loss": 0.1668,
      "step": 2250
    },
    {
      "epoch": 1.356024096385542,
      "grad_norm": 0.6666011214256287,
      "learning_rate": 3.3049698795180723e-06,
      "loss": 0.2143,
      "step": 2251
    },
    {
      "epoch": 1.3566265060240963,
      "grad_norm": 0.5991705656051636,
      "learning_rate": 3.30421686746988e-06,
      "loss": 0.1701,
      "step": 2252
    },
    {
      "epoch": 1.3572289156626507,
      "grad_norm": 0.6144558787345886,
      "learning_rate": 3.303463855421687e-06,
      "loss": 0.2278,
      "step": 2253
    },
    {
      "epoch": 1.3578313253012049,
      "grad_norm": 0.4941895306110382,
      "learning_rate": 3.3027108433734943e-06,
      "loss": 0.2101,
      "step": 2254
    },
    {
      "epoch": 1.358433734939759,
      "grad_norm": 0.4637187719345093,
      "learning_rate": 3.3019578313253017e-06,
      "loss": 0.1232,
      "step": 2255
    },
    {
      "epoch": 1.3590361445783132,
      "grad_norm": 0.5218448042869568,
      "learning_rate": 3.3012048192771086e-06,
      "loss": 0.1546,
      "step": 2256
    },
    {
      "epoch": 1.3596385542168674,
      "grad_norm": 0.7143616080284119,
      "learning_rate": 3.300451807228916e-06,
      "loss": 0.2149,
      "step": 2257
    },
    {
      "epoch": 1.3602409638554218,
      "grad_norm": 0.4809199273586273,
      "learning_rate": 3.299698795180723e-06,
      "loss": 0.1525,
      "step": 2258
    },
    {
      "epoch": 1.3608433734939758,
      "grad_norm": 0.5641434788703918,
      "learning_rate": 3.2989457831325306e-06,
      "loss": 0.1673,
      "step": 2259
    },
    {
      "epoch": 1.3614457831325302,
      "grad_norm": 0.5887335538864136,
      "learning_rate": 3.2981927710843376e-06,
      "loss": 0.1527,
      "step": 2260
    },
    {
      "epoch": 1.3620481927710844,
      "grad_norm": 0.5249329805374146,
      "learning_rate": 3.297439759036145e-06,
      "loss": 0.1806,
      "step": 2261
    },
    {
      "epoch": 1.3626506024096385,
      "grad_norm": 0.5898881554603577,
      "learning_rate": 3.2966867469879522e-06,
      "loss": 0.1858,
      "step": 2262
    },
    {
      "epoch": 1.3632530120481927,
      "grad_norm": 0.6389039158821106,
      "learning_rate": 3.295933734939759e-06,
      "loss": 0.1906,
      "step": 2263
    },
    {
      "epoch": 1.363855421686747,
      "grad_norm": 0.5538780093193054,
      "learning_rate": 3.2951807228915665e-06,
      "loss": 0.1881,
      "step": 2264
    },
    {
      "epoch": 1.3644578313253013,
      "grad_norm": 0.5516562461853027,
      "learning_rate": 3.2944277108433734e-06,
      "loss": 0.2515,
      "step": 2265
    },
    {
      "epoch": 1.3650602409638555,
      "grad_norm": 0.6149827241897583,
      "learning_rate": 3.2936746987951812e-06,
      "loss": 0.23,
      "step": 2266
    },
    {
      "epoch": 1.3656626506024097,
      "grad_norm": 0.4951159656047821,
      "learning_rate": 3.292921686746988e-06,
      "loss": 0.1742,
      "step": 2267
    },
    {
      "epoch": 1.3662650602409638,
      "grad_norm": 0.5311926603317261,
      "learning_rate": 3.292168674698795e-06,
      "loss": 0.1527,
      "step": 2268
    },
    {
      "epoch": 1.366867469879518,
      "grad_norm": 1.3799688816070557,
      "learning_rate": 3.291415662650603e-06,
      "loss": 0.1782,
      "step": 2269
    },
    {
      "epoch": 1.3674698795180724,
      "grad_norm": 0.47714996337890625,
      "learning_rate": 3.2906626506024098e-06,
      "loss": 0.1609,
      "step": 2270
    },
    {
      "epoch": 1.3680722891566264,
      "grad_norm": 0.6473389863967896,
      "learning_rate": 3.289909638554217e-06,
      "loss": 0.1722,
      "step": 2271
    },
    {
      "epoch": 1.3686746987951808,
      "grad_norm": 0.519450306892395,
      "learning_rate": 3.2891566265060245e-06,
      "loss": 0.1418,
      "step": 2272
    },
    {
      "epoch": 1.369277108433735,
      "grad_norm": 0.6811778545379639,
      "learning_rate": 3.288403614457832e-06,
      "loss": 0.1939,
      "step": 2273
    },
    {
      "epoch": 1.3698795180722891,
      "grad_norm": 0.7148946523666382,
      "learning_rate": 3.2876506024096387e-06,
      "loss": 0.2282,
      "step": 2274
    },
    {
      "epoch": 1.3704819277108433,
      "grad_norm": 0.6063940525054932,
      "learning_rate": 3.2868975903614457e-06,
      "loss": 0.1689,
      "step": 2275
    },
    {
      "epoch": 1.3710843373493975,
      "grad_norm": 0.5927646160125732,
      "learning_rate": 3.2861445783132534e-06,
      "loss": 0.2197,
      "step": 2276
    },
    {
      "epoch": 1.371686746987952,
      "grad_norm": 0.5576387047767639,
      "learning_rate": 3.2853915662650604e-06,
      "loss": 0.1621,
      "step": 2277
    },
    {
      "epoch": 1.372289156626506,
      "grad_norm": 0.5469284653663635,
      "learning_rate": 3.284638554216868e-06,
      "loss": 0.1622,
      "step": 2278
    },
    {
      "epoch": 1.3728915662650603,
      "grad_norm": 0.5385607481002808,
      "learning_rate": 3.283885542168675e-06,
      "loss": 0.1431,
      "step": 2279
    },
    {
      "epoch": 1.3734939759036144,
      "grad_norm": 0.585292398929596,
      "learning_rate": 3.283132530120482e-06,
      "loss": 0.1821,
      "step": 2280
    },
    {
      "epoch": 1.3740963855421686,
      "grad_norm": 0.5657411813735962,
      "learning_rate": 3.2823795180722893e-06,
      "loss": 0.1764,
      "step": 2281
    },
    {
      "epoch": 1.374698795180723,
      "grad_norm": 0.5038337111473083,
      "learning_rate": 3.2816265060240967e-06,
      "loss": 0.1846,
      "step": 2282
    },
    {
      "epoch": 1.375301204819277,
      "grad_norm": 0.49475112557411194,
      "learning_rate": 3.280873493975904e-06,
      "loss": 0.1756,
      "step": 2283
    },
    {
      "epoch": 1.3759036144578314,
      "grad_norm": 0.4723498821258545,
      "learning_rate": 3.280120481927711e-06,
      "loss": 0.1612,
      "step": 2284
    },
    {
      "epoch": 1.3765060240963856,
      "grad_norm": 0.502638041973114,
      "learning_rate": 3.2793674698795187e-06,
      "loss": 0.1628,
      "step": 2285
    },
    {
      "epoch": 1.3771084337349397,
      "grad_norm": 0.6392061114311218,
      "learning_rate": 3.2786144578313256e-06,
      "loss": 0.1714,
      "step": 2286
    },
    {
      "epoch": 1.377710843373494,
      "grad_norm": 0.6197419762611389,
      "learning_rate": 3.2778614457831326e-06,
      "loss": 0.1879,
      "step": 2287
    },
    {
      "epoch": 1.378313253012048,
      "grad_norm": 0.6170632243156433,
      "learning_rate": 3.2771084337349403e-06,
      "loss": 0.2091,
      "step": 2288
    },
    {
      "epoch": 1.3789156626506025,
      "grad_norm": 0.6485678553581238,
      "learning_rate": 3.2763554216867473e-06,
      "loss": 0.2023,
      "step": 2289
    },
    {
      "epoch": 1.3795180722891567,
      "grad_norm": 0.5812242031097412,
      "learning_rate": 3.2756024096385546e-06,
      "loss": 0.1583,
      "step": 2290
    },
    {
      "epoch": 1.3801204819277109,
      "grad_norm": 0.5617656707763672,
      "learning_rate": 3.2748493975903615e-06,
      "loss": 0.2252,
      "step": 2291
    },
    {
      "epoch": 1.380722891566265,
      "grad_norm": 0.5015190243721008,
      "learning_rate": 3.274096385542169e-06,
      "loss": 0.1398,
      "step": 2292
    },
    {
      "epoch": 1.3813253012048192,
      "grad_norm": 0.4753565192222595,
      "learning_rate": 3.2733433734939762e-06,
      "loss": 0.1521,
      "step": 2293
    },
    {
      "epoch": 1.3819277108433736,
      "grad_norm": 0.534571647644043,
      "learning_rate": 3.272590361445783e-06,
      "loss": 0.1351,
      "step": 2294
    },
    {
      "epoch": 1.3825301204819276,
      "grad_norm": 0.5284066200256348,
      "learning_rate": 3.271837349397591e-06,
      "loss": 0.1633,
      "step": 2295
    },
    {
      "epoch": 1.383132530120482,
      "grad_norm": 0.4850466549396515,
      "learning_rate": 3.271084337349398e-06,
      "loss": 0.1727,
      "step": 2296
    },
    {
      "epoch": 1.3837349397590362,
      "grad_norm": 0.5696829557418823,
      "learning_rate": 3.270331325301205e-06,
      "loss": 0.1679,
      "step": 2297
    },
    {
      "epoch": 1.3843373493975903,
      "grad_norm": 0.6792857646942139,
      "learning_rate": 3.269578313253012e-06,
      "loss": 0.1402,
      "step": 2298
    },
    {
      "epoch": 1.3849397590361445,
      "grad_norm": 0.6742584109306335,
      "learning_rate": 3.2688253012048195e-06,
      "loss": 0.1806,
      "step": 2299
    },
    {
      "epoch": 1.3855421686746987,
      "grad_norm": 0.47656819224357605,
      "learning_rate": 3.268072289156627e-06,
      "loss": 0.1772,
      "step": 2300
    },
    {
      "epoch": 1.386144578313253,
      "grad_norm": 0.6963129043579102,
      "learning_rate": 3.2673192771084338e-06,
      "loss": 0.1883,
      "step": 2301
    },
    {
      "epoch": 1.3867469879518073,
      "grad_norm": 0.5339241623878479,
      "learning_rate": 3.2665662650602415e-06,
      "loss": 0.1901,
      "step": 2302
    },
    {
      "epoch": 1.3873493975903615,
      "grad_norm": 0.6482173204421997,
      "learning_rate": 3.2658132530120484e-06,
      "loss": 0.1705,
      "step": 2303
    },
    {
      "epoch": 1.3879518072289156,
      "grad_norm": 0.6005140542984009,
      "learning_rate": 3.2650602409638554e-06,
      "loss": 0.168,
      "step": 2304
    },
    {
      "epoch": 1.3885542168674698,
      "grad_norm": 0.5595460534095764,
      "learning_rate": 3.264307228915663e-06,
      "loss": 0.2452,
      "step": 2305
    },
    {
      "epoch": 1.3891566265060242,
      "grad_norm": 0.6096150875091553,
      "learning_rate": 3.26355421686747e-06,
      "loss": 0.1665,
      "step": 2306
    },
    {
      "epoch": 1.3897590361445782,
      "grad_norm": 0.5504295825958252,
      "learning_rate": 3.2628012048192774e-06,
      "loss": 0.17,
      "step": 2307
    },
    {
      "epoch": 1.3903614457831326,
      "grad_norm": 0.5190852284431458,
      "learning_rate": 3.2620481927710843e-06,
      "loss": 0.1772,
      "step": 2308
    },
    {
      "epoch": 1.3909638554216868,
      "grad_norm": 0.7424014210700989,
      "learning_rate": 3.261295180722892e-06,
      "loss": 0.1805,
      "step": 2309
    },
    {
      "epoch": 1.391566265060241,
      "grad_norm": 0.5821924209594727,
      "learning_rate": 3.260542168674699e-06,
      "loss": 0.2443,
      "step": 2310
    },
    {
      "epoch": 1.3921686746987951,
      "grad_norm": 0.6247314214706421,
      "learning_rate": 3.259789156626506e-06,
      "loss": 0.1865,
      "step": 2311
    },
    {
      "epoch": 1.3927710843373493,
      "grad_norm": 0.4846785068511963,
      "learning_rate": 3.2590361445783137e-06,
      "loss": 0.144,
      "step": 2312
    },
    {
      "epoch": 1.3933734939759037,
      "grad_norm": 0.5591020584106445,
      "learning_rate": 3.2582831325301207e-06,
      "loss": 0.1841,
      "step": 2313
    },
    {
      "epoch": 1.393975903614458,
      "grad_norm": 0.5734455585479736,
      "learning_rate": 3.257530120481928e-06,
      "loss": 0.2185,
      "step": 2314
    },
    {
      "epoch": 1.394578313253012,
      "grad_norm": 0.6357713341712952,
      "learning_rate": 3.2567771084337354e-06,
      "loss": 0.2105,
      "step": 2315
    },
    {
      "epoch": 1.3951807228915662,
      "grad_norm": 0.5022171139717102,
      "learning_rate": 3.2560240963855423e-06,
      "loss": 0.1699,
      "step": 2316
    },
    {
      "epoch": 1.3957831325301204,
      "grad_norm": 0.5916590094566345,
      "learning_rate": 3.2552710843373496e-06,
      "loss": 0.1557,
      "step": 2317
    },
    {
      "epoch": 1.3963855421686748,
      "grad_norm": 0.6864150166511536,
      "learning_rate": 3.2545180722891566e-06,
      "loss": 0.21,
      "step": 2318
    },
    {
      "epoch": 1.3969879518072288,
      "grad_norm": 0.633799135684967,
      "learning_rate": 3.2537650602409643e-06,
      "loss": 0.1691,
      "step": 2319
    },
    {
      "epoch": 1.3975903614457832,
      "grad_norm": 1.0018101930618286,
      "learning_rate": 3.2530120481927713e-06,
      "loss": 0.2725,
      "step": 2320
    },
    {
      "epoch": 1.3981927710843374,
      "grad_norm": 0.9098756909370422,
      "learning_rate": 3.252259036144579e-06,
      "loss": 0.2434,
      "step": 2321
    },
    {
      "epoch": 1.3987951807228916,
      "grad_norm": 0.8349637985229492,
      "learning_rate": 3.251506024096386e-06,
      "loss": 0.2986,
      "step": 2322
    },
    {
      "epoch": 1.3993975903614457,
      "grad_norm": 0.8344448804855347,
      "learning_rate": 3.250753012048193e-06,
      "loss": 0.2765,
      "step": 2323
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.7757549285888672,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 0.2938,
      "step": 2324
    },
    {
      "epoch": 1.4006024096385543,
      "grad_norm": 0.8302164077758789,
      "learning_rate": 3.2492469879518076e-06,
      "loss": 0.2943,
      "step": 2325
    },
    {
      "epoch": 1.4012048192771085,
      "grad_norm": 0.7120240926742554,
      "learning_rate": 3.248493975903615e-06,
      "loss": 0.3248,
      "step": 2326
    },
    {
      "epoch": 1.4018072289156627,
      "grad_norm": 0.6904529929161072,
      "learning_rate": 3.247740963855422e-06,
      "loss": 0.3004,
      "step": 2327
    },
    {
      "epoch": 1.4024096385542169,
      "grad_norm": 0.7328500747680664,
      "learning_rate": 3.2469879518072288e-06,
      "loss": 0.2933,
      "step": 2328
    },
    {
      "epoch": 1.403012048192771,
      "grad_norm": 0.5989951491355896,
      "learning_rate": 3.2462349397590365e-06,
      "loss": 0.2753,
      "step": 2329
    },
    {
      "epoch": 1.4036144578313254,
      "grad_norm": 0.6466780304908752,
      "learning_rate": 3.2454819277108435e-06,
      "loss": 0.288,
      "step": 2330
    },
    {
      "epoch": 1.4042168674698794,
      "grad_norm": 0.5593780279159546,
      "learning_rate": 3.244728915662651e-06,
      "loss": 0.2551,
      "step": 2331
    },
    {
      "epoch": 1.4048192771084338,
      "grad_norm": 0.5628364682197571,
      "learning_rate": 3.243975903614458e-06,
      "loss": 0.2272,
      "step": 2332
    },
    {
      "epoch": 1.405421686746988,
      "grad_norm": 0.6064491868019104,
      "learning_rate": 3.2432228915662655e-06,
      "loss": 0.259,
      "step": 2333
    },
    {
      "epoch": 1.4060240963855422,
      "grad_norm": 0.5967546701431274,
      "learning_rate": 3.2424698795180724e-06,
      "loss": 0.2397,
      "step": 2334
    },
    {
      "epoch": 1.4066265060240963,
      "grad_norm": 0.6528752446174622,
      "learning_rate": 3.2417168674698794e-06,
      "loss": 0.2242,
      "step": 2335
    },
    {
      "epoch": 1.4072289156626505,
      "grad_norm": 0.6562812924385071,
      "learning_rate": 3.240963855421687e-06,
      "loss": 0.278,
      "step": 2336
    },
    {
      "epoch": 1.407831325301205,
      "grad_norm": 0.5522204637527466,
      "learning_rate": 3.240210843373494e-06,
      "loss": 0.2415,
      "step": 2337
    },
    {
      "epoch": 1.408433734939759,
      "grad_norm": 0.6265519857406616,
      "learning_rate": 3.239457831325302e-06,
      "loss": 0.2579,
      "step": 2338
    },
    {
      "epoch": 1.4090361445783133,
      "grad_norm": 0.556352436542511,
      "learning_rate": 3.2387048192771088e-06,
      "loss": 0.2474,
      "step": 2339
    },
    {
      "epoch": 1.4096385542168675,
      "grad_norm": 0.6295725703239441,
      "learning_rate": 3.2379518072289157e-06,
      "loss": 0.2269,
      "step": 2340
    },
    {
      "epoch": 1.4102409638554216,
      "grad_norm": 0.639319896697998,
      "learning_rate": 3.237198795180723e-06,
      "loss": 0.2385,
      "step": 2341
    },
    {
      "epoch": 1.410843373493976,
      "grad_norm": 0.6206361651420593,
      "learning_rate": 3.2364457831325304e-06,
      "loss": 0.2557,
      "step": 2342
    },
    {
      "epoch": 1.41144578313253,
      "grad_norm": 0.6533638834953308,
      "learning_rate": 3.2356927710843377e-06,
      "loss": 0.2593,
      "step": 2343
    },
    {
      "epoch": 1.4120481927710844,
      "grad_norm": 0.5552395582199097,
      "learning_rate": 3.2349397590361447e-06,
      "loss": 0.2662,
      "step": 2344
    },
    {
      "epoch": 1.4126506024096386,
      "grad_norm": 0.632305383682251,
      "learning_rate": 3.2341867469879524e-06,
      "loss": 0.2654,
      "step": 2345
    },
    {
      "epoch": 1.4132530120481928,
      "grad_norm": 0.6614351868629456,
      "learning_rate": 3.2334337349397593e-06,
      "loss": 0.2838,
      "step": 2346
    },
    {
      "epoch": 1.413855421686747,
      "grad_norm": 0.5592346787452698,
      "learning_rate": 3.2326807228915663e-06,
      "loss": 0.2717,
      "step": 2347
    },
    {
      "epoch": 1.4144578313253011,
      "grad_norm": 0.5929403901100159,
      "learning_rate": 3.231927710843374e-06,
      "loss": 0.2658,
      "step": 2348
    },
    {
      "epoch": 1.4150602409638555,
      "grad_norm": 0.6149333119392395,
      "learning_rate": 3.231174698795181e-06,
      "loss": 0.2606,
      "step": 2349
    },
    {
      "epoch": 1.4156626506024097,
      "grad_norm": 0.7722839713096619,
      "learning_rate": 3.2304216867469883e-06,
      "loss": 0.3032,
      "step": 2350
    },
    {
      "epoch": 1.4162650602409639,
      "grad_norm": 0.5795394778251648,
      "learning_rate": 3.2296686746987952e-06,
      "loss": 0.2482,
      "step": 2351
    },
    {
      "epoch": 1.416867469879518,
      "grad_norm": 0.613959789276123,
      "learning_rate": 3.2289156626506026e-06,
      "loss": 0.2569,
      "step": 2352
    },
    {
      "epoch": 1.4174698795180722,
      "grad_norm": 0.5342872142791748,
      "learning_rate": 3.22816265060241e-06,
      "loss": 0.2392,
      "step": 2353
    },
    {
      "epoch": 1.4180722891566266,
      "grad_norm": 0.5274674296379089,
      "learning_rate": 3.227409638554217e-06,
      "loss": 0.2824,
      "step": 2354
    },
    {
      "epoch": 1.4186746987951806,
      "grad_norm": 0.59607994556427,
      "learning_rate": 3.2266566265060246e-06,
      "loss": 0.2631,
      "step": 2355
    },
    {
      "epoch": 1.419277108433735,
      "grad_norm": 0.5904875993728638,
      "learning_rate": 3.2259036144578316e-06,
      "loss": 0.2234,
      "step": 2356
    },
    {
      "epoch": 1.4198795180722892,
      "grad_norm": 0.5440592765808105,
      "learning_rate": 3.225150602409639e-06,
      "loss": 0.2709,
      "step": 2357
    },
    {
      "epoch": 1.4204819277108434,
      "grad_norm": 0.5255182385444641,
      "learning_rate": 3.2243975903614463e-06,
      "loss": 0.2555,
      "step": 2358
    },
    {
      "epoch": 1.4210843373493975,
      "grad_norm": 0.662528932094574,
      "learning_rate": 3.223644578313253e-06,
      "loss": 0.2396,
      "step": 2359
    },
    {
      "epoch": 1.4216867469879517,
      "grad_norm": 0.6007463932037354,
      "learning_rate": 3.2228915662650605e-06,
      "loss": 0.2696,
      "step": 2360
    },
    {
      "epoch": 1.4222891566265061,
      "grad_norm": 0.5690494775772095,
      "learning_rate": 3.2221385542168675e-06,
      "loss": 0.2965,
      "step": 2361
    },
    {
      "epoch": 1.4228915662650603,
      "grad_norm": 0.580123245716095,
      "learning_rate": 3.2213855421686752e-06,
      "loss": 0.2514,
      "step": 2362
    },
    {
      "epoch": 1.4234939759036145,
      "grad_norm": 0.5446504950523376,
      "learning_rate": 3.220632530120482e-06,
      "loss": 0.2812,
      "step": 2363
    },
    {
      "epoch": 1.4240963855421687,
      "grad_norm": 0.6128400564193726,
      "learning_rate": 3.219879518072289e-06,
      "loss": 0.2789,
      "step": 2364
    },
    {
      "epoch": 1.4246987951807228,
      "grad_norm": 0.5300059914588928,
      "learning_rate": 3.219126506024097e-06,
      "loss": 0.2731,
      "step": 2365
    },
    {
      "epoch": 1.4253012048192772,
      "grad_norm": 0.6008949279785156,
      "learning_rate": 3.2183734939759038e-06,
      "loss": 0.2477,
      "step": 2366
    },
    {
      "epoch": 1.4259036144578312,
      "grad_norm": 0.6226508617401123,
      "learning_rate": 3.217620481927711e-06,
      "loss": 0.2872,
      "step": 2367
    },
    {
      "epoch": 1.4265060240963856,
      "grad_norm": 0.6875553727149963,
      "learning_rate": 3.216867469879518e-06,
      "loss": 0.2439,
      "step": 2368
    },
    {
      "epoch": 1.4271084337349398,
      "grad_norm": 0.5213350057601929,
      "learning_rate": 3.216114457831326e-06,
      "loss": 0.2313,
      "step": 2369
    },
    {
      "epoch": 1.427710843373494,
      "grad_norm": 0.588936984539032,
      "learning_rate": 3.2153614457831327e-06,
      "loss": 0.2779,
      "step": 2370
    },
    {
      "epoch": 1.4283132530120481,
      "grad_norm": 0.6273915767669678,
      "learning_rate": 3.2146084337349397e-06,
      "loss": 0.2852,
      "step": 2371
    },
    {
      "epoch": 1.4289156626506023,
      "grad_norm": 0.5654228925704956,
      "learning_rate": 3.2138554216867474e-06,
      "loss": 0.2846,
      "step": 2372
    },
    {
      "epoch": 1.4295180722891567,
      "grad_norm": 0.6271271705627441,
      "learning_rate": 3.2131024096385544e-06,
      "loss": 0.2445,
      "step": 2373
    },
    {
      "epoch": 1.430120481927711,
      "grad_norm": 0.5905309915542603,
      "learning_rate": 3.2123493975903617e-06,
      "loss": 0.249,
      "step": 2374
    },
    {
      "epoch": 1.430722891566265,
      "grad_norm": 0.5643014907836914,
      "learning_rate": 3.211596385542169e-06,
      "loss": 0.2939,
      "step": 2375
    },
    {
      "epoch": 1.4313253012048193,
      "grad_norm": 0.5555552840232849,
      "learning_rate": 3.210843373493976e-06,
      "loss": 0.2194,
      "step": 2376
    },
    {
      "epoch": 1.4319277108433734,
      "grad_norm": 0.6028635501861572,
      "learning_rate": 3.2100903614457833e-06,
      "loss": 0.2144,
      "step": 2377
    },
    {
      "epoch": 1.4325301204819278,
      "grad_norm": 0.6061719059944153,
      "learning_rate": 3.2093373493975903e-06,
      "loss": 0.2127,
      "step": 2378
    },
    {
      "epoch": 1.4331325301204818,
      "grad_norm": 0.5237616896629333,
      "learning_rate": 3.208584337349398e-06,
      "loss": 0.2463,
      "step": 2379
    },
    {
      "epoch": 1.4337349397590362,
      "grad_norm": 0.6972345113754272,
      "learning_rate": 3.207831325301205e-06,
      "loss": 0.3298,
      "step": 2380
    },
    {
      "epoch": 1.4343373493975904,
      "grad_norm": 0.5049048662185669,
      "learning_rate": 3.2070783132530127e-06,
      "loss": 0.2569,
      "step": 2381
    },
    {
      "epoch": 1.4349397590361446,
      "grad_norm": 0.6576194167137146,
      "learning_rate": 3.2063253012048197e-06,
      "loss": 0.3237,
      "step": 2382
    },
    {
      "epoch": 1.4355421686746987,
      "grad_norm": 0.5846759080886841,
      "learning_rate": 3.2055722891566266e-06,
      "loss": 0.2249,
      "step": 2383
    },
    {
      "epoch": 1.436144578313253,
      "grad_norm": 0.6252762675285339,
      "learning_rate": 3.204819277108434e-06,
      "loss": 0.2738,
      "step": 2384
    },
    {
      "epoch": 1.4367469879518073,
      "grad_norm": 0.6506037712097168,
      "learning_rate": 3.2040662650602413e-06,
      "loss": 0.2433,
      "step": 2385
    },
    {
      "epoch": 1.4373493975903615,
      "grad_norm": 0.5675609111785889,
      "learning_rate": 3.2033132530120486e-06,
      "loss": 0.2479,
      "step": 2386
    },
    {
      "epoch": 1.4379518072289157,
      "grad_norm": 0.6130643486976624,
      "learning_rate": 3.2025602409638555e-06,
      "loss": 0.2996,
      "step": 2387
    },
    {
      "epoch": 1.4385542168674699,
      "grad_norm": 0.5720256567001343,
      "learning_rate": 3.2018072289156625e-06,
      "loss": 0.2642,
      "step": 2388
    },
    {
      "epoch": 1.439156626506024,
      "grad_norm": 0.5460541248321533,
      "learning_rate": 3.2010542168674702e-06,
      "loss": 0.2083,
      "step": 2389
    },
    {
      "epoch": 1.4397590361445782,
      "grad_norm": 0.4878169298171997,
      "learning_rate": 3.200301204819277e-06,
      "loss": 0.2464,
      "step": 2390
    },
    {
      "epoch": 1.4403614457831324,
      "grad_norm": 0.5968235731124878,
      "learning_rate": 3.199548192771085e-06,
      "loss": 0.2625,
      "step": 2391
    },
    {
      "epoch": 1.4409638554216868,
      "grad_norm": 0.5710805654525757,
      "learning_rate": 3.198795180722892e-06,
      "loss": 0.2539,
      "step": 2392
    },
    {
      "epoch": 1.441566265060241,
      "grad_norm": 0.5997821092605591,
      "learning_rate": 3.1980421686746992e-06,
      "loss": 0.2797,
      "step": 2393
    },
    {
      "epoch": 1.4421686746987952,
      "grad_norm": 0.5065556168556213,
      "learning_rate": 3.197289156626506e-06,
      "loss": 0.2401,
      "step": 2394
    },
    {
      "epoch": 1.4427710843373494,
      "grad_norm": 0.6750203371047974,
      "learning_rate": 3.1965361445783135e-06,
      "loss": 0.2699,
      "step": 2395
    },
    {
      "epoch": 1.4433734939759035,
      "grad_norm": 0.5978608131408691,
      "learning_rate": 3.195783132530121e-06,
      "loss": 0.2442,
      "step": 2396
    },
    {
      "epoch": 1.443975903614458,
      "grad_norm": 0.6289084553718567,
      "learning_rate": 3.1950301204819278e-06,
      "loss": 0.3366,
      "step": 2397
    },
    {
      "epoch": 1.4445783132530121,
      "grad_norm": 0.6427929997444153,
      "learning_rate": 3.1942771084337355e-06,
      "loss": 0.2855,
      "step": 2398
    },
    {
      "epoch": 1.4451807228915663,
      "grad_norm": 0.55491042137146,
      "learning_rate": 3.1935240963855425e-06,
      "loss": 0.2766,
      "step": 2399
    },
    {
      "epoch": 1.4457831325301205,
      "grad_norm": 0.5477178692817688,
      "learning_rate": 3.1927710843373494e-06,
      "loss": 0.2512,
      "step": 2400
    },
    {
      "epoch": 1.4463855421686747,
      "grad_norm": 0.5116598606109619,
      "learning_rate": 3.192018072289157e-06,
      "loss": 0.2011,
      "step": 2401
    },
    {
      "epoch": 1.4469879518072288,
      "grad_norm": 0.5209147334098816,
      "learning_rate": 3.191265060240964e-06,
      "loss": 0.232,
      "step": 2402
    },
    {
      "epoch": 1.447590361445783,
      "grad_norm": 0.7579258680343628,
      "learning_rate": 3.1905120481927714e-06,
      "loss": 0.2351,
      "step": 2403
    },
    {
      "epoch": 1.4481927710843374,
      "grad_norm": 0.5788765549659729,
      "learning_rate": 3.1897590361445784e-06,
      "loss": 0.2737,
      "step": 2404
    },
    {
      "epoch": 1.4487951807228916,
      "grad_norm": 0.5584558844566345,
      "learning_rate": 3.189006024096386e-06,
      "loss": 0.2517,
      "step": 2405
    },
    {
      "epoch": 1.4493975903614458,
      "grad_norm": 0.6435784697532654,
      "learning_rate": 3.188253012048193e-06,
      "loss": 0.2523,
      "step": 2406
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.6914664506912231,
      "learning_rate": 3.1875e-06,
      "loss": 0.294,
      "step": 2407
    },
    {
      "epoch": 1.4506024096385541,
      "grad_norm": 0.5770010948181152,
      "learning_rate": 3.1867469879518077e-06,
      "loss": 0.2522,
      "step": 2408
    },
    {
      "epoch": 1.4512048192771085,
      "grad_norm": 0.5325085520744324,
      "learning_rate": 3.1859939759036147e-06,
      "loss": 0.2497,
      "step": 2409
    },
    {
      "epoch": 1.4518072289156627,
      "grad_norm": 0.5166339874267578,
      "learning_rate": 3.185240963855422e-06,
      "loss": 0.2148,
      "step": 2410
    },
    {
      "epoch": 1.452409638554217,
      "grad_norm": 0.5910872220993042,
      "learning_rate": 3.184487951807229e-06,
      "loss": 0.2452,
      "step": 2411
    },
    {
      "epoch": 1.453012048192771,
      "grad_norm": 0.5139243006706238,
      "learning_rate": 3.1837349397590363e-06,
      "loss": 0.2636,
      "step": 2412
    },
    {
      "epoch": 1.4536144578313253,
      "grad_norm": 0.5173881649971008,
      "learning_rate": 3.1829819277108436e-06,
      "loss": 0.2853,
      "step": 2413
    },
    {
      "epoch": 1.4542168674698794,
      "grad_norm": 0.5573296546936035,
      "learning_rate": 3.1822289156626506e-06,
      "loss": 0.2033,
      "step": 2414
    },
    {
      "epoch": 1.4548192771084336,
      "grad_norm": 0.6855025291442871,
      "learning_rate": 3.1814759036144583e-06,
      "loss": 0.3503,
      "step": 2415
    },
    {
      "epoch": 1.455421686746988,
      "grad_norm": 0.54245525598526,
      "learning_rate": 3.1807228915662653e-06,
      "loss": 0.2611,
      "step": 2416
    },
    {
      "epoch": 1.4560240963855422,
      "grad_norm": 0.612921953201294,
      "learning_rate": 3.1799698795180726e-06,
      "loss": 0.2885,
      "step": 2417
    },
    {
      "epoch": 1.4566265060240964,
      "grad_norm": 0.4837702512741089,
      "learning_rate": 3.17921686746988e-06,
      "loss": 0.2092,
      "step": 2418
    },
    {
      "epoch": 1.4572289156626506,
      "grad_norm": 0.5444379448890686,
      "learning_rate": 3.178463855421687e-06,
      "loss": 0.2448,
      "step": 2419
    },
    {
      "epoch": 1.4578313253012047,
      "grad_norm": 0.5546878576278687,
      "learning_rate": 3.1777108433734942e-06,
      "loss": 0.2798,
      "step": 2420
    },
    {
      "epoch": 1.4584337349397591,
      "grad_norm": 0.5542672872543335,
      "learning_rate": 3.176957831325301e-06,
      "loss": 0.2858,
      "step": 2421
    },
    {
      "epoch": 1.4590361445783133,
      "grad_norm": 0.5550721883773804,
      "learning_rate": 3.176204819277109e-06,
      "loss": 0.2751,
      "step": 2422
    },
    {
      "epoch": 1.4596385542168675,
      "grad_norm": 0.5547224283218384,
      "learning_rate": 3.175451807228916e-06,
      "loss": 0.2332,
      "step": 2423
    },
    {
      "epoch": 1.4602409638554217,
      "grad_norm": 0.5667891502380371,
      "learning_rate": 3.1746987951807228e-06,
      "loss": 0.2809,
      "step": 2424
    },
    {
      "epoch": 1.4608433734939759,
      "grad_norm": 0.5891345739364624,
      "learning_rate": 3.1739457831325306e-06,
      "loss": 0.2133,
      "step": 2425
    },
    {
      "epoch": 1.46144578313253,
      "grad_norm": 0.5767468214035034,
      "learning_rate": 3.1731927710843375e-06,
      "loss": 0.2671,
      "step": 2426
    },
    {
      "epoch": 1.4620481927710842,
      "grad_norm": 0.5335732102394104,
      "learning_rate": 3.172439759036145e-06,
      "loss": 0.2409,
      "step": 2427
    },
    {
      "epoch": 1.4626506024096386,
      "grad_norm": 0.5545883178710938,
      "learning_rate": 3.171686746987952e-06,
      "loss": 0.2759,
      "step": 2428
    },
    {
      "epoch": 1.4632530120481928,
      "grad_norm": 0.563125729560852,
      "learning_rate": 3.1709337349397595e-06,
      "loss": 0.2584,
      "step": 2429
    },
    {
      "epoch": 1.463855421686747,
      "grad_norm": 0.5786144137382507,
      "learning_rate": 3.1701807228915664e-06,
      "loss": 0.2597,
      "step": 2430
    },
    {
      "epoch": 1.4644578313253012,
      "grad_norm": 0.6624649167060852,
      "learning_rate": 3.1694277108433734e-06,
      "loss": 0.2609,
      "step": 2431
    },
    {
      "epoch": 1.4650602409638553,
      "grad_norm": 0.5543053150177002,
      "learning_rate": 3.168674698795181e-06,
      "loss": 0.2685,
      "step": 2432
    },
    {
      "epoch": 1.4656626506024097,
      "grad_norm": 0.5874087810516357,
      "learning_rate": 3.167921686746988e-06,
      "loss": 0.2566,
      "step": 2433
    },
    {
      "epoch": 1.466265060240964,
      "grad_norm": 0.46255260705947876,
      "learning_rate": 3.167168674698796e-06,
      "loss": 0.2245,
      "step": 2434
    },
    {
      "epoch": 1.466867469879518,
      "grad_norm": 0.4770320653915405,
      "learning_rate": 3.1664156626506028e-06,
      "loss": 0.2109,
      "step": 2435
    },
    {
      "epoch": 1.4674698795180723,
      "grad_norm": 0.5149782299995422,
      "learning_rate": 3.1656626506024097e-06,
      "loss": 0.2374,
      "step": 2436
    },
    {
      "epoch": 1.4680722891566265,
      "grad_norm": 0.5521286725997925,
      "learning_rate": 3.164909638554217e-06,
      "loss": 0.2677,
      "step": 2437
    },
    {
      "epoch": 1.4686746987951806,
      "grad_norm": 0.5386617183685303,
      "learning_rate": 3.1641566265060244e-06,
      "loss": 0.2502,
      "step": 2438
    },
    {
      "epoch": 1.4692771084337348,
      "grad_norm": 0.5220769047737122,
      "learning_rate": 3.1634036144578317e-06,
      "loss": 0.2311,
      "step": 2439
    },
    {
      "epoch": 1.4698795180722892,
      "grad_norm": 0.5836488008499146,
      "learning_rate": 3.1626506024096387e-06,
      "loss": 0.3139,
      "step": 2440
    },
    {
      "epoch": 1.4704819277108434,
      "grad_norm": 0.6120570302009583,
      "learning_rate": 3.1618975903614464e-06,
      "loss": 0.2315,
      "step": 2441
    },
    {
      "epoch": 1.4710843373493976,
      "grad_norm": 0.5184957385063171,
      "learning_rate": 3.1611445783132534e-06,
      "loss": 0.2369,
      "step": 2442
    },
    {
      "epoch": 1.4716867469879518,
      "grad_norm": 0.5782061815261841,
      "learning_rate": 3.1603915662650603e-06,
      "loss": 0.2302,
      "step": 2443
    },
    {
      "epoch": 1.472289156626506,
      "grad_norm": 0.523245096206665,
      "learning_rate": 3.1596385542168676e-06,
      "loss": 0.2566,
      "step": 2444
    },
    {
      "epoch": 1.4728915662650603,
      "grad_norm": 0.5399289131164551,
      "learning_rate": 3.158885542168675e-06,
      "loss": 0.2264,
      "step": 2445
    },
    {
      "epoch": 1.4734939759036145,
      "grad_norm": 0.6125203371047974,
      "learning_rate": 3.1581325301204823e-06,
      "loss": 0.2683,
      "step": 2446
    },
    {
      "epoch": 1.4740963855421687,
      "grad_norm": 0.506611168384552,
      "learning_rate": 3.1573795180722893e-06,
      "loss": 0.2342,
      "step": 2447
    },
    {
      "epoch": 1.4746987951807229,
      "grad_norm": 0.5905421376228333,
      "learning_rate": 3.156626506024096e-06,
      "loss": 0.2604,
      "step": 2448
    },
    {
      "epoch": 1.475301204819277,
      "grad_norm": 0.5504855513572693,
      "learning_rate": 3.155873493975904e-06,
      "loss": 0.2494,
      "step": 2449
    },
    {
      "epoch": 1.4759036144578312,
      "grad_norm": 0.5015400052070618,
      "learning_rate": 3.155120481927711e-06,
      "loss": 0.2222,
      "step": 2450
    },
    {
      "epoch": 1.4765060240963854,
      "grad_norm": 0.5754329562187195,
      "learning_rate": 3.1543674698795186e-06,
      "loss": 0.2805,
      "step": 2451
    },
    {
      "epoch": 1.4771084337349398,
      "grad_norm": 0.6114501357078552,
      "learning_rate": 3.1536144578313256e-06,
      "loss": 0.2836,
      "step": 2452
    },
    {
      "epoch": 1.477710843373494,
      "grad_norm": 0.5018747448921204,
      "learning_rate": 3.152861445783133e-06,
      "loss": 0.225,
      "step": 2453
    },
    {
      "epoch": 1.4783132530120482,
      "grad_norm": 0.6304158568382263,
      "learning_rate": 3.15210843373494e-06,
      "loss": 0.271,
      "step": 2454
    },
    {
      "epoch": 1.4789156626506024,
      "grad_norm": 0.5679088234901428,
      "learning_rate": 3.151355421686747e-06,
      "loss": 0.2127,
      "step": 2455
    },
    {
      "epoch": 1.4795180722891565,
      "grad_norm": 0.6650118827819824,
      "learning_rate": 3.1506024096385545e-06,
      "loss": 0.2958,
      "step": 2456
    },
    {
      "epoch": 1.480120481927711,
      "grad_norm": 0.49773862957954407,
      "learning_rate": 3.1498493975903615e-06,
      "loss": 0.206,
      "step": 2457
    },
    {
      "epoch": 1.4807228915662651,
      "grad_norm": 0.5622771978378296,
      "learning_rate": 3.1490963855421692e-06,
      "loss": 0.2909,
      "step": 2458
    },
    {
      "epoch": 1.4813253012048193,
      "grad_norm": 0.7401031255722046,
      "learning_rate": 3.148343373493976e-06,
      "loss": 0.2798,
      "step": 2459
    },
    {
      "epoch": 1.4819277108433735,
      "grad_norm": 0.502618134021759,
      "learning_rate": 3.147590361445783e-06,
      "loss": 0.2333,
      "step": 2460
    },
    {
      "epoch": 1.4825301204819277,
      "grad_norm": 0.5155951976776123,
      "learning_rate": 3.146837349397591e-06,
      "loss": 0.3046,
      "step": 2461
    },
    {
      "epoch": 1.4831325301204819,
      "grad_norm": 0.593297004699707,
      "learning_rate": 3.1460843373493978e-06,
      "loss": 0.2179,
      "step": 2462
    },
    {
      "epoch": 1.483734939759036,
      "grad_norm": 0.5207009315490723,
      "learning_rate": 3.145331325301205e-06,
      "loss": 0.2424,
      "step": 2463
    },
    {
      "epoch": 1.4843373493975904,
      "grad_norm": 0.5744780898094177,
      "learning_rate": 3.144578313253012e-06,
      "loss": 0.2656,
      "step": 2464
    },
    {
      "epoch": 1.4849397590361446,
      "grad_norm": 0.5152987241744995,
      "learning_rate": 3.14382530120482e-06,
      "loss": 0.2309,
      "step": 2465
    },
    {
      "epoch": 1.4855421686746988,
      "grad_norm": 0.6082754135131836,
      "learning_rate": 3.1430722891566268e-06,
      "loss": 0.3133,
      "step": 2466
    },
    {
      "epoch": 1.486144578313253,
      "grad_norm": 0.5882532000541687,
      "learning_rate": 3.1423192771084337e-06,
      "loss": 0.2767,
      "step": 2467
    },
    {
      "epoch": 1.4867469879518072,
      "grad_norm": 0.5169745087623596,
      "learning_rate": 3.1415662650602414e-06,
      "loss": 0.2105,
      "step": 2468
    },
    {
      "epoch": 1.4873493975903616,
      "grad_norm": 0.5314979553222656,
      "learning_rate": 3.1408132530120484e-06,
      "loss": 0.3114,
      "step": 2469
    },
    {
      "epoch": 1.4879518072289157,
      "grad_norm": 0.5830325484275818,
      "learning_rate": 3.1400602409638557e-06,
      "loss": 0.2347,
      "step": 2470
    },
    {
      "epoch": 1.48855421686747,
      "grad_norm": 0.5092951059341431,
      "learning_rate": 3.139307228915663e-06,
      "loss": 0.2466,
      "step": 2471
    },
    {
      "epoch": 1.489156626506024,
      "grad_norm": 0.5399070978164673,
      "learning_rate": 3.13855421686747e-06,
      "loss": 0.2555,
      "step": 2472
    },
    {
      "epoch": 1.4897590361445783,
      "grad_norm": 0.5885124802589417,
      "learning_rate": 3.1378012048192773e-06,
      "loss": 0.2984,
      "step": 2473
    },
    {
      "epoch": 1.4903614457831325,
      "grad_norm": 0.5483728051185608,
      "learning_rate": 3.1370481927710843e-06,
      "loss": 0.2136,
      "step": 2474
    },
    {
      "epoch": 1.4909638554216866,
      "grad_norm": 0.5625059008598328,
      "learning_rate": 3.136295180722892e-06,
      "loss": 0.2414,
      "step": 2475
    },
    {
      "epoch": 1.491566265060241,
      "grad_norm": 0.5989115238189697,
      "learning_rate": 3.135542168674699e-06,
      "loss": 0.2848,
      "step": 2476
    },
    {
      "epoch": 1.4921686746987952,
      "grad_norm": 0.561137318611145,
      "learning_rate": 3.1347891566265063e-06,
      "loss": 0.2361,
      "step": 2477
    },
    {
      "epoch": 1.4927710843373494,
      "grad_norm": 0.5371520519256592,
      "learning_rate": 3.1340361445783137e-06,
      "loss": 0.2959,
      "step": 2478
    },
    {
      "epoch": 1.4933734939759036,
      "grad_norm": 0.5435571074485779,
      "learning_rate": 3.1332831325301206e-06,
      "loss": 0.2638,
      "step": 2479
    },
    {
      "epoch": 1.4939759036144578,
      "grad_norm": 0.5449188947677612,
      "learning_rate": 3.132530120481928e-06,
      "loss": 0.2546,
      "step": 2480
    },
    {
      "epoch": 1.4945783132530122,
      "grad_norm": 0.6810524463653564,
      "learning_rate": 3.131777108433735e-06,
      "loss": 0.2741,
      "step": 2481
    },
    {
      "epoch": 1.4951807228915663,
      "grad_norm": 0.5939525961875916,
      "learning_rate": 3.1310240963855426e-06,
      "loss": 0.3148,
      "step": 2482
    },
    {
      "epoch": 1.4957831325301205,
      "grad_norm": 0.5821215510368347,
      "learning_rate": 3.1302710843373496e-06,
      "loss": 0.2364,
      "step": 2483
    },
    {
      "epoch": 1.4963855421686747,
      "grad_norm": 0.5141160488128662,
      "learning_rate": 3.1295180722891565e-06,
      "loss": 0.2353,
      "step": 2484
    },
    {
      "epoch": 1.4969879518072289,
      "grad_norm": 0.5528602600097656,
      "learning_rate": 3.1287650602409643e-06,
      "loss": 0.2817,
      "step": 2485
    },
    {
      "epoch": 1.497590361445783,
      "grad_norm": 0.7226681113243103,
      "learning_rate": 3.128012048192771e-06,
      "loss": 0.3166,
      "step": 2486
    },
    {
      "epoch": 1.4981927710843372,
      "grad_norm": 0.4833119511604309,
      "learning_rate": 3.1272590361445785e-06,
      "loss": 0.2348,
      "step": 2487
    },
    {
      "epoch": 1.4987951807228916,
      "grad_norm": 0.5153506994247437,
      "learning_rate": 3.126506024096386e-06,
      "loss": 0.2148,
      "step": 2488
    },
    {
      "epoch": 1.4993975903614458,
      "grad_norm": 0.48531028628349304,
      "learning_rate": 3.1257530120481932e-06,
      "loss": 0.2357,
      "step": 2489
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.5047698616981506,
      "learning_rate": 3.125e-06,
      "loss": 0.2272,
      "step": 2490
    },
    {
      "epoch": 1.5006024096385542,
      "grad_norm": 0.4777768552303314,
      "learning_rate": 3.124246987951807e-06,
      "loss": 0.2052,
      "step": 2491
    },
    {
      "epoch": 1.5012048192771084,
      "grad_norm": 0.4991918206214905,
      "learning_rate": 3.123493975903615e-06,
      "loss": 0.2144,
      "step": 2492
    },
    {
      "epoch": 1.5018072289156628,
      "grad_norm": 0.5081857442855835,
      "learning_rate": 3.1227409638554218e-06,
      "loss": 0.2105,
      "step": 2493
    },
    {
      "epoch": 1.5024096385542167,
      "grad_norm": 0.5156662464141846,
      "learning_rate": 3.1219879518072295e-06,
      "loss": 0.2417,
      "step": 2494
    },
    {
      "epoch": 1.5030120481927711,
      "grad_norm": 0.5580551028251648,
      "learning_rate": 3.1212349397590365e-06,
      "loss": 0.2377,
      "step": 2495
    },
    {
      "epoch": 1.5036144578313253,
      "grad_norm": 0.5990864038467407,
      "learning_rate": 3.120481927710844e-06,
      "loss": 0.2467,
      "step": 2496
    },
    {
      "epoch": 1.5042168674698795,
      "grad_norm": 0.577620804309845,
      "learning_rate": 3.1197289156626507e-06,
      "loss": 0.2115,
      "step": 2497
    },
    {
      "epoch": 1.5048192771084339,
      "grad_norm": 0.5261167883872986,
      "learning_rate": 3.118975903614458e-06,
      "loss": 0.2826,
      "step": 2498
    },
    {
      "epoch": 1.5054216867469878,
      "grad_norm": 0.572068989276886,
      "learning_rate": 3.1182228915662654e-06,
      "loss": 0.2523,
      "step": 2499
    },
    {
      "epoch": 1.5060240963855422,
      "grad_norm": 0.5107630491256714,
      "learning_rate": 3.1174698795180724e-06,
      "loss": 0.215,
      "step": 2500
    },
    {
      "epoch": 1.5066265060240964,
      "grad_norm": 0.5066666007041931,
      "learning_rate": 3.11671686746988e-06,
      "loss": 0.2348,
      "step": 2501
    },
    {
      "epoch": 1.5072289156626506,
      "grad_norm": 0.5677217841148376,
      "learning_rate": 3.115963855421687e-06,
      "loss": 0.2268,
      "step": 2502
    },
    {
      "epoch": 1.5078313253012048,
      "grad_norm": 0.5786640048027039,
      "learning_rate": 3.115210843373494e-06,
      "loss": 0.2156,
      "step": 2503
    },
    {
      "epoch": 1.508433734939759,
      "grad_norm": 0.4951143264770508,
      "learning_rate": 3.1144578313253018e-06,
      "loss": 0.2228,
      "step": 2504
    },
    {
      "epoch": 1.5090361445783134,
      "grad_norm": 0.5324504375457764,
      "learning_rate": 3.1137048192771087e-06,
      "loss": 0.2522,
      "step": 2505
    },
    {
      "epoch": 1.5096385542168673,
      "grad_norm": 0.5235363841056824,
      "learning_rate": 3.112951807228916e-06,
      "loss": 0.2314,
      "step": 2506
    },
    {
      "epoch": 1.5102409638554217,
      "grad_norm": 0.5059245824813843,
      "learning_rate": 3.112198795180723e-06,
      "loss": 0.2495,
      "step": 2507
    },
    {
      "epoch": 1.510843373493976,
      "grad_norm": 0.658089280128479,
      "learning_rate": 3.1114457831325307e-06,
      "loss": 0.2866,
      "step": 2508
    },
    {
      "epoch": 1.51144578313253,
      "grad_norm": 0.65912926197052,
      "learning_rate": 3.1106927710843377e-06,
      "loss": 0.2747,
      "step": 2509
    },
    {
      "epoch": 1.5120481927710845,
      "grad_norm": 0.6051180362701416,
      "learning_rate": 3.1099397590361446e-06,
      "loss": 0.2472,
      "step": 2510
    },
    {
      "epoch": 1.5126506024096384,
      "grad_norm": 0.5861499905586243,
      "learning_rate": 3.1091867469879523e-06,
      "loss": 0.2415,
      "step": 2511
    },
    {
      "epoch": 1.5132530120481928,
      "grad_norm": 0.4869890809059143,
      "learning_rate": 3.1084337349397593e-06,
      "loss": 0.2316,
      "step": 2512
    },
    {
      "epoch": 1.513855421686747,
      "grad_norm": 0.617426335811615,
      "learning_rate": 3.1076807228915666e-06,
      "loss": 0.2327,
      "step": 2513
    },
    {
      "epoch": 1.5144578313253012,
      "grad_norm": 0.558455228805542,
      "learning_rate": 3.1069277108433735e-06,
      "loss": 0.2675,
      "step": 2514
    },
    {
      "epoch": 1.5150602409638554,
      "grad_norm": 0.5333744883537292,
      "learning_rate": 3.106174698795181e-06,
      "loss": 0.2348,
      "step": 2515
    },
    {
      "epoch": 1.5156626506024096,
      "grad_norm": 0.5591518878936768,
      "learning_rate": 3.1054216867469882e-06,
      "loss": 0.2523,
      "step": 2516
    },
    {
      "epoch": 1.516265060240964,
      "grad_norm": 0.6895400285720825,
      "learning_rate": 3.104668674698795e-06,
      "loss": 0.2151,
      "step": 2517
    },
    {
      "epoch": 1.516867469879518,
      "grad_norm": 0.6291475892066956,
      "learning_rate": 3.103915662650603e-06,
      "loss": 0.2681,
      "step": 2518
    },
    {
      "epoch": 1.5174698795180723,
      "grad_norm": 0.5827904343605042,
      "learning_rate": 3.10316265060241e-06,
      "loss": 0.2812,
      "step": 2519
    },
    {
      "epoch": 1.5180722891566265,
      "grad_norm": 0.5631107091903687,
      "learning_rate": 3.1024096385542172e-06,
      "loss": 0.2249,
      "step": 2520
    },
    {
      "epoch": 1.5186746987951807,
      "grad_norm": 0.5182760953903198,
      "learning_rate": 3.1016566265060246e-06,
      "loss": 0.2116,
      "step": 2521
    },
    {
      "epoch": 1.519277108433735,
      "grad_norm": 0.5642891526222229,
      "learning_rate": 3.1009036144578315e-06,
      "loss": 0.2241,
      "step": 2522
    },
    {
      "epoch": 1.519879518072289,
      "grad_norm": 0.5026355981826782,
      "learning_rate": 3.100150602409639e-06,
      "loss": 0.219,
      "step": 2523
    },
    {
      "epoch": 1.5204819277108435,
      "grad_norm": 0.5466691851615906,
      "learning_rate": 3.0993975903614458e-06,
      "loss": 0.2596,
      "step": 2524
    },
    {
      "epoch": 1.5210843373493976,
      "grad_norm": 0.5880428552627563,
      "learning_rate": 3.0986445783132535e-06,
      "loss": 0.2174,
      "step": 2525
    },
    {
      "epoch": 1.5216867469879518,
      "grad_norm": 0.5525841116905212,
      "learning_rate": 3.0978915662650605e-06,
      "loss": 0.2322,
      "step": 2526
    },
    {
      "epoch": 1.522289156626506,
      "grad_norm": 0.5649967193603516,
      "learning_rate": 3.0971385542168674e-06,
      "loss": 0.3049,
      "step": 2527
    },
    {
      "epoch": 1.5228915662650602,
      "grad_norm": 0.5468086004257202,
      "learning_rate": 3.096385542168675e-06,
      "loss": 0.2628,
      "step": 2528
    },
    {
      "epoch": 1.5234939759036146,
      "grad_norm": 0.655627429485321,
      "learning_rate": 3.095632530120482e-06,
      "loss": 0.3134,
      "step": 2529
    },
    {
      "epoch": 1.5240963855421685,
      "grad_norm": 0.5016013979911804,
      "learning_rate": 3.0948795180722894e-06,
      "loss": 0.188,
      "step": 2530
    },
    {
      "epoch": 1.524698795180723,
      "grad_norm": 0.5937414169311523,
      "learning_rate": 3.0941265060240968e-06,
      "loss": 0.2513,
      "step": 2531
    },
    {
      "epoch": 1.5253012048192771,
      "grad_norm": 0.5643494129180908,
      "learning_rate": 3.093373493975904e-06,
      "loss": 0.2723,
      "step": 2532
    },
    {
      "epoch": 1.5259036144578313,
      "grad_norm": 0.5446150302886963,
      "learning_rate": 3.092620481927711e-06,
      "loss": 0.25,
      "step": 2533
    },
    {
      "epoch": 1.5265060240963857,
      "grad_norm": 0.550642192363739,
      "learning_rate": 3.091867469879518e-06,
      "loss": 0.2379,
      "step": 2534
    },
    {
      "epoch": 1.5271084337349397,
      "grad_norm": 0.6046343445777893,
      "learning_rate": 3.0911144578313257e-06,
      "loss": 0.2947,
      "step": 2535
    },
    {
      "epoch": 1.527710843373494,
      "grad_norm": 0.563088595867157,
      "learning_rate": 3.0903614457831327e-06,
      "loss": 0.2787,
      "step": 2536
    },
    {
      "epoch": 1.5283132530120482,
      "grad_norm": 0.48780766129493713,
      "learning_rate": 3.0896084337349404e-06,
      "loss": 0.1911,
      "step": 2537
    },
    {
      "epoch": 1.5289156626506024,
      "grad_norm": 0.4915483593940735,
      "learning_rate": 3.0888554216867474e-06,
      "loss": 0.2252,
      "step": 2538
    },
    {
      "epoch": 1.5295180722891566,
      "grad_norm": 0.5980543494224548,
      "learning_rate": 3.0881024096385543e-06,
      "loss": 0.2657,
      "step": 2539
    },
    {
      "epoch": 1.5301204819277108,
      "grad_norm": 0.5138888955116272,
      "learning_rate": 3.0873493975903616e-06,
      "loss": 0.2397,
      "step": 2540
    },
    {
      "epoch": 1.5307228915662652,
      "grad_norm": 0.625053346157074,
      "learning_rate": 3.086596385542169e-06,
      "loss": 0.2799,
      "step": 2541
    },
    {
      "epoch": 1.5313253012048191,
      "grad_norm": 0.6088456511497498,
      "learning_rate": 3.0858433734939763e-06,
      "loss": 0.2377,
      "step": 2542
    },
    {
      "epoch": 1.5319277108433735,
      "grad_norm": 0.68287593126297,
      "learning_rate": 3.0850903614457833e-06,
      "loss": 0.2968,
      "step": 2543
    },
    {
      "epoch": 1.5325301204819277,
      "grad_norm": 0.6071880459785461,
      "learning_rate": 3.084337349397591e-06,
      "loss": 0.2878,
      "step": 2544
    },
    {
      "epoch": 1.533132530120482,
      "grad_norm": 0.5991312265396118,
      "learning_rate": 3.083584337349398e-06,
      "loss": 0.2174,
      "step": 2545
    },
    {
      "epoch": 1.5337349397590363,
      "grad_norm": 0.497709721326828,
      "learning_rate": 3.082831325301205e-06,
      "loss": 0.2541,
      "step": 2546
    },
    {
      "epoch": 1.5343373493975903,
      "grad_norm": 0.565122663974762,
      "learning_rate": 3.0820783132530122e-06,
      "loss": 0.198,
      "step": 2547
    },
    {
      "epoch": 1.5349397590361447,
      "grad_norm": 0.5782677531242371,
      "learning_rate": 3.0813253012048196e-06,
      "loss": 0.2637,
      "step": 2548
    },
    {
      "epoch": 1.5355421686746988,
      "grad_norm": 0.541778028011322,
      "learning_rate": 3.080572289156627e-06,
      "loss": 0.2442,
      "step": 2549
    },
    {
      "epoch": 1.536144578313253,
      "grad_norm": 0.5387038588523865,
      "learning_rate": 3.079819277108434e-06,
      "loss": 0.2373,
      "step": 2550
    },
    {
      "epoch": 1.5367469879518072,
      "grad_norm": 0.5987521409988403,
      "learning_rate": 3.0790662650602408e-06,
      "loss": 0.278,
      "step": 2551
    },
    {
      "epoch": 1.5373493975903614,
      "grad_norm": 0.5501717329025269,
      "learning_rate": 3.0783132530120485e-06,
      "loss": 0.2114,
      "step": 2552
    },
    {
      "epoch": 1.5379518072289158,
      "grad_norm": 0.5688167810440063,
      "learning_rate": 3.0775602409638555e-06,
      "loss": 0.2673,
      "step": 2553
    },
    {
      "epoch": 1.5385542168674697,
      "grad_norm": 0.526825487613678,
      "learning_rate": 3.0768072289156632e-06,
      "loss": 0.2586,
      "step": 2554
    },
    {
      "epoch": 1.5391566265060241,
      "grad_norm": 0.6079076528549194,
      "learning_rate": 3.07605421686747e-06,
      "loss": 0.2749,
      "step": 2555
    },
    {
      "epoch": 1.5397590361445783,
      "grad_norm": 0.4977433979511261,
      "learning_rate": 3.0753012048192775e-06,
      "loss": 0.2445,
      "step": 2556
    },
    {
      "epoch": 1.5403614457831325,
      "grad_norm": 0.5074222087860107,
      "learning_rate": 3.0745481927710844e-06,
      "loss": 0.2276,
      "step": 2557
    },
    {
      "epoch": 1.540963855421687,
      "grad_norm": 0.5665612816810608,
      "learning_rate": 3.073795180722892e-06,
      "loss": 0.2398,
      "step": 2558
    },
    {
      "epoch": 1.5415662650602409,
      "grad_norm": 0.5162533521652222,
      "learning_rate": 3.073042168674699e-06,
      "loss": 0.267,
      "step": 2559
    },
    {
      "epoch": 1.5421686746987953,
      "grad_norm": 0.5334479808807373,
      "learning_rate": 3.072289156626506e-06,
      "loss": 0.2834,
      "step": 2560
    },
    {
      "epoch": 1.5427710843373494,
      "grad_norm": 0.5315413475036621,
      "learning_rate": 3.071536144578314e-06,
      "loss": 0.2666,
      "step": 2561
    },
    {
      "epoch": 1.5433734939759036,
      "grad_norm": 0.6240335702896118,
      "learning_rate": 3.0707831325301208e-06,
      "loss": 0.2314,
      "step": 2562
    },
    {
      "epoch": 1.5439759036144578,
      "grad_norm": 0.5816382765769958,
      "learning_rate": 3.0700301204819277e-06,
      "loss": 0.2506,
      "step": 2563
    },
    {
      "epoch": 1.544578313253012,
      "grad_norm": 0.5431756377220154,
      "learning_rate": 3.0692771084337355e-06,
      "loss": 0.278,
      "step": 2564
    },
    {
      "epoch": 1.5451807228915664,
      "grad_norm": 0.5842044353485107,
      "learning_rate": 3.0685240963855424e-06,
      "loss": 0.2683,
      "step": 2565
    },
    {
      "epoch": 1.5457831325301203,
      "grad_norm": 0.5269380807876587,
      "learning_rate": 3.0677710843373497e-06,
      "loss": 0.2824,
      "step": 2566
    },
    {
      "epoch": 1.5463855421686747,
      "grad_norm": 0.6339095830917358,
      "learning_rate": 3.0670180722891567e-06,
      "loss": 0.2746,
      "step": 2567
    },
    {
      "epoch": 1.546987951807229,
      "grad_norm": 0.5363377332687378,
      "learning_rate": 3.0662650602409644e-06,
      "loss": 0.2018,
      "step": 2568
    },
    {
      "epoch": 1.547590361445783,
      "grad_norm": 0.6392870545387268,
      "learning_rate": 3.0655120481927714e-06,
      "loss": 0.2882,
      "step": 2569
    },
    {
      "epoch": 1.5481927710843375,
      "grad_norm": 0.5575040578842163,
      "learning_rate": 3.0647590361445783e-06,
      "loss": 0.2281,
      "step": 2570
    },
    {
      "epoch": 1.5487951807228915,
      "grad_norm": 0.5430043339729309,
      "learning_rate": 3.064006024096386e-06,
      "loss": 0.2266,
      "step": 2571
    },
    {
      "epoch": 1.5493975903614459,
      "grad_norm": 0.5302825570106506,
      "learning_rate": 3.063253012048193e-06,
      "loss": 0.2534,
      "step": 2572
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.5116309523582458,
      "learning_rate": 3.0625000000000003e-06,
      "loss": 0.259,
      "step": 2573
    },
    {
      "epoch": 1.5506024096385542,
      "grad_norm": 0.5306240916252136,
      "learning_rate": 3.0617469879518077e-06,
      "loss": 0.2962,
      "step": 2574
    },
    {
      "epoch": 1.5512048192771084,
      "grad_norm": 0.6006422638893127,
      "learning_rate": 3.0609939759036146e-06,
      "loss": 0.2892,
      "step": 2575
    },
    {
      "epoch": 1.5518072289156626,
      "grad_norm": 0.5772674679756165,
      "learning_rate": 3.060240963855422e-06,
      "loss": 0.2406,
      "step": 2576
    },
    {
      "epoch": 1.552409638554217,
      "grad_norm": 0.7374581694602966,
      "learning_rate": 3.059487951807229e-06,
      "loss": 0.3602,
      "step": 2577
    },
    {
      "epoch": 1.553012048192771,
      "grad_norm": 0.5229020714759827,
      "learning_rate": 3.0587349397590366e-06,
      "loss": 0.235,
      "step": 2578
    },
    {
      "epoch": 1.5536144578313253,
      "grad_norm": 0.5887014865875244,
      "learning_rate": 3.0579819277108436e-06,
      "loss": 0.2368,
      "step": 2579
    },
    {
      "epoch": 1.5542168674698795,
      "grad_norm": 0.5527264475822449,
      "learning_rate": 3.057228915662651e-06,
      "loss": 0.2539,
      "step": 2580
    },
    {
      "epoch": 1.5548192771084337,
      "grad_norm": 0.573772668838501,
      "learning_rate": 3.0564759036144583e-06,
      "loss": 0.2636,
      "step": 2581
    },
    {
      "epoch": 1.555421686746988,
      "grad_norm": 0.5590604543685913,
      "learning_rate": 3.055722891566265e-06,
      "loss": 0.2767,
      "step": 2582
    },
    {
      "epoch": 1.556024096385542,
      "grad_norm": 0.9206777811050415,
      "learning_rate": 3.0549698795180725e-06,
      "loss": 0.2293,
      "step": 2583
    },
    {
      "epoch": 1.5566265060240965,
      "grad_norm": 0.5552124977111816,
      "learning_rate": 3.0542168674698795e-06,
      "loss": 0.2315,
      "step": 2584
    },
    {
      "epoch": 1.5572289156626506,
      "grad_norm": 0.5786864161491394,
      "learning_rate": 3.0534638554216872e-06,
      "loss": 0.253,
      "step": 2585
    },
    {
      "epoch": 1.5578313253012048,
      "grad_norm": 0.5226536393165588,
      "learning_rate": 3.052710843373494e-06,
      "loss": 0.2106,
      "step": 2586
    },
    {
      "epoch": 1.558433734939759,
      "grad_norm": 0.560633659362793,
      "learning_rate": 3.051957831325301e-06,
      "loss": 0.2131,
      "step": 2587
    },
    {
      "epoch": 1.5590361445783132,
      "grad_norm": 0.5263730883598328,
      "learning_rate": 3.051204819277109e-06,
      "loss": 0.2404,
      "step": 2588
    },
    {
      "epoch": 1.5596385542168676,
      "grad_norm": 0.4611617922782898,
      "learning_rate": 3.0504518072289158e-06,
      "loss": 0.2137,
      "step": 2589
    },
    {
      "epoch": 1.5602409638554215,
      "grad_norm": 0.5070927739143372,
      "learning_rate": 3.049698795180723e-06,
      "loss": 0.2121,
      "step": 2590
    },
    {
      "epoch": 1.560843373493976,
      "grad_norm": 0.5442496538162231,
      "learning_rate": 3.0489457831325305e-06,
      "loss": 0.1967,
      "step": 2591
    },
    {
      "epoch": 1.5614457831325301,
      "grad_norm": 0.5631046295166016,
      "learning_rate": 3.048192771084338e-06,
      "loss": 0.2389,
      "step": 2592
    },
    {
      "epoch": 1.5620481927710843,
      "grad_norm": 0.5532267689704895,
      "learning_rate": 3.0474397590361448e-06,
      "loss": 0.248,
      "step": 2593
    },
    {
      "epoch": 1.5626506024096387,
      "grad_norm": 0.574636697769165,
      "learning_rate": 3.0466867469879517e-06,
      "loss": 0.2097,
      "step": 2594
    },
    {
      "epoch": 1.5632530120481927,
      "grad_norm": 0.5459479689598083,
      "learning_rate": 3.0459337349397594e-06,
      "loss": 0.2186,
      "step": 2595
    },
    {
      "epoch": 1.563855421686747,
      "grad_norm": 0.5476576089859009,
      "learning_rate": 3.0451807228915664e-06,
      "loss": 0.1914,
      "step": 2596
    },
    {
      "epoch": 1.5644578313253013,
      "grad_norm": 0.5349079370498657,
      "learning_rate": 3.044427710843374e-06,
      "loss": 0.201,
      "step": 2597
    },
    {
      "epoch": 1.5650602409638554,
      "grad_norm": 2.050621271133423,
      "learning_rate": 3.043674698795181e-06,
      "loss": 0.224,
      "step": 2598
    },
    {
      "epoch": 1.5656626506024096,
      "grad_norm": 0.5535681843757629,
      "learning_rate": 3.042921686746988e-06,
      "loss": 0.2151,
      "step": 2599
    },
    {
      "epoch": 1.5662650602409638,
      "grad_norm": 0.5902515053749084,
      "learning_rate": 3.0421686746987953e-06,
      "loss": 0.2804,
      "step": 2600
    },
    {
      "epoch": 1.5668674698795182,
      "grad_norm": 0.4837913513183594,
      "learning_rate": 3.0414156626506027e-06,
      "loss": 0.2638,
      "step": 2601
    },
    {
      "epoch": 1.5674698795180722,
      "grad_norm": 0.6979572772979736,
      "learning_rate": 3.04066265060241e-06,
      "loss": 0.2355,
      "step": 2602
    },
    {
      "epoch": 1.5680722891566266,
      "grad_norm": 0.5868033170700073,
      "learning_rate": 3.039909638554217e-06,
      "loss": 0.2548,
      "step": 2603
    },
    {
      "epoch": 1.5686746987951807,
      "grad_norm": 0.5370408296585083,
      "learning_rate": 3.0391566265060247e-06,
      "loss": 0.2358,
      "step": 2604
    },
    {
      "epoch": 1.569277108433735,
      "grad_norm": 0.5092900395393372,
      "learning_rate": 3.0384036144578317e-06,
      "loss": 0.2189,
      "step": 2605
    },
    {
      "epoch": 1.5698795180722893,
      "grad_norm": 0.5667831301689148,
      "learning_rate": 3.0376506024096386e-06,
      "loss": 0.2779,
      "step": 2606
    },
    {
      "epoch": 1.5704819277108433,
      "grad_norm": 0.5831313729286194,
      "learning_rate": 3.0368975903614464e-06,
      "loss": 0.2801,
      "step": 2607
    },
    {
      "epoch": 1.5710843373493977,
      "grad_norm": 0.5284463167190552,
      "learning_rate": 3.0361445783132533e-06,
      "loss": 0.2035,
      "step": 2608
    },
    {
      "epoch": 1.5716867469879519,
      "grad_norm": 0.6179309487342834,
      "learning_rate": 3.0353915662650606e-06,
      "loss": 0.2962,
      "step": 2609
    },
    {
      "epoch": 1.572289156626506,
      "grad_norm": 0.5790106654167175,
      "learning_rate": 3.0346385542168676e-06,
      "loss": 0.2295,
      "step": 2610
    },
    {
      "epoch": 1.5728915662650602,
      "grad_norm": 0.5257449746131897,
      "learning_rate": 3.033885542168675e-06,
      "loss": 0.2348,
      "step": 2611
    },
    {
      "epoch": 1.5734939759036144,
      "grad_norm": 0.4969647526741028,
      "learning_rate": 3.0331325301204823e-06,
      "loss": 0.2107,
      "step": 2612
    },
    {
      "epoch": 1.5740963855421688,
      "grad_norm": 0.5044500827789307,
      "learning_rate": 3.032379518072289e-06,
      "loss": 0.2133,
      "step": 2613
    },
    {
      "epoch": 1.5746987951807228,
      "grad_norm": 0.5426118969917297,
      "learning_rate": 3.031626506024097e-06,
      "loss": 0.2457,
      "step": 2614
    },
    {
      "epoch": 1.5753012048192772,
      "grad_norm": 0.5308597683906555,
      "learning_rate": 3.030873493975904e-06,
      "loss": 0.2354,
      "step": 2615
    },
    {
      "epoch": 1.5759036144578313,
      "grad_norm": 0.5562046766281128,
      "learning_rate": 3.0301204819277112e-06,
      "loss": 0.2013,
      "step": 2616
    },
    {
      "epoch": 1.5765060240963855,
      "grad_norm": 0.5506836175918579,
      "learning_rate": 3.029367469879518e-06,
      "loss": 0.2016,
      "step": 2617
    },
    {
      "epoch": 1.57710843373494,
      "grad_norm": 0.5399800539016724,
      "learning_rate": 3.0286144578313255e-06,
      "loss": 0.2527,
      "step": 2618
    },
    {
      "epoch": 1.5777108433734939,
      "grad_norm": 0.4923170804977417,
      "learning_rate": 3.027861445783133e-06,
      "loss": 0.2105,
      "step": 2619
    },
    {
      "epoch": 1.5783132530120483,
      "grad_norm": 0.6084428429603577,
      "learning_rate": 3.0271084337349398e-06,
      "loss": 0.2628,
      "step": 2620
    },
    {
      "epoch": 1.5789156626506025,
      "grad_norm": 0.6798736453056335,
      "learning_rate": 3.0263554216867475e-06,
      "loss": 0.2406,
      "step": 2621
    },
    {
      "epoch": 1.5795180722891566,
      "grad_norm": 0.6019076704978943,
      "learning_rate": 3.0256024096385545e-06,
      "loss": 0.255,
      "step": 2622
    },
    {
      "epoch": 1.5801204819277108,
      "grad_norm": 0.58636873960495,
      "learning_rate": 3.0248493975903614e-06,
      "loss": 0.2147,
      "step": 2623
    },
    {
      "epoch": 1.580722891566265,
      "grad_norm": 0.5965721607208252,
      "learning_rate": 3.024096385542169e-06,
      "loss": 0.2284,
      "step": 2624
    },
    {
      "epoch": 1.5813253012048194,
      "grad_norm": 0.5277860164642334,
      "learning_rate": 3.023343373493976e-06,
      "loss": 0.2289,
      "step": 2625
    },
    {
      "epoch": 1.5819277108433734,
      "grad_norm": 0.6279382109642029,
      "learning_rate": 3.0225903614457834e-06,
      "loss": 0.2353,
      "step": 2626
    },
    {
      "epoch": 1.5825301204819278,
      "grad_norm": 0.5300484299659729,
      "learning_rate": 3.0218373493975904e-06,
      "loss": 0.239,
      "step": 2627
    },
    {
      "epoch": 1.583132530120482,
      "grad_norm": 0.5886445045471191,
      "learning_rate": 3.021084337349398e-06,
      "loss": 0.2205,
      "step": 2628
    },
    {
      "epoch": 1.5837349397590361,
      "grad_norm": 0.5964300632476807,
      "learning_rate": 3.020331325301205e-06,
      "loss": 0.2754,
      "step": 2629
    },
    {
      "epoch": 1.5843373493975905,
      "grad_norm": 0.48493316769599915,
      "learning_rate": 3.019578313253012e-06,
      "loss": 0.2412,
      "step": 2630
    },
    {
      "epoch": 1.5849397590361445,
      "grad_norm": 0.48469698429107666,
      "learning_rate": 3.0188253012048198e-06,
      "loss": 0.2573,
      "step": 2631
    },
    {
      "epoch": 1.5855421686746989,
      "grad_norm": 0.5487112402915955,
      "learning_rate": 3.0180722891566267e-06,
      "loss": 0.2749,
      "step": 2632
    },
    {
      "epoch": 1.586144578313253,
      "grad_norm": 0.6186749339103699,
      "learning_rate": 3.017319277108434e-06,
      "loss": 0.2177,
      "step": 2633
    },
    {
      "epoch": 1.5867469879518072,
      "grad_norm": 0.5897281765937805,
      "learning_rate": 3.0165662650602414e-06,
      "loss": 0.2539,
      "step": 2634
    },
    {
      "epoch": 1.5873493975903614,
      "grad_norm": 0.5874027013778687,
      "learning_rate": 3.0158132530120483e-06,
      "loss": 0.2584,
      "step": 2635
    },
    {
      "epoch": 1.5879518072289156,
      "grad_norm": 0.7558828592300415,
      "learning_rate": 3.0150602409638556e-06,
      "loss": 0.2847,
      "step": 2636
    },
    {
      "epoch": 1.58855421686747,
      "grad_norm": 0.4947279393672943,
      "learning_rate": 3.0143072289156626e-06,
      "loss": 0.2301,
      "step": 2637
    },
    {
      "epoch": 1.589156626506024,
      "grad_norm": 0.5697571635246277,
      "learning_rate": 3.0135542168674703e-06,
      "loss": 0.2383,
      "step": 2638
    },
    {
      "epoch": 1.5897590361445784,
      "grad_norm": 0.5396745204925537,
      "learning_rate": 3.0128012048192773e-06,
      "loss": 0.209,
      "step": 2639
    },
    {
      "epoch": 1.5903614457831325,
      "grad_norm": 0.5818625092506409,
      "learning_rate": 3.012048192771085e-06,
      "loss": 0.2579,
      "step": 2640
    },
    {
      "epoch": 1.5909638554216867,
      "grad_norm": 0.7252237796783447,
      "learning_rate": 3.011295180722892e-06,
      "loss": 0.2627,
      "step": 2641
    },
    {
      "epoch": 1.5915662650602411,
      "grad_norm": 0.5458794832229614,
      "learning_rate": 3.010542168674699e-06,
      "loss": 0.2444,
      "step": 2642
    },
    {
      "epoch": 1.592168674698795,
      "grad_norm": 0.7021608352661133,
      "learning_rate": 3.0097891566265062e-06,
      "loss": 0.209,
      "step": 2643
    },
    {
      "epoch": 1.5927710843373495,
      "grad_norm": 0.5410102605819702,
      "learning_rate": 3.0090361445783136e-06,
      "loss": 0.2491,
      "step": 2644
    },
    {
      "epoch": 1.5933734939759037,
      "grad_norm": 0.5365752577781677,
      "learning_rate": 3.008283132530121e-06,
      "loss": 0.2444,
      "step": 2645
    },
    {
      "epoch": 1.5939759036144578,
      "grad_norm": 0.5658975839614868,
      "learning_rate": 3.007530120481928e-06,
      "loss": 0.2563,
      "step": 2646
    },
    {
      "epoch": 1.594578313253012,
      "grad_norm": 0.5152380466461182,
      "learning_rate": 3.0067771084337348e-06,
      "loss": 0.2407,
      "step": 2647
    },
    {
      "epoch": 1.5951807228915662,
      "grad_norm": 0.5948957204818726,
      "learning_rate": 3.0060240963855426e-06,
      "loss": 0.2421,
      "step": 2648
    },
    {
      "epoch": 1.5957831325301206,
      "grad_norm": 0.553339421749115,
      "learning_rate": 3.0052710843373495e-06,
      "loss": 0.2547,
      "step": 2649
    },
    {
      "epoch": 1.5963855421686746,
      "grad_norm": 0.45653417706489563,
      "learning_rate": 3.004518072289157e-06,
      "loss": 0.2325,
      "step": 2650
    },
    {
      "epoch": 1.596987951807229,
      "grad_norm": 0.5563080906867981,
      "learning_rate": 3.003765060240964e-06,
      "loss": 0.2477,
      "step": 2651
    },
    {
      "epoch": 1.5975903614457831,
      "grad_norm": 0.5552076697349548,
      "learning_rate": 3.0030120481927715e-06,
      "loss": 0.2234,
      "step": 2652
    },
    {
      "epoch": 1.5981927710843373,
      "grad_norm": 0.6639105081558228,
      "learning_rate": 3.0022590361445785e-06,
      "loss": 0.291,
      "step": 2653
    },
    {
      "epoch": 1.5987951807228917,
      "grad_norm": 0.5342197418212891,
      "learning_rate": 3.0015060240963854e-06,
      "loss": 0.2455,
      "step": 2654
    },
    {
      "epoch": 1.5993975903614457,
      "grad_norm": 0.5392404794692993,
      "learning_rate": 3.000753012048193e-06,
      "loss": 0.2306,
      "step": 2655
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5720417499542236,
      "learning_rate": 3e-06,
      "loss": 0.2222,
      "step": 2656
    },
    {
      "epoch": 1.6006024096385543,
      "grad_norm": 0.5038575530052185,
      "learning_rate": 2.999246987951808e-06,
      "loss": 0.2659,
      "step": 2657
    },
    {
      "epoch": 1.6012048192771084,
      "grad_norm": 0.5252010226249695,
      "learning_rate": 2.9984939759036148e-06,
      "loss": 0.2548,
      "step": 2658
    },
    {
      "epoch": 1.6018072289156626,
      "grad_norm": 0.6509184837341309,
      "learning_rate": 2.9977409638554217e-06,
      "loss": 0.2461,
      "step": 2659
    },
    {
      "epoch": 1.6024096385542168,
      "grad_norm": 0.4734135866165161,
      "learning_rate": 2.996987951807229e-06,
      "loss": 0.2057,
      "step": 2660
    },
    {
      "epoch": 1.6030120481927712,
      "grad_norm": 0.5329214334487915,
      "learning_rate": 2.9962349397590364e-06,
      "loss": 0.2377,
      "step": 2661
    },
    {
      "epoch": 1.6036144578313252,
      "grad_norm": 0.6361532211303711,
      "learning_rate": 2.9954819277108437e-06,
      "loss": 0.2873,
      "step": 2662
    },
    {
      "epoch": 1.6042168674698796,
      "grad_norm": 0.626910924911499,
      "learning_rate": 2.9947289156626507e-06,
      "loss": 0.2805,
      "step": 2663
    },
    {
      "epoch": 1.6048192771084338,
      "grad_norm": 0.5638440847396851,
      "learning_rate": 2.9939759036144584e-06,
      "loss": 0.2056,
      "step": 2664
    },
    {
      "epoch": 1.605421686746988,
      "grad_norm": 0.5779736042022705,
      "learning_rate": 2.9932228915662654e-06,
      "loss": 0.2318,
      "step": 2665
    },
    {
      "epoch": 1.6060240963855423,
      "grad_norm": 0.5617344379425049,
      "learning_rate": 2.9924698795180723e-06,
      "loss": 0.2192,
      "step": 2666
    },
    {
      "epoch": 1.6066265060240963,
      "grad_norm": 0.5290015339851379,
      "learning_rate": 2.99171686746988e-06,
      "loss": 0.283,
      "step": 2667
    },
    {
      "epoch": 1.6072289156626507,
      "grad_norm": 0.6760057806968689,
      "learning_rate": 2.990963855421687e-06,
      "loss": 0.2686,
      "step": 2668
    },
    {
      "epoch": 1.6078313253012049,
      "grad_norm": 0.5633249878883362,
      "learning_rate": 2.9902108433734943e-06,
      "loss": 0.266,
      "step": 2669
    },
    {
      "epoch": 1.608433734939759,
      "grad_norm": 0.6516712307929993,
      "learning_rate": 2.9894578313253013e-06,
      "loss": 0.2297,
      "step": 2670
    },
    {
      "epoch": 1.6090361445783132,
      "grad_norm": 0.47244203090667725,
      "learning_rate": 2.9887048192771086e-06,
      "loss": 0.2168,
      "step": 2671
    },
    {
      "epoch": 1.6096385542168674,
      "grad_norm": 0.5099690556526184,
      "learning_rate": 2.987951807228916e-06,
      "loss": 0.2301,
      "step": 2672
    },
    {
      "epoch": 1.6102409638554218,
      "grad_norm": 0.6186298727989197,
      "learning_rate": 2.987198795180723e-06,
      "loss": 0.2872,
      "step": 2673
    },
    {
      "epoch": 1.6108433734939758,
      "grad_norm": 0.4511312246322632,
      "learning_rate": 2.9864457831325307e-06,
      "loss": 0.172,
      "step": 2674
    },
    {
      "epoch": 1.6114457831325302,
      "grad_norm": 0.5469964146614075,
      "learning_rate": 2.9856927710843376e-06,
      "loss": 0.2036,
      "step": 2675
    },
    {
      "epoch": 1.6120481927710844,
      "grad_norm": 0.4901087284088135,
      "learning_rate": 2.984939759036145e-06,
      "loss": 0.2324,
      "step": 2676
    },
    {
      "epoch": 1.6126506024096385,
      "grad_norm": 0.5749203562736511,
      "learning_rate": 2.9841867469879523e-06,
      "loss": 0.2526,
      "step": 2677
    },
    {
      "epoch": 1.613253012048193,
      "grad_norm": 0.7270306944847107,
      "learning_rate": 2.983433734939759e-06,
      "loss": 0.2506,
      "step": 2678
    },
    {
      "epoch": 1.613855421686747,
      "grad_norm": 0.4710494577884674,
      "learning_rate": 2.9826807228915665e-06,
      "loss": 0.232,
      "step": 2679
    },
    {
      "epoch": 1.6144578313253013,
      "grad_norm": 0.46426963806152344,
      "learning_rate": 2.9819277108433735e-06,
      "loss": 0.2139,
      "step": 2680
    },
    {
      "epoch": 1.6150602409638555,
      "grad_norm": 0.5763738751411438,
      "learning_rate": 2.9811746987951812e-06,
      "loss": 0.2591,
      "step": 2681
    },
    {
      "epoch": 1.6156626506024097,
      "grad_norm": 0.503856360912323,
      "learning_rate": 2.980421686746988e-06,
      "loss": 0.1914,
      "step": 2682
    },
    {
      "epoch": 1.6162650602409638,
      "grad_norm": 0.5450673699378967,
      "learning_rate": 2.979668674698795e-06,
      "loss": 0.292,
      "step": 2683
    },
    {
      "epoch": 1.616867469879518,
      "grad_norm": 0.4872444272041321,
      "learning_rate": 2.978915662650603e-06,
      "loss": 0.1932,
      "step": 2684
    },
    {
      "epoch": 1.6174698795180724,
      "grad_norm": 0.4875189960002899,
      "learning_rate": 2.97816265060241e-06,
      "loss": 0.2571,
      "step": 2685
    },
    {
      "epoch": 1.6180722891566264,
      "grad_norm": 0.6058480143547058,
      "learning_rate": 2.977409638554217e-06,
      "loss": 0.2273,
      "step": 2686
    },
    {
      "epoch": 1.6186746987951808,
      "grad_norm": 0.5360676050186157,
      "learning_rate": 2.976656626506024e-06,
      "loss": 0.2973,
      "step": 2687
    },
    {
      "epoch": 1.619277108433735,
      "grad_norm": 0.5617274045944214,
      "learning_rate": 2.975903614457832e-06,
      "loss": 0.2662,
      "step": 2688
    },
    {
      "epoch": 1.6198795180722891,
      "grad_norm": 0.5999377369880676,
      "learning_rate": 2.9751506024096388e-06,
      "loss": 0.27,
      "step": 2689
    },
    {
      "epoch": 1.6204819277108435,
      "grad_norm": 0.5257488489151001,
      "learning_rate": 2.9743975903614457e-06,
      "loss": 0.236,
      "step": 2690
    },
    {
      "epoch": 1.6210843373493975,
      "grad_norm": 0.561362087726593,
      "learning_rate": 2.9736445783132535e-06,
      "loss": 0.1881,
      "step": 2691
    },
    {
      "epoch": 1.621686746987952,
      "grad_norm": 0.5385614633560181,
      "learning_rate": 2.9728915662650604e-06,
      "loss": 0.1988,
      "step": 2692
    },
    {
      "epoch": 1.622289156626506,
      "grad_norm": 0.5481355786323547,
      "learning_rate": 2.9721385542168677e-06,
      "loss": 0.2451,
      "step": 2693
    },
    {
      "epoch": 1.6228915662650603,
      "grad_norm": 0.5745681524276733,
      "learning_rate": 2.971385542168675e-06,
      "loss": 0.2428,
      "step": 2694
    },
    {
      "epoch": 1.6234939759036144,
      "grad_norm": 0.5268573760986328,
      "learning_rate": 2.970632530120482e-06,
      "loss": 0.2792,
      "step": 2695
    },
    {
      "epoch": 1.6240963855421686,
      "grad_norm": 0.650983452796936,
      "learning_rate": 2.9698795180722894e-06,
      "loss": 0.2166,
      "step": 2696
    },
    {
      "epoch": 1.624698795180723,
      "grad_norm": 0.5015254020690918,
      "learning_rate": 2.9691265060240963e-06,
      "loss": 0.2291,
      "step": 2697
    },
    {
      "epoch": 1.625301204819277,
      "grad_norm": 0.5943843126296997,
      "learning_rate": 2.968373493975904e-06,
      "loss": 0.2581,
      "step": 2698
    },
    {
      "epoch": 1.6259036144578314,
      "grad_norm": 0.5975523591041565,
      "learning_rate": 2.967620481927711e-06,
      "loss": 0.2346,
      "step": 2699
    },
    {
      "epoch": 1.6265060240963856,
      "grad_norm": 0.49458426237106323,
      "learning_rate": 2.9668674698795187e-06,
      "loss": 0.2144,
      "step": 2700
    },
    {
      "epoch": 1.6271084337349397,
      "grad_norm": 0.6637639403343201,
      "learning_rate": 2.9661144578313257e-06,
      "loss": 0.2923,
      "step": 2701
    },
    {
      "epoch": 1.627710843373494,
      "grad_norm": 0.4959884583950043,
      "learning_rate": 2.9653614457831326e-06,
      "loss": 0.2165,
      "step": 2702
    },
    {
      "epoch": 1.628313253012048,
      "grad_norm": 0.5798774361610413,
      "learning_rate": 2.96460843373494e-06,
      "loss": 0.2434,
      "step": 2703
    },
    {
      "epoch": 1.6289156626506025,
      "grad_norm": 0.5906445980072021,
      "learning_rate": 2.9638554216867473e-06,
      "loss": 0.2582,
      "step": 2704
    },
    {
      "epoch": 1.6295180722891565,
      "grad_norm": 0.6757745742797852,
      "learning_rate": 2.9631024096385546e-06,
      "loss": 0.2881,
      "step": 2705
    },
    {
      "epoch": 1.6301204819277109,
      "grad_norm": 0.5245389938354492,
      "learning_rate": 2.9623493975903616e-06,
      "loss": 0.2199,
      "step": 2706
    },
    {
      "epoch": 1.630722891566265,
      "grad_norm": 0.5831773281097412,
      "learning_rate": 2.9615963855421685e-06,
      "loss": 0.2351,
      "step": 2707
    },
    {
      "epoch": 1.6313253012048192,
      "grad_norm": 0.5510335564613342,
      "learning_rate": 2.9608433734939763e-06,
      "loss": 0.1829,
      "step": 2708
    },
    {
      "epoch": 1.6319277108433736,
      "grad_norm": 0.5393422842025757,
      "learning_rate": 2.960090361445783e-06,
      "loss": 0.237,
      "step": 2709
    },
    {
      "epoch": 1.6325301204819276,
      "grad_norm": 0.486166387796402,
      "learning_rate": 2.959337349397591e-06,
      "loss": 0.2028,
      "step": 2710
    },
    {
      "epoch": 1.633132530120482,
      "grad_norm": 0.519661009311676,
      "learning_rate": 2.958584337349398e-06,
      "loss": 0.2191,
      "step": 2711
    },
    {
      "epoch": 1.6337349397590362,
      "grad_norm": 0.49491065740585327,
      "learning_rate": 2.9578313253012052e-06,
      "loss": 0.1959,
      "step": 2712
    },
    {
      "epoch": 1.6343373493975903,
      "grad_norm": 0.4850024878978729,
      "learning_rate": 2.957078313253012e-06,
      "loss": 0.2048,
      "step": 2713
    },
    {
      "epoch": 1.6349397590361445,
      "grad_norm": 0.5161650776863098,
      "learning_rate": 2.9563253012048195e-06,
      "loss": 0.2272,
      "step": 2714
    },
    {
      "epoch": 1.6355421686746987,
      "grad_norm": 0.5111050009727478,
      "learning_rate": 2.955572289156627e-06,
      "loss": 0.216,
      "step": 2715
    },
    {
      "epoch": 1.636144578313253,
      "grad_norm": 0.5303648114204407,
      "learning_rate": 2.9548192771084338e-06,
      "loss": 0.2523,
      "step": 2716
    },
    {
      "epoch": 1.636746987951807,
      "grad_norm": 0.501465916633606,
      "learning_rate": 2.9540662650602416e-06,
      "loss": 0.2122,
      "step": 2717
    },
    {
      "epoch": 1.6373493975903615,
      "grad_norm": 0.5051769018173218,
      "learning_rate": 2.9533132530120485e-06,
      "loss": 0.2187,
      "step": 2718
    },
    {
      "epoch": 1.6379518072289156,
      "grad_norm": 0.539404571056366,
      "learning_rate": 2.9525602409638554e-06,
      "loss": 0.2351,
      "step": 2719
    },
    {
      "epoch": 1.6385542168674698,
      "grad_norm": 0.6367895603179932,
      "learning_rate": 2.9518072289156627e-06,
      "loss": 0.2109,
      "step": 2720
    },
    {
      "epoch": 1.6391566265060242,
      "grad_norm": 0.5668970346450806,
      "learning_rate": 2.95105421686747e-06,
      "loss": 0.2752,
      "step": 2721
    },
    {
      "epoch": 1.6397590361445782,
      "grad_norm": 0.5721153616905212,
      "learning_rate": 2.9503012048192774e-06,
      "loss": 0.2353,
      "step": 2722
    },
    {
      "epoch": 1.6403614457831326,
      "grad_norm": 0.4950086176395416,
      "learning_rate": 2.9495481927710844e-06,
      "loss": 0.2211,
      "step": 2723
    },
    {
      "epoch": 1.6409638554216868,
      "grad_norm": 0.4969854950904846,
      "learning_rate": 2.948795180722892e-06,
      "loss": 0.2584,
      "step": 2724
    },
    {
      "epoch": 1.641566265060241,
      "grad_norm": 0.5239477753639221,
      "learning_rate": 2.948042168674699e-06,
      "loss": 0.2181,
      "step": 2725
    },
    {
      "epoch": 1.6421686746987951,
      "grad_norm": 0.5381899476051331,
      "learning_rate": 2.947289156626506e-06,
      "loss": 0.2155,
      "step": 2726
    },
    {
      "epoch": 1.6427710843373493,
      "grad_norm": 0.5471500158309937,
      "learning_rate": 2.9465361445783138e-06,
      "loss": 0.224,
      "step": 2727
    },
    {
      "epoch": 1.6433734939759037,
      "grad_norm": 0.5048891305923462,
      "learning_rate": 2.9457831325301207e-06,
      "loss": 0.2519,
      "step": 2728
    },
    {
      "epoch": 1.6439759036144577,
      "grad_norm": 0.4997885525226593,
      "learning_rate": 2.945030120481928e-06,
      "loss": 0.2078,
      "step": 2729
    },
    {
      "epoch": 1.644578313253012,
      "grad_norm": 0.47455838322639465,
      "learning_rate": 2.944277108433735e-06,
      "loss": 0.2109,
      "step": 2730
    },
    {
      "epoch": 1.6451807228915662,
      "grad_norm": 0.5009235143661499,
      "learning_rate": 2.9435240963855423e-06,
      "loss": 0.1891,
      "step": 2731
    },
    {
      "epoch": 1.6457831325301204,
      "grad_norm": 0.5941985249519348,
      "learning_rate": 2.9427710843373497e-06,
      "loss": 0.255,
      "step": 2732
    },
    {
      "epoch": 1.6463855421686748,
      "grad_norm": 0.5567125678062439,
      "learning_rate": 2.9420180722891566e-06,
      "loss": 0.2535,
      "step": 2733
    },
    {
      "epoch": 1.6469879518072288,
      "grad_norm": 0.506476879119873,
      "learning_rate": 2.9412650602409644e-06,
      "loss": 0.2157,
      "step": 2734
    },
    {
      "epoch": 1.6475903614457832,
      "grad_norm": 0.48738792538642883,
      "learning_rate": 2.9405120481927713e-06,
      "loss": 0.2271,
      "step": 2735
    },
    {
      "epoch": 1.6481927710843374,
      "grad_norm": 0.49776577949523926,
      "learning_rate": 2.9397590361445786e-06,
      "loss": 0.1991,
      "step": 2736
    },
    {
      "epoch": 1.6487951807228916,
      "grad_norm": 0.521399974822998,
      "learning_rate": 2.939006024096386e-06,
      "loss": 0.1945,
      "step": 2737
    },
    {
      "epoch": 1.6493975903614457,
      "grad_norm": 0.5578209161758423,
      "learning_rate": 2.938253012048193e-06,
      "loss": 0.2416,
      "step": 2738
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.6421268582344055,
      "learning_rate": 2.9375000000000003e-06,
      "loss": 0.2427,
      "step": 2739
    },
    {
      "epoch": 1.6506024096385543,
      "grad_norm": 0.9013307690620422,
      "learning_rate": 2.936746987951807e-06,
      "loss": 0.2593,
      "step": 2740
    },
    {
      "epoch": 1.6512048192771083,
      "grad_norm": 1.0228254795074463,
      "learning_rate": 2.935993975903615e-06,
      "loss": 0.2763,
      "step": 2741
    },
    {
      "epoch": 1.6518072289156627,
      "grad_norm": 0.7268248200416565,
      "learning_rate": 2.935240963855422e-06,
      "loss": 0.3021,
      "step": 2742
    },
    {
      "epoch": 1.6524096385542169,
      "grad_norm": 1.0622435808181763,
      "learning_rate": 2.934487951807229e-06,
      "loss": 0.2265,
      "step": 2743
    },
    {
      "epoch": 1.653012048192771,
      "grad_norm": 0.8409695029258728,
      "learning_rate": 2.9337349397590366e-06,
      "loss": 0.2603,
      "step": 2744
    },
    {
      "epoch": 1.6536144578313254,
      "grad_norm": 0.8231180906295776,
      "learning_rate": 2.9329819277108435e-06,
      "loss": 0.262,
      "step": 2745
    },
    {
      "epoch": 1.6542168674698794,
      "grad_norm": 0.89323890209198,
      "learning_rate": 2.932228915662651e-06,
      "loss": 0.3277,
      "step": 2746
    },
    {
      "epoch": 1.6548192771084338,
      "grad_norm": 0.6814759969711304,
      "learning_rate": 2.931475903614458e-06,
      "loss": 0.3139,
      "step": 2747
    },
    {
      "epoch": 1.655421686746988,
      "grad_norm": 0.870322585105896,
      "learning_rate": 2.9307228915662655e-06,
      "loss": 0.3798,
      "step": 2748
    },
    {
      "epoch": 1.6560240963855422,
      "grad_norm": 0.8006384968757629,
      "learning_rate": 2.9299698795180725e-06,
      "loss": 0.2999,
      "step": 2749
    },
    {
      "epoch": 1.6566265060240963,
      "grad_norm": 0.7523050904273987,
      "learning_rate": 2.9292168674698794e-06,
      "loss": 0.2243,
      "step": 2750
    },
    {
      "epoch": 1.6572289156626505,
      "grad_norm": 0.6849119067192078,
      "learning_rate": 2.928463855421687e-06,
      "loss": 0.2653,
      "step": 2751
    },
    {
      "epoch": 1.657831325301205,
      "grad_norm": 0.6625815629959106,
      "learning_rate": 2.927710843373494e-06,
      "loss": 0.2729,
      "step": 2752
    },
    {
      "epoch": 1.6584337349397589,
      "grad_norm": 0.6891040205955505,
      "learning_rate": 2.926957831325302e-06,
      "loss": 0.3062,
      "step": 2753
    },
    {
      "epoch": 1.6590361445783133,
      "grad_norm": 0.7522635459899902,
      "learning_rate": 2.9262048192771088e-06,
      "loss": 0.2868,
      "step": 2754
    },
    {
      "epoch": 1.6596385542168675,
      "grad_norm": 0.7016297578811646,
      "learning_rate": 2.9254518072289157e-06,
      "loss": 0.2632,
      "step": 2755
    },
    {
      "epoch": 1.6602409638554216,
      "grad_norm": 0.6261813640594482,
      "learning_rate": 2.924698795180723e-06,
      "loss": 0.2511,
      "step": 2756
    },
    {
      "epoch": 1.660843373493976,
      "grad_norm": 0.6359614729881287,
      "learning_rate": 2.92394578313253e-06,
      "loss": 0.2387,
      "step": 2757
    },
    {
      "epoch": 1.66144578313253,
      "grad_norm": 0.7013652324676514,
      "learning_rate": 2.9231927710843378e-06,
      "loss": 0.2799,
      "step": 2758
    },
    {
      "epoch": 1.6620481927710844,
      "grad_norm": 0.6705511212348938,
      "learning_rate": 2.9224397590361447e-06,
      "loss": 0.2876,
      "step": 2759
    },
    {
      "epoch": 1.6626506024096386,
      "grad_norm": 0.618860125541687,
      "learning_rate": 2.9216867469879524e-06,
      "loss": 0.2707,
      "step": 2760
    },
    {
      "epoch": 1.6632530120481928,
      "grad_norm": 0.599361002445221,
      "learning_rate": 2.9209337349397594e-06,
      "loss": 0.2419,
      "step": 2761
    },
    {
      "epoch": 1.663855421686747,
      "grad_norm": 0.6980398297309875,
      "learning_rate": 2.9201807228915663e-06,
      "loss": 0.319,
      "step": 2762
    },
    {
      "epoch": 1.6644578313253011,
      "grad_norm": 0.5670559406280518,
      "learning_rate": 2.9194277108433736e-06,
      "loss": 0.2594,
      "step": 2763
    },
    {
      "epoch": 1.6650602409638555,
      "grad_norm": 0.5943061113357544,
      "learning_rate": 2.918674698795181e-06,
      "loss": 0.2827,
      "step": 2764
    },
    {
      "epoch": 1.6656626506024095,
      "grad_norm": 0.6428506970405579,
      "learning_rate": 2.9179216867469883e-06,
      "loss": 0.2601,
      "step": 2765
    },
    {
      "epoch": 1.6662650602409639,
      "grad_norm": 0.5982648730278015,
      "learning_rate": 2.9171686746987953e-06,
      "loss": 0.2578,
      "step": 2766
    },
    {
      "epoch": 1.666867469879518,
      "grad_norm": 0.5731760859489441,
      "learning_rate": 2.916415662650602e-06,
      "loss": 0.2781,
      "step": 2767
    },
    {
      "epoch": 1.6674698795180722,
      "grad_norm": 0.5860134363174438,
      "learning_rate": 2.91566265060241e-06,
      "loss": 0.3192,
      "step": 2768
    },
    {
      "epoch": 1.6680722891566266,
      "grad_norm": 0.5350678563117981,
      "learning_rate": 2.914909638554217e-06,
      "loss": 0.2179,
      "step": 2769
    },
    {
      "epoch": 1.6686746987951806,
      "grad_norm": 0.6864668726921082,
      "learning_rate": 2.9141566265060247e-06,
      "loss": 0.3208,
      "step": 2770
    },
    {
      "epoch": 1.669277108433735,
      "grad_norm": 0.645639955997467,
      "learning_rate": 2.9134036144578316e-06,
      "loss": 0.2433,
      "step": 2771
    },
    {
      "epoch": 1.6698795180722892,
      "grad_norm": 0.5501186847686768,
      "learning_rate": 2.912650602409639e-06,
      "loss": 0.2908,
      "step": 2772
    },
    {
      "epoch": 1.6704819277108434,
      "grad_norm": 0.5990048050880432,
      "learning_rate": 2.911897590361446e-06,
      "loss": 0.2828,
      "step": 2773
    },
    {
      "epoch": 1.6710843373493975,
      "grad_norm": 0.6300340294837952,
      "learning_rate": 2.911144578313253e-06,
      "loss": 0.2163,
      "step": 2774
    },
    {
      "epoch": 1.6716867469879517,
      "grad_norm": 0.6100671291351318,
      "learning_rate": 2.9103915662650606e-06,
      "loss": 0.3239,
      "step": 2775
    },
    {
      "epoch": 1.6722891566265061,
      "grad_norm": 3.429516077041626,
      "learning_rate": 2.9096385542168675e-06,
      "loss": 0.3202,
      "step": 2776
    },
    {
      "epoch": 1.67289156626506,
      "grad_norm": 0.5466312766075134,
      "learning_rate": 2.9088855421686753e-06,
      "loss": 0.2613,
      "step": 2777
    },
    {
      "epoch": 1.6734939759036145,
      "grad_norm": 0.5714623928070068,
      "learning_rate": 2.908132530120482e-06,
      "loss": 0.2765,
      "step": 2778
    },
    {
      "epoch": 1.6740963855421687,
      "grad_norm": 0.5795286297798157,
      "learning_rate": 2.907379518072289e-06,
      "loss": 0.2337,
      "step": 2779
    },
    {
      "epoch": 1.6746987951807228,
      "grad_norm": 0.5550721287727356,
      "learning_rate": 2.906626506024097e-06,
      "loss": 0.3185,
      "step": 2780
    },
    {
      "epoch": 1.6753012048192772,
      "grad_norm": 0.5331584215164185,
      "learning_rate": 2.905873493975904e-06,
      "loss": 0.2686,
      "step": 2781
    },
    {
      "epoch": 1.6759036144578312,
      "grad_norm": 0.5677890181541443,
      "learning_rate": 2.905120481927711e-06,
      "loss": 0.2806,
      "step": 2782
    },
    {
      "epoch": 1.6765060240963856,
      "grad_norm": 0.579393744468689,
      "learning_rate": 2.904367469879518e-06,
      "loss": 0.2818,
      "step": 2783
    },
    {
      "epoch": 1.6771084337349398,
      "grad_norm": 0.6120854616165161,
      "learning_rate": 2.903614457831326e-06,
      "loss": 0.2654,
      "step": 2784
    },
    {
      "epoch": 1.677710843373494,
      "grad_norm": 0.6398674845695496,
      "learning_rate": 2.9028614457831328e-06,
      "loss": 0.2865,
      "step": 2785
    },
    {
      "epoch": 1.6783132530120481,
      "grad_norm": 0.5551995038986206,
      "learning_rate": 2.9021084337349397e-06,
      "loss": 0.2429,
      "step": 2786
    },
    {
      "epoch": 1.6789156626506023,
      "grad_norm": 0.5613297820091248,
      "learning_rate": 2.9013554216867475e-06,
      "loss": 0.2583,
      "step": 2787
    },
    {
      "epoch": 1.6795180722891567,
      "grad_norm": 0.6081441044807434,
      "learning_rate": 2.9006024096385544e-06,
      "loss": 0.2799,
      "step": 2788
    },
    {
      "epoch": 1.6801204819277107,
      "grad_norm": 0.5533169507980347,
      "learning_rate": 2.8998493975903617e-06,
      "loss": 0.2216,
      "step": 2789
    },
    {
      "epoch": 1.680722891566265,
      "grad_norm": 0.6109607219696045,
      "learning_rate": 2.899096385542169e-06,
      "loss": 0.2385,
      "step": 2790
    },
    {
      "epoch": 1.6813253012048193,
      "grad_norm": 0.6255646347999573,
      "learning_rate": 2.898343373493976e-06,
      "loss": 0.3064,
      "step": 2791
    },
    {
      "epoch": 1.6819277108433734,
      "grad_norm": 0.5427842140197754,
      "learning_rate": 2.8975903614457834e-06,
      "loss": 0.2943,
      "step": 2792
    },
    {
      "epoch": 1.6825301204819278,
      "grad_norm": 0.594146192073822,
      "learning_rate": 2.8968373493975903e-06,
      "loss": 0.2648,
      "step": 2793
    },
    {
      "epoch": 1.6831325301204818,
      "grad_norm": 0.642410397529602,
      "learning_rate": 2.896084337349398e-06,
      "loss": 0.2495,
      "step": 2794
    },
    {
      "epoch": 1.6837349397590362,
      "grad_norm": 0.5647461414337158,
      "learning_rate": 2.895331325301205e-06,
      "loss": 0.288,
      "step": 2795
    },
    {
      "epoch": 1.6843373493975904,
      "grad_norm": 0.6337657570838928,
      "learning_rate": 2.8945783132530123e-06,
      "loss": 0.3056,
      "step": 2796
    },
    {
      "epoch": 1.6849397590361446,
      "grad_norm": 0.5539818406105042,
      "learning_rate": 2.8938253012048197e-06,
      "loss": 0.2541,
      "step": 2797
    },
    {
      "epoch": 1.6855421686746987,
      "grad_norm": 0.9705225229263306,
      "learning_rate": 2.8930722891566266e-06,
      "loss": 0.2569,
      "step": 2798
    },
    {
      "epoch": 1.686144578313253,
      "grad_norm": 0.6025680899620056,
      "learning_rate": 2.892319277108434e-06,
      "loss": 0.2946,
      "step": 2799
    },
    {
      "epoch": 1.6867469879518073,
      "grad_norm": 0.5593487024307251,
      "learning_rate": 2.891566265060241e-06,
      "loss": 0.2475,
      "step": 2800
    },
    {
      "epoch": 1.6873493975903613,
      "grad_norm": 0.5867063403129578,
      "learning_rate": 2.8908132530120487e-06,
      "loss": 0.2326,
      "step": 2801
    },
    {
      "epoch": 1.6879518072289157,
      "grad_norm": 0.5543235540390015,
      "learning_rate": 2.8900602409638556e-06,
      "loss": 0.2087,
      "step": 2802
    },
    {
      "epoch": 1.6885542168674699,
      "grad_norm": 0.6014825105667114,
      "learning_rate": 2.8893072289156625e-06,
      "loss": 0.319,
      "step": 2803
    },
    {
      "epoch": 1.689156626506024,
      "grad_norm": 0.5465919375419617,
      "learning_rate": 2.8885542168674703e-06,
      "loss": 0.2106,
      "step": 2804
    },
    {
      "epoch": 1.6897590361445785,
      "grad_norm": 0.5161965489387512,
      "learning_rate": 2.887801204819277e-06,
      "loss": 0.2235,
      "step": 2805
    },
    {
      "epoch": 1.6903614457831324,
      "grad_norm": 0.5996086001396179,
      "learning_rate": 2.8870481927710845e-06,
      "loss": 0.2691,
      "step": 2806
    },
    {
      "epoch": 1.6909638554216868,
      "grad_norm": 0.553363025188446,
      "learning_rate": 2.886295180722892e-06,
      "loss": 0.2215,
      "step": 2807
    },
    {
      "epoch": 1.691566265060241,
      "grad_norm": 0.6296811103820801,
      "learning_rate": 2.8855421686746992e-06,
      "loss": 0.2562,
      "step": 2808
    },
    {
      "epoch": 1.6921686746987952,
      "grad_norm": 0.5151382684707642,
      "learning_rate": 2.884789156626506e-06,
      "loss": 0.2522,
      "step": 2809
    },
    {
      "epoch": 1.6927710843373494,
      "grad_norm": 0.5859878659248352,
      "learning_rate": 2.884036144578313e-06,
      "loss": 0.2944,
      "step": 2810
    },
    {
      "epoch": 1.6933734939759035,
      "grad_norm": 0.711604118347168,
      "learning_rate": 2.883283132530121e-06,
      "loss": 0.2141,
      "step": 2811
    },
    {
      "epoch": 1.693975903614458,
      "grad_norm": 0.6480367183685303,
      "learning_rate": 2.882530120481928e-06,
      "loss": 0.2513,
      "step": 2812
    },
    {
      "epoch": 1.694578313253012,
      "grad_norm": 0.6139869689941406,
      "learning_rate": 2.8817771084337356e-06,
      "loss": 0.2732,
      "step": 2813
    },
    {
      "epoch": 1.6951807228915663,
      "grad_norm": 0.6743630170822144,
      "learning_rate": 2.8810240963855425e-06,
      "loss": 0.2814,
      "step": 2814
    },
    {
      "epoch": 1.6957831325301205,
      "grad_norm": 0.6125281453132629,
      "learning_rate": 2.8802710843373494e-06,
      "loss": 0.2544,
      "step": 2815
    },
    {
      "epoch": 1.6963855421686747,
      "grad_norm": 0.6218463182449341,
      "learning_rate": 2.8795180722891568e-06,
      "loss": 0.2796,
      "step": 2816
    },
    {
      "epoch": 1.696987951807229,
      "grad_norm": 0.628844141960144,
      "learning_rate": 2.878765060240964e-06,
      "loss": 0.3315,
      "step": 2817
    },
    {
      "epoch": 1.697590361445783,
      "grad_norm": 0.6180964708328247,
      "learning_rate": 2.8780120481927715e-06,
      "loss": 0.2648,
      "step": 2818
    },
    {
      "epoch": 1.6981927710843374,
      "grad_norm": 0.5903927087783813,
      "learning_rate": 2.8772590361445784e-06,
      "loss": 0.2201,
      "step": 2819
    },
    {
      "epoch": 1.6987951807228916,
      "grad_norm": 0.5446271896362305,
      "learning_rate": 2.876506024096386e-06,
      "loss": 0.2855,
      "step": 2820
    },
    {
      "epoch": 1.6993975903614458,
      "grad_norm": 0.5463207960128784,
      "learning_rate": 2.875753012048193e-06,
      "loss": 0.248,
      "step": 2821
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.5396354794502258,
      "learning_rate": 2.875e-06,
      "loss": 0.2428,
      "step": 2822
    },
    {
      "epoch": 1.7006024096385541,
      "grad_norm": 0.582619845867157,
      "learning_rate": 2.8742469879518078e-06,
      "loss": 0.2724,
      "step": 2823
    },
    {
      "epoch": 1.7012048192771085,
      "grad_norm": 0.5808096528053284,
      "learning_rate": 2.8734939759036147e-06,
      "loss": 0.2325,
      "step": 2824
    },
    {
      "epoch": 1.7018072289156625,
      "grad_norm": 0.6411769390106201,
      "learning_rate": 2.872740963855422e-06,
      "loss": 0.2441,
      "step": 2825
    },
    {
      "epoch": 1.702409638554217,
      "grad_norm": 0.6307106614112854,
      "learning_rate": 2.871987951807229e-06,
      "loss": 0.3202,
      "step": 2826
    },
    {
      "epoch": 1.703012048192771,
      "grad_norm": 0.6089051961898804,
      "learning_rate": 2.8712349397590363e-06,
      "loss": 0.2482,
      "step": 2827
    },
    {
      "epoch": 1.7036144578313253,
      "grad_norm": 0.5197254419326782,
      "learning_rate": 2.8704819277108437e-06,
      "loss": 0.2536,
      "step": 2828
    },
    {
      "epoch": 1.7042168674698797,
      "grad_norm": 0.5223581790924072,
      "learning_rate": 2.8697289156626506e-06,
      "loss": 0.2063,
      "step": 2829
    },
    {
      "epoch": 1.7048192771084336,
      "grad_norm": 0.5688710808753967,
      "learning_rate": 2.8689759036144584e-06,
      "loss": 0.2559,
      "step": 2830
    },
    {
      "epoch": 1.705421686746988,
      "grad_norm": 0.6098304986953735,
      "learning_rate": 2.8682228915662653e-06,
      "loss": 0.2383,
      "step": 2831
    },
    {
      "epoch": 1.7060240963855422,
      "grad_norm": 0.5701785683631897,
      "learning_rate": 2.8674698795180726e-06,
      "loss": 0.2737,
      "step": 2832
    },
    {
      "epoch": 1.7066265060240964,
      "grad_norm": 0.5771558880805969,
      "learning_rate": 2.8667168674698796e-06,
      "loss": 0.2401,
      "step": 2833
    },
    {
      "epoch": 1.7072289156626506,
      "grad_norm": 0.5742142200469971,
      "learning_rate": 2.865963855421687e-06,
      "loss": 0.2258,
      "step": 2834
    },
    {
      "epoch": 1.7078313253012047,
      "grad_norm": 0.5565782189369202,
      "learning_rate": 2.8652108433734943e-06,
      "loss": 0.2272,
      "step": 2835
    },
    {
      "epoch": 1.7084337349397591,
      "grad_norm": 0.5555839538574219,
      "learning_rate": 2.864457831325301e-06,
      "loss": 0.3161,
      "step": 2836
    },
    {
      "epoch": 1.709036144578313,
      "grad_norm": 0.6162076592445374,
      "learning_rate": 2.863704819277109e-06,
      "loss": 0.2637,
      "step": 2837
    },
    {
      "epoch": 1.7096385542168675,
      "grad_norm": 0.6723014116287231,
      "learning_rate": 2.862951807228916e-06,
      "loss": 0.3277,
      "step": 2838
    },
    {
      "epoch": 1.7102409638554217,
      "grad_norm": 0.6005992293357849,
      "learning_rate": 2.862198795180723e-06,
      "loss": 0.2564,
      "step": 2839
    },
    {
      "epoch": 1.7108433734939759,
      "grad_norm": 0.5409968495368958,
      "learning_rate": 2.8614457831325306e-06,
      "loss": 0.2091,
      "step": 2840
    },
    {
      "epoch": 1.7114457831325303,
      "grad_norm": 0.506450355052948,
      "learning_rate": 2.8606927710843375e-06,
      "loss": 0.2285,
      "step": 2841
    },
    {
      "epoch": 1.7120481927710842,
      "grad_norm": 0.5995890498161316,
      "learning_rate": 2.859939759036145e-06,
      "loss": 0.2939,
      "step": 2842
    },
    {
      "epoch": 1.7126506024096386,
      "grad_norm": 0.5532249808311462,
      "learning_rate": 2.8591867469879518e-06,
      "loss": 0.2397,
      "step": 2843
    },
    {
      "epoch": 1.7132530120481928,
      "grad_norm": 0.5810617208480835,
      "learning_rate": 2.8584337349397595e-06,
      "loss": 0.2296,
      "step": 2844
    },
    {
      "epoch": 1.713855421686747,
      "grad_norm": 0.6483919620513916,
      "learning_rate": 2.8576807228915665e-06,
      "loss": 0.2615,
      "step": 2845
    },
    {
      "epoch": 1.7144578313253012,
      "grad_norm": 0.7234387993812561,
      "learning_rate": 2.8569277108433734e-06,
      "loss": 0.2686,
      "step": 2846
    },
    {
      "epoch": 1.7150602409638553,
      "grad_norm": 0.5733547806739807,
      "learning_rate": 2.856174698795181e-06,
      "loss": 0.2501,
      "step": 2847
    },
    {
      "epoch": 1.7156626506024097,
      "grad_norm": 0.6056634187698364,
      "learning_rate": 2.855421686746988e-06,
      "loss": 0.2578,
      "step": 2848
    },
    {
      "epoch": 1.7162650602409637,
      "grad_norm": 0.6151286959648132,
      "learning_rate": 2.8546686746987954e-06,
      "loss": 0.2772,
      "step": 2849
    },
    {
      "epoch": 1.716867469879518,
      "grad_norm": 0.5403634309768677,
      "learning_rate": 2.853915662650603e-06,
      "loss": 0.3046,
      "step": 2850
    },
    {
      "epoch": 1.7174698795180723,
      "grad_norm": 0.6997929215431213,
      "learning_rate": 2.8531626506024097e-06,
      "loss": 0.2642,
      "step": 2851
    },
    {
      "epoch": 1.7180722891566265,
      "grad_norm": 0.5721835494041443,
      "learning_rate": 2.852409638554217e-06,
      "loss": 0.2623,
      "step": 2852
    },
    {
      "epoch": 1.7186746987951809,
      "grad_norm": 0.7189844846725464,
      "learning_rate": 2.851656626506024e-06,
      "loss": 0.2872,
      "step": 2853
    },
    {
      "epoch": 1.7192771084337348,
      "grad_norm": 0.6398394703865051,
      "learning_rate": 2.8509036144578318e-06,
      "loss": 0.31,
      "step": 2854
    },
    {
      "epoch": 1.7198795180722892,
      "grad_norm": 0.5798163414001465,
      "learning_rate": 2.8501506024096387e-06,
      "loss": 0.2648,
      "step": 2855
    },
    {
      "epoch": 1.7204819277108434,
      "grad_norm": 0.6269143223762512,
      "learning_rate": 2.8493975903614465e-06,
      "loss": 0.2582,
      "step": 2856
    },
    {
      "epoch": 1.7210843373493976,
      "grad_norm": 0.5850370526313782,
      "learning_rate": 2.8486445783132534e-06,
      "loss": 0.2755,
      "step": 2857
    },
    {
      "epoch": 1.7216867469879518,
      "grad_norm": 0.6397426724433899,
      "learning_rate": 2.8478915662650603e-06,
      "loss": 0.2917,
      "step": 2858
    },
    {
      "epoch": 1.722289156626506,
      "grad_norm": 0.572502851486206,
      "learning_rate": 2.8471385542168677e-06,
      "loss": 0.3018,
      "step": 2859
    },
    {
      "epoch": 1.7228915662650603,
      "grad_norm": 0.5910204648971558,
      "learning_rate": 2.846385542168675e-06,
      "loss": 0.2248,
      "step": 2860
    },
    {
      "epoch": 1.7234939759036143,
      "grad_norm": 0.6844425797462463,
      "learning_rate": 2.8456325301204824e-06,
      "loss": 0.2054,
      "step": 2861
    },
    {
      "epoch": 1.7240963855421687,
      "grad_norm": 0.5992622375488281,
      "learning_rate": 2.8448795180722893e-06,
      "loss": 0.2651,
      "step": 2862
    },
    {
      "epoch": 1.7246987951807229,
      "grad_norm": 0.5717109441757202,
      "learning_rate": 2.844126506024096e-06,
      "loss": 0.2667,
      "step": 2863
    },
    {
      "epoch": 1.725301204819277,
      "grad_norm": 0.541680097579956,
      "learning_rate": 2.843373493975904e-06,
      "loss": 0.2142,
      "step": 2864
    },
    {
      "epoch": 1.7259036144578315,
      "grad_norm": 0.576897919178009,
      "learning_rate": 2.842620481927711e-06,
      "loss": 0.2263,
      "step": 2865
    },
    {
      "epoch": 1.7265060240963854,
      "grad_norm": 0.6637639403343201,
      "learning_rate": 2.8418674698795182e-06,
      "loss": 0.273,
      "step": 2866
    },
    {
      "epoch": 1.7271084337349398,
      "grad_norm": 0.6032841205596924,
      "learning_rate": 2.8411144578313256e-06,
      "loss": 0.2217,
      "step": 2867
    },
    {
      "epoch": 1.727710843373494,
      "grad_norm": 0.597395122051239,
      "learning_rate": 2.840361445783133e-06,
      "loss": 0.2719,
      "step": 2868
    },
    {
      "epoch": 1.7283132530120482,
      "grad_norm": 0.577115535736084,
      "learning_rate": 2.83960843373494e-06,
      "loss": 0.2317,
      "step": 2869
    },
    {
      "epoch": 1.7289156626506024,
      "grad_norm": 0.5303841829299927,
      "learning_rate": 2.838855421686747e-06,
      "loss": 0.2657,
      "step": 2870
    },
    {
      "epoch": 1.7295180722891565,
      "grad_norm": 0.5578153133392334,
      "learning_rate": 2.8381024096385546e-06,
      "loss": 0.2699,
      "step": 2871
    },
    {
      "epoch": 1.730120481927711,
      "grad_norm": 0.6368694305419922,
      "learning_rate": 2.8373493975903615e-06,
      "loss": 0.2163,
      "step": 2872
    },
    {
      "epoch": 1.730722891566265,
      "grad_norm": 0.549206018447876,
      "learning_rate": 2.8365963855421693e-06,
      "loss": 0.2342,
      "step": 2873
    },
    {
      "epoch": 1.7313253012048193,
      "grad_norm": 0.6119303703308105,
      "learning_rate": 2.835843373493976e-06,
      "loss": 0.2465,
      "step": 2874
    },
    {
      "epoch": 1.7319277108433735,
      "grad_norm": 0.5953869819641113,
      "learning_rate": 2.835090361445783e-06,
      "loss": 0.2978,
      "step": 2875
    },
    {
      "epoch": 1.7325301204819277,
      "grad_norm": 0.5426425933837891,
      "learning_rate": 2.8343373493975905e-06,
      "loss": 0.224,
      "step": 2876
    },
    {
      "epoch": 1.733132530120482,
      "grad_norm": 0.5791156888008118,
      "learning_rate": 2.833584337349398e-06,
      "loss": 0.23,
      "step": 2877
    },
    {
      "epoch": 1.733734939759036,
      "grad_norm": 0.5712792873382568,
      "learning_rate": 2.832831325301205e-06,
      "loss": 0.2156,
      "step": 2878
    },
    {
      "epoch": 1.7343373493975904,
      "grad_norm": 0.5738540291786194,
      "learning_rate": 2.832078313253012e-06,
      "loss": 0.2375,
      "step": 2879
    },
    {
      "epoch": 1.7349397590361446,
      "grad_norm": 0.5183407068252563,
      "learning_rate": 2.83132530120482e-06,
      "loss": 0.1971,
      "step": 2880
    },
    {
      "epoch": 1.7355421686746988,
      "grad_norm": 0.566568911075592,
      "learning_rate": 2.8305722891566268e-06,
      "loss": 0.248,
      "step": 2881
    },
    {
      "epoch": 1.736144578313253,
      "grad_norm": 0.5653177499771118,
      "learning_rate": 2.8298192771084337e-06,
      "loss": 0.2488,
      "step": 2882
    },
    {
      "epoch": 1.7367469879518072,
      "grad_norm": 0.56003338098526,
      "learning_rate": 2.8290662650602415e-06,
      "loss": 0.2776,
      "step": 2883
    },
    {
      "epoch": 1.7373493975903616,
      "grad_norm": 0.609763503074646,
      "learning_rate": 2.8283132530120484e-06,
      "loss": 0.2315,
      "step": 2884
    },
    {
      "epoch": 1.7379518072289155,
      "grad_norm": 0.6249604225158691,
      "learning_rate": 2.8275602409638558e-06,
      "loss": 0.2217,
      "step": 2885
    },
    {
      "epoch": 1.73855421686747,
      "grad_norm": 0.5924234986305237,
      "learning_rate": 2.8268072289156627e-06,
      "loss": 0.2463,
      "step": 2886
    },
    {
      "epoch": 1.739156626506024,
      "grad_norm": 0.6141673922538757,
      "learning_rate": 2.82605421686747e-06,
      "loss": 0.3112,
      "step": 2887
    },
    {
      "epoch": 1.7397590361445783,
      "grad_norm": 0.5754060745239258,
      "learning_rate": 2.8253012048192774e-06,
      "loss": 0.2582,
      "step": 2888
    },
    {
      "epoch": 1.7403614457831327,
      "grad_norm": 0.6504164338111877,
      "learning_rate": 2.8245481927710843e-06,
      "loss": 0.2645,
      "step": 2889
    },
    {
      "epoch": 1.7409638554216866,
      "grad_norm": 0.5533757209777832,
      "learning_rate": 2.823795180722892e-06,
      "loss": 0.2206,
      "step": 2890
    },
    {
      "epoch": 1.741566265060241,
      "grad_norm": 0.5765870809555054,
      "learning_rate": 2.823042168674699e-06,
      "loss": 0.2028,
      "step": 2891
    },
    {
      "epoch": 1.7421686746987952,
      "grad_norm": 0.5716943740844727,
      "learning_rate": 2.8222891566265063e-06,
      "loss": 0.2628,
      "step": 2892
    },
    {
      "epoch": 1.7427710843373494,
      "grad_norm": 0.6840528845787048,
      "learning_rate": 2.8215361445783137e-06,
      "loss": 0.2405,
      "step": 2893
    },
    {
      "epoch": 1.7433734939759036,
      "grad_norm": 0.6445660591125488,
      "learning_rate": 2.8207831325301206e-06,
      "loss": 0.275,
      "step": 2894
    },
    {
      "epoch": 1.7439759036144578,
      "grad_norm": 0.62705397605896,
      "learning_rate": 2.820030120481928e-06,
      "loss": 0.2601,
      "step": 2895
    },
    {
      "epoch": 1.7445783132530122,
      "grad_norm": 0.583177387714386,
      "learning_rate": 2.819277108433735e-06,
      "loss": 0.2807,
      "step": 2896
    },
    {
      "epoch": 1.7451807228915661,
      "grad_norm": 0.678117036819458,
      "learning_rate": 2.8185240963855427e-06,
      "loss": 0.3014,
      "step": 2897
    },
    {
      "epoch": 1.7457831325301205,
      "grad_norm": 0.6329528093338013,
      "learning_rate": 2.8177710843373496e-06,
      "loss": 0.2847,
      "step": 2898
    },
    {
      "epoch": 1.7463855421686747,
      "grad_norm": 0.5972285866737366,
      "learning_rate": 2.8170180722891565e-06,
      "loss": 0.2361,
      "step": 2899
    },
    {
      "epoch": 1.7469879518072289,
      "grad_norm": 0.5813182592391968,
      "learning_rate": 2.8162650602409643e-06,
      "loss": 0.2714,
      "step": 2900
    },
    {
      "epoch": 1.7475903614457833,
      "grad_norm": 0.668085515499115,
      "learning_rate": 2.815512048192771e-06,
      "loss": 0.2878,
      "step": 2901
    },
    {
      "epoch": 1.7481927710843372,
      "grad_norm": 0.5799455046653748,
      "learning_rate": 2.8147590361445786e-06,
      "loss": 0.2193,
      "step": 2902
    },
    {
      "epoch": 1.7487951807228916,
      "grad_norm": 0.6382896304130554,
      "learning_rate": 2.8140060240963855e-06,
      "loss": 0.2309,
      "step": 2903
    },
    {
      "epoch": 1.7493975903614458,
      "grad_norm": 0.5699949264526367,
      "learning_rate": 2.8132530120481933e-06,
      "loss": 0.2795,
      "step": 2904
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.6346192359924316,
      "learning_rate": 2.8125e-06,
      "loss": 0.2843,
      "step": 2905
    },
    {
      "epoch": 1.7506024096385542,
      "grad_norm": 0.556011974811554,
      "learning_rate": 2.811746987951807e-06,
      "loss": 0.2064,
      "step": 2906
    },
    {
      "epoch": 1.7512048192771084,
      "grad_norm": 0.5800340175628662,
      "learning_rate": 2.810993975903615e-06,
      "loss": 0.2616,
      "step": 2907
    },
    {
      "epoch": 1.7518072289156628,
      "grad_norm": 0.6828972697257996,
      "learning_rate": 2.810240963855422e-06,
      "loss": 0.266,
      "step": 2908
    },
    {
      "epoch": 1.7524096385542167,
      "grad_norm": 0.6413012742996216,
      "learning_rate": 2.809487951807229e-06,
      "loss": 0.2859,
      "step": 2909
    },
    {
      "epoch": 1.7530120481927711,
      "grad_norm": 0.6295209527015686,
      "learning_rate": 2.8087349397590365e-06,
      "loss": 0.2554,
      "step": 2910
    },
    {
      "epoch": 1.7536144578313253,
      "grad_norm": 0.547592043876648,
      "learning_rate": 2.807981927710844e-06,
      "loss": 0.2557,
      "step": 2911
    },
    {
      "epoch": 1.7542168674698795,
      "grad_norm": 0.6041595339775085,
      "learning_rate": 2.8072289156626508e-06,
      "loss": 0.1998,
      "step": 2912
    },
    {
      "epoch": 1.7548192771084339,
      "grad_norm": 0.7154403328895569,
      "learning_rate": 2.8064759036144577e-06,
      "loss": 0.3087,
      "step": 2913
    },
    {
      "epoch": 1.7554216867469878,
      "grad_norm": 0.5438987612724304,
      "learning_rate": 2.8057228915662655e-06,
      "loss": 0.2526,
      "step": 2914
    },
    {
      "epoch": 1.7560240963855422,
      "grad_norm": 0.5876872539520264,
      "learning_rate": 2.8049698795180724e-06,
      "loss": 0.2198,
      "step": 2915
    },
    {
      "epoch": 1.7566265060240964,
      "grad_norm": 0.6253940463066101,
      "learning_rate": 2.80421686746988e-06,
      "loss": 0.2404,
      "step": 2916
    },
    {
      "epoch": 1.7572289156626506,
      "grad_norm": 0.5980711579322815,
      "learning_rate": 2.803463855421687e-06,
      "loss": 0.3063,
      "step": 2917
    },
    {
      "epoch": 1.7578313253012048,
      "grad_norm": 0.6771260499954224,
      "learning_rate": 2.802710843373494e-06,
      "loss": 0.2684,
      "step": 2918
    },
    {
      "epoch": 1.758433734939759,
      "grad_norm": 0.645010232925415,
      "learning_rate": 2.8019578313253014e-06,
      "loss": 0.2506,
      "step": 2919
    },
    {
      "epoch": 1.7590361445783134,
      "grad_norm": 0.6564720273017883,
      "learning_rate": 2.8012048192771087e-06,
      "loss": 0.2846,
      "step": 2920
    },
    {
      "epoch": 1.7596385542168673,
      "grad_norm": 0.582118034362793,
      "learning_rate": 2.800451807228916e-06,
      "loss": 0.214,
      "step": 2921
    },
    {
      "epoch": 1.7602409638554217,
      "grad_norm": 0.5354605317115784,
      "learning_rate": 2.799698795180723e-06,
      "loss": 0.18,
      "step": 2922
    },
    {
      "epoch": 1.760843373493976,
      "grad_norm": 0.5562846064567566,
      "learning_rate": 2.7989457831325308e-06,
      "loss": 0.2522,
      "step": 2923
    },
    {
      "epoch": 1.76144578313253,
      "grad_norm": 0.6384525895118713,
      "learning_rate": 2.7981927710843377e-06,
      "loss": 0.2394,
      "step": 2924
    },
    {
      "epoch": 1.7620481927710845,
      "grad_norm": 0.6339713335037231,
      "learning_rate": 2.7974397590361446e-06,
      "loss": 0.2743,
      "step": 2925
    },
    {
      "epoch": 1.7626506024096384,
      "grad_norm": 0.5535727739334106,
      "learning_rate": 2.7966867469879524e-06,
      "loss": 0.2766,
      "step": 2926
    },
    {
      "epoch": 1.7632530120481928,
      "grad_norm": 0.6084950566291809,
      "learning_rate": 2.7959337349397593e-06,
      "loss": 0.2537,
      "step": 2927
    },
    {
      "epoch": 1.763855421686747,
      "grad_norm": 0.6244560480117798,
      "learning_rate": 2.7951807228915666e-06,
      "loss": 0.2984,
      "step": 2928
    },
    {
      "epoch": 1.7644578313253012,
      "grad_norm": 0.6337765455245972,
      "learning_rate": 2.7944277108433736e-06,
      "loss": 0.2978,
      "step": 2929
    },
    {
      "epoch": 1.7650602409638554,
      "grad_norm": 0.6843369007110596,
      "learning_rate": 2.793674698795181e-06,
      "loss": 0.3255,
      "step": 2930
    },
    {
      "epoch": 1.7656626506024096,
      "grad_norm": 0.5945088863372803,
      "learning_rate": 2.7929216867469883e-06,
      "loss": 0.2424,
      "step": 2931
    },
    {
      "epoch": 1.766265060240964,
      "grad_norm": 0.5224618315696716,
      "learning_rate": 2.792168674698795e-06,
      "loss": 0.2165,
      "step": 2932
    },
    {
      "epoch": 1.766867469879518,
      "grad_norm": 0.6423541903495789,
      "learning_rate": 2.791415662650603e-06,
      "loss": 0.2322,
      "step": 2933
    },
    {
      "epoch": 1.7674698795180723,
      "grad_norm": 0.503802478313446,
      "learning_rate": 2.79066265060241e-06,
      "loss": 0.2145,
      "step": 2934
    },
    {
      "epoch": 1.7680722891566265,
      "grad_norm": 0.6336342692375183,
      "learning_rate": 2.7899096385542172e-06,
      "loss": 0.2695,
      "step": 2935
    },
    {
      "epoch": 1.7686746987951807,
      "grad_norm": 0.5662713050842285,
      "learning_rate": 2.789156626506024e-06,
      "loss": 0.3262,
      "step": 2936
    },
    {
      "epoch": 1.769277108433735,
      "grad_norm": 0.6681957244873047,
      "learning_rate": 2.7884036144578315e-06,
      "loss": 0.1833,
      "step": 2937
    },
    {
      "epoch": 1.769879518072289,
      "grad_norm": 0.5558494329452515,
      "learning_rate": 2.787650602409639e-06,
      "loss": 0.2671,
      "step": 2938
    },
    {
      "epoch": 1.7704819277108435,
      "grad_norm": 0.5716837048530579,
      "learning_rate": 2.7868975903614458e-06,
      "loss": 0.2231,
      "step": 2939
    },
    {
      "epoch": 1.7710843373493976,
      "grad_norm": 0.5510777831077576,
      "learning_rate": 2.7861445783132536e-06,
      "loss": 0.2821,
      "step": 2940
    },
    {
      "epoch": 1.7716867469879518,
      "grad_norm": 0.5798457264900208,
      "learning_rate": 2.7853915662650605e-06,
      "loss": 0.2625,
      "step": 2941
    },
    {
      "epoch": 1.772289156626506,
      "grad_norm": 0.6732995510101318,
      "learning_rate": 2.7846385542168674e-06,
      "loss": 0.225,
      "step": 2942
    },
    {
      "epoch": 1.7728915662650602,
      "grad_norm": 0.6066150665283203,
      "learning_rate": 2.783885542168675e-06,
      "loss": 0.2671,
      "step": 2943
    },
    {
      "epoch": 1.7734939759036146,
      "grad_norm": 0.5954195857048035,
      "learning_rate": 2.783132530120482e-06,
      "loss": 0.3003,
      "step": 2944
    },
    {
      "epoch": 1.7740963855421685,
      "grad_norm": 0.5950978994369507,
      "learning_rate": 2.7823795180722895e-06,
      "loss": 0.2641,
      "step": 2945
    },
    {
      "epoch": 1.774698795180723,
      "grad_norm": 0.5965657234191895,
      "learning_rate": 2.7816265060240964e-06,
      "loss": 0.2302,
      "step": 2946
    },
    {
      "epoch": 1.7753012048192771,
      "grad_norm": 0.6247801780700684,
      "learning_rate": 2.780873493975904e-06,
      "loss": 0.2712,
      "step": 2947
    },
    {
      "epoch": 1.7759036144578313,
      "grad_norm": 0.6403746008872986,
      "learning_rate": 2.780120481927711e-06,
      "loss": 0.2869,
      "step": 2948
    },
    {
      "epoch": 1.7765060240963857,
      "grad_norm": 0.54190993309021,
      "learning_rate": 2.779367469879518e-06,
      "loss": 0.2532,
      "step": 2949
    },
    {
      "epoch": 1.7771084337349397,
      "grad_norm": 0.627047061920166,
      "learning_rate": 2.7786144578313258e-06,
      "loss": 0.255,
      "step": 2950
    },
    {
      "epoch": 1.777710843373494,
      "grad_norm": 0.7005287408828735,
      "learning_rate": 2.7778614457831327e-06,
      "loss": 0.3548,
      "step": 2951
    },
    {
      "epoch": 1.7783132530120482,
      "grad_norm": 0.5629523396492004,
      "learning_rate": 2.77710843373494e-06,
      "loss": 0.3027,
      "step": 2952
    },
    {
      "epoch": 1.7789156626506024,
      "grad_norm": 0.5440244674682617,
      "learning_rate": 2.7763554216867474e-06,
      "loss": 0.237,
      "step": 2953
    },
    {
      "epoch": 1.7795180722891566,
      "grad_norm": 0.6096304059028625,
      "learning_rate": 2.7756024096385543e-06,
      "loss": 0.2839,
      "step": 2954
    },
    {
      "epoch": 1.7801204819277108,
      "grad_norm": 0.6108313202857971,
      "learning_rate": 2.7748493975903617e-06,
      "loss": 0.2917,
      "step": 2955
    },
    {
      "epoch": 1.7807228915662652,
      "grad_norm": 0.592644453048706,
      "learning_rate": 2.7740963855421686e-06,
      "loss": 0.2794,
      "step": 2956
    },
    {
      "epoch": 1.7813253012048191,
      "grad_norm": 0.6139903664588928,
      "learning_rate": 2.7733433734939764e-06,
      "loss": 0.3019,
      "step": 2957
    },
    {
      "epoch": 1.7819277108433735,
      "grad_norm": 0.5765265822410583,
      "learning_rate": 2.7725903614457833e-06,
      "loss": 0.2497,
      "step": 2958
    },
    {
      "epoch": 1.7825301204819277,
      "grad_norm": 0.5894823670387268,
      "learning_rate": 2.771837349397591e-06,
      "loss": 0.2892,
      "step": 2959
    },
    {
      "epoch": 1.783132530120482,
      "grad_norm": 0.6229848265647888,
      "learning_rate": 2.771084337349398e-06,
      "loss": 0.2218,
      "step": 2960
    },
    {
      "epoch": 1.7837349397590363,
      "grad_norm": 0.6047875881195068,
      "learning_rate": 2.770331325301205e-06,
      "loss": 0.3032,
      "step": 2961
    },
    {
      "epoch": 1.7843373493975903,
      "grad_norm": 0.6928234100341797,
      "learning_rate": 2.7695783132530123e-06,
      "loss": 0.2884,
      "step": 2962
    },
    {
      "epoch": 1.7849397590361447,
      "grad_norm": 0.5293429493904114,
      "learning_rate": 2.7688253012048196e-06,
      "loss": 0.2924,
      "step": 2963
    },
    {
      "epoch": 1.7855421686746988,
      "grad_norm": 0.644944965839386,
      "learning_rate": 2.768072289156627e-06,
      "loss": 0.3022,
      "step": 2964
    },
    {
      "epoch": 1.786144578313253,
      "grad_norm": 0.5182520151138306,
      "learning_rate": 2.767319277108434e-06,
      "loss": 0.2387,
      "step": 2965
    },
    {
      "epoch": 1.7867469879518072,
      "grad_norm": 0.6601910591125488,
      "learning_rate": 2.766566265060241e-06,
      "loss": 0.2592,
      "step": 2966
    },
    {
      "epoch": 1.7873493975903614,
      "grad_norm": 0.6062853336334229,
      "learning_rate": 2.7658132530120486e-06,
      "loss": 0.2853,
      "step": 2967
    },
    {
      "epoch": 1.7879518072289158,
      "grad_norm": 0.7011969089508057,
      "learning_rate": 2.7650602409638555e-06,
      "loss": 0.2824,
      "step": 2968
    },
    {
      "epoch": 1.7885542168674697,
      "grad_norm": 0.6158970594406128,
      "learning_rate": 2.764307228915663e-06,
      "loss": 0.2076,
      "step": 2969
    },
    {
      "epoch": 1.7891566265060241,
      "grad_norm": 0.6390960216522217,
      "learning_rate": 2.76355421686747e-06,
      "loss": 0.2815,
      "step": 2970
    },
    {
      "epoch": 1.7897590361445783,
      "grad_norm": 0.5743770003318787,
      "learning_rate": 2.7628012048192775e-06,
      "loss": 0.2159,
      "step": 2971
    },
    {
      "epoch": 1.7903614457831325,
      "grad_norm": 0.6870405077934265,
      "learning_rate": 2.7620481927710845e-06,
      "loss": 0.2607,
      "step": 2972
    },
    {
      "epoch": 1.790963855421687,
      "grad_norm": 0.5657457113265991,
      "learning_rate": 2.7612951807228914e-06,
      "loss": 0.2288,
      "step": 2973
    },
    {
      "epoch": 1.7915662650602409,
      "grad_norm": 0.5644007325172424,
      "learning_rate": 2.760542168674699e-06,
      "loss": 0.233,
      "step": 2974
    },
    {
      "epoch": 1.7921686746987953,
      "grad_norm": 0.6446425318717957,
      "learning_rate": 2.759789156626506e-06,
      "loss": 0.2408,
      "step": 2975
    },
    {
      "epoch": 1.7927710843373494,
      "grad_norm": 0.5835264921188354,
      "learning_rate": 2.759036144578314e-06,
      "loss": 0.2434,
      "step": 2976
    },
    {
      "epoch": 1.7933734939759036,
      "grad_norm": 0.6635376214981079,
      "learning_rate": 2.758283132530121e-06,
      "loss": 0.2599,
      "step": 2977
    },
    {
      "epoch": 1.7939759036144578,
      "grad_norm": 0.6018796563148499,
      "learning_rate": 2.7575301204819277e-06,
      "loss": 0.208,
      "step": 2978
    },
    {
      "epoch": 1.794578313253012,
      "grad_norm": 0.746710479259491,
      "learning_rate": 2.756777108433735e-06,
      "loss": 0.2759,
      "step": 2979
    },
    {
      "epoch": 1.7951807228915664,
      "grad_norm": 0.5067864656448364,
      "learning_rate": 2.7560240963855424e-06,
      "loss": 0.2023,
      "step": 2980
    },
    {
      "epoch": 1.7957831325301203,
      "grad_norm": 0.665776252746582,
      "learning_rate": 2.7552710843373498e-06,
      "loss": 0.3454,
      "step": 2981
    },
    {
      "epoch": 1.7963855421686747,
      "grad_norm": 0.49583908915519714,
      "learning_rate": 2.7545180722891567e-06,
      "loss": 0.209,
      "step": 2982
    },
    {
      "epoch": 1.796987951807229,
      "grad_norm": 0.5697276592254639,
      "learning_rate": 2.7537650602409645e-06,
      "loss": 0.285,
      "step": 2983
    },
    {
      "epoch": 1.797590361445783,
      "grad_norm": 0.594260036945343,
      "learning_rate": 2.7530120481927714e-06,
      "loss": 0.2439,
      "step": 2984
    },
    {
      "epoch": 1.7981927710843375,
      "grad_norm": 0.5843951106071472,
      "learning_rate": 2.7522590361445783e-06,
      "loss": 0.2575,
      "step": 2985
    },
    {
      "epoch": 1.7987951807228915,
      "grad_norm": 0.5462666749954224,
      "learning_rate": 2.751506024096386e-06,
      "loss": 0.229,
      "step": 2986
    },
    {
      "epoch": 1.7993975903614459,
      "grad_norm": 0.5366875529289246,
      "learning_rate": 2.750753012048193e-06,
      "loss": 0.221,
      "step": 2987
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.5630320310592651,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 0.2143,
      "step": 2988
    },
    {
      "epoch": 1.8006024096385542,
      "grad_norm": 0.545186460018158,
      "learning_rate": 2.7492469879518073e-06,
      "loss": 0.2722,
      "step": 2989
    },
    {
      "epoch": 1.8012048192771084,
      "grad_norm": 0.606437623500824,
      "learning_rate": 2.7484939759036146e-06,
      "loss": 0.2249,
      "step": 2990
    },
    {
      "epoch": 1.8018072289156626,
      "grad_norm": 0.5444990396499634,
      "learning_rate": 2.747740963855422e-06,
      "loss": 0.2296,
      "step": 2991
    },
    {
      "epoch": 1.802409638554217,
      "grad_norm": 0.6545323729515076,
      "learning_rate": 2.746987951807229e-06,
      "loss": 0.2369,
      "step": 2992
    },
    {
      "epoch": 1.803012048192771,
      "grad_norm": 0.9495243430137634,
      "learning_rate": 2.7462349397590367e-06,
      "loss": 0.321,
      "step": 2993
    },
    {
      "epoch": 1.8036144578313253,
      "grad_norm": 0.6737210154533386,
      "learning_rate": 2.7454819277108436e-06,
      "loss": 0.3051,
      "step": 2994
    },
    {
      "epoch": 1.8042168674698795,
      "grad_norm": 0.7048584818840027,
      "learning_rate": 2.744728915662651e-06,
      "loss": 0.2569,
      "step": 2995
    },
    {
      "epoch": 1.8048192771084337,
      "grad_norm": 0.6650682091712952,
      "learning_rate": 2.7439759036144583e-06,
      "loss": 0.3042,
      "step": 2996
    },
    {
      "epoch": 1.805421686746988,
      "grad_norm": 0.675697922706604,
      "learning_rate": 2.7432228915662652e-06,
      "loss": 0.3257,
      "step": 2997
    },
    {
      "epoch": 1.806024096385542,
      "grad_norm": 0.5161435008049011,
      "learning_rate": 2.7424698795180726e-06,
      "loss": 0.2642,
      "step": 2998
    },
    {
      "epoch": 1.8066265060240965,
      "grad_norm": 0.6210014820098877,
      "learning_rate": 2.7417168674698795e-06,
      "loss": 0.294,
      "step": 2999
    },
    {
      "epoch": 1.8072289156626506,
      "grad_norm": 0.547045886516571,
      "learning_rate": 2.7409638554216873e-06,
      "loss": 0.2779,
      "step": 3000
    },
    {
      "epoch": 1.8078313253012048,
      "grad_norm": 0.6838036775588989,
      "learning_rate": 2.740210843373494e-06,
      "loss": 0.2367,
      "step": 3001
    },
    {
      "epoch": 1.808433734939759,
      "grad_norm": 0.7033842206001282,
      "learning_rate": 2.739457831325301e-06,
      "loss": 0.2859,
      "step": 3002
    },
    {
      "epoch": 1.8090361445783132,
      "grad_norm": 0.5758792161941528,
      "learning_rate": 2.738704819277109e-06,
      "loss": 0.2796,
      "step": 3003
    },
    {
      "epoch": 1.8096385542168676,
      "grad_norm": 0.6600974798202515,
      "learning_rate": 2.737951807228916e-06,
      "loss": 0.2844,
      "step": 3004
    },
    {
      "epoch": 1.8102409638554215,
      "grad_norm": 0.6064568161964417,
      "learning_rate": 2.737198795180723e-06,
      "loss": 0.2601,
      "step": 3005
    },
    {
      "epoch": 1.810843373493976,
      "grad_norm": 0.7188630700111389,
      "learning_rate": 2.73644578313253e-06,
      "loss": 0.3001,
      "step": 3006
    },
    {
      "epoch": 1.8114457831325301,
      "grad_norm": 0.7019768953323364,
      "learning_rate": 2.735692771084338e-06,
      "loss": 0.2715,
      "step": 3007
    },
    {
      "epoch": 1.8120481927710843,
      "grad_norm": 0.595352828502655,
      "learning_rate": 2.7349397590361448e-06,
      "loss": 0.2526,
      "step": 3008
    },
    {
      "epoch": 1.8126506024096387,
      "grad_norm": 0.5459718704223633,
      "learning_rate": 2.7341867469879517e-06,
      "loss": 0.2606,
      "step": 3009
    },
    {
      "epoch": 1.8132530120481927,
      "grad_norm": 0.5494746565818787,
      "learning_rate": 2.7334337349397595e-06,
      "loss": 0.2048,
      "step": 3010
    },
    {
      "epoch": 1.813855421686747,
      "grad_norm": 0.7283318638801575,
      "learning_rate": 2.7326807228915664e-06,
      "loss": 0.2687,
      "step": 3011
    },
    {
      "epoch": 1.8144578313253013,
      "grad_norm": 0.5983808040618896,
      "learning_rate": 2.7319277108433737e-06,
      "loss": 0.2073,
      "step": 3012
    },
    {
      "epoch": 1.8150602409638554,
      "grad_norm": 0.5786295533180237,
      "learning_rate": 2.731174698795181e-06,
      "loss": 0.2348,
      "step": 3013
    },
    {
      "epoch": 1.8156626506024096,
      "grad_norm": 1.9782440662384033,
      "learning_rate": 2.730421686746988e-06,
      "loss": 0.2483,
      "step": 3014
    },
    {
      "epoch": 1.8162650602409638,
      "grad_norm": 0.5348997116088867,
      "learning_rate": 2.7296686746987954e-06,
      "loss": 0.2653,
      "step": 3015
    },
    {
      "epoch": 1.8168674698795182,
      "grad_norm": 0.6623420715332031,
      "learning_rate": 2.7289156626506023e-06,
      "loss": 0.2885,
      "step": 3016
    },
    {
      "epoch": 1.8174698795180722,
      "grad_norm": 0.5545188188552856,
      "learning_rate": 2.72816265060241e-06,
      "loss": 0.2414,
      "step": 3017
    },
    {
      "epoch": 1.8180722891566266,
      "grad_norm": 0.5136175751686096,
      "learning_rate": 2.727409638554217e-06,
      "loss": 0.2614,
      "step": 3018
    },
    {
      "epoch": 1.8186746987951807,
      "grad_norm": 0.6152043342590332,
      "learning_rate": 2.7266566265060248e-06,
      "loss": 0.2511,
      "step": 3019
    },
    {
      "epoch": 1.819277108433735,
      "grad_norm": 0.5719178318977356,
      "learning_rate": 2.7259036144578317e-06,
      "loss": 0.2661,
      "step": 3020
    },
    {
      "epoch": 1.8198795180722893,
      "grad_norm": 0.5984506011009216,
      "learning_rate": 2.7251506024096386e-06,
      "loss": 0.2765,
      "step": 3021
    },
    {
      "epoch": 1.8204819277108433,
      "grad_norm": 0.5925734639167786,
      "learning_rate": 2.724397590361446e-06,
      "loss": 0.2859,
      "step": 3022
    },
    {
      "epoch": 1.8210843373493977,
      "grad_norm": 0.6152724623680115,
      "learning_rate": 2.7236445783132533e-06,
      "loss": 0.2187,
      "step": 3023
    },
    {
      "epoch": 1.8216867469879519,
      "grad_norm": 0.5716767907142639,
      "learning_rate": 2.7228915662650607e-06,
      "loss": 0.2673,
      "step": 3024
    },
    {
      "epoch": 1.822289156626506,
      "grad_norm": 0.7276856303215027,
      "learning_rate": 2.7221385542168676e-06,
      "loss": 0.3297,
      "step": 3025
    },
    {
      "epoch": 1.8228915662650602,
      "grad_norm": 0.5860779881477356,
      "learning_rate": 2.7213855421686745e-06,
      "loss": 0.2792,
      "step": 3026
    },
    {
      "epoch": 1.8234939759036144,
      "grad_norm": 0.5507634282112122,
      "learning_rate": 2.7206325301204823e-06,
      "loss": 0.2398,
      "step": 3027
    },
    {
      "epoch": 1.8240963855421688,
      "grad_norm": 0.5153141021728516,
      "learning_rate": 2.719879518072289e-06,
      "loss": 0.2536,
      "step": 3028
    },
    {
      "epoch": 1.8246987951807228,
      "grad_norm": 0.5753674507141113,
      "learning_rate": 2.719126506024097e-06,
      "loss": 0.2731,
      "step": 3029
    },
    {
      "epoch": 1.8253012048192772,
      "grad_norm": 0.6077108383178711,
      "learning_rate": 2.718373493975904e-06,
      "loss": 0.2869,
      "step": 3030
    },
    {
      "epoch": 1.8259036144578313,
      "grad_norm": 0.5417460203170776,
      "learning_rate": 2.7176204819277113e-06,
      "loss": 0.235,
      "step": 3031
    },
    {
      "epoch": 1.8265060240963855,
      "grad_norm": 0.6116606593132019,
      "learning_rate": 2.716867469879518e-06,
      "loss": 0.24,
      "step": 3032
    },
    {
      "epoch": 1.82710843373494,
      "grad_norm": 0.703959047794342,
      "learning_rate": 2.7161144578313255e-06,
      "loss": 0.2745,
      "step": 3033
    },
    {
      "epoch": 1.8277108433734939,
      "grad_norm": 0.744982123374939,
      "learning_rate": 2.715361445783133e-06,
      "loss": 0.2814,
      "step": 3034
    },
    {
      "epoch": 1.8283132530120483,
      "grad_norm": 0.6002308130264282,
      "learning_rate": 2.71460843373494e-06,
      "loss": 0.2549,
      "step": 3035
    },
    {
      "epoch": 1.8289156626506025,
      "grad_norm": 0.5722746849060059,
      "learning_rate": 2.7138554216867476e-06,
      "loss": 0.2414,
      "step": 3036
    },
    {
      "epoch": 1.8295180722891566,
      "grad_norm": 0.5488101243972778,
      "learning_rate": 2.7131024096385545e-06,
      "loss": 0.2761,
      "step": 3037
    },
    {
      "epoch": 1.8301204819277108,
      "grad_norm": 0.60716712474823,
      "learning_rate": 2.7123493975903614e-06,
      "loss": 0.2753,
      "step": 3038
    },
    {
      "epoch": 1.830722891566265,
      "grad_norm": 0.5668926239013672,
      "learning_rate": 2.7115963855421688e-06,
      "loss": 0.2977,
      "step": 3039
    },
    {
      "epoch": 1.8313253012048194,
      "grad_norm": 0.5092598795890808,
      "learning_rate": 2.710843373493976e-06,
      "loss": 0.2401,
      "step": 3040
    },
    {
      "epoch": 1.8319277108433734,
      "grad_norm": 0.640735924243927,
      "learning_rate": 2.7100903614457835e-06,
      "loss": 0.2683,
      "step": 3041
    },
    {
      "epoch": 1.8325301204819278,
      "grad_norm": 0.5873278379440308,
      "learning_rate": 2.7093373493975904e-06,
      "loss": 0.2724,
      "step": 3042
    },
    {
      "epoch": 1.833132530120482,
      "grad_norm": 0.4824361801147461,
      "learning_rate": 2.708584337349398e-06,
      "loss": 0.235,
      "step": 3043
    },
    {
      "epoch": 1.8337349397590361,
      "grad_norm": 0.5257923007011414,
      "learning_rate": 2.707831325301205e-06,
      "loss": 0.2106,
      "step": 3044
    },
    {
      "epoch": 1.8343373493975905,
      "grad_norm": 0.6080875992774963,
      "learning_rate": 2.707078313253012e-06,
      "loss": 0.2419,
      "step": 3045
    },
    {
      "epoch": 1.8349397590361445,
      "grad_norm": 0.6103489398956299,
      "learning_rate": 2.7063253012048198e-06,
      "loss": 0.2723,
      "step": 3046
    },
    {
      "epoch": 1.8355421686746989,
      "grad_norm": 0.7193398475646973,
      "learning_rate": 2.7055722891566267e-06,
      "loss": 0.3132,
      "step": 3047
    },
    {
      "epoch": 1.836144578313253,
      "grad_norm": 0.5596995949745178,
      "learning_rate": 2.704819277108434e-06,
      "loss": 0.2442,
      "step": 3048
    },
    {
      "epoch": 1.8367469879518072,
      "grad_norm": 0.614489734172821,
      "learning_rate": 2.704066265060241e-06,
      "loss": 0.3072,
      "step": 3049
    },
    {
      "epoch": 1.8373493975903614,
      "grad_norm": 0.5209197402000427,
      "learning_rate": 2.7033132530120483e-06,
      "loss": 0.2136,
      "step": 3050
    },
    {
      "epoch": 1.8379518072289156,
      "grad_norm": 0.5534026622772217,
      "learning_rate": 2.7025602409638557e-06,
      "loss": 0.2068,
      "step": 3051
    },
    {
      "epoch": 1.83855421686747,
      "grad_norm": 0.6413031220436096,
      "learning_rate": 2.7018072289156626e-06,
      "loss": 0.243,
      "step": 3052
    },
    {
      "epoch": 1.839156626506024,
      "grad_norm": 0.6472389698028564,
      "learning_rate": 2.7010542168674704e-06,
      "loss": 0.2808,
      "step": 3053
    },
    {
      "epoch": 1.8397590361445784,
      "grad_norm": 0.6786032319068909,
      "learning_rate": 2.7003012048192773e-06,
      "loss": 0.2874,
      "step": 3054
    },
    {
      "epoch": 1.8403614457831325,
      "grad_norm": 0.5534523129463196,
      "learning_rate": 2.6995481927710846e-06,
      "loss": 0.3089,
      "step": 3055
    },
    {
      "epoch": 1.8409638554216867,
      "grad_norm": 0.48849937319755554,
      "learning_rate": 2.698795180722892e-06,
      "loss": 0.2168,
      "step": 3056
    },
    {
      "epoch": 1.8415662650602411,
      "grad_norm": 0.6577600836753845,
      "learning_rate": 2.698042168674699e-06,
      "loss": 0.269,
      "step": 3057
    },
    {
      "epoch": 1.842168674698795,
      "grad_norm": 0.6971876621246338,
      "learning_rate": 2.6972891566265063e-06,
      "loss": 0.2157,
      "step": 3058
    },
    {
      "epoch": 1.8427710843373495,
      "grad_norm": 0.612063467502594,
      "learning_rate": 2.696536144578313e-06,
      "loss": 0.2579,
      "step": 3059
    },
    {
      "epoch": 1.8433734939759037,
      "grad_norm": 0.7289704084396362,
      "learning_rate": 2.695783132530121e-06,
      "loss": 0.2757,
      "step": 3060
    },
    {
      "epoch": 1.8439759036144578,
      "grad_norm": 0.6477507948875427,
      "learning_rate": 2.695030120481928e-06,
      "loss": 0.3252,
      "step": 3061
    },
    {
      "epoch": 1.844578313253012,
      "grad_norm": 0.5686324238777161,
      "learning_rate": 2.694277108433735e-06,
      "loss": 0.2823,
      "step": 3062
    },
    {
      "epoch": 1.8451807228915662,
      "grad_norm": 0.5427959561347961,
      "learning_rate": 2.6935240963855426e-06,
      "loss": 0.2431,
      "step": 3063
    },
    {
      "epoch": 1.8457831325301206,
      "grad_norm": 0.5806515216827393,
      "learning_rate": 2.6927710843373495e-06,
      "loss": 0.2814,
      "step": 3064
    },
    {
      "epoch": 1.8463855421686746,
      "grad_norm": 0.5137542486190796,
      "learning_rate": 2.692018072289157e-06,
      "loss": 0.2736,
      "step": 3065
    },
    {
      "epoch": 1.846987951807229,
      "grad_norm": 0.5289814472198486,
      "learning_rate": 2.691265060240964e-06,
      "loss": 0.253,
      "step": 3066
    },
    {
      "epoch": 1.8475903614457831,
      "grad_norm": 0.5643815398216248,
      "learning_rate": 2.6905120481927716e-06,
      "loss": 0.2789,
      "step": 3067
    },
    {
      "epoch": 1.8481927710843373,
      "grad_norm": 0.5002881288528442,
      "learning_rate": 2.6897590361445785e-06,
      "loss": 0.2321,
      "step": 3068
    },
    {
      "epoch": 1.8487951807228917,
      "grad_norm": 0.5623161196708679,
      "learning_rate": 2.6890060240963854e-06,
      "loss": 0.2703,
      "step": 3069
    },
    {
      "epoch": 1.8493975903614457,
      "grad_norm": 0.603445827960968,
      "learning_rate": 2.688253012048193e-06,
      "loss": 0.2914,
      "step": 3070
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6397742033004761,
      "learning_rate": 2.6875e-06,
      "loss": 0.234,
      "step": 3071
    },
    {
      "epoch": 1.8506024096385543,
      "grad_norm": 0.7855578660964966,
      "learning_rate": 2.6867469879518075e-06,
      "loss": 0.2671,
      "step": 3072
    },
    {
      "epoch": 1.8512048192771084,
      "grad_norm": 0.6261795163154602,
      "learning_rate": 2.685993975903615e-06,
      "loss": 0.2266,
      "step": 3073
    },
    {
      "epoch": 1.8518072289156626,
      "grad_norm": 0.7137795686721802,
      "learning_rate": 2.6852409638554217e-06,
      "loss": 0.3136,
      "step": 3074
    },
    {
      "epoch": 1.8524096385542168,
      "grad_norm": 0.5439490675926208,
      "learning_rate": 2.684487951807229e-06,
      "loss": 0.2052,
      "step": 3075
    },
    {
      "epoch": 1.8530120481927712,
      "grad_norm": 0.6766350269317627,
      "learning_rate": 2.683734939759036e-06,
      "loss": 0.2935,
      "step": 3076
    },
    {
      "epoch": 1.8536144578313252,
      "grad_norm": 0.5337269902229309,
      "learning_rate": 2.6829819277108438e-06,
      "loss": 0.2276,
      "step": 3077
    },
    {
      "epoch": 1.8542168674698796,
      "grad_norm": 0.7184707522392273,
      "learning_rate": 2.6822289156626507e-06,
      "loss": 0.2533,
      "step": 3078
    },
    {
      "epoch": 1.8548192771084338,
      "grad_norm": 0.5831192135810852,
      "learning_rate": 2.6814759036144585e-06,
      "loss": 0.2525,
      "step": 3079
    },
    {
      "epoch": 1.855421686746988,
      "grad_norm": 0.6680519580841064,
      "learning_rate": 2.6807228915662654e-06,
      "loss": 0.3033,
      "step": 3080
    },
    {
      "epoch": 1.8560240963855423,
      "grad_norm": 0.6238777041435242,
      "learning_rate": 2.6799698795180723e-06,
      "loss": 0.2226,
      "step": 3081
    },
    {
      "epoch": 1.8566265060240963,
      "grad_norm": 0.5075692534446716,
      "learning_rate": 2.6792168674698797e-06,
      "loss": 0.2349,
      "step": 3082
    },
    {
      "epoch": 1.8572289156626507,
      "grad_norm": 0.6537754535675049,
      "learning_rate": 2.678463855421687e-06,
      "loss": 0.2382,
      "step": 3083
    },
    {
      "epoch": 1.8578313253012049,
      "grad_norm": 0.6359582543373108,
      "learning_rate": 2.6777108433734944e-06,
      "loss": 0.2536,
      "step": 3084
    },
    {
      "epoch": 1.858433734939759,
      "grad_norm": 0.5208137035369873,
      "learning_rate": 2.6769578313253013e-06,
      "loss": 0.262,
      "step": 3085
    },
    {
      "epoch": 1.8590361445783132,
      "grad_norm": 0.5882440805435181,
      "learning_rate": 2.676204819277108e-06,
      "loss": 0.2577,
      "step": 3086
    },
    {
      "epoch": 1.8596385542168674,
      "grad_norm": 0.5951642394065857,
      "learning_rate": 2.675451807228916e-06,
      "loss": 0.2578,
      "step": 3087
    },
    {
      "epoch": 1.8602409638554218,
      "grad_norm": 0.5580189824104309,
      "learning_rate": 2.674698795180723e-06,
      "loss": 0.2482,
      "step": 3088
    },
    {
      "epoch": 1.8608433734939758,
      "grad_norm": 0.6521716117858887,
      "learning_rate": 2.6739457831325307e-06,
      "loss": 0.2922,
      "step": 3089
    },
    {
      "epoch": 1.8614457831325302,
      "grad_norm": 0.6033421754837036,
      "learning_rate": 2.6731927710843376e-06,
      "loss": 0.2754,
      "step": 3090
    },
    {
      "epoch": 1.8620481927710844,
      "grad_norm": 0.769521951675415,
      "learning_rate": 2.672439759036145e-06,
      "loss": 0.2882,
      "step": 3091
    },
    {
      "epoch": 1.8626506024096385,
      "grad_norm": 0.6633104085922241,
      "learning_rate": 2.671686746987952e-06,
      "loss": 0.2426,
      "step": 3092
    },
    {
      "epoch": 1.863253012048193,
      "grad_norm": 0.5940378904342651,
      "learning_rate": 2.6709337349397592e-06,
      "loss": 0.2411,
      "step": 3093
    },
    {
      "epoch": 1.863855421686747,
      "grad_norm": 0.5575546622276306,
      "learning_rate": 2.6701807228915666e-06,
      "loss": 0.2374,
      "step": 3094
    },
    {
      "epoch": 1.8644578313253013,
      "grad_norm": 0.5543168783187866,
      "learning_rate": 2.6694277108433735e-06,
      "loss": 0.2929,
      "step": 3095
    },
    {
      "epoch": 1.8650602409638555,
      "grad_norm": 0.7321314811706543,
      "learning_rate": 2.6686746987951813e-06,
      "loss": 0.307,
      "step": 3096
    },
    {
      "epoch": 1.8656626506024097,
      "grad_norm": 0.5858937501907349,
      "learning_rate": 2.667921686746988e-06,
      "loss": 0.2811,
      "step": 3097
    },
    {
      "epoch": 1.8662650602409638,
      "grad_norm": 0.5996493697166443,
      "learning_rate": 2.667168674698795e-06,
      "loss": 0.2867,
      "step": 3098
    },
    {
      "epoch": 1.866867469879518,
      "grad_norm": 0.62822425365448,
      "learning_rate": 2.666415662650603e-06,
      "loss": 0.2606,
      "step": 3099
    },
    {
      "epoch": 1.8674698795180724,
      "grad_norm": 0.6666296124458313,
      "learning_rate": 2.66566265060241e-06,
      "loss": 0.3109,
      "step": 3100
    },
    {
      "epoch": 1.8680722891566264,
      "grad_norm": 0.5713356733322144,
      "learning_rate": 2.664909638554217e-06,
      "loss": 0.2076,
      "step": 3101
    },
    {
      "epoch": 1.8686746987951808,
      "grad_norm": 0.627458393573761,
      "learning_rate": 2.664156626506024e-06,
      "loss": 0.329,
      "step": 3102
    },
    {
      "epoch": 1.869277108433735,
      "grad_norm": 0.5754279494285583,
      "learning_rate": 2.663403614457832e-06,
      "loss": 0.2255,
      "step": 3103
    },
    {
      "epoch": 1.8698795180722891,
      "grad_norm": 0.6247242093086243,
      "learning_rate": 2.662650602409639e-06,
      "loss": 0.2137,
      "step": 3104
    },
    {
      "epoch": 1.8704819277108435,
      "grad_norm": 0.6270878314971924,
      "learning_rate": 2.6618975903614457e-06,
      "loss": 0.2132,
      "step": 3105
    },
    {
      "epoch": 1.8710843373493975,
      "grad_norm": 0.5741562843322754,
      "learning_rate": 2.6611445783132535e-06,
      "loss": 0.2381,
      "step": 3106
    },
    {
      "epoch": 1.871686746987952,
      "grad_norm": 0.6784057021141052,
      "learning_rate": 2.6603915662650604e-06,
      "loss": 0.2974,
      "step": 3107
    },
    {
      "epoch": 1.872289156626506,
      "grad_norm": 0.6212564706802368,
      "learning_rate": 2.6596385542168678e-06,
      "loss": 0.2755,
      "step": 3108
    },
    {
      "epoch": 1.8728915662650603,
      "grad_norm": 0.5751429796218872,
      "learning_rate": 2.6588855421686747e-06,
      "loss": 0.2338,
      "step": 3109
    },
    {
      "epoch": 1.8734939759036144,
      "grad_norm": 0.7737252712249756,
      "learning_rate": 2.658132530120482e-06,
      "loss": 0.3416,
      "step": 3110
    },
    {
      "epoch": 1.8740963855421686,
      "grad_norm": 0.6992591619491577,
      "learning_rate": 2.6573795180722894e-06,
      "loss": 0.2452,
      "step": 3111
    },
    {
      "epoch": 1.874698795180723,
      "grad_norm": 0.5716558694839478,
      "learning_rate": 2.6566265060240963e-06,
      "loss": 0.2804,
      "step": 3112
    },
    {
      "epoch": 1.875301204819277,
      "grad_norm": 0.7260786294937134,
      "learning_rate": 2.655873493975904e-06,
      "loss": 0.2304,
      "step": 3113
    },
    {
      "epoch": 1.8759036144578314,
      "grad_norm": 0.5433376431465149,
      "learning_rate": 2.655120481927711e-06,
      "loss": 0.2604,
      "step": 3114
    },
    {
      "epoch": 1.8765060240963856,
      "grad_norm": 0.7806674242019653,
      "learning_rate": 2.6543674698795184e-06,
      "loss": 0.3144,
      "step": 3115
    },
    {
      "epoch": 1.8771084337349397,
      "grad_norm": 0.56708824634552,
      "learning_rate": 2.6536144578313257e-06,
      "loss": 0.2332,
      "step": 3116
    },
    {
      "epoch": 1.877710843373494,
      "grad_norm": 0.5967129468917847,
      "learning_rate": 2.6528614457831326e-06,
      "loss": 0.2608,
      "step": 3117
    },
    {
      "epoch": 1.878313253012048,
      "grad_norm": 0.6391881108283997,
      "learning_rate": 2.65210843373494e-06,
      "loss": 0.2164,
      "step": 3118
    },
    {
      "epoch": 1.8789156626506025,
      "grad_norm": 0.4908415377140045,
      "learning_rate": 2.651355421686747e-06,
      "loss": 0.2102,
      "step": 3119
    },
    {
      "epoch": 1.8795180722891565,
      "grad_norm": 0.6740322709083557,
      "learning_rate": 2.6506024096385547e-06,
      "loss": 0.3205,
      "step": 3120
    },
    {
      "epoch": 1.8801204819277109,
      "grad_norm": 0.6062023639678955,
      "learning_rate": 2.6498493975903616e-06,
      "loss": 0.2765,
      "step": 3121
    },
    {
      "epoch": 1.880722891566265,
      "grad_norm": 0.5883563160896301,
      "learning_rate": 2.6490963855421685e-06,
      "loss": 0.2806,
      "step": 3122
    },
    {
      "epoch": 1.8813253012048192,
      "grad_norm": 0.6279758810997009,
      "learning_rate": 2.6483433734939763e-06,
      "loss": 0.2892,
      "step": 3123
    },
    {
      "epoch": 1.8819277108433736,
      "grad_norm": 0.6055791974067688,
      "learning_rate": 2.6475903614457832e-06,
      "loss": 0.2638,
      "step": 3124
    },
    {
      "epoch": 1.8825301204819276,
      "grad_norm": 0.6386858820915222,
      "learning_rate": 2.6468373493975906e-06,
      "loss": 0.3167,
      "step": 3125
    },
    {
      "epoch": 1.883132530120482,
      "grad_norm": 0.6167463660240173,
      "learning_rate": 2.646084337349398e-06,
      "loss": 0.2898,
      "step": 3126
    },
    {
      "epoch": 1.8837349397590362,
      "grad_norm": 0.6951698660850525,
      "learning_rate": 2.6453313253012053e-06,
      "loss": 0.2487,
      "step": 3127
    },
    {
      "epoch": 1.8843373493975903,
      "grad_norm": 0.8114525079727173,
      "learning_rate": 2.644578313253012e-06,
      "loss": 0.2393,
      "step": 3128
    },
    {
      "epoch": 1.8849397590361445,
      "grad_norm": 0.5293447375297546,
      "learning_rate": 2.643825301204819e-06,
      "loss": 0.2386,
      "step": 3129
    },
    {
      "epoch": 1.8855421686746987,
      "grad_norm": 0.6030012965202332,
      "learning_rate": 2.643072289156627e-06,
      "loss": 0.3192,
      "step": 3130
    },
    {
      "epoch": 1.886144578313253,
      "grad_norm": 0.5774451494216919,
      "learning_rate": 2.642319277108434e-06,
      "loss": 0.2364,
      "step": 3131
    },
    {
      "epoch": 1.886746987951807,
      "grad_norm": 0.5596238374710083,
      "learning_rate": 2.6415662650602416e-06,
      "loss": 0.2862,
      "step": 3132
    },
    {
      "epoch": 1.8873493975903615,
      "grad_norm": 0.5919758677482605,
      "learning_rate": 2.6408132530120485e-06,
      "loss": 0.276,
      "step": 3133
    },
    {
      "epoch": 1.8879518072289156,
      "grad_norm": 0.5849523544311523,
      "learning_rate": 2.6400602409638554e-06,
      "loss": 0.269,
      "step": 3134
    },
    {
      "epoch": 1.8885542168674698,
      "grad_norm": 0.7745740413665771,
      "learning_rate": 2.6393072289156628e-06,
      "loss": 0.2848,
      "step": 3135
    },
    {
      "epoch": 1.8891566265060242,
      "grad_norm": 0.656395673751831,
      "learning_rate": 2.63855421686747e-06,
      "loss": 0.2881,
      "step": 3136
    },
    {
      "epoch": 1.8897590361445782,
      "grad_norm": 0.6060119867324829,
      "learning_rate": 2.6378012048192775e-06,
      "loss": 0.2748,
      "step": 3137
    },
    {
      "epoch": 1.8903614457831326,
      "grad_norm": 0.5367897748947144,
      "learning_rate": 2.6370481927710844e-06,
      "loss": 0.2477,
      "step": 3138
    },
    {
      "epoch": 1.8909638554216868,
      "grad_norm": 0.5453497767448425,
      "learning_rate": 2.636295180722892e-06,
      "loss": 0.2135,
      "step": 3139
    },
    {
      "epoch": 1.891566265060241,
      "grad_norm": 0.6374385356903076,
      "learning_rate": 2.635542168674699e-06,
      "loss": 0.3052,
      "step": 3140
    },
    {
      "epoch": 1.8921686746987951,
      "grad_norm": 0.571337103843689,
      "learning_rate": 2.634789156626506e-06,
      "loss": 0.2673,
      "step": 3141
    },
    {
      "epoch": 1.8927710843373493,
      "grad_norm": 0.5748969316482544,
      "learning_rate": 2.634036144578314e-06,
      "loss": 0.2455,
      "step": 3142
    },
    {
      "epoch": 1.8933734939759037,
      "grad_norm": 0.6444056630134583,
      "learning_rate": 2.6332831325301207e-06,
      "loss": 0.2599,
      "step": 3143
    },
    {
      "epoch": 1.8939759036144577,
      "grad_norm": 0.6384322643280029,
      "learning_rate": 2.632530120481928e-06,
      "loss": 0.2297,
      "step": 3144
    },
    {
      "epoch": 1.894578313253012,
      "grad_norm": 0.5618897676467896,
      "learning_rate": 2.631777108433735e-06,
      "loss": 0.2994,
      "step": 3145
    },
    {
      "epoch": 1.8951807228915662,
      "grad_norm": 0.5493547916412354,
      "learning_rate": 2.631024096385542e-06,
      "loss": 0.238,
      "step": 3146
    },
    {
      "epoch": 1.8957831325301204,
      "grad_norm": 0.4990960955619812,
      "learning_rate": 2.6302710843373497e-06,
      "loss": 0.2146,
      "step": 3147
    },
    {
      "epoch": 1.8963855421686748,
      "grad_norm": 0.5862109661102295,
      "learning_rate": 2.6295180722891566e-06,
      "loss": 0.2398,
      "step": 3148
    },
    {
      "epoch": 1.8969879518072288,
      "grad_norm": 0.7640473246574402,
      "learning_rate": 2.6287650602409644e-06,
      "loss": 0.3493,
      "step": 3149
    },
    {
      "epoch": 1.8975903614457832,
      "grad_norm": 0.6301027536392212,
      "learning_rate": 2.6280120481927713e-06,
      "loss": 0.2674,
      "step": 3150
    },
    {
      "epoch": 1.8981927710843374,
      "grad_norm": 0.5163722038269043,
      "learning_rate": 2.6272590361445787e-06,
      "loss": 0.195,
      "step": 3151
    },
    {
      "epoch": 1.8987951807228916,
      "grad_norm": 0.5736712217330933,
      "learning_rate": 2.6265060240963856e-06,
      "loss": 0.2721,
      "step": 3152
    },
    {
      "epoch": 1.8993975903614457,
      "grad_norm": 0.6798304915428162,
      "learning_rate": 2.625753012048193e-06,
      "loss": 0.2824,
      "step": 3153
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.5430425405502319,
      "learning_rate": 2.6250000000000003e-06,
      "loss": 0.2735,
      "step": 3154
    },
    {
      "epoch": 1.9006024096385543,
      "grad_norm": 0.5992231965065002,
      "learning_rate": 2.624246987951807e-06,
      "loss": 0.269,
      "step": 3155
    },
    {
      "epoch": 1.9012048192771083,
      "grad_norm": 0.5642034411430359,
      "learning_rate": 2.623493975903615e-06,
      "loss": 0.2315,
      "step": 3156
    },
    {
      "epoch": 1.9018072289156627,
      "grad_norm": 0.6257142424583435,
      "learning_rate": 2.622740963855422e-06,
      "loss": 0.2757,
      "step": 3157
    },
    {
      "epoch": 1.9024096385542169,
      "grad_norm": 0.5797433853149414,
      "learning_rate": 2.621987951807229e-06,
      "loss": 0.3075,
      "step": 3158
    },
    {
      "epoch": 1.903012048192771,
      "grad_norm": 0.7078094482421875,
      "learning_rate": 2.6212349397590366e-06,
      "loss": 0.2872,
      "step": 3159
    },
    {
      "epoch": 1.9036144578313254,
      "grad_norm": 0.6250106692314148,
      "learning_rate": 2.6204819277108435e-06,
      "loss": 0.3251,
      "step": 3160
    },
    {
      "epoch": 1.9042168674698794,
      "grad_norm": 0.7059879302978516,
      "learning_rate": 2.619728915662651e-06,
      "loss": 0.2584,
      "step": 3161
    },
    {
      "epoch": 1.9048192771084338,
      "grad_norm": 0.6021633148193359,
      "learning_rate": 2.618975903614458e-06,
      "loss": 0.258,
      "step": 3162
    },
    {
      "epoch": 1.905421686746988,
      "grad_norm": 0.5716032981872559,
      "learning_rate": 2.6182228915662656e-06,
      "loss": 0.258,
      "step": 3163
    },
    {
      "epoch": 1.9060240963855422,
      "grad_norm": 0.619914174079895,
      "learning_rate": 2.6174698795180725e-06,
      "loss": 0.2636,
      "step": 3164
    },
    {
      "epoch": 1.9066265060240963,
      "grad_norm": 0.5367321372032166,
      "learning_rate": 2.6167168674698794e-06,
      "loss": 0.2346,
      "step": 3165
    },
    {
      "epoch": 1.9072289156626505,
      "grad_norm": 0.6807891130447388,
      "learning_rate": 2.615963855421687e-06,
      "loss": 0.3373,
      "step": 3166
    },
    {
      "epoch": 1.907831325301205,
      "grad_norm": 0.5148495435714722,
      "learning_rate": 2.615210843373494e-06,
      "loss": 0.2703,
      "step": 3167
    },
    {
      "epoch": 1.9084337349397589,
      "grad_norm": 0.6081481575965881,
      "learning_rate": 2.6144578313253015e-06,
      "loss": 0.2743,
      "step": 3168
    },
    {
      "epoch": 1.9090361445783133,
      "grad_norm": 0.6047347784042358,
      "learning_rate": 2.613704819277109e-06,
      "loss": 0.2276,
      "step": 3169
    },
    {
      "epoch": 1.9096385542168675,
      "grad_norm": 0.5851589441299438,
      "learning_rate": 2.6129518072289157e-06,
      "loss": 0.2261,
      "step": 3170
    },
    {
      "epoch": 1.9102409638554216,
      "grad_norm": 0.5615344047546387,
      "learning_rate": 2.612198795180723e-06,
      "loss": 0.2753,
      "step": 3171
    },
    {
      "epoch": 1.910843373493976,
      "grad_norm": 0.5766253471374512,
      "learning_rate": 2.61144578313253e-06,
      "loss": 0.211,
      "step": 3172
    },
    {
      "epoch": 1.91144578313253,
      "grad_norm": 0.5958265662193298,
      "learning_rate": 2.6106927710843378e-06,
      "loss": 0.2398,
      "step": 3173
    },
    {
      "epoch": 1.9120481927710844,
      "grad_norm": 0.5306608080863953,
      "learning_rate": 2.6099397590361447e-06,
      "loss": 0.2439,
      "step": 3174
    },
    {
      "epoch": 1.9126506024096386,
      "grad_norm": 0.5873633027076721,
      "learning_rate": 2.6091867469879525e-06,
      "loss": 0.2501,
      "step": 3175
    },
    {
      "epoch": 1.9132530120481928,
      "grad_norm": 0.5385767221450806,
      "learning_rate": 2.6084337349397594e-06,
      "loss": 0.2435,
      "step": 3176
    },
    {
      "epoch": 1.913855421686747,
      "grad_norm": 0.5539021492004395,
      "learning_rate": 2.6076807228915663e-06,
      "loss": 0.2437,
      "step": 3177
    },
    {
      "epoch": 1.9144578313253011,
      "grad_norm": 0.6907088160514832,
      "learning_rate": 2.6069277108433737e-06,
      "loss": 0.2831,
      "step": 3178
    },
    {
      "epoch": 1.9150602409638555,
      "grad_norm": 0.5503753423690796,
      "learning_rate": 2.606174698795181e-06,
      "loss": 0.2708,
      "step": 3179
    },
    {
      "epoch": 1.9156626506024095,
      "grad_norm": 0.5738696455955505,
      "learning_rate": 2.6054216867469884e-06,
      "loss": 0.2632,
      "step": 3180
    },
    {
      "epoch": 1.9162650602409639,
      "grad_norm": 0.6257913112640381,
      "learning_rate": 2.6046686746987953e-06,
      "loss": 0.2786,
      "step": 3181
    },
    {
      "epoch": 1.916867469879518,
      "grad_norm": 0.5431970953941345,
      "learning_rate": 2.6039156626506022e-06,
      "loss": 0.2493,
      "step": 3182
    },
    {
      "epoch": 1.9174698795180722,
      "grad_norm": 0.7134976387023926,
      "learning_rate": 2.60316265060241e-06,
      "loss": 0.2314,
      "step": 3183
    },
    {
      "epoch": 1.9180722891566266,
      "grad_norm": 0.6211205720901489,
      "learning_rate": 2.602409638554217e-06,
      "loss": 0.2681,
      "step": 3184
    },
    {
      "epoch": 1.9186746987951806,
      "grad_norm": 0.5782912373542786,
      "learning_rate": 2.6016566265060243e-06,
      "loss": 0.272,
      "step": 3185
    },
    {
      "epoch": 1.919277108433735,
      "grad_norm": 0.6099122762680054,
      "learning_rate": 2.6009036144578316e-06,
      "loss": 0.2397,
      "step": 3186
    },
    {
      "epoch": 1.9198795180722892,
      "grad_norm": 0.5517905950546265,
      "learning_rate": 2.600150602409639e-06,
      "loss": 0.2504,
      "step": 3187
    },
    {
      "epoch": 1.9204819277108434,
      "grad_norm": 0.6014814972877502,
      "learning_rate": 2.599397590361446e-06,
      "loss": 0.2535,
      "step": 3188
    },
    {
      "epoch": 1.9210843373493975,
      "grad_norm": 0.6085145473480225,
      "learning_rate": 2.598644578313253e-06,
      "loss": 0.221,
      "step": 3189
    },
    {
      "epoch": 1.9216867469879517,
      "grad_norm": 0.54904705286026,
      "learning_rate": 2.5978915662650606e-06,
      "loss": 0.2636,
      "step": 3190
    },
    {
      "epoch": 1.9222891566265061,
      "grad_norm": 0.5709123611450195,
      "learning_rate": 2.5971385542168675e-06,
      "loss": 0.2877,
      "step": 3191
    },
    {
      "epoch": 1.92289156626506,
      "grad_norm": 0.5584767460823059,
      "learning_rate": 2.5963855421686753e-06,
      "loss": 0.2285,
      "step": 3192
    },
    {
      "epoch": 1.9234939759036145,
      "grad_norm": 0.637160062789917,
      "learning_rate": 2.595632530120482e-06,
      "loss": 0.2116,
      "step": 3193
    },
    {
      "epoch": 1.9240963855421687,
      "grad_norm": 0.5410520434379578,
      "learning_rate": 2.594879518072289e-06,
      "loss": 0.2058,
      "step": 3194
    },
    {
      "epoch": 1.9246987951807228,
      "grad_norm": 0.57733154296875,
      "learning_rate": 2.5941265060240965e-06,
      "loss": 0.2478,
      "step": 3195
    },
    {
      "epoch": 1.9253012048192772,
      "grad_norm": 0.6830615997314453,
      "learning_rate": 2.593373493975904e-06,
      "loss": 0.2813,
      "step": 3196
    },
    {
      "epoch": 1.9259036144578312,
      "grad_norm": 0.5357493162155151,
      "learning_rate": 2.592620481927711e-06,
      "loss": 0.1933,
      "step": 3197
    },
    {
      "epoch": 1.9265060240963856,
      "grad_norm": 0.5673058032989502,
      "learning_rate": 2.591867469879518e-06,
      "loss": 0.2112,
      "step": 3198
    },
    {
      "epoch": 1.9271084337349398,
      "grad_norm": 0.6732386946678162,
      "learning_rate": 2.591114457831326e-06,
      "loss": 0.2912,
      "step": 3199
    },
    {
      "epoch": 1.927710843373494,
      "grad_norm": 0.5545352101325989,
      "learning_rate": 2.590361445783133e-06,
      "loss": 0.2076,
      "step": 3200
    },
    {
      "epoch": 1.9283132530120481,
      "grad_norm": 0.5551244020462036,
      "learning_rate": 2.5896084337349397e-06,
      "loss": 0.2448,
      "step": 3201
    },
    {
      "epoch": 1.9289156626506023,
      "grad_norm": 0.5452647805213928,
      "learning_rate": 2.5888554216867475e-06,
      "loss": 0.199,
      "step": 3202
    },
    {
      "epoch": 1.9295180722891567,
      "grad_norm": 0.5977333188056946,
      "learning_rate": 2.5881024096385544e-06,
      "loss": 0.2739,
      "step": 3203
    },
    {
      "epoch": 1.9301204819277107,
      "grad_norm": 0.624014139175415,
      "learning_rate": 2.5873493975903618e-06,
      "loss": 0.2737,
      "step": 3204
    },
    {
      "epoch": 1.930722891566265,
      "grad_norm": 0.5483556389808655,
      "learning_rate": 2.5865963855421687e-06,
      "loss": 0.2031,
      "step": 3205
    },
    {
      "epoch": 1.9313253012048193,
      "grad_norm": 0.6183611750602722,
      "learning_rate": 2.585843373493976e-06,
      "loss": 0.2547,
      "step": 3206
    },
    {
      "epoch": 1.9319277108433734,
      "grad_norm": 0.5857467651367188,
      "learning_rate": 2.5850903614457834e-06,
      "loss": 0.2696,
      "step": 3207
    },
    {
      "epoch": 1.9325301204819278,
      "grad_norm": 0.7157143950462341,
      "learning_rate": 2.5843373493975903e-06,
      "loss": 0.2494,
      "step": 3208
    },
    {
      "epoch": 1.9331325301204818,
      "grad_norm": 0.6104727983474731,
      "learning_rate": 2.583584337349398e-06,
      "loss": 0.2472,
      "step": 3209
    },
    {
      "epoch": 1.9337349397590362,
      "grad_norm": 0.4918639361858368,
      "learning_rate": 2.582831325301205e-06,
      "loss": 0.1926,
      "step": 3210
    },
    {
      "epoch": 1.9343373493975904,
      "grad_norm": 0.5502023696899414,
      "learning_rate": 2.5820783132530124e-06,
      "loss": 0.2024,
      "step": 3211
    },
    {
      "epoch": 1.9349397590361446,
      "grad_norm": 0.7231521010398865,
      "learning_rate": 2.5813253012048197e-06,
      "loss": 0.2878,
      "step": 3212
    },
    {
      "epoch": 1.9355421686746987,
      "grad_norm": 0.6682872176170349,
      "learning_rate": 2.5805722891566266e-06,
      "loss": 0.2662,
      "step": 3213
    },
    {
      "epoch": 1.936144578313253,
      "grad_norm": 0.5573123097419739,
      "learning_rate": 2.579819277108434e-06,
      "loss": 0.24,
      "step": 3214
    },
    {
      "epoch": 1.9367469879518073,
      "grad_norm": 0.5911213755607605,
      "learning_rate": 2.579066265060241e-06,
      "loss": 0.2251,
      "step": 3215
    },
    {
      "epoch": 1.9373493975903613,
      "grad_norm": 0.5243656039237976,
      "learning_rate": 2.5783132530120487e-06,
      "loss": 0.2108,
      "step": 3216
    },
    {
      "epoch": 1.9379518072289157,
      "grad_norm": 0.5805282592773438,
      "learning_rate": 2.5775602409638556e-06,
      "loss": 0.2531,
      "step": 3217
    },
    {
      "epoch": 1.9385542168674699,
      "grad_norm": 0.5483254790306091,
      "learning_rate": 2.5768072289156625e-06,
      "loss": 0.1972,
      "step": 3218
    },
    {
      "epoch": 1.939156626506024,
      "grad_norm": 0.5801590085029602,
      "learning_rate": 2.5760542168674703e-06,
      "loss": 0.2072,
      "step": 3219
    },
    {
      "epoch": 1.9397590361445785,
      "grad_norm": 0.5822049379348755,
      "learning_rate": 2.5753012048192772e-06,
      "loss": 0.3147,
      "step": 3220
    },
    {
      "epoch": 1.9403614457831324,
      "grad_norm": 0.6339209079742432,
      "learning_rate": 2.5745481927710846e-06,
      "loss": 0.3042,
      "step": 3221
    },
    {
      "epoch": 1.9409638554216868,
      "grad_norm": 0.620611846446991,
      "learning_rate": 2.5737951807228915e-06,
      "loss": 0.2566,
      "step": 3222
    },
    {
      "epoch": 1.941566265060241,
      "grad_norm": 0.5990533232688904,
      "learning_rate": 2.5730421686746993e-06,
      "loss": 0.2459,
      "step": 3223
    },
    {
      "epoch": 1.9421686746987952,
      "grad_norm": 0.5454714894294739,
      "learning_rate": 2.572289156626506e-06,
      "loss": 0.2723,
      "step": 3224
    },
    {
      "epoch": 1.9427710843373494,
      "grad_norm": 0.47272413969039917,
      "learning_rate": 2.571536144578313e-06,
      "loss": 0.2061,
      "step": 3225
    },
    {
      "epoch": 1.9433734939759035,
      "grad_norm": 0.5002028346061707,
      "learning_rate": 2.570783132530121e-06,
      "loss": 0.1912,
      "step": 3226
    },
    {
      "epoch": 1.943975903614458,
      "grad_norm": 0.5795593857765198,
      "learning_rate": 2.570030120481928e-06,
      "loss": 0.29,
      "step": 3227
    },
    {
      "epoch": 1.944578313253012,
      "grad_norm": 0.5477785468101501,
      "learning_rate": 2.569277108433735e-06,
      "loss": 0.2505,
      "step": 3228
    },
    {
      "epoch": 1.9451807228915663,
      "grad_norm": 0.5305472612380981,
      "learning_rate": 2.5685240963855425e-06,
      "loss": 0.207,
      "step": 3229
    },
    {
      "epoch": 1.9457831325301205,
      "grad_norm": 0.5369771122932434,
      "learning_rate": 2.5677710843373494e-06,
      "loss": 0.2389,
      "step": 3230
    },
    {
      "epoch": 1.9463855421686747,
      "grad_norm": 0.7032210826873779,
      "learning_rate": 2.5670180722891568e-06,
      "loss": 0.2735,
      "step": 3231
    },
    {
      "epoch": 1.946987951807229,
      "grad_norm": 0.5660738945007324,
      "learning_rate": 2.5662650602409637e-06,
      "loss": 0.2507,
      "step": 3232
    },
    {
      "epoch": 1.947590361445783,
      "grad_norm": 0.5821724534034729,
      "learning_rate": 2.5655120481927715e-06,
      "loss": 0.201,
      "step": 3233
    },
    {
      "epoch": 1.9481927710843374,
      "grad_norm": 0.6345906853675842,
      "learning_rate": 2.5647590361445784e-06,
      "loss": 0.2102,
      "step": 3234
    },
    {
      "epoch": 1.9487951807228916,
      "grad_norm": 0.6036908030509949,
      "learning_rate": 2.564006024096386e-06,
      "loss": 0.2839,
      "step": 3235
    },
    {
      "epoch": 1.9493975903614458,
      "grad_norm": 0.6351702809333801,
      "learning_rate": 2.563253012048193e-06,
      "loss": 0.1806,
      "step": 3236
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.6102986931800842,
      "learning_rate": 2.5625e-06,
      "loss": 0.2344,
      "step": 3237
    },
    {
      "epoch": 1.9506024096385541,
      "grad_norm": 0.5664275288581848,
      "learning_rate": 2.5617469879518074e-06,
      "loss": 0.2894,
      "step": 3238
    },
    {
      "epoch": 1.9512048192771085,
      "grad_norm": 0.6163204908370972,
      "learning_rate": 2.5609939759036147e-06,
      "loss": 0.2743,
      "step": 3239
    },
    {
      "epoch": 1.9518072289156625,
      "grad_norm": 0.6781104803085327,
      "learning_rate": 2.560240963855422e-06,
      "loss": 0.2994,
      "step": 3240
    },
    {
      "epoch": 1.952409638554217,
      "grad_norm": 0.6382510662078857,
      "learning_rate": 2.559487951807229e-06,
      "loss": 0.2714,
      "step": 3241
    },
    {
      "epoch": 1.953012048192771,
      "grad_norm": 0.8111344575881958,
      "learning_rate": 2.558734939759036e-06,
      "loss": 0.3056,
      "step": 3242
    },
    {
      "epoch": 1.9536144578313253,
      "grad_norm": 0.5992786884307861,
      "learning_rate": 2.5579819277108437e-06,
      "loss": 0.214,
      "step": 3243
    },
    {
      "epoch": 1.9542168674698797,
      "grad_norm": 0.5807995200157166,
      "learning_rate": 2.5572289156626506e-06,
      "loss": 0.2562,
      "step": 3244
    },
    {
      "epoch": 1.9548192771084336,
      "grad_norm": 0.8119271397590637,
      "learning_rate": 2.5564759036144584e-06,
      "loss": 0.269,
      "step": 3245
    },
    {
      "epoch": 1.955421686746988,
      "grad_norm": 0.599631130695343,
      "learning_rate": 2.5557228915662653e-06,
      "loss": 0.282,
      "step": 3246
    },
    {
      "epoch": 1.9560240963855422,
      "grad_norm": 0.5550262331962585,
      "learning_rate": 2.5549698795180727e-06,
      "loss": 0.223,
      "step": 3247
    },
    {
      "epoch": 1.9566265060240964,
      "grad_norm": 0.5861968994140625,
      "learning_rate": 2.5542168674698796e-06,
      "loss": 0.2677,
      "step": 3248
    },
    {
      "epoch": 1.9572289156626506,
      "grad_norm": 0.5967864990234375,
      "learning_rate": 2.553463855421687e-06,
      "loss": 0.2799,
      "step": 3249
    },
    {
      "epoch": 1.9578313253012047,
      "grad_norm": 0.5226314067840576,
      "learning_rate": 2.5527108433734943e-06,
      "loss": 0.2454,
      "step": 3250
    },
    {
      "epoch": 1.9584337349397591,
      "grad_norm": 0.6252250075340271,
      "learning_rate": 2.5519578313253012e-06,
      "loss": 0.2705,
      "step": 3251
    },
    {
      "epoch": 1.959036144578313,
      "grad_norm": 0.6760451197624207,
      "learning_rate": 2.551204819277109e-06,
      "loss": 0.2574,
      "step": 3252
    },
    {
      "epoch": 1.9596385542168675,
      "grad_norm": 0.6225343942642212,
      "learning_rate": 2.550451807228916e-06,
      "loss": 0.2133,
      "step": 3253
    },
    {
      "epoch": 1.9602409638554217,
      "grad_norm": 0.6044511198997498,
      "learning_rate": 2.549698795180723e-06,
      "loss": 0.2088,
      "step": 3254
    },
    {
      "epoch": 1.9608433734939759,
      "grad_norm": 0.668098509311676,
      "learning_rate": 2.54894578313253e-06,
      "loss": 0.2588,
      "step": 3255
    },
    {
      "epoch": 1.9614457831325303,
      "grad_norm": 0.5919760465621948,
      "learning_rate": 2.5481927710843375e-06,
      "loss": 0.2597,
      "step": 3256
    },
    {
      "epoch": 1.9620481927710842,
      "grad_norm": 0.5607988238334656,
      "learning_rate": 2.547439759036145e-06,
      "loss": 0.2435,
      "step": 3257
    },
    {
      "epoch": 1.9626506024096386,
      "grad_norm": 0.5891239047050476,
      "learning_rate": 2.546686746987952e-06,
      "loss": 0.2606,
      "step": 3258
    },
    {
      "epoch": 1.9632530120481928,
      "grad_norm": 0.609943687915802,
      "learning_rate": 2.5459337349397596e-06,
      "loss": 0.249,
      "step": 3259
    },
    {
      "epoch": 1.963855421686747,
      "grad_norm": 0.6080290079116821,
      "learning_rate": 2.5451807228915665e-06,
      "loss": 0.2671,
      "step": 3260
    },
    {
      "epoch": 1.9644578313253012,
      "grad_norm": 0.629896342754364,
      "learning_rate": 2.5444277108433734e-06,
      "loss": 0.2326,
      "step": 3261
    },
    {
      "epoch": 1.9650602409638553,
      "grad_norm": 0.624618411064148,
      "learning_rate": 2.543674698795181e-06,
      "loss": 0.2721,
      "step": 3262
    },
    {
      "epoch": 1.9656626506024097,
      "grad_norm": 0.558030903339386,
      "learning_rate": 2.542921686746988e-06,
      "loss": 0.2404,
      "step": 3263
    },
    {
      "epoch": 1.9662650602409637,
      "grad_norm": 0.8760672807693481,
      "learning_rate": 2.5421686746987955e-06,
      "loss": 0.3266,
      "step": 3264
    },
    {
      "epoch": 1.966867469879518,
      "grad_norm": 0.7646276950836182,
      "learning_rate": 2.5414156626506024e-06,
      "loss": 0.288,
      "step": 3265
    },
    {
      "epoch": 1.9674698795180723,
      "grad_norm": 0.5714373588562012,
      "learning_rate": 2.5406626506024097e-06,
      "loss": 0.2594,
      "step": 3266
    },
    {
      "epoch": 1.9680722891566265,
      "grad_norm": 0.6490867137908936,
      "learning_rate": 2.539909638554217e-06,
      "loss": 0.249,
      "step": 3267
    },
    {
      "epoch": 1.9686746987951809,
      "grad_norm": 0.6648671627044678,
      "learning_rate": 2.539156626506024e-06,
      "loss": 0.3287,
      "step": 3268
    },
    {
      "epoch": 1.9692771084337348,
      "grad_norm": 0.7334941029548645,
      "learning_rate": 2.538403614457832e-06,
      "loss": 0.337,
      "step": 3269
    },
    {
      "epoch": 1.9698795180722892,
      "grad_norm": 0.5544813275337219,
      "learning_rate": 2.5376506024096387e-06,
      "loss": 0.2337,
      "step": 3270
    },
    {
      "epoch": 1.9704819277108434,
      "grad_norm": 0.5805374383926392,
      "learning_rate": 2.536897590361446e-06,
      "loss": 0.2446,
      "step": 3271
    },
    {
      "epoch": 1.9710843373493976,
      "grad_norm": 0.5941969156265259,
      "learning_rate": 2.5361445783132534e-06,
      "loss": 0.2671,
      "step": 3272
    },
    {
      "epoch": 1.9716867469879518,
      "grad_norm": 0.5831687450408936,
      "learning_rate": 2.5353915662650603e-06,
      "loss": 0.2885,
      "step": 3273
    },
    {
      "epoch": 1.972289156626506,
      "grad_norm": 0.5570191144943237,
      "learning_rate": 2.5346385542168677e-06,
      "loss": 0.205,
      "step": 3274
    },
    {
      "epoch": 1.9728915662650603,
      "grad_norm": 0.5429847836494446,
      "learning_rate": 2.5338855421686746e-06,
      "loss": 0.1935,
      "step": 3275
    },
    {
      "epoch": 1.9734939759036143,
      "grad_norm": 0.7764939665794373,
      "learning_rate": 2.5331325301204824e-06,
      "loss": 0.3015,
      "step": 3276
    },
    {
      "epoch": 1.9740963855421687,
      "grad_norm": 0.5336548686027527,
      "learning_rate": 2.5323795180722893e-06,
      "loss": 0.2534,
      "step": 3277
    },
    {
      "epoch": 1.9746987951807229,
      "grad_norm": 0.5727588534355164,
      "learning_rate": 2.5316265060240962e-06,
      "loss": 0.2739,
      "step": 3278
    },
    {
      "epoch": 1.975301204819277,
      "grad_norm": 0.5974290370941162,
      "learning_rate": 2.530873493975904e-06,
      "loss": 0.2461,
      "step": 3279
    },
    {
      "epoch": 1.9759036144578315,
      "grad_norm": 0.5666519999504089,
      "learning_rate": 2.530120481927711e-06,
      "loss": 0.2197,
      "step": 3280
    },
    {
      "epoch": 1.9765060240963854,
      "grad_norm": 0.6265653371810913,
      "learning_rate": 2.5293674698795183e-06,
      "loss": 0.2308,
      "step": 3281
    },
    {
      "epoch": 1.9771084337349398,
      "grad_norm": 0.5780048966407776,
      "learning_rate": 2.5286144578313256e-06,
      "loss": 0.2294,
      "step": 3282
    },
    {
      "epoch": 1.977710843373494,
      "grad_norm": 0.5834525227546692,
      "learning_rate": 2.527861445783133e-06,
      "loss": 0.2942,
      "step": 3283
    },
    {
      "epoch": 1.9783132530120482,
      "grad_norm": 0.5870824456214905,
      "learning_rate": 2.52710843373494e-06,
      "loss": 0.2291,
      "step": 3284
    },
    {
      "epoch": 1.9789156626506024,
      "grad_norm": 0.5808792114257812,
      "learning_rate": 2.526355421686747e-06,
      "loss": 0.2537,
      "step": 3285
    },
    {
      "epoch": 1.9795180722891565,
      "grad_norm": 0.8376796245574951,
      "learning_rate": 2.5256024096385546e-06,
      "loss": 0.2686,
      "step": 3286
    },
    {
      "epoch": 1.980120481927711,
      "grad_norm": 0.7481284141540527,
      "learning_rate": 2.5248493975903615e-06,
      "loss": 0.2945,
      "step": 3287
    },
    {
      "epoch": 1.980722891566265,
      "grad_norm": 0.6015635132789612,
      "learning_rate": 2.524096385542169e-06,
      "loss": 0.3107,
      "step": 3288
    },
    {
      "epoch": 1.9813253012048193,
      "grad_norm": 0.5454339981079102,
      "learning_rate": 2.5233433734939762e-06,
      "loss": 0.2215,
      "step": 3289
    },
    {
      "epoch": 1.9819277108433735,
      "grad_norm": 0.6216524839401245,
      "learning_rate": 2.522590361445783e-06,
      "loss": 0.3184,
      "step": 3290
    },
    {
      "epoch": 1.9825301204819277,
      "grad_norm": 0.6528908014297485,
      "learning_rate": 2.5218373493975905e-06,
      "loss": 0.2679,
      "step": 3291
    },
    {
      "epoch": 1.983132530120482,
      "grad_norm": 0.586555540561676,
      "learning_rate": 2.5210843373493974e-06,
      "loss": 0.2109,
      "step": 3292
    },
    {
      "epoch": 1.983734939759036,
      "grad_norm": 0.5869808793067932,
      "learning_rate": 2.520331325301205e-06,
      "loss": 0.2127,
      "step": 3293
    },
    {
      "epoch": 1.9843373493975904,
      "grad_norm": 0.58155357837677,
      "learning_rate": 2.519578313253012e-06,
      "loss": 0.2718,
      "step": 3294
    },
    {
      "epoch": 1.9849397590361446,
      "grad_norm": 0.6427553296089172,
      "learning_rate": 2.51882530120482e-06,
      "loss": 0.2784,
      "step": 3295
    },
    {
      "epoch": 1.9855421686746988,
      "grad_norm": 0.7626997828483582,
      "learning_rate": 2.518072289156627e-06,
      "loss": 0.3236,
      "step": 3296
    },
    {
      "epoch": 1.986144578313253,
      "grad_norm": 0.5753155946731567,
      "learning_rate": 2.5173192771084337e-06,
      "loss": 0.3017,
      "step": 3297
    },
    {
      "epoch": 1.9867469879518072,
      "grad_norm": 0.6438107490539551,
      "learning_rate": 2.516566265060241e-06,
      "loss": 0.3313,
      "step": 3298
    },
    {
      "epoch": 1.9873493975903616,
      "grad_norm": 0.6169772744178772,
      "learning_rate": 2.5158132530120484e-06,
      "loss": 0.282,
      "step": 3299
    },
    {
      "epoch": 1.9879518072289155,
      "grad_norm": 0.5052189826965332,
      "learning_rate": 2.5150602409638558e-06,
      "loss": 0.2343,
      "step": 3300
    },
    {
      "epoch": 1.98855421686747,
      "grad_norm": 0.7864608764648438,
      "learning_rate": 2.5143072289156627e-06,
      "loss": 0.2947,
      "step": 3301
    },
    {
      "epoch": 1.989156626506024,
      "grad_norm": 0.688396155834198,
      "learning_rate": 2.5135542168674696e-06,
      "loss": 0.2184,
      "step": 3302
    },
    {
      "epoch": 1.9897590361445783,
      "grad_norm": 0.7367432117462158,
      "learning_rate": 2.5128012048192774e-06,
      "loss": 0.3379,
      "step": 3303
    },
    {
      "epoch": 1.9903614457831327,
      "grad_norm": 0.5175305008888245,
      "learning_rate": 2.5120481927710843e-06,
      "loss": 0.2373,
      "step": 3304
    },
    {
      "epoch": 1.9909638554216866,
      "grad_norm": 0.6765639185905457,
      "learning_rate": 2.511295180722892e-06,
      "loss": 0.2994,
      "step": 3305
    },
    {
      "epoch": 1.991566265060241,
      "grad_norm": 0.532923698425293,
      "learning_rate": 2.510542168674699e-06,
      "loss": 0.2751,
      "step": 3306
    },
    {
      "epoch": 1.9921686746987952,
      "grad_norm": 0.6391251087188721,
      "learning_rate": 2.5097891566265064e-06,
      "loss": 0.2696,
      "step": 3307
    },
    {
      "epoch": 1.9927710843373494,
      "grad_norm": 0.5296996235847473,
      "learning_rate": 2.5090361445783133e-06,
      "loss": 0.2498,
      "step": 3308
    },
    {
      "epoch": 1.9933734939759036,
      "grad_norm": 0.5746636986732483,
      "learning_rate": 2.5082831325301206e-06,
      "loss": 0.2551,
      "step": 3309
    },
    {
      "epoch": 1.9939759036144578,
      "grad_norm": 0.5233425498008728,
      "learning_rate": 2.507530120481928e-06,
      "loss": 0.2656,
      "step": 3310
    },
    {
      "epoch": 1.9945783132530122,
      "grad_norm": 0.6373552083969116,
      "learning_rate": 2.506777108433735e-06,
      "loss": 0.2012,
      "step": 3311
    },
    {
      "epoch": 1.9951807228915661,
      "grad_norm": 0.6019036173820496,
      "learning_rate": 2.5060240963855427e-06,
      "loss": 0.2542,
      "step": 3312
    },
    {
      "epoch": 1.9957831325301205,
      "grad_norm": 0.607774019241333,
      "learning_rate": 2.5052710843373496e-06,
      "loss": 0.2647,
      "step": 3313
    },
    {
      "epoch": 1.9963855421686747,
      "grad_norm": 0.5534173250198364,
      "learning_rate": 2.5045180722891565e-06,
      "loss": 0.2327,
      "step": 3314
    },
    {
      "epoch": 1.9969879518072289,
      "grad_norm": 0.6042105555534363,
      "learning_rate": 2.5037650602409643e-06,
      "loss": 0.3276,
      "step": 3315
    },
    {
      "epoch": 1.9975903614457833,
      "grad_norm": 0.6341678500175476,
      "learning_rate": 2.5030120481927712e-06,
      "loss": 0.2704,
      "step": 3316
    },
    {
      "epoch": 1.9981927710843372,
      "grad_norm": 0.5779947638511658,
      "learning_rate": 2.5022590361445786e-06,
      "loss": 0.2073,
      "step": 3317
    },
    {
      "epoch": 1.9987951807228916,
      "grad_norm": 0.5716872811317444,
      "learning_rate": 2.5015060240963855e-06,
      "loss": 0.2436,
      "step": 3318
    },
    {
      "epoch": 1.9993975903614458,
      "grad_norm": 0.5450007319450378,
      "learning_rate": 2.5007530120481933e-06,
      "loss": 0.2154,
      "step": 3319
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6385161876678467,
      "learning_rate": 2.5e-06,
      "loss": 0.3092,
      "step": 3320
    },
    {
      "epoch": 2.0006024096385544,
      "grad_norm": 0.8024923205375671,
      "learning_rate": 2.4992469879518076e-06,
      "loss": 0.1702,
      "step": 3321
    },
    {
      "epoch": 2.0012048192771084,
      "grad_norm": 0.8469679355621338,
      "learning_rate": 2.498493975903615e-06,
      "loss": 0.1874,
      "step": 3322
    },
    {
      "epoch": 2.0018072289156628,
      "grad_norm": 0.7643341422080994,
      "learning_rate": 2.497740963855422e-06,
      "loss": 0.1674,
      "step": 3323
    },
    {
      "epoch": 2.0024096385542167,
      "grad_norm": 0.9172062277793884,
      "learning_rate": 2.496987951807229e-06,
      "loss": 0.2207,
      "step": 3324
    },
    {
      "epoch": 2.003012048192771,
      "grad_norm": 0.9315671920776367,
      "learning_rate": 2.496234939759036e-06,
      "loss": 0.2128,
      "step": 3325
    },
    {
      "epoch": 2.003614457831325,
      "grad_norm": 0.8643494844436646,
      "learning_rate": 2.4954819277108434e-06,
      "loss": 0.1942,
      "step": 3326
    },
    {
      "epoch": 2.0042168674698795,
      "grad_norm": 0.6451783180236816,
      "learning_rate": 2.494728915662651e-06,
      "loss": 0.1992,
      "step": 3327
    },
    {
      "epoch": 2.004819277108434,
      "grad_norm": 0.6450877785682678,
      "learning_rate": 2.493975903614458e-06,
      "loss": 0.2158,
      "step": 3328
    },
    {
      "epoch": 2.005421686746988,
      "grad_norm": 0.6373112201690674,
      "learning_rate": 2.4932228915662655e-06,
      "loss": 0.2265,
      "step": 3329
    },
    {
      "epoch": 2.0060240963855422,
      "grad_norm": 0.6666014790534973,
      "learning_rate": 2.4924698795180724e-06,
      "loss": 0.1613,
      "step": 3330
    },
    {
      "epoch": 2.006626506024096,
      "grad_norm": 0.7412822842597961,
      "learning_rate": 2.4917168674698798e-06,
      "loss": 0.188,
      "step": 3331
    },
    {
      "epoch": 2.0072289156626506,
      "grad_norm": 0.7405569553375244,
      "learning_rate": 2.490963855421687e-06,
      "loss": 0.2192,
      "step": 3332
    },
    {
      "epoch": 2.007831325301205,
      "grad_norm": 0.7187984585762024,
      "learning_rate": 2.490210843373494e-06,
      "loss": 0.2131,
      "step": 3333
    },
    {
      "epoch": 2.008433734939759,
      "grad_norm": 0.6788316369056702,
      "learning_rate": 2.4894578313253014e-06,
      "loss": 0.1518,
      "step": 3334
    },
    {
      "epoch": 2.0090361445783134,
      "grad_norm": 0.6207025647163391,
      "learning_rate": 2.4887048192771087e-06,
      "loss": 0.2051,
      "step": 3335
    },
    {
      "epoch": 2.0096385542168673,
      "grad_norm": 0.6455203294754028,
      "learning_rate": 2.4879518072289157e-06,
      "loss": 0.1524,
      "step": 3336
    },
    {
      "epoch": 2.0102409638554217,
      "grad_norm": 0.6969999074935913,
      "learning_rate": 2.487198795180723e-06,
      "loss": 0.1972,
      "step": 3337
    },
    {
      "epoch": 2.0108433734939757,
      "grad_norm": 0.74053555727005,
      "learning_rate": 2.4864457831325304e-06,
      "loss": 0.2118,
      "step": 3338
    },
    {
      "epoch": 2.01144578313253,
      "grad_norm": 0.5795629024505615,
      "learning_rate": 2.4856927710843377e-06,
      "loss": 0.2087,
      "step": 3339
    },
    {
      "epoch": 2.0120481927710845,
      "grad_norm": 0.5396515727043152,
      "learning_rate": 2.484939759036145e-06,
      "loss": 0.1688,
      "step": 3340
    },
    {
      "epoch": 2.0126506024096384,
      "grad_norm": 0.6875001788139343,
      "learning_rate": 2.484186746987952e-06,
      "loss": 0.18,
      "step": 3341
    },
    {
      "epoch": 2.013253012048193,
      "grad_norm": 0.7106782793998718,
      "learning_rate": 2.4834337349397593e-06,
      "loss": 0.1842,
      "step": 3342
    },
    {
      "epoch": 2.013855421686747,
      "grad_norm": 0.6441059708595276,
      "learning_rate": 2.4826807228915663e-06,
      "loss": 0.2261,
      "step": 3343
    },
    {
      "epoch": 2.014457831325301,
      "grad_norm": 0.6201217770576477,
      "learning_rate": 2.4819277108433736e-06,
      "loss": 0.1763,
      "step": 3344
    },
    {
      "epoch": 2.0150602409638556,
      "grad_norm": 0.6825686097145081,
      "learning_rate": 2.481174698795181e-06,
      "loss": 0.1975,
      "step": 3345
    },
    {
      "epoch": 2.0156626506024096,
      "grad_norm": 0.6102952361106873,
      "learning_rate": 2.4804216867469883e-06,
      "loss": 0.1968,
      "step": 3346
    },
    {
      "epoch": 2.016265060240964,
      "grad_norm": 0.5768699049949646,
      "learning_rate": 2.4796686746987956e-06,
      "loss": 0.243,
      "step": 3347
    },
    {
      "epoch": 2.016867469879518,
      "grad_norm": 0.591445803642273,
      "learning_rate": 2.4789156626506026e-06,
      "loss": 0.1601,
      "step": 3348
    },
    {
      "epoch": 2.0174698795180723,
      "grad_norm": 0.6461237072944641,
      "learning_rate": 2.47816265060241e-06,
      "loss": 0.172,
      "step": 3349
    },
    {
      "epoch": 2.0180722891566263,
      "grad_norm": 0.6624032855033875,
      "learning_rate": 2.4774096385542173e-06,
      "loss": 0.1579,
      "step": 3350
    },
    {
      "epoch": 2.0186746987951807,
      "grad_norm": 0.5834676027297974,
      "learning_rate": 2.476656626506024e-06,
      "loss": 0.1562,
      "step": 3351
    },
    {
      "epoch": 2.019277108433735,
      "grad_norm": 0.572773277759552,
      "learning_rate": 2.4759036144578315e-06,
      "loss": 0.1676,
      "step": 3352
    },
    {
      "epoch": 2.019879518072289,
      "grad_norm": 0.5460970997810364,
      "learning_rate": 2.475150602409639e-06,
      "loss": 0.1816,
      "step": 3353
    },
    {
      "epoch": 2.0204819277108435,
      "grad_norm": 0.6180958151817322,
      "learning_rate": 2.474397590361446e-06,
      "loss": 0.196,
      "step": 3354
    },
    {
      "epoch": 2.0210843373493974,
      "grad_norm": 0.5671325922012329,
      "learning_rate": 2.473644578313253e-06,
      "loss": 0.1725,
      "step": 3355
    },
    {
      "epoch": 2.021686746987952,
      "grad_norm": 0.5987182259559631,
      "learning_rate": 2.4728915662650605e-06,
      "loss": 0.1938,
      "step": 3356
    },
    {
      "epoch": 2.022289156626506,
      "grad_norm": 0.5223979353904724,
      "learning_rate": 2.472138554216868e-06,
      "loss": 0.1893,
      "step": 3357
    },
    {
      "epoch": 2.02289156626506,
      "grad_norm": 0.5686728358268738,
      "learning_rate": 2.4713855421686748e-06,
      "loss": 0.2406,
      "step": 3358
    },
    {
      "epoch": 2.0234939759036146,
      "grad_norm": 0.6389288902282715,
      "learning_rate": 2.470632530120482e-06,
      "loss": 0.1919,
      "step": 3359
    },
    {
      "epoch": 2.0240963855421685,
      "grad_norm": 0.5871267914772034,
      "learning_rate": 2.469879518072289e-06,
      "loss": 0.1517,
      "step": 3360
    },
    {
      "epoch": 2.024698795180723,
      "grad_norm": 0.6171734929084778,
      "learning_rate": 2.4691265060240964e-06,
      "loss": 0.1521,
      "step": 3361
    },
    {
      "epoch": 2.025301204819277,
      "grad_norm": 0.5852165222167969,
      "learning_rate": 2.4683734939759038e-06,
      "loss": 0.1789,
      "step": 3362
    },
    {
      "epoch": 2.0259036144578313,
      "grad_norm": 0.6011784076690674,
      "learning_rate": 2.467620481927711e-06,
      "loss": 0.1527,
      "step": 3363
    },
    {
      "epoch": 2.0265060240963857,
      "grad_norm": 0.5434779524803162,
      "learning_rate": 2.4668674698795185e-06,
      "loss": 0.2268,
      "step": 3364
    },
    {
      "epoch": 2.0271084337349397,
      "grad_norm": 0.4970790147781372,
      "learning_rate": 2.466114457831326e-06,
      "loss": 0.187,
      "step": 3365
    },
    {
      "epoch": 2.027710843373494,
      "grad_norm": 0.5530688166618347,
      "learning_rate": 2.4653614457831327e-06,
      "loss": 0.2219,
      "step": 3366
    },
    {
      "epoch": 2.028313253012048,
      "grad_norm": 0.579724133014679,
      "learning_rate": 2.46460843373494e-06,
      "loss": 0.1527,
      "step": 3367
    },
    {
      "epoch": 2.0289156626506024,
      "grad_norm": 0.515040397644043,
      "learning_rate": 2.463855421686747e-06,
      "loss": 0.1587,
      "step": 3368
    },
    {
      "epoch": 2.029518072289157,
      "grad_norm": 0.5909228920936584,
      "learning_rate": 2.4631024096385543e-06,
      "loss": 0.1683,
      "step": 3369
    },
    {
      "epoch": 2.0301204819277108,
      "grad_norm": 0.6429057717323303,
      "learning_rate": 2.4623493975903617e-06,
      "loss": 0.1773,
      "step": 3370
    },
    {
      "epoch": 2.030722891566265,
      "grad_norm": 0.5986312031745911,
      "learning_rate": 2.461596385542169e-06,
      "loss": 0.1745,
      "step": 3371
    },
    {
      "epoch": 2.031325301204819,
      "grad_norm": 0.5634295344352722,
      "learning_rate": 2.460843373493976e-06,
      "loss": 0.1688,
      "step": 3372
    },
    {
      "epoch": 2.0319277108433735,
      "grad_norm": 1.048356294631958,
      "learning_rate": 2.4600903614457833e-06,
      "loss": 0.1965,
      "step": 3373
    },
    {
      "epoch": 2.0325301204819275,
      "grad_norm": 0.6557255983352661,
      "learning_rate": 2.4593373493975907e-06,
      "loss": 0.2,
      "step": 3374
    },
    {
      "epoch": 2.033132530120482,
      "grad_norm": 0.4661986231803894,
      "learning_rate": 2.458584337349398e-06,
      "loss": 0.1529,
      "step": 3375
    },
    {
      "epoch": 2.0337349397590363,
      "grad_norm": 0.558846116065979,
      "learning_rate": 2.457831325301205e-06,
      "loss": 0.2077,
      "step": 3376
    },
    {
      "epoch": 2.0343373493975903,
      "grad_norm": 0.5065878033638,
      "learning_rate": 2.4570783132530123e-06,
      "loss": 0.1369,
      "step": 3377
    },
    {
      "epoch": 2.0349397590361447,
      "grad_norm": 0.5246680378913879,
      "learning_rate": 2.456325301204819e-06,
      "loss": 0.2016,
      "step": 3378
    },
    {
      "epoch": 2.0355421686746986,
      "grad_norm": 0.5443844199180603,
      "learning_rate": 2.4555722891566266e-06,
      "loss": 0.1464,
      "step": 3379
    },
    {
      "epoch": 2.036144578313253,
      "grad_norm": 0.5528634190559387,
      "learning_rate": 2.454819277108434e-06,
      "loss": 0.1685,
      "step": 3380
    },
    {
      "epoch": 2.0367469879518074,
      "grad_norm": 0.605064868927002,
      "learning_rate": 2.4540662650602413e-06,
      "loss": 0.1666,
      "step": 3381
    },
    {
      "epoch": 2.0373493975903614,
      "grad_norm": 0.4591310918331146,
      "learning_rate": 2.4533132530120486e-06,
      "loss": 0.1691,
      "step": 3382
    },
    {
      "epoch": 2.037951807228916,
      "grad_norm": 0.5457998514175415,
      "learning_rate": 2.452560240963856e-06,
      "loss": 0.1719,
      "step": 3383
    },
    {
      "epoch": 2.0385542168674697,
      "grad_norm": 0.6010745763778687,
      "learning_rate": 2.451807228915663e-06,
      "loss": 0.25,
      "step": 3384
    },
    {
      "epoch": 2.039156626506024,
      "grad_norm": 0.9340564608573914,
      "learning_rate": 2.4510542168674702e-06,
      "loss": 0.1603,
      "step": 3385
    },
    {
      "epoch": 2.039759036144578,
      "grad_norm": 0.5325174927711487,
      "learning_rate": 2.450301204819277e-06,
      "loss": 0.1501,
      "step": 3386
    },
    {
      "epoch": 2.0403614457831325,
      "grad_norm": 0.5137730836868286,
      "learning_rate": 2.4495481927710845e-06,
      "loss": 0.1944,
      "step": 3387
    },
    {
      "epoch": 2.040963855421687,
      "grad_norm": 0.6149349212646484,
      "learning_rate": 2.448795180722892e-06,
      "loss": 0.1507,
      "step": 3388
    },
    {
      "epoch": 2.041566265060241,
      "grad_norm": 2.355217933654785,
      "learning_rate": 2.448042168674699e-06,
      "loss": 0.2,
      "step": 3389
    },
    {
      "epoch": 2.0421686746987953,
      "grad_norm": 0.5311011672019958,
      "learning_rate": 2.447289156626506e-06,
      "loss": 0.1383,
      "step": 3390
    },
    {
      "epoch": 2.042771084337349,
      "grad_norm": 0.6097875237464905,
      "learning_rate": 2.4465361445783135e-06,
      "loss": 0.2275,
      "step": 3391
    },
    {
      "epoch": 2.0433734939759036,
      "grad_norm": 0.561245322227478,
      "learning_rate": 2.445783132530121e-06,
      "loss": 0.1563,
      "step": 3392
    },
    {
      "epoch": 2.043975903614458,
      "grad_norm": 0.6419820785522461,
      "learning_rate": 2.4450301204819277e-06,
      "loss": 0.1862,
      "step": 3393
    },
    {
      "epoch": 2.044578313253012,
      "grad_norm": 0.482607901096344,
      "learning_rate": 2.444277108433735e-06,
      "loss": 0.1919,
      "step": 3394
    },
    {
      "epoch": 2.0451807228915664,
      "grad_norm": 0.4794381856918335,
      "learning_rate": 2.4435240963855424e-06,
      "loss": 0.1881,
      "step": 3395
    },
    {
      "epoch": 2.0457831325301203,
      "grad_norm": 0.6556724309921265,
      "learning_rate": 2.4427710843373494e-06,
      "loss": 0.1728,
      "step": 3396
    },
    {
      "epoch": 2.0463855421686747,
      "grad_norm": 0.5658885836601257,
      "learning_rate": 2.4420180722891567e-06,
      "loss": 0.1909,
      "step": 3397
    },
    {
      "epoch": 2.0469879518072287,
      "grad_norm": 0.531578779220581,
      "learning_rate": 2.441265060240964e-06,
      "loss": 0.1789,
      "step": 3398
    },
    {
      "epoch": 2.047590361445783,
      "grad_norm": 0.5289185643196106,
      "learning_rate": 2.4405120481927714e-06,
      "loss": 0.1676,
      "step": 3399
    },
    {
      "epoch": 2.0481927710843375,
      "grad_norm": 0.5250594019889832,
      "learning_rate": 2.4397590361445788e-06,
      "loss": 0.195,
      "step": 3400
    },
    {
      "epoch": 2.0487951807228915,
      "grad_norm": 0.4629347026348114,
      "learning_rate": 2.4390060240963857e-06,
      "loss": 0.1499,
      "step": 3401
    },
    {
      "epoch": 2.049397590361446,
      "grad_norm": 0.5078510642051697,
      "learning_rate": 2.438253012048193e-06,
      "loss": 0.1583,
      "step": 3402
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.5431936979293823,
      "learning_rate": 2.4375e-06,
      "loss": 0.1553,
      "step": 3403
    },
    {
      "epoch": 2.0506024096385542,
      "grad_norm": 0.7167165279388428,
      "learning_rate": 2.4367469879518073e-06,
      "loss": 0.213,
      "step": 3404
    },
    {
      "epoch": 2.0512048192771086,
      "grad_norm": 0.5367341041564941,
      "learning_rate": 2.4359939759036147e-06,
      "loss": 0.1971,
      "step": 3405
    },
    {
      "epoch": 2.0518072289156626,
      "grad_norm": 0.5536328554153442,
      "learning_rate": 2.435240963855422e-06,
      "loss": 0.1531,
      "step": 3406
    },
    {
      "epoch": 2.052409638554217,
      "grad_norm": 0.5334307551383972,
      "learning_rate": 2.4344879518072293e-06,
      "loss": 0.1936,
      "step": 3407
    },
    {
      "epoch": 2.053012048192771,
      "grad_norm": 0.5368667244911194,
      "learning_rate": 2.4337349397590363e-06,
      "loss": 0.1415,
      "step": 3408
    },
    {
      "epoch": 2.0536144578313253,
      "grad_norm": 0.6191784739494324,
      "learning_rate": 2.4329819277108436e-06,
      "loss": 0.2172,
      "step": 3409
    },
    {
      "epoch": 2.0542168674698793,
      "grad_norm": 0.5164696574211121,
      "learning_rate": 2.432228915662651e-06,
      "loss": 0.1535,
      "step": 3410
    },
    {
      "epoch": 2.0548192771084337,
      "grad_norm": 0.4949262738227844,
      "learning_rate": 2.431475903614458e-06,
      "loss": 0.1532,
      "step": 3411
    },
    {
      "epoch": 2.055421686746988,
      "grad_norm": 0.6147348880767822,
      "learning_rate": 2.4307228915662652e-06,
      "loss": 0.2004,
      "step": 3412
    },
    {
      "epoch": 2.056024096385542,
      "grad_norm": 0.5601897239685059,
      "learning_rate": 2.4299698795180726e-06,
      "loss": 0.1703,
      "step": 3413
    },
    {
      "epoch": 2.0566265060240965,
      "grad_norm": 0.6970565915107727,
      "learning_rate": 2.4292168674698795e-06,
      "loss": 0.2023,
      "step": 3414
    },
    {
      "epoch": 2.0572289156626504,
      "grad_norm": 0.569390058517456,
      "learning_rate": 2.428463855421687e-06,
      "loss": 0.1662,
      "step": 3415
    },
    {
      "epoch": 2.057831325301205,
      "grad_norm": 0.5257327556610107,
      "learning_rate": 2.4277108433734942e-06,
      "loss": 0.1727,
      "step": 3416
    },
    {
      "epoch": 2.0584337349397592,
      "grad_norm": 0.5377451181411743,
      "learning_rate": 2.4269578313253016e-06,
      "loss": 0.1722,
      "step": 3417
    },
    {
      "epoch": 2.059036144578313,
      "grad_norm": 0.5093873143196106,
      "learning_rate": 2.426204819277109e-06,
      "loss": 0.1715,
      "step": 3418
    },
    {
      "epoch": 2.0596385542168676,
      "grad_norm": 0.6210658550262451,
      "learning_rate": 2.425451807228916e-06,
      "loss": 0.1776,
      "step": 3419
    },
    {
      "epoch": 2.0602409638554215,
      "grad_norm": 0.5649843215942383,
      "learning_rate": 2.424698795180723e-06,
      "loss": 0.1679,
      "step": 3420
    },
    {
      "epoch": 2.060843373493976,
      "grad_norm": 0.5661121010780334,
      "learning_rate": 2.42394578313253e-06,
      "loss": 0.1483,
      "step": 3421
    },
    {
      "epoch": 2.06144578313253,
      "grad_norm": 0.5966997146606445,
      "learning_rate": 2.4231927710843375e-06,
      "loss": 0.2047,
      "step": 3422
    },
    {
      "epoch": 2.0620481927710843,
      "grad_norm": 0.7173665761947632,
      "learning_rate": 2.422439759036145e-06,
      "loss": 0.195,
      "step": 3423
    },
    {
      "epoch": 2.0626506024096387,
      "grad_norm": 0.6252619624137878,
      "learning_rate": 2.421686746987952e-06,
      "loss": 0.1639,
      "step": 3424
    },
    {
      "epoch": 2.0632530120481927,
      "grad_norm": 0.5441561937332153,
      "learning_rate": 2.4209337349397595e-06,
      "loss": 0.133,
      "step": 3425
    },
    {
      "epoch": 2.063855421686747,
      "grad_norm": 0.6552125811576843,
      "learning_rate": 2.4201807228915664e-06,
      "loss": 0.2063,
      "step": 3426
    },
    {
      "epoch": 2.064457831325301,
      "grad_norm": 0.4966287314891815,
      "learning_rate": 2.4194277108433738e-06,
      "loss": 0.1421,
      "step": 3427
    },
    {
      "epoch": 2.0650602409638554,
      "grad_norm": 0.626677930355072,
      "learning_rate": 2.4186746987951807e-06,
      "loss": 0.2368,
      "step": 3428
    },
    {
      "epoch": 2.06566265060241,
      "grad_norm": 0.5332422852516174,
      "learning_rate": 2.417921686746988e-06,
      "loss": 0.1583,
      "step": 3429
    },
    {
      "epoch": 2.066265060240964,
      "grad_norm": 0.4871351718902588,
      "learning_rate": 2.4171686746987954e-06,
      "loss": 0.1455,
      "step": 3430
    },
    {
      "epoch": 2.066867469879518,
      "grad_norm": 0.5183328986167908,
      "learning_rate": 2.4164156626506027e-06,
      "loss": 0.18,
      "step": 3431
    },
    {
      "epoch": 2.067469879518072,
      "grad_norm": 0.48707470297813416,
      "learning_rate": 2.4156626506024097e-06,
      "loss": 0.1768,
      "step": 3432
    },
    {
      "epoch": 2.0680722891566266,
      "grad_norm": 0.5775975584983826,
      "learning_rate": 2.414909638554217e-06,
      "loss": 0.1863,
      "step": 3433
    },
    {
      "epoch": 2.0686746987951805,
      "grad_norm": 0.5343275666236877,
      "learning_rate": 2.4141566265060244e-06,
      "loss": 0.1487,
      "step": 3434
    },
    {
      "epoch": 2.069277108433735,
      "grad_norm": 0.47294992208480835,
      "learning_rate": 2.4134036144578317e-06,
      "loss": 0.1581,
      "step": 3435
    },
    {
      "epoch": 2.0698795180722893,
      "grad_norm": 0.5830618143081665,
      "learning_rate": 2.4126506024096386e-06,
      "loss": 0.1631,
      "step": 3436
    },
    {
      "epoch": 2.0704819277108433,
      "grad_norm": 0.5064898133277893,
      "learning_rate": 2.411897590361446e-06,
      "loss": 0.1423,
      "step": 3437
    },
    {
      "epoch": 2.0710843373493977,
      "grad_norm": 0.6824265122413635,
      "learning_rate": 2.411144578313253e-06,
      "loss": 0.2355,
      "step": 3438
    },
    {
      "epoch": 2.0716867469879516,
      "grad_norm": 0.5977683663368225,
      "learning_rate": 2.4103915662650603e-06,
      "loss": 0.1617,
      "step": 3439
    },
    {
      "epoch": 2.072289156626506,
      "grad_norm": 0.5751093626022339,
      "learning_rate": 2.4096385542168676e-06,
      "loss": 0.1949,
      "step": 3440
    },
    {
      "epoch": 2.0728915662650604,
      "grad_norm": 0.5833286046981812,
      "learning_rate": 2.408885542168675e-06,
      "loss": 0.2149,
      "step": 3441
    },
    {
      "epoch": 2.0734939759036144,
      "grad_norm": 0.5926445126533508,
      "learning_rate": 2.4081325301204823e-06,
      "loss": 0.1519,
      "step": 3442
    },
    {
      "epoch": 2.074096385542169,
      "grad_norm": 0.5575172901153564,
      "learning_rate": 2.4073795180722897e-06,
      "loss": 0.1812,
      "step": 3443
    },
    {
      "epoch": 2.0746987951807228,
      "grad_norm": 0.5286271572113037,
      "learning_rate": 2.4066265060240966e-06,
      "loss": 0.1366,
      "step": 3444
    },
    {
      "epoch": 2.075301204819277,
      "grad_norm": 0.6000181436538696,
      "learning_rate": 2.405873493975904e-06,
      "loss": 0.1506,
      "step": 3445
    },
    {
      "epoch": 2.075903614457831,
      "grad_norm": 0.540450930595398,
      "learning_rate": 2.405120481927711e-06,
      "loss": 0.1892,
      "step": 3446
    },
    {
      "epoch": 2.0765060240963855,
      "grad_norm": 0.6743507981300354,
      "learning_rate": 2.404367469879518e-06,
      "loss": 0.2147,
      "step": 3447
    },
    {
      "epoch": 2.07710843373494,
      "grad_norm": 0.466459184885025,
      "learning_rate": 2.4036144578313256e-06,
      "loss": 0.1411,
      "step": 3448
    },
    {
      "epoch": 2.077710843373494,
      "grad_norm": 0.5244677066802979,
      "learning_rate": 2.402861445783133e-06,
      "loss": 0.2173,
      "step": 3449
    },
    {
      "epoch": 2.0783132530120483,
      "grad_norm": 0.5805519819259644,
      "learning_rate": 2.40210843373494e-06,
      "loss": 0.2081,
      "step": 3450
    },
    {
      "epoch": 2.0789156626506022,
      "grad_norm": 0.5894073247909546,
      "learning_rate": 2.401355421686747e-06,
      "loss": 0.1919,
      "step": 3451
    },
    {
      "epoch": 2.0795180722891566,
      "grad_norm": 0.6353521347045898,
      "learning_rate": 2.4006024096385545e-06,
      "loss": 0.1976,
      "step": 3452
    },
    {
      "epoch": 2.080120481927711,
      "grad_norm": 0.6760376691818237,
      "learning_rate": 2.399849397590362e-06,
      "loss": 0.1544,
      "step": 3453
    },
    {
      "epoch": 2.080722891566265,
      "grad_norm": 0.5879683494567871,
      "learning_rate": 2.399096385542169e-06,
      "loss": 0.1549,
      "step": 3454
    },
    {
      "epoch": 2.0813253012048194,
      "grad_norm": 2.4793877601623535,
      "learning_rate": 2.398343373493976e-06,
      "loss": 0.1616,
      "step": 3455
    },
    {
      "epoch": 2.0819277108433734,
      "grad_norm": 0.606518030166626,
      "learning_rate": 2.397590361445783e-06,
      "loss": 0.2107,
      "step": 3456
    },
    {
      "epoch": 2.0825301204819278,
      "grad_norm": 0.5003078579902649,
      "learning_rate": 2.3968373493975904e-06,
      "loss": 0.1978,
      "step": 3457
    },
    {
      "epoch": 2.0831325301204817,
      "grad_norm": 0.565986156463623,
      "learning_rate": 2.3960843373493978e-06,
      "loss": 0.1553,
      "step": 3458
    },
    {
      "epoch": 2.083734939759036,
      "grad_norm": 0.5842318534851074,
      "learning_rate": 2.395331325301205e-06,
      "loss": 0.1958,
      "step": 3459
    },
    {
      "epoch": 2.0843373493975905,
      "grad_norm": 0.5875769853591919,
      "learning_rate": 2.3945783132530125e-06,
      "loss": 0.1809,
      "step": 3460
    },
    {
      "epoch": 2.0849397590361445,
      "grad_norm": 0.5159313082695007,
      "learning_rate": 2.3938253012048194e-06,
      "loss": 0.1591,
      "step": 3461
    },
    {
      "epoch": 2.085542168674699,
      "grad_norm": 0.5468465685844421,
      "learning_rate": 2.3930722891566267e-06,
      "loss": 0.1732,
      "step": 3462
    },
    {
      "epoch": 2.086144578313253,
      "grad_norm": 0.7239194512367249,
      "learning_rate": 2.3923192771084337e-06,
      "loss": 0.1706,
      "step": 3463
    },
    {
      "epoch": 2.0867469879518072,
      "grad_norm": 0.4976423680782318,
      "learning_rate": 2.391566265060241e-06,
      "loss": 0.1809,
      "step": 3464
    },
    {
      "epoch": 2.0873493975903616,
      "grad_norm": 0.5267043709754944,
      "learning_rate": 2.3908132530120484e-06,
      "loss": 0.1546,
      "step": 3465
    },
    {
      "epoch": 2.0879518072289156,
      "grad_norm": 0.5167995095252991,
      "learning_rate": 2.3900602409638557e-06,
      "loss": 0.1527,
      "step": 3466
    },
    {
      "epoch": 2.08855421686747,
      "grad_norm": 0.6221651434898376,
      "learning_rate": 2.389307228915663e-06,
      "loss": 0.174,
      "step": 3467
    },
    {
      "epoch": 2.089156626506024,
      "grad_norm": 0.5809212923049927,
      "learning_rate": 2.38855421686747e-06,
      "loss": 0.1687,
      "step": 3468
    },
    {
      "epoch": 2.0897590361445784,
      "grad_norm": 0.5258522033691406,
      "learning_rate": 2.3878012048192773e-06,
      "loss": 0.1548,
      "step": 3469
    },
    {
      "epoch": 2.0903614457831323,
      "grad_norm": 0.6379382610321045,
      "learning_rate": 2.3870481927710847e-06,
      "loss": 0.1806,
      "step": 3470
    },
    {
      "epoch": 2.0909638554216867,
      "grad_norm": 0.48905181884765625,
      "learning_rate": 2.3862951807228916e-06,
      "loss": 0.1742,
      "step": 3471
    },
    {
      "epoch": 2.091566265060241,
      "grad_norm": 0.539222002029419,
      "learning_rate": 2.385542168674699e-06,
      "loss": 0.1894,
      "step": 3472
    },
    {
      "epoch": 2.092168674698795,
      "grad_norm": 0.5324714779853821,
      "learning_rate": 2.3847891566265063e-06,
      "loss": 0.145,
      "step": 3473
    },
    {
      "epoch": 2.0927710843373495,
      "grad_norm": 0.49196019768714905,
      "learning_rate": 2.3840361445783132e-06,
      "loss": 0.1654,
      "step": 3474
    },
    {
      "epoch": 2.0933734939759034,
      "grad_norm": 0.8752831220626831,
      "learning_rate": 2.3832831325301206e-06,
      "loss": 0.2378,
      "step": 3475
    },
    {
      "epoch": 2.093975903614458,
      "grad_norm": 0.5778565406799316,
      "learning_rate": 2.382530120481928e-06,
      "loss": 0.1976,
      "step": 3476
    },
    {
      "epoch": 2.0945783132530122,
      "grad_norm": 0.5751739740371704,
      "learning_rate": 2.3817771084337353e-06,
      "loss": 0.1702,
      "step": 3477
    },
    {
      "epoch": 2.095180722891566,
      "grad_norm": 0.5057639479637146,
      "learning_rate": 2.3810240963855426e-06,
      "loss": 0.149,
      "step": 3478
    },
    {
      "epoch": 2.0957831325301206,
      "grad_norm": 0.5361483693122864,
      "learning_rate": 2.3802710843373495e-06,
      "loss": 0.1769,
      "step": 3479
    },
    {
      "epoch": 2.0963855421686746,
      "grad_norm": 0.574903666973114,
      "learning_rate": 2.379518072289157e-06,
      "loss": 0.1677,
      "step": 3480
    },
    {
      "epoch": 2.096987951807229,
      "grad_norm": 0.4909112751483917,
      "learning_rate": 2.378765060240964e-06,
      "loss": 0.1491,
      "step": 3481
    },
    {
      "epoch": 2.097590361445783,
      "grad_norm": 0.5512781143188477,
      "learning_rate": 2.378012048192771e-06,
      "loss": 0.1736,
      "step": 3482
    },
    {
      "epoch": 2.0981927710843373,
      "grad_norm": 0.5901639461517334,
      "learning_rate": 2.3772590361445785e-06,
      "loss": 0.1732,
      "step": 3483
    },
    {
      "epoch": 2.0987951807228917,
      "grad_norm": 0.5054052472114563,
      "learning_rate": 2.376506024096386e-06,
      "loss": 0.155,
      "step": 3484
    },
    {
      "epoch": 2.0993975903614457,
      "grad_norm": 0.7056239247322083,
      "learning_rate": 2.375753012048193e-06,
      "loss": 0.2231,
      "step": 3485
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.5750464200973511,
      "learning_rate": 2.375e-06,
      "loss": 0.1658,
      "step": 3486
    },
    {
      "epoch": 2.100602409638554,
      "grad_norm": 0.6725653409957886,
      "learning_rate": 2.3742469879518075e-06,
      "loss": 0.2003,
      "step": 3487
    },
    {
      "epoch": 2.1012048192771084,
      "grad_norm": 0.5609780550003052,
      "learning_rate": 2.373493975903615e-06,
      "loss": 0.1454,
      "step": 3488
    },
    {
      "epoch": 2.101807228915663,
      "grad_norm": 0.5277065634727478,
      "learning_rate": 2.3727409638554218e-06,
      "loss": 0.1777,
      "step": 3489
    },
    {
      "epoch": 2.102409638554217,
      "grad_norm": 0.6235278248786926,
      "learning_rate": 2.371987951807229e-06,
      "loss": 0.1732,
      "step": 3490
    },
    {
      "epoch": 2.103012048192771,
      "grad_norm": 0.5224083662033081,
      "learning_rate": 2.3712349397590364e-06,
      "loss": 0.1437,
      "step": 3491
    },
    {
      "epoch": 2.103614457831325,
      "grad_norm": 0.475370854139328,
      "learning_rate": 2.3704819277108434e-06,
      "loss": 0.1617,
      "step": 3492
    },
    {
      "epoch": 2.1042168674698796,
      "grad_norm": 0.5858540534973145,
      "learning_rate": 2.3697289156626507e-06,
      "loss": 0.1665,
      "step": 3493
    },
    {
      "epoch": 2.1048192771084335,
      "grad_norm": 0.5798099040985107,
      "learning_rate": 2.368975903614458e-06,
      "loss": 0.1744,
      "step": 3494
    },
    {
      "epoch": 2.105421686746988,
      "grad_norm": 0.550408661365509,
      "learning_rate": 2.3682228915662654e-06,
      "loss": 0.1853,
      "step": 3495
    },
    {
      "epoch": 2.1060240963855423,
      "grad_norm": 0.575110912322998,
      "learning_rate": 2.3674698795180723e-06,
      "loss": 0.138,
      "step": 3496
    },
    {
      "epoch": 2.1066265060240963,
      "grad_norm": 0.48044806718826294,
      "learning_rate": 2.3667168674698797e-06,
      "loss": 0.1495,
      "step": 3497
    },
    {
      "epoch": 2.1072289156626507,
      "grad_norm": 0.6712057590484619,
      "learning_rate": 2.3659638554216866e-06,
      "loss": 0.1981,
      "step": 3498
    },
    {
      "epoch": 2.1078313253012047,
      "grad_norm": 0.45215925574302673,
      "learning_rate": 2.365210843373494e-06,
      "loss": 0.1137,
      "step": 3499
    },
    {
      "epoch": 2.108433734939759,
      "grad_norm": 0.5921338796615601,
      "learning_rate": 2.3644578313253013e-06,
      "loss": 0.1585,
      "step": 3500
    },
    {
      "epoch": 2.1090361445783135,
      "grad_norm": 0.5250471234321594,
      "learning_rate": 2.3637048192771087e-06,
      "loss": 0.1881,
      "step": 3501
    },
    {
      "epoch": 2.1096385542168674,
      "grad_norm": 0.612320065498352,
      "learning_rate": 2.362951807228916e-06,
      "loss": 0.1506,
      "step": 3502
    },
    {
      "epoch": 2.110240963855422,
      "grad_norm": 0.5652648210525513,
      "learning_rate": 2.3621987951807234e-06,
      "loss": 0.1782,
      "step": 3503
    },
    {
      "epoch": 2.1108433734939758,
      "grad_norm": 0.527677059173584,
      "learning_rate": 2.3614457831325303e-06,
      "loss": 0.1906,
      "step": 3504
    },
    {
      "epoch": 2.11144578313253,
      "grad_norm": 0.6051639318466187,
      "learning_rate": 2.3606927710843376e-06,
      "loss": 0.1886,
      "step": 3505
    },
    {
      "epoch": 2.112048192771084,
      "grad_norm": 0.6122929453849792,
      "learning_rate": 2.3599397590361446e-06,
      "loss": 0.178,
      "step": 3506
    },
    {
      "epoch": 2.1126506024096385,
      "grad_norm": 0.4537566304206848,
      "learning_rate": 2.359186746987952e-06,
      "loss": 0.1359,
      "step": 3507
    },
    {
      "epoch": 2.113253012048193,
      "grad_norm": 0.6246505379676819,
      "learning_rate": 2.3584337349397593e-06,
      "loss": 0.199,
      "step": 3508
    },
    {
      "epoch": 2.113855421686747,
      "grad_norm": 0.5585948824882507,
      "learning_rate": 2.3576807228915666e-06,
      "loss": 0.2021,
      "step": 3509
    },
    {
      "epoch": 2.1144578313253013,
      "grad_norm": 0.6240267753601074,
      "learning_rate": 2.3569277108433735e-06,
      "loss": 0.1656,
      "step": 3510
    },
    {
      "epoch": 2.1150602409638553,
      "grad_norm": 0.5456238389015198,
      "learning_rate": 2.356174698795181e-06,
      "loss": 0.1107,
      "step": 3511
    },
    {
      "epoch": 2.1156626506024097,
      "grad_norm": 0.6696534156799316,
      "learning_rate": 2.3554216867469882e-06,
      "loss": 0.194,
      "step": 3512
    },
    {
      "epoch": 2.116265060240964,
      "grad_norm": 0.7669286131858826,
      "learning_rate": 2.3546686746987956e-06,
      "loss": 0.2051,
      "step": 3513
    },
    {
      "epoch": 2.116867469879518,
      "grad_norm": 0.5563139915466309,
      "learning_rate": 2.3539156626506025e-06,
      "loss": 0.1572,
      "step": 3514
    },
    {
      "epoch": 2.1174698795180724,
      "grad_norm": 0.5427438020706177,
      "learning_rate": 2.35316265060241e-06,
      "loss": 0.1784,
      "step": 3515
    },
    {
      "epoch": 2.1180722891566264,
      "grad_norm": 0.6871263980865479,
      "learning_rate": 2.3524096385542168e-06,
      "loss": 0.196,
      "step": 3516
    },
    {
      "epoch": 2.1186746987951808,
      "grad_norm": 0.5590916275978088,
      "learning_rate": 2.351656626506024e-06,
      "loss": 0.1548,
      "step": 3517
    },
    {
      "epoch": 2.1192771084337347,
      "grad_norm": 0.7941166758537292,
      "learning_rate": 2.3509036144578315e-06,
      "loss": 0.2075,
      "step": 3518
    },
    {
      "epoch": 2.119879518072289,
      "grad_norm": 0.5211894512176514,
      "learning_rate": 2.350150602409639e-06,
      "loss": 0.1688,
      "step": 3519
    },
    {
      "epoch": 2.1204819277108435,
      "grad_norm": 0.5968431234359741,
      "learning_rate": 2.349397590361446e-06,
      "loss": 0.1399,
      "step": 3520
    },
    {
      "epoch": 2.1210843373493975,
      "grad_norm": 0.7860793471336365,
      "learning_rate": 2.3486445783132535e-06,
      "loss": 0.2045,
      "step": 3521
    },
    {
      "epoch": 2.121686746987952,
      "grad_norm": 0.74896639585495,
      "learning_rate": 2.3478915662650604e-06,
      "loss": 0.1672,
      "step": 3522
    },
    {
      "epoch": 2.122289156626506,
      "grad_norm": 0.7169128060340881,
      "learning_rate": 2.3471385542168678e-06,
      "loss": 0.2579,
      "step": 3523
    },
    {
      "epoch": 2.1228915662650603,
      "grad_norm": 0.45057815313339233,
      "learning_rate": 2.3463855421686747e-06,
      "loss": 0.1307,
      "step": 3524
    },
    {
      "epoch": 2.1234939759036147,
      "grad_norm": 0.6335071325302124,
      "learning_rate": 2.345632530120482e-06,
      "loss": 0.178,
      "step": 3525
    },
    {
      "epoch": 2.1240963855421686,
      "grad_norm": 0.4443429708480835,
      "learning_rate": 2.3448795180722894e-06,
      "loss": 0.1502,
      "step": 3526
    },
    {
      "epoch": 2.124698795180723,
      "grad_norm": 0.5645781755447388,
      "learning_rate": 2.3441265060240968e-06,
      "loss": 0.1768,
      "step": 3527
    },
    {
      "epoch": 2.125301204819277,
      "grad_norm": 0.48021960258483887,
      "learning_rate": 2.3433734939759037e-06,
      "loss": 0.178,
      "step": 3528
    },
    {
      "epoch": 2.1259036144578314,
      "grad_norm": 0.523273766040802,
      "learning_rate": 2.342620481927711e-06,
      "loss": 0.1293,
      "step": 3529
    },
    {
      "epoch": 2.1265060240963853,
      "grad_norm": 0.5381661653518677,
      "learning_rate": 2.3418674698795184e-06,
      "loss": 0.1753,
      "step": 3530
    },
    {
      "epoch": 2.1271084337349397,
      "grad_norm": 0.5137754082679749,
      "learning_rate": 2.3411144578313257e-06,
      "loss": 0.1516,
      "step": 3531
    },
    {
      "epoch": 2.127710843373494,
      "grad_norm": 0.5102006793022156,
      "learning_rate": 2.3403614457831327e-06,
      "loss": 0.2022,
      "step": 3532
    },
    {
      "epoch": 2.128313253012048,
      "grad_norm": 0.5657976269721985,
      "learning_rate": 2.33960843373494e-06,
      "loss": 0.1897,
      "step": 3533
    },
    {
      "epoch": 2.1289156626506025,
      "grad_norm": 0.49575069546699524,
      "learning_rate": 2.338855421686747e-06,
      "loss": 0.1538,
      "step": 3534
    },
    {
      "epoch": 2.1295180722891565,
      "grad_norm": 0.4654635488986969,
      "learning_rate": 2.3381024096385543e-06,
      "loss": 0.1414,
      "step": 3535
    },
    {
      "epoch": 2.130120481927711,
      "grad_norm": 0.5413070321083069,
      "learning_rate": 2.3373493975903616e-06,
      "loss": 0.1622,
      "step": 3536
    },
    {
      "epoch": 2.1307228915662653,
      "grad_norm": 0.4878726601600647,
      "learning_rate": 2.336596385542169e-06,
      "loss": 0.1642,
      "step": 3537
    },
    {
      "epoch": 2.1313253012048192,
      "grad_norm": 0.48220717906951904,
      "learning_rate": 2.3358433734939763e-06,
      "loss": 0.1647,
      "step": 3538
    },
    {
      "epoch": 2.1319277108433736,
      "grad_norm": 0.5378234386444092,
      "learning_rate": 2.3350903614457832e-06,
      "loss": 0.1802,
      "step": 3539
    },
    {
      "epoch": 2.1325301204819276,
      "grad_norm": 0.5710850358009338,
      "learning_rate": 2.3343373493975906e-06,
      "loss": 0.178,
      "step": 3540
    },
    {
      "epoch": 2.133132530120482,
      "grad_norm": 0.5932935476303101,
      "learning_rate": 2.3335843373493975e-06,
      "loss": 0.1529,
      "step": 3541
    },
    {
      "epoch": 2.133734939759036,
      "grad_norm": 0.4934181869029999,
      "learning_rate": 2.332831325301205e-06,
      "loss": 0.1791,
      "step": 3542
    },
    {
      "epoch": 2.1343373493975903,
      "grad_norm": 0.5063537955284119,
      "learning_rate": 2.3320783132530122e-06,
      "loss": 0.1579,
      "step": 3543
    },
    {
      "epoch": 2.1349397590361447,
      "grad_norm": 0.5956956744194031,
      "learning_rate": 2.3313253012048196e-06,
      "loss": 0.2123,
      "step": 3544
    },
    {
      "epoch": 2.1355421686746987,
      "grad_norm": 0.4515224099159241,
      "learning_rate": 2.330572289156627e-06,
      "loss": 0.1442,
      "step": 3545
    },
    {
      "epoch": 2.136144578313253,
      "grad_norm": 0.6452073454856873,
      "learning_rate": 2.329819277108434e-06,
      "loss": 0.178,
      "step": 3546
    },
    {
      "epoch": 2.136746987951807,
      "grad_norm": 0.47071945667266846,
      "learning_rate": 2.329066265060241e-06,
      "loss": 0.1406,
      "step": 3547
    },
    {
      "epoch": 2.1373493975903615,
      "grad_norm": 0.4578985273838043,
      "learning_rate": 2.3283132530120485e-06,
      "loss": 0.1779,
      "step": 3548
    },
    {
      "epoch": 2.137951807228916,
      "grad_norm": 0.6201589107513428,
      "learning_rate": 2.3275602409638555e-06,
      "loss": 0.2273,
      "step": 3549
    },
    {
      "epoch": 2.13855421686747,
      "grad_norm": 0.5133152604103088,
      "learning_rate": 2.326807228915663e-06,
      "loss": 0.1622,
      "step": 3550
    },
    {
      "epoch": 2.1391566265060242,
      "grad_norm": 0.5281580090522766,
      "learning_rate": 2.32605421686747e-06,
      "loss": 0.1203,
      "step": 3551
    },
    {
      "epoch": 2.139759036144578,
      "grad_norm": 0.4759292006492615,
      "learning_rate": 2.325301204819277e-06,
      "loss": 0.1288,
      "step": 3552
    },
    {
      "epoch": 2.1403614457831326,
      "grad_norm": 0.5962051749229431,
      "learning_rate": 2.3245481927710844e-06,
      "loss": 0.173,
      "step": 3553
    },
    {
      "epoch": 2.1409638554216865,
      "grad_norm": 0.7568002343177795,
      "learning_rate": 2.3237951807228918e-06,
      "loss": 0.2216,
      "step": 3554
    },
    {
      "epoch": 2.141566265060241,
      "grad_norm": 0.5751909613609314,
      "learning_rate": 2.323042168674699e-06,
      "loss": 0.1733,
      "step": 3555
    },
    {
      "epoch": 2.1421686746987953,
      "grad_norm": 0.6196345686912537,
      "learning_rate": 2.3222891566265065e-06,
      "loss": 0.1868,
      "step": 3556
    },
    {
      "epoch": 2.1427710843373493,
      "grad_norm": 0.49725013971328735,
      "learning_rate": 2.3215361445783134e-06,
      "loss": 0.1423,
      "step": 3557
    },
    {
      "epoch": 2.1433734939759037,
      "grad_norm": 0.535197377204895,
      "learning_rate": 2.3207831325301207e-06,
      "loss": 0.1866,
      "step": 3558
    },
    {
      "epoch": 2.1439759036144577,
      "grad_norm": 0.5951826572418213,
      "learning_rate": 2.3200301204819277e-06,
      "loss": 0.1976,
      "step": 3559
    },
    {
      "epoch": 2.144578313253012,
      "grad_norm": 0.5115329027175903,
      "learning_rate": 2.319277108433735e-06,
      "loss": 0.1691,
      "step": 3560
    },
    {
      "epoch": 2.1451807228915665,
      "grad_norm": 0.5408492684364319,
      "learning_rate": 2.3185240963855424e-06,
      "loss": 0.1433,
      "step": 3561
    },
    {
      "epoch": 2.1457831325301204,
      "grad_norm": 0.6055808067321777,
      "learning_rate": 2.3177710843373497e-06,
      "loss": 0.1616,
      "step": 3562
    },
    {
      "epoch": 2.146385542168675,
      "grad_norm": 0.5753475427627563,
      "learning_rate": 2.317018072289157e-06,
      "loss": 0.159,
      "step": 3563
    },
    {
      "epoch": 2.146987951807229,
      "grad_norm": 0.43657973408699036,
      "learning_rate": 2.316265060240964e-06,
      "loss": 0.1221,
      "step": 3564
    },
    {
      "epoch": 2.147590361445783,
      "grad_norm": 0.6806954741477966,
      "learning_rate": 2.3155120481927713e-06,
      "loss": 0.1826,
      "step": 3565
    },
    {
      "epoch": 2.148192771084337,
      "grad_norm": 0.5956966876983643,
      "learning_rate": 2.3147590361445787e-06,
      "loss": 0.176,
      "step": 3566
    },
    {
      "epoch": 2.1487951807228916,
      "grad_norm": 0.5486631989479065,
      "learning_rate": 2.3140060240963856e-06,
      "loss": 0.1542,
      "step": 3567
    },
    {
      "epoch": 2.149397590361446,
      "grad_norm": 0.5284417271614075,
      "learning_rate": 2.313253012048193e-06,
      "loss": 0.1501,
      "step": 3568
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.5952894687652588,
      "learning_rate": 2.3125000000000003e-06,
      "loss": 0.1821,
      "step": 3569
    },
    {
      "epoch": 2.1506024096385543,
      "grad_norm": 0.45463135838508606,
      "learning_rate": 2.3117469879518072e-06,
      "loss": 0.159,
      "step": 3570
    },
    {
      "epoch": 2.1512048192771083,
      "grad_norm": 0.46306124329566956,
      "learning_rate": 2.3109939759036146e-06,
      "loss": 0.1623,
      "step": 3571
    },
    {
      "epoch": 2.1518072289156627,
      "grad_norm": 0.5278573632240295,
      "learning_rate": 2.310240963855422e-06,
      "loss": 0.1299,
      "step": 3572
    },
    {
      "epoch": 2.152409638554217,
      "grad_norm": 0.5637245178222656,
      "learning_rate": 2.3094879518072293e-06,
      "loss": 0.1765,
      "step": 3573
    },
    {
      "epoch": 2.153012048192771,
      "grad_norm": 0.7148364186286926,
      "learning_rate": 2.308734939759036e-06,
      "loss": 0.1878,
      "step": 3574
    },
    {
      "epoch": 2.1536144578313254,
      "grad_norm": 0.5513962507247925,
      "learning_rate": 2.3079819277108435e-06,
      "loss": 0.1543,
      "step": 3575
    },
    {
      "epoch": 2.1542168674698794,
      "grad_norm": 0.7244274616241455,
      "learning_rate": 2.3072289156626505e-06,
      "loss": 0.1657,
      "step": 3576
    },
    {
      "epoch": 2.154819277108434,
      "grad_norm": 0.5753297209739685,
      "learning_rate": 2.306475903614458e-06,
      "loss": 0.2294,
      "step": 3577
    },
    {
      "epoch": 2.1554216867469878,
      "grad_norm": 0.5559269785881042,
      "learning_rate": 2.305722891566265e-06,
      "loss": 0.1622,
      "step": 3578
    },
    {
      "epoch": 2.156024096385542,
      "grad_norm": 0.5622099041938782,
      "learning_rate": 2.3049698795180725e-06,
      "loss": 0.168,
      "step": 3579
    },
    {
      "epoch": 2.1566265060240966,
      "grad_norm": 0.6111180186271667,
      "learning_rate": 2.30421686746988e-06,
      "loss": 0.17,
      "step": 3580
    },
    {
      "epoch": 2.1572289156626505,
      "grad_norm": 0.5150572061538696,
      "learning_rate": 2.3034638554216872e-06,
      "loss": 0.152,
      "step": 3581
    },
    {
      "epoch": 2.157831325301205,
      "grad_norm": 0.4885941743850708,
      "learning_rate": 2.302710843373494e-06,
      "loss": 0.1361,
      "step": 3582
    },
    {
      "epoch": 2.158433734939759,
      "grad_norm": 0.5342434048652649,
      "learning_rate": 2.3019578313253015e-06,
      "loss": 0.1371,
      "step": 3583
    },
    {
      "epoch": 2.1590361445783133,
      "grad_norm": 0.5967900156974792,
      "learning_rate": 2.3012048192771084e-06,
      "loss": 0.1876,
      "step": 3584
    },
    {
      "epoch": 2.1596385542168672,
      "grad_norm": 0.5483462810516357,
      "learning_rate": 2.3004518072289158e-06,
      "loss": 0.165,
      "step": 3585
    },
    {
      "epoch": 2.1602409638554216,
      "grad_norm": 0.665067732334137,
      "learning_rate": 2.299698795180723e-06,
      "loss": 0.1378,
      "step": 3586
    },
    {
      "epoch": 2.160843373493976,
      "grad_norm": 0.6254856586456299,
      "learning_rate": 2.2989457831325305e-06,
      "loss": 0.1792,
      "step": 3587
    },
    {
      "epoch": 2.16144578313253,
      "grad_norm": 0.5411292910575867,
      "learning_rate": 2.2981927710843374e-06,
      "loss": 0.1392,
      "step": 3588
    },
    {
      "epoch": 2.1620481927710844,
      "grad_norm": 0.5390067100524902,
      "learning_rate": 2.2974397590361447e-06,
      "loss": 0.1704,
      "step": 3589
    },
    {
      "epoch": 2.1626506024096384,
      "grad_norm": 0.5642544627189636,
      "learning_rate": 2.296686746987952e-06,
      "loss": 0.1716,
      "step": 3590
    },
    {
      "epoch": 2.1632530120481928,
      "grad_norm": 0.5871756672859192,
      "learning_rate": 2.2959337349397594e-06,
      "loss": 0.153,
      "step": 3591
    },
    {
      "epoch": 2.163855421686747,
      "grad_norm": 0.462621808052063,
      "learning_rate": 2.2951807228915664e-06,
      "loss": 0.1371,
      "step": 3592
    },
    {
      "epoch": 2.164457831325301,
      "grad_norm": 0.5662382245063782,
      "learning_rate": 2.2944277108433737e-06,
      "loss": 0.1284,
      "step": 3593
    },
    {
      "epoch": 2.1650602409638555,
      "grad_norm": 0.5288719534873962,
      "learning_rate": 2.2936746987951806e-06,
      "loss": 0.1552,
      "step": 3594
    },
    {
      "epoch": 2.1656626506024095,
      "grad_norm": 0.6408740878105164,
      "learning_rate": 2.292921686746988e-06,
      "loss": 0.1564,
      "step": 3595
    },
    {
      "epoch": 2.166265060240964,
      "grad_norm": 0.7128946185112,
      "learning_rate": 2.2921686746987953e-06,
      "loss": 0.1624,
      "step": 3596
    },
    {
      "epoch": 2.1668674698795183,
      "grad_norm": 0.48481783270835876,
      "learning_rate": 2.2914156626506027e-06,
      "loss": 0.1589,
      "step": 3597
    },
    {
      "epoch": 2.1674698795180722,
      "grad_norm": 3.3546741008758545,
      "learning_rate": 2.29066265060241e-06,
      "loss": 0.2163,
      "step": 3598
    },
    {
      "epoch": 2.1680722891566266,
      "grad_norm": 0.617536723613739,
      "learning_rate": 2.2899096385542174e-06,
      "loss": 0.1868,
      "step": 3599
    },
    {
      "epoch": 2.1686746987951806,
      "grad_norm": 0.5340006947517395,
      "learning_rate": 2.2891566265060243e-06,
      "loss": 0.1904,
      "step": 3600
    },
    {
      "epoch": 2.169277108433735,
      "grad_norm": 0.4916497766971588,
      "learning_rate": 2.2884036144578316e-06,
      "loss": 0.1407,
      "step": 3601
    },
    {
      "epoch": 2.169879518072289,
      "grad_norm": 0.5442842841148376,
      "learning_rate": 2.2876506024096386e-06,
      "loss": 0.1973,
      "step": 3602
    },
    {
      "epoch": 2.1704819277108434,
      "grad_norm": 0.5554933547973633,
      "learning_rate": 2.286897590361446e-06,
      "loss": 0.1426,
      "step": 3603
    },
    {
      "epoch": 2.1710843373493978,
      "grad_norm": 0.6487897038459778,
      "learning_rate": 2.2861445783132533e-06,
      "loss": 0.1889,
      "step": 3604
    },
    {
      "epoch": 2.1716867469879517,
      "grad_norm": 0.48138755559921265,
      "learning_rate": 2.2853915662650606e-06,
      "loss": 0.1657,
      "step": 3605
    },
    {
      "epoch": 2.172289156626506,
      "grad_norm": 0.5445444583892822,
      "learning_rate": 2.2846385542168675e-06,
      "loss": 0.1671,
      "step": 3606
    },
    {
      "epoch": 2.17289156626506,
      "grad_norm": 0.6127693057060242,
      "learning_rate": 2.283885542168675e-06,
      "loss": 0.182,
      "step": 3607
    },
    {
      "epoch": 2.1734939759036145,
      "grad_norm": 0.5786764621734619,
      "learning_rate": 2.2831325301204822e-06,
      "loss": 0.145,
      "step": 3608
    },
    {
      "epoch": 2.1740963855421684,
      "grad_norm": 0.6673089861869812,
      "learning_rate": 2.282379518072289e-06,
      "loss": 0.1947,
      "step": 3609
    },
    {
      "epoch": 2.174698795180723,
      "grad_norm": 0.5997542142868042,
      "learning_rate": 2.2816265060240965e-06,
      "loss": 0.2049,
      "step": 3610
    },
    {
      "epoch": 2.1753012048192772,
      "grad_norm": 0.5352113246917725,
      "learning_rate": 2.280873493975904e-06,
      "loss": 0.1425,
      "step": 3611
    },
    {
      "epoch": 2.175903614457831,
      "grad_norm": 0.5330120921134949,
      "learning_rate": 2.2801204819277108e-06,
      "loss": 0.1848,
      "step": 3612
    },
    {
      "epoch": 2.1765060240963856,
      "grad_norm": 0.6746066808700562,
      "learning_rate": 2.279367469879518e-06,
      "loss": 0.1764,
      "step": 3613
    },
    {
      "epoch": 2.1771084337349396,
      "grad_norm": 0.5653623938560486,
      "learning_rate": 2.2786144578313255e-06,
      "loss": 0.1656,
      "step": 3614
    },
    {
      "epoch": 2.177710843373494,
      "grad_norm": 0.530806839466095,
      "learning_rate": 2.277861445783133e-06,
      "loss": 0.1468,
      "step": 3615
    },
    {
      "epoch": 2.1783132530120484,
      "grad_norm": 0.4299790561199188,
      "learning_rate": 2.27710843373494e-06,
      "loss": 0.1459,
      "step": 3616
    },
    {
      "epoch": 2.1789156626506023,
      "grad_norm": 0.5135143995285034,
      "learning_rate": 2.276355421686747e-06,
      "loss": 0.1375,
      "step": 3617
    },
    {
      "epoch": 2.1795180722891567,
      "grad_norm": 0.5363240242004395,
      "learning_rate": 2.2756024096385544e-06,
      "loss": 0.1532,
      "step": 3618
    },
    {
      "epoch": 2.1801204819277107,
      "grad_norm": 0.7095863819122314,
      "learning_rate": 2.2748493975903614e-06,
      "loss": 0.2061,
      "step": 3619
    },
    {
      "epoch": 2.180722891566265,
      "grad_norm": 0.6408828496932983,
      "learning_rate": 2.2740963855421687e-06,
      "loss": 0.1851,
      "step": 3620
    },
    {
      "epoch": 2.1813253012048195,
      "grad_norm": 0.9694306254386902,
      "learning_rate": 2.273343373493976e-06,
      "loss": 0.2097,
      "step": 3621
    },
    {
      "epoch": 2.1819277108433734,
      "grad_norm": 0.5739444494247437,
      "learning_rate": 2.2725903614457834e-06,
      "loss": 0.1903,
      "step": 3622
    },
    {
      "epoch": 2.182530120481928,
      "grad_norm": 0.565801739692688,
      "learning_rate": 2.2718373493975908e-06,
      "loss": 0.1651,
      "step": 3623
    },
    {
      "epoch": 2.183132530120482,
      "grad_norm": 0.605711042881012,
      "learning_rate": 2.2710843373493977e-06,
      "loss": 0.1947,
      "step": 3624
    },
    {
      "epoch": 2.183734939759036,
      "grad_norm": 0.49057453870773315,
      "learning_rate": 2.270331325301205e-06,
      "loss": 0.149,
      "step": 3625
    },
    {
      "epoch": 2.18433734939759,
      "grad_norm": 0.4846870005130768,
      "learning_rate": 2.2695783132530124e-06,
      "loss": 0.1426,
      "step": 3626
    },
    {
      "epoch": 2.1849397590361446,
      "grad_norm": 0.5886766910552979,
      "learning_rate": 2.2688253012048193e-06,
      "loss": 0.2074,
      "step": 3627
    },
    {
      "epoch": 2.185542168674699,
      "grad_norm": 0.5320413708686829,
      "learning_rate": 2.2680722891566267e-06,
      "loss": 0.1504,
      "step": 3628
    },
    {
      "epoch": 2.186144578313253,
      "grad_norm": 0.6584779620170593,
      "learning_rate": 2.267319277108434e-06,
      "loss": 0.1753,
      "step": 3629
    },
    {
      "epoch": 2.1867469879518073,
      "grad_norm": 0.5481996536254883,
      "learning_rate": 2.266566265060241e-06,
      "loss": 0.164,
      "step": 3630
    },
    {
      "epoch": 2.1873493975903613,
      "grad_norm": 0.4909261465072632,
      "learning_rate": 2.2658132530120483e-06,
      "loss": 0.16,
      "step": 3631
    },
    {
      "epoch": 2.1879518072289157,
      "grad_norm": 0.6635171175003052,
      "learning_rate": 2.2650602409638556e-06,
      "loss": 0.203,
      "step": 3632
    },
    {
      "epoch": 2.1885542168674696,
      "grad_norm": 0.498553067445755,
      "learning_rate": 2.264307228915663e-06,
      "loss": 0.1466,
      "step": 3633
    },
    {
      "epoch": 2.189156626506024,
      "grad_norm": 0.49650245904922485,
      "learning_rate": 2.2635542168674703e-06,
      "loss": 0.168,
      "step": 3634
    },
    {
      "epoch": 2.1897590361445785,
      "grad_norm": 0.7256317734718323,
      "learning_rate": 2.2628012048192773e-06,
      "loss": 0.168,
      "step": 3635
    },
    {
      "epoch": 2.1903614457831324,
      "grad_norm": 0.5938775539398193,
      "learning_rate": 2.2620481927710846e-06,
      "loss": 0.1737,
      "step": 3636
    },
    {
      "epoch": 2.190963855421687,
      "grad_norm": 0.5280905365943909,
      "learning_rate": 2.2612951807228915e-06,
      "loss": 0.1626,
      "step": 3637
    },
    {
      "epoch": 2.1915662650602408,
      "grad_norm": 0.6935991048812866,
      "learning_rate": 2.260542168674699e-06,
      "loss": 0.2467,
      "step": 3638
    },
    {
      "epoch": 2.192168674698795,
      "grad_norm": 0.5496538877487183,
      "learning_rate": 2.2597891566265062e-06,
      "loss": 0.164,
      "step": 3639
    },
    {
      "epoch": 2.1927710843373496,
      "grad_norm": 0.4640416204929352,
      "learning_rate": 2.2590361445783136e-06,
      "loss": 0.1544,
      "step": 3640
    },
    {
      "epoch": 2.1933734939759035,
      "grad_norm": 0.480605810880661,
      "learning_rate": 2.258283132530121e-06,
      "loss": 0.1254,
      "step": 3641
    },
    {
      "epoch": 2.193975903614458,
      "grad_norm": 0.5253809094429016,
      "learning_rate": 2.257530120481928e-06,
      "loss": 0.168,
      "step": 3642
    },
    {
      "epoch": 2.194578313253012,
      "grad_norm": 0.5434663891792297,
      "learning_rate": 2.256777108433735e-06,
      "loss": 0.1453,
      "step": 3643
    },
    {
      "epoch": 2.1951807228915663,
      "grad_norm": 0.5733345746994019,
      "learning_rate": 2.256024096385542e-06,
      "loss": 0.1682,
      "step": 3644
    },
    {
      "epoch": 2.1957831325301207,
      "grad_norm": 0.63547682762146,
      "learning_rate": 2.2552710843373495e-06,
      "loss": 0.1821,
      "step": 3645
    },
    {
      "epoch": 2.1963855421686747,
      "grad_norm": 0.6109859943389893,
      "learning_rate": 2.254518072289157e-06,
      "loss": 0.1766,
      "step": 3646
    },
    {
      "epoch": 2.196987951807229,
      "grad_norm": 2.100393533706665,
      "learning_rate": 2.253765060240964e-06,
      "loss": 0.1574,
      "step": 3647
    },
    {
      "epoch": 2.197590361445783,
      "grad_norm": 0.5767305493354797,
      "learning_rate": 2.253012048192771e-06,
      "loss": 0.1545,
      "step": 3648
    },
    {
      "epoch": 2.1981927710843374,
      "grad_norm": 0.5841920375823975,
      "learning_rate": 2.2522590361445784e-06,
      "loss": 0.1631,
      "step": 3649
    },
    {
      "epoch": 2.1987951807228914,
      "grad_norm": 0.44462910294532776,
      "learning_rate": 2.2515060240963858e-06,
      "loss": 0.1378,
      "step": 3650
    },
    {
      "epoch": 2.1993975903614458,
      "grad_norm": 0.6701146364212036,
      "learning_rate": 2.250753012048193e-06,
      "loss": 0.195,
      "step": 3651
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5429290533065796,
      "learning_rate": 2.25e-06,
      "loss": 0.1499,
      "step": 3652
    },
    {
      "epoch": 2.200602409638554,
      "grad_norm": 0.5346117615699768,
      "learning_rate": 2.2492469879518074e-06,
      "loss": 0.1414,
      "step": 3653
    },
    {
      "epoch": 2.2012048192771085,
      "grad_norm": 0.5631871819496155,
      "learning_rate": 2.2484939759036143e-06,
      "loss": 0.1294,
      "step": 3654
    },
    {
      "epoch": 2.2018072289156625,
      "grad_norm": 0.6284955739974976,
      "learning_rate": 2.2477409638554217e-06,
      "loss": 0.2116,
      "step": 3655
    },
    {
      "epoch": 2.202409638554217,
      "grad_norm": 0.49217286705970764,
      "learning_rate": 2.246987951807229e-06,
      "loss": 0.1513,
      "step": 3656
    },
    {
      "epoch": 2.203012048192771,
      "grad_norm": 0.5492326617240906,
      "learning_rate": 2.2462349397590364e-06,
      "loss": 0.1648,
      "step": 3657
    },
    {
      "epoch": 2.2036144578313253,
      "grad_norm": 0.5461472868919373,
      "learning_rate": 2.2454819277108437e-06,
      "loss": 0.1372,
      "step": 3658
    },
    {
      "epoch": 2.2042168674698797,
      "grad_norm": 0.6706647276878357,
      "learning_rate": 2.244728915662651e-06,
      "loss": 0.201,
      "step": 3659
    },
    {
      "epoch": 2.2048192771084336,
      "grad_norm": 0.566932737827301,
      "learning_rate": 2.243975903614458e-06,
      "loss": 0.2009,
      "step": 3660
    },
    {
      "epoch": 2.205421686746988,
      "grad_norm": 0.49303093552589417,
      "learning_rate": 2.2432228915662653e-06,
      "loss": 0.1284,
      "step": 3661
    },
    {
      "epoch": 2.206024096385542,
      "grad_norm": 0.5046042203903198,
      "learning_rate": 2.2424698795180723e-06,
      "loss": 0.1495,
      "step": 3662
    },
    {
      "epoch": 2.2066265060240964,
      "grad_norm": 0.5273137092590332,
      "learning_rate": 2.2417168674698796e-06,
      "loss": 0.1362,
      "step": 3663
    },
    {
      "epoch": 2.207228915662651,
      "grad_norm": 0.4787658751010895,
      "learning_rate": 2.240963855421687e-06,
      "loss": 0.1724,
      "step": 3664
    },
    {
      "epoch": 2.2078313253012047,
      "grad_norm": 0.6290585398674011,
      "learning_rate": 2.2402108433734943e-06,
      "loss": 0.1956,
      "step": 3665
    },
    {
      "epoch": 2.208433734939759,
      "grad_norm": 0.5722196102142334,
      "learning_rate": 2.2394578313253012e-06,
      "loss": 0.1741,
      "step": 3666
    },
    {
      "epoch": 2.209036144578313,
      "grad_norm": 0.6550503969192505,
      "learning_rate": 2.2387048192771086e-06,
      "loss": 0.2009,
      "step": 3667
    },
    {
      "epoch": 2.2096385542168675,
      "grad_norm": 0.6017492413520813,
      "learning_rate": 2.237951807228916e-06,
      "loss": 0.184,
      "step": 3668
    },
    {
      "epoch": 2.210240963855422,
      "grad_norm": 0.573021411895752,
      "learning_rate": 2.2371987951807233e-06,
      "loss": 0.1833,
      "step": 3669
    },
    {
      "epoch": 2.210843373493976,
      "grad_norm": 0.6811338067054749,
      "learning_rate": 2.23644578313253e-06,
      "loss": 0.161,
      "step": 3670
    },
    {
      "epoch": 2.2114457831325303,
      "grad_norm": 0.5298153758049011,
      "learning_rate": 2.2356927710843376e-06,
      "loss": 0.1377,
      "step": 3671
    },
    {
      "epoch": 2.212048192771084,
      "grad_norm": 0.48172640800476074,
      "learning_rate": 2.2349397590361445e-06,
      "loss": 0.1614,
      "step": 3672
    },
    {
      "epoch": 2.2126506024096386,
      "grad_norm": 0.8267249464988708,
      "learning_rate": 2.234186746987952e-06,
      "loss": 0.2065,
      "step": 3673
    },
    {
      "epoch": 2.2132530120481926,
      "grad_norm": 0.4949454069137573,
      "learning_rate": 2.233433734939759e-06,
      "loss": 0.1496,
      "step": 3674
    },
    {
      "epoch": 2.213855421686747,
      "grad_norm": 0.49479880928993225,
      "learning_rate": 2.2326807228915665e-06,
      "loss": 0.1449,
      "step": 3675
    },
    {
      "epoch": 2.2144578313253014,
      "grad_norm": 0.5416296720504761,
      "learning_rate": 2.231927710843374e-06,
      "loss": 0.1559,
      "step": 3676
    },
    {
      "epoch": 2.2150602409638553,
      "grad_norm": 0.5759478807449341,
      "learning_rate": 2.231174698795181e-06,
      "loss": 0.1846,
      "step": 3677
    },
    {
      "epoch": 2.2156626506024097,
      "grad_norm": 0.4799223840236664,
      "learning_rate": 2.230421686746988e-06,
      "loss": 0.1511,
      "step": 3678
    },
    {
      "epoch": 2.2162650602409637,
      "grad_norm": 0.6189200282096863,
      "learning_rate": 2.229668674698795e-06,
      "loss": 0.1486,
      "step": 3679
    },
    {
      "epoch": 2.216867469879518,
      "grad_norm": 0.48286348581314087,
      "learning_rate": 2.2289156626506024e-06,
      "loss": 0.1501,
      "step": 3680
    },
    {
      "epoch": 2.217469879518072,
      "grad_norm": 0.5823566913604736,
      "learning_rate": 2.2281626506024098e-06,
      "loss": 0.1572,
      "step": 3681
    },
    {
      "epoch": 2.2180722891566265,
      "grad_norm": 0.530010461807251,
      "learning_rate": 2.227409638554217e-06,
      "loss": 0.151,
      "step": 3682
    },
    {
      "epoch": 2.218674698795181,
      "grad_norm": 0.5296306610107422,
      "learning_rate": 2.2266566265060245e-06,
      "loss": 0.1444,
      "step": 3683
    },
    {
      "epoch": 2.219277108433735,
      "grad_norm": 0.4859711229801178,
      "learning_rate": 2.2259036144578314e-06,
      "loss": 0.1659,
      "step": 3684
    },
    {
      "epoch": 2.2198795180722892,
      "grad_norm": 0.5575504302978516,
      "learning_rate": 2.2251506024096387e-06,
      "loss": 0.1655,
      "step": 3685
    },
    {
      "epoch": 2.220481927710843,
      "grad_norm": 0.4554615318775177,
      "learning_rate": 2.224397590361446e-06,
      "loss": 0.163,
      "step": 3686
    },
    {
      "epoch": 2.2210843373493976,
      "grad_norm": 0.5413665175437927,
      "learning_rate": 2.223644578313253e-06,
      "loss": 0.1658,
      "step": 3687
    },
    {
      "epoch": 2.221686746987952,
      "grad_norm": 0.5502626299858093,
      "learning_rate": 2.2228915662650604e-06,
      "loss": 0.1443,
      "step": 3688
    },
    {
      "epoch": 2.222289156626506,
      "grad_norm": 0.6685003042221069,
      "learning_rate": 2.2221385542168677e-06,
      "loss": 0.1765,
      "step": 3689
    },
    {
      "epoch": 2.2228915662650603,
      "grad_norm": 0.533494234085083,
      "learning_rate": 2.2213855421686746e-06,
      "loss": 0.121,
      "step": 3690
    },
    {
      "epoch": 2.2234939759036143,
      "grad_norm": 0.6055545210838318,
      "learning_rate": 2.220632530120482e-06,
      "loss": 0.1964,
      "step": 3691
    },
    {
      "epoch": 2.2240963855421687,
      "grad_norm": 0.6746540069580078,
      "learning_rate": 2.2198795180722893e-06,
      "loss": 0.1944,
      "step": 3692
    },
    {
      "epoch": 2.224698795180723,
      "grad_norm": 0.4585537910461426,
      "learning_rate": 2.2191265060240967e-06,
      "loss": 0.1319,
      "step": 3693
    },
    {
      "epoch": 2.225301204819277,
      "grad_norm": 0.5371602773666382,
      "learning_rate": 2.218373493975904e-06,
      "loss": 0.1505,
      "step": 3694
    },
    {
      "epoch": 2.2259036144578315,
      "grad_norm": 0.5877625346183777,
      "learning_rate": 2.217620481927711e-06,
      "loss": 0.125,
      "step": 3695
    },
    {
      "epoch": 2.2265060240963854,
      "grad_norm": 0.4935423731803894,
      "learning_rate": 2.2168674698795183e-06,
      "loss": 0.1463,
      "step": 3696
    },
    {
      "epoch": 2.22710843373494,
      "grad_norm": 0.6114687323570251,
      "learning_rate": 2.2161144578313252e-06,
      "loss": 0.1699,
      "step": 3697
    },
    {
      "epoch": 2.227710843373494,
      "grad_norm": 0.5111570358276367,
      "learning_rate": 2.2153614457831326e-06,
      "loss": 0.1894,
      "step": 3698
    },
    {
      "epoch": 2.228313253012048,
      "grad_norm": 0.5372416377067566,
      "learning_rate": 2.21460843373494e-06,
      "loss": 0.1639,
      "step": 3699
    },
    {
      "epoch": 2.2289156626506026,
      "grad_norm": 0.48891663551330566,
      "learning_rate": 2.2138554216867473e-06,
      "loss": 0.162,
      "step": 3700
    },
    {
      "epoch": 2.2295180722891565,
      "grad_norm": 0.5212699770927429,
      "learning_rate": 2.2131024096385546e-06,
      "loss": 0.1377,
      "step": 3701
    },
    {
      "epoch": 2.230120481927711,
      "grad_norm": 0.6227508187294006,
      "learning_rate": 2.2123493975903615e-06,
      "loss": 0.1338,
      "step": 3702
    },
    {
      "epoch": 2.230722891566265,
      "grad_norm": 0.5238739848136902,
      "learning_rate": 2.211596385542169e-06,
      "loss": 0.1567,
      "step": 3703
    },
    {
      "epoch": 2.2313253012048193,
      "grad_norm": 0.48919954895973206,
      "learning_rate": 2.2108433734939762e-06,
      "loss": 0.1611,
      "step": 3704
    },
    {
      "epoch": 2.2319277108433733,
      "grad_norm": 0.7600412368774414,
      "learning_rate": 2.210090361445783e-06,
      "loss": 0.2216,
      "step": 3705
    },
    {
      "epoch": 2.2325301204819277,
      "grad_norm": 0.5496997237205505,
      "learning_rate": 2.2093373493975905e-06,
      "loss": 0.1394,
      "step": 3706
    },
    {
      "epoch": 2.233132530120482,
      "grad_norm": 0.5844596028327942,
      "learning_rate": 2.208584337349398e-06,
      "loss": 0.1383,
      "step": 3707
    },
    {
      "epoch": 2.233734939759036,
      "grad_norm": 0.4984162151813507,
      "learning_rate": 2.207831325301205e-06,
      "loss": 0.1568,
      "step": 3708
    },
    {
      "epoch": 2.2343373493975904,
      "grad_norm": 0.48712190985679626,
      "learning_rate": 2.207078313253012e-06,
      "loss": 0.1666,
      "step": 3709
    },
    {
      "epoch": 2.2349397590361444,
      "grad_norm": 0.4402486979961395,
      "learning_rate": 2.2063253012048195e-06,
      "loss": 0.123,
      "step": 3710
    },
    {
      "epoch": 2.235542168674699,
      "grad_norm": 0.43183010816574097,
      "learning_rate": 2.205572289156627e-06,
      "loss": 0.1286,
      "step": 3711
    },
    {
      "epoch": 2.236144578313253,
      "grad_norm": 0.5675169825553894,
      "learning_rate": 2.2048192771084338e-06,
      "loss": 0.1588,
      "step": 3712
    },
    {
      "epoch": 2.236746987951807,
      "grad_norm": 0.634485125541687,
      "learning_rate": 2.204066265060241e-06,
      "loss": 0.1309,
      "step": 3713
    },
    {
      "epoch": 2.2373493975903616,
      "grad_norm": 0.5280108451843262,
      "learning_rate": 2.203313253012048e-06,
      "loss": 0.1486,
      "step": 3714
    },
    {
      "epoch": 2.2379518072289155,
      "grad_norm": 0.5002466440200806,
      "learning_rate": 2.2025602409638554e-06,
      "loss": 0.1034,
      "step": 3715
    },
    {
      "epoch": 2.23855421686747,
      "grad_norm": 0.6366646885871887,
      "learning_rate": 2.2018072289156627e-06,
      "loss": 0.2018,
      "step": 3716
    },
    {
      "epoch": 2.2391566265060243,
      "grad_norm": 0.7715662121772766,
      "learning_rate": 2.20105421686747e-06,
      "loss": 0.1915,
      "step": 3717
    },
    {
      "epoch": 2.2397590361445783,
      "grad_norm": 0.7179409265518188,
      "learning_rate": 2.2003012048192774e-06,
      "loss": 0.1952,
      "step": 3718
    },
    {
      "epoch": 2.2403614457831327,
      "grad_norm": 0.6132806539535522,
      "learning_rate": 2.1995481927710848e-06,
      "loss": 0.1694,
      "step": 3719
    },
    {
      "epoch": 2.2409638554216866,
      "grad_norm": 0.5676008462905884,
      "learning_rate": 2.1987951807228917e-06,
      "loss": 0.1643,
      "step": 3720
    },
    {
      "epoch": 2.241566265060241,
      "grad_norm": 0.5058092474937439,
      "learning_rate": 2.198042168674699e-06,
      "loss": 0.1557,
      "step": 3721
    },
    {
      "epoch": 2.242168674698795,
      "grad_norm": 1.0512993335723877,
      "learning_rate": 2.197289156626506e-06,
      "loss": 0.1671,
      "step": 3722
    },
    {
      "epoch": 2.2427710843373494,
      "grad_norm": 0.5048577189445496,
      "learning_rate": 2.1965361445783133e-06,
      "loss": 0.1703,
      "step": 3723
    },
    {
      "epoch": 2.243373493975904,
      "grad_norm": 0.5598694682121277,
      "learning_rate": 2.1957831325301207e-06,
      "loss": 0.1447,
      "step": 3724
    },
    {
      "epoch": 2.2439759036144578,
      "grad_norm": 0.5629581212997437,
      "learning_rate": 2.195030120481928e-06,
      "loss": 0.1679,
      "step": 3725
    },
    {
      "epoch": 2.244578313253012,
      "grad_norm": 0.5515469312667847,
      "learning_rate": 2.194277108433735e-06,
      "loss": 0.1372,
      "step": 3726
    },
    {
      "epoch": 2.245180722891566,
      "grad_norm": 0.5523377656936646,
      "learning_rate": 2.1935240963855423e-06,
      "loss": 0.1585,
      "step": 3727
    },
    {
      "epoch": 2.2457831325301205,
      "grad_norm": 0.5991208553314209,
      "learning_rate": 2.1927710843373496e-06,
      "loss": 0.1928,
      "step": 3728
    },
    {
      "epoch": 2.2463855421686745,
      "grad_norm": 0.5921646356582642,
      "learning_rate": 2.192018072289157e-06,
      "loss": 0.1264,
      "step": 3729
    },
    {
      "epoch": 2.246987951807229,
      "grad_norm": 0.5297541618347168,
      "learning_rate": 2.191265060240964e-06,
      "loss": 0.1268,
      "step": 3730
    },
    {
      "epoch": 2.2475903614457833,
      "grad_norm": 0.5286402106285095,
      "learning_rate": 2.1905120481927713e-06,
      "loss": 0.1452,
      "step": 3731
    },
    {
      "epoch": 2.2481927710843372,
      "grad_norm": 0.5537211894989014,
      "learning_rate": 2.189759036144578e-06,
      "loss": 0.1395,
      "step": 3732
    },
    {
      "epoch": 2.2487951807228916,
      "grad_norm": 0.5378417372703552,
      "learning_rate": 2.1890060240963855e-06,
      "loss": 0.1724,
      "step": 3733
    },
    {
      "epoch": 2.2493975903614456,
      "grad_norm": 0.5835872292518616,
      "learning_rate": 2.188253012048193e-06,
      "loss": 0.1979,
      "step": 3734
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.5157282948493958,
      "learning_rate": 2.1875000000000002e-06,
      "loss": 0.1622,
      "step": 3735
    },
    {
      "epoch": 2.2506024096385544,
      "grad_norm": 0.49919000267982483,
      "learning_rate": 2.1867469879518076e-06,
      "loss": 0.1766,
      "step": 3736
    },
    {
      "epoch": 2.2512048192771084,
      "grad_norm": 0.5238417387008667,
      "learning_rate": 2.185993975903615e-06,
      "loss": 0.1454,
      "step": 3737
    },
    {
      "epoch": 2.2518072289156628,
      "grad_norm": 0.5524575710296631,
      "learning_rate": 2.185240963855422e-06,
      "loss": 0.1708,
      "step": 3738
    },
    {
      "epoch": 2.2524096385542167,
      "grad_norm": 0.7074792981147766,
      "learning_rate": 2.184487951807229e-06,
      "loss": 0.1848,
      "step": 3739
    },
    {
      "epoch": 2.253012048192771,
      "grad_norm": 0.5704392194747925,
      "learning_rate": 2.183734939759036e-06,
      "loss": 0.1815,
      "step": 3740
    },
    {
      "epoch": 2.2536144578313255,
      "grad_norm": 0.575291097164154,
      "learning_rate": 2.1829819277108435e-06,
      "loss": 0.1667,
      "step": 3741
    },
    {
      "epoch": 2.2542168674698795,
      "grad_norm": 0.4957277178764343,
      "learning_rate": 2.182228915662651e-06,
      "loss": 0.1303,
      "step": 3742
    },
    {
      "epoch": 2.254819277108434,
      "grad_norm": 0.5994545221328735,
      "learning_rate": 2.181475903614458e-06,
      "loss": 0.1475,
      "step": 3743
    },
    {
      "epoch": 2.255421686746988,
      "grad_norm": 0.6180930137634277,
      "learning_rate": 2.1807228915662655e-06,
      "loss": 0.1603,
      "step": 3744
    },
    {
      "epoch": 2.2560240963855422,
      "grad_norm": 0.5510154962539673,
      "learning_rate": 2.1799698795180724e-06,
      "loss": 0.1294,
      "step": 3745
    },
    {
      "epoch": 2.256626506024096,
      "grad_norm": 0.5162535309791565,
      "learning_rate": 2.17921686746988e-06,
      "loss": 0.1422,
      "step": 3746
    },
    {
      "epoch": 2.2572289156626506,
      "grad_norm": 0.5694355368614197,
      "learning_rate": 2.1784638554216867e-06,
      "loss": 0.1891,
      "step": 3747
    },
    {
      "epoch": 2.257831325301205,
      "grad_norm": 0.6252744793891907,
      "learning_rate": 2.177710843373494e-06,
      "loss": 0.1462,
      "step": 3748
    },
    {
      "epoch": 2.258433734939759,
      "grad_norm": 0.47007185220718384,
      "learning_rate": 2.1769578313253014e-06,
      "loss": 0.1526,
      "step": 3749
    },
    {
      "epoch": 2.2590361445783134,
      "grad_norm": 0.533318817615509,
      "learning_rate": 2.1762048192771088e-06,
      "loss": 0.1623,
      "step": 3750
    },
    {
      "epoch": 2.2596385542168673,
      "grad_norm": 0.6846603155136108,
      "learning_rate": 2.1754518072289157e-06,
      "loss": 0.2363,
      "step": 3751
    },
    {
      "epoch": 2.2602409638554217,
      "grad_norm": 0.5526257753372192,
      "learning_rate": 2.174698795180723e-06,
      "loss": 0.2318,
      "step": 3752
    },
    {
      "epoch": 2.2608433734939757,
      "grad_norm": 0.6808133721351624,
      "learning_rate": 2.1739457831325304e-06,
      "loss": 0.1762,
      "step": 3753
    },
    {
      "epoch": 2.26144578313253,
      "grad_norm": 0.6482111215591431,
      "learning_rate": 2.1731927710843377e-06,
      "loss": 0.2022,
      "step": 3754
    },
    {
      "epoch": 2.2620481927710845,
      "grad_norm": 0.5803993344306946,
      "learning_rate": 2.1724397590361447e-06,
      "loss": 0.1647,
      "step": 3755
    },
    {
      "epoch": 2.2626506024096384,
      "grad_norm": 0.6262899041175842,
      "learning_rate": 2.171686746987952e-06,
      "loss": 0.1852,
      "step": 3756
    },
    {
      "epoch": 2.263253012048193,
      "grad_norm": 0.6534356474876404,
      "learning_rate": 2.170933734939759e-06,
      "loss": 0.1876,
      "step": 3757
    },
    {
      "epoch": 2.263855421686747,
      "grad_norm": 0.5774783492088318,
      "learning_rate": 2.1701807228915663e-06,
      "loss": 0.124,
      "step": 3758
    },
    {
      "epoch": 2.264457831325301,
      "grad_norm": 0.7787294387817383,
      "learning_rate": 2.1694277108433736e-06,
      "loss": 0.1719,
      "step": 3759
    },
    {
      "epoch": 2.2650602409638556,
      "grad_norm": 0.4666183590888977,
      "learning_rate": 2.168674698795181e-06,
      "loss": 0.1288,
      "step": 3760
    },
    {
      "epoch": 2.2656626506024096,
      "grad_norm": 0.5816658139228821,
      "learning_rate": 2.1679216867469883e-06,
      "loss": 0.153,
      "step": 3761
    },
    {
      "epoch": 2.266265060240964,
      "grad_norm": 0.5252967476844788,
      "learning_rate": 2.1671686746987957e-06,
      "loss": 0.1392,
      "step": 3762
    },
    {
      "epoch": 2.266867469879518,
      "grad_norm": 0.4515860974788666,
      "learning_rate": 2.1664156626506026e-06,
      "loss": 0.1453,
      "step": 3763
    },
    {
      "epoch": 2.2674698795180723,
      "grad_norm": 0.574504017829895,
      "learning_rate": 2.16566265060241e-06,
      "loss": 0.1715,
      "step": 3764
    },
    {
      "epoch": 2.2680722891566267,
      "grad_norm": 0.41138336062431335,
      "learning_rate": 2.164909638554217e-06,
      "loss": 0.1397,
      "step": 3765
    },
    {
      "epoch": 2.2686746987951807,
      "grad_norm": 0.4953141510486603,
      "learning_rate": 2.1641566265060242e-06,
      "loss": 0.1384,
      "step": 3766
    },
    {
      "epoch": 2.269277108433735,
      "grad_norm": 0.46586212515830994,
      "learning_rate": 2.1634036144578316e-06,
      "loss": 0.1543,
      "step": 3767
    },
    {
      "epoch": 2.269879518072289,
      "grad_norm": 0.5697423219680786,
      "learning_rate": 2.162650602409639e-06,
      "loss": 0.143,
      "step": 3768
    },
    {
      "epoch": 2.2704819277108435,
      "grad_norm": 0.5636116862297058,
      "learning_rate": 2.161897590361446e-06,
      "loss": 0.1712,
      "step": 3769
    },
    {
      "epoch": 2.2710843373493974,
      "grad_norm": 0.5309965014457703,
      "learning_rate": 2.161144578313253e-06,
      "loss": 0.1486,
      "step": 3770
    },
    {
      "epoch": 2.271686746987952,
      "grad_norm": 0.6858384609222412,
      "learning_rate": 2.1603915662650605e-06,
      "loss": 0.184,
      "step": 3771
    },
    {
      "epoch": 2.272289156626506,
      "grad_norm": 0.5675019025802612,
      "learning_rate": 2.159638554216868e-06,
      "loss": 0.1098,
      "step": 3772
    },
    {
      "epoch": 2.27289156626506,
      "grad_norm": 0.5267936587333679,
      "learning_rate": 2.158885542168675e-06,
      "loss": 0.1242,
      "step": 3773
    },
    {
      "epoch": 2.2734939759036146,
      "grad_norm": 0.6396405696868896,
      "learning_rate": 2.158132530120482e-06,
      "loss": 0.1434,
      "step": 3774
    },
    {
      "epoch": 2.2740963855421685,
      "grad_norm": 0.5688868165016174,
      "learning_rate": 2.157379518072289e-06,
      "loss": 0.1848,
      "step": 3775
    },
    {
      "epoch": 2.274698795180723,
      "grad_norm": 0.5037094950675964,
      "learning_rate": 2.1566265060240964e-06,
      "loss": 0.1125,
      "step": 3776
    },
    {
      "epoch": 2.275301204819277,
      "grad_norm": 0.5924029350280762,
      "learning_rate": 2.1558734939759038e-06,
      "loss": 0.1465,
      "step": 3777
    },
    {
      "epoch": 2.2759036144578313,
      "grad_norm": 0.5009700059890747,
      "learning_rate": 2.155120481927711e-06,
      "loss": 0.1435,
      "step": 3778
    },
    {
      "epoch": 2.2765060240963857,
      "grad_norm": 0.7344866991043091,
      "learning_rate": 2.1543674698795185e-06,
      "loss": 0.2071,
      "step": 3779
    },
    {
      "epoch": 2.2771084337349397,
      "grad_norm": 0.6272113919258118,
      "learning_rate": 2.1536144578313254e-06,
      "loss": 0.1792,
      "step": 3780
    },
    {
      "epoch": 2.277710843373494,
      "grad_norm": 0.5301660299301147,
      "learning_rate": 2.1528614457831328e-06,
      "loss": 0.1625,
      "step": 3781
    },
    {
      "epoch": 2.278313253012048,
      "grad_norm": 0.747069239616394,
      "learning_rate": 2.1521084337349397e-06,
      "loss": 0.2415,
      "step": 3782
    },
    {
      "epoch": 2.2789156626506024,
      "grad_norm": 0.4742451310157776,
      "learning_rate": 2.151355421686747e-06,
      "loss": 0.1534,
      "step": 3783
    },
    {
      "epoch": 2.279518072289157,
      "grad_norm": 0.6835019588470459,
      "learning_rate": 2.1506024096385544e-06,
      "loss": 0.2181,
      "step": 3784
    },
    {
      "epoch": 2.2801204819277108,
      "grad_norm": 0.6024201512336731,
      "learning_rate": 2.1498493975903617e-06,
      "loss": 0.1676,
      "step": 3785
    },
    {
      "epoch": 2.280722891566265,
      "grad_norm": 0.6644080281257629,
      "learning_rate": 2.149096385542169e-06,
      "loss": 0.1413,
      "step": 3786
    },
    {
      "epoch": 2.281325301204819,
      "grad_norm": 0.7327603101730347,
      "learning_rate": 2.148343373493976e-06,
      "loss": 0.1479,
      "step": 3787
    },
    {
      "epoch": 2.2819277108433735,
      "grad_norm": 0.5692760944366455,
      "learning_rate": 2.1475903614457833e-06,
      "loss": 0.2007,
      "step": 3788
    },
    {
      "epoch": 2.282530120481928,
      "grad_norm": 0.5737794041633606,
      "learning_rate": 2.1468373493975907e-06,
      "loss": 0.1648,
      "step": 3789
    },
    {
      "epoch": 2.283132530120482,
      "grad_norm": 0.5717291235923767,
      "learning_rate": 2.1460843373493976e-06,
      "loss": 0.1558,
      "step": 3790
    },
    {
      "epoch": 2.2837349397590363,
      "grad_norm": 0.728601336479187,
      "learning_rate": 2.145331325301205e-06,
      "loss": 0.2212,
      "step": 3791
    },
    {
      "epoch": 2.2843373493975903,
      "grad_norm": 0.5410086512565613,
      "learning_rate": 2.1445783132530123e-06,
      "loss": 0.1602,
      "step": 3792
    },
    {
      "epoch": 2.2849397590361447,
      "grad_norm": 0.552857518196106,
      "learning_rate": 2.1438253012048192e-06,
      "loss": 0.131,
      "step": 3793
    },
    {
      "epoch": 2.2855421686746986,
      "grad_norm": 0.5963062644004822,
      "learning_rate": 2.1430722891566266e-06,
      "loss": 0.1561,
      "step": 3794
    },
    {
      "epoch": 2.286144578313253,
      "grad_norm": 0.5352966785430908,
      "learning_rate": 2.142319277108434e-06,
      "loss": 0.153,
      "step": 3795
    },
    {
      "epoch": 2.2867469879518074,
      "grad_norm": 0.6832054853439331,
      "learning_rate": 2.1415662650602413e-06,
      "loss": 0.1809,
      "step": 3796
    },
    {
      "epoch": 2.2873493975903614,
      "grad_norm": 0.5620738863945007,
      "learning_rate": 2.1408132530120486e-06,
      "loss": 0.1373,
      "step": 3797
    },
    {
      "epoch": 2.287951807228916,
      "grad_norm": 0.4646996855735779,
      "learning_rate": 2.1400602409638556e-06,
      "loss": 0.1479,
      "step": 3798
    },
    {
      "epoch": 2.2885542168674697,
      "grad_norm": 0.5834665894508362,
      "learning_rate": 2.139307228915663e-06,
      "loss": 0.1905,
      "step": 3799
    },
    {
      "epoch": 2.289156626506024,
      "grad_norm": 0.5343644618988037,
      "learning_rate": 2.13855421686747e-06,
      "loss": 0.1381,
      "step": 3800
    },
    {
      "epoch": 2.289759036144578,
      "grad_norm": 0.5567318201065063,
      "learning_rate": 2.137801204819277e-06,
      "loss": 0.1291,
      "step": 3801
    },
    {
      "epoch": 2.2903614457831325,
      "grad_norm": 0.5154531598091125,
      "learning_rate": 2.1370481927710845e-06,
      "loss": 0.1116,
      "step": 3802
    },
    {
      "epoch": 2.290963855421687,
      "grad_norm": 0.5695613622665405,
      "learning_rate": 2.136295180722892e-06,
      "loss": 0.1377,
      "step": 3803
    },
    {
      "epoch": 2.291566265060241,
      "grad_norm": 0.6741025447845459,
      "learning_rate": 2.1355421686746992e-06,
      "loss": 0.1486,
      "step": 3804
    },
    {
      "epoch": 2.2921686746987953,
      "grad_norm": 0.5408270359039307,
      "learning_rate": 2.134789156626506e-06,
      "loss": 0.1783,
      "step": 3805
    },
    {
      "epoch": 2.292771084337349,
      "grad_norm": 0.4829654395580292,
      "learning_rate": 2.1340361445783135e-06,
      "loss": 0.13,
      "step": 3806
    },
    {
      "epoch": 2.2933734939759036,
      "grad_norm": 0.557584822177887,
      "learning_rate": 2.133283132530121e-06,
      "loss": 0.1589,
      "step": 3807
    },
    {
      "epoch": 2.293975903614458,
      "grad_norm": 0.5368130803108215,
      "learning_rate": 2.1325301204819278e-06,
      "loss": 0.1223,
      "step": 3808
    },
    {
      "epoch": 2.294578313253012,
      "grad_norm": 0.5392963886260986,
      "learning_rate": 2.131777108433735e-06,
      "loss": 0.1604,
      "step": 3809
    },
    {
      "epoch": 2.2951807228915664,
      "grad_norm": 0.5194373726844788,
      "learning_rate": 2.1310240963855425e-06,
      "loss": 0.1444,
      "step": 3810
    },
    {
      "epoch": 2.2957831325301203,
      "grad_norm": 0.4817348122596741,
      "learning_rate": 2.1302710843373494e-06,
      "loss": 0.149,
      "step": 3811
    },
    {
      "epoch": 2.2963855421686747,
      "grad_norm": 0.5989698767662048,
      "learning_rate": 2.1295180722891567e-06,
      "loss": 0.1525,
      "step": 3812
    },
    {
      "epoch": 2.296987951807229,
      "grad_norm": 0.5490046143531799,
      "learning_rate": 2.128765060240964e-06,
      "loss": 0.1631,
      "step": 3813
    },
    {
      "epoch": 2.297590361445783,
      "grad_norm": 0.5159215331077576,
      "learning_rate": 2.1280120481927714e-06,
      "loss": 0.1353,
      "step": 3814
    },
    {
      "epoch": 2.2981927710843375,
      "grad_norm": 0.5209348797798157,
      "learning_rate": 2.1272590361445784e-06,
      "loss": 0.1474,
      "step": 3815
    },
    {
      "epoch": 2.2987951807228915,
      "grad_norm": 0.6068539619445801,
      "learning_rate": 2.1265060240963857e-06,
      "loss": 0.1284,
      "step": 3816
    },
    {
      "epoch": 2.299397590361446,
      "grad_norm": 0.4507477581501007,
      "learning_rate": 2.1257530120481926e-06,
      "loss": 0.1324,
      "step": 3817
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.6277135014533997,
      "learning_rate": 2.125e-06,
      "loss": 0.1953,
      "step": 3818
    },
    {
      "epoch": 2.3006024096385542,
      "grad_norm": 0.5411591529846191,
      "learning_rate": 2.1242469879518073e-06,
      "loss": 0.1528,
      "step": 3819
    },
    {
      "epoch": 2.3012048192771086,
      "grad_norm": 0.5421663522720337,
      "learning_rate": 2.1234939759036147e-06,
      "loss": 0.135,
      "step": 3820
    },
    {
      "epoch": 2.3018072289156626,
      "grad_norm": 0.5997201204299927,
      "learning_rate": 2.122740963855422e-06,
      "loss": 0.1568,
      "step": 3821
    },
    {
      "epoch": 2.302409638554217,
      "grad_norm": 0.47785428166389465,
      "learning_rate": 2.1219879518072294e-06,
      "loss": 0.1411,
      "step": 3822
    },
    {
      "epoch": 2.303012048192771,
      "grad_norm": 0.5231183767318726,
      "learning_rate": 2.1212349397590363e-06,
      "loss": 0.1387,
      "step": 3823
    },
    {
      "epoch": 2.3036144578313253,
      "grad_norm": 0.504134476184845,
      "learning_rate": 2.1204819277108437e-06,
      "loss": 0.1356,
      "step": 3824
    },
    {
      "epoch": 2.3042168674698793,
      "grad_norm": 0.562868058681488,
      "learning_rate": 2.1197289156626506e-06,
      "loss": 0.1622,
      "step": 3825
    },
    {
      "epoch": 2.3048192771084337,
      "grad_norm": 0.4954647123813629,
      "learning_rate": 2.118975903614458e-06,
      "loss": 0.1434,
      "step": 3826
    },
    {
      "epoch": 2.305421686746988,
      "grad_norm": 0.570575475692749,
      "learning_rate": 2.1182228915662653e-06,
      "loss": 0.1904,
      "step": 3827
    },
    {
      "epoch": 2.306024096385542,
      "grad_norm": 0.4658171236515045,
      "learning_rate": 2.1174698795180726e-06,
      "loss": 0.1266,
      "step": 3828
    },
    {
      "epoch": 2.3066265060240965,
      "grad_norm": 0.4893855154514313,
      "learning_rate": 2.1167168674698795e-06,
      "loss": 0.1483,
      "step": 3829
    },
    {
      "epoch": 2.3072289156626504,
      "grad_norm": 0.4460257589817047,
      "learning_rate": 2.115963855421687e-06,
      "loss": 0.1442,
      "step": 3830
    },
    {
      "epoch": 2.307831325301205,
      "grad_norm": 0.6203446984291077,
      "learning_rate": 2.1152108433734942e-06,
      "loss": 0.1373,
      "step": 3831
    },
    {
      "epoch": 2.3084337349397592,
      "grad_norm": 0.6924559473991394,
      "learning_rate": 2.1144578313253016e-06,
      "loss": 0.132,
      "step": 3832
    },
    {
      "epoch": 2.309036144578313,
      "grad_norm": 0.5457113981246948,
      "learning_rate": 2.1137048192771085e-06,
      "loss": 0.1545,
      "step": 3833
    },
    {
      "epoch": 2.3096385542168676,
      "grad_norm": 0.6573840379714966,
      "learning_rate": 2.112951807228916e-06,
      "loss": 0.1905,
      "step": 3834
    },
    {
      "epoch": 2.3102409638554215,
      "grad_norm": 0.4624963700771332,
      "learning_rate": 2.1121987951807228e-06,
      "loss": 0.1116,
      "step": 3835
    },
    {
      "epoch": 2.310843373493976,
      "grad_norm": 0.634857177734375,
      "learning_rate": 2.11144578313253e-06,
      "loss": 0.1509,
      "step": 3836
    },
    {
      "epoch": 2.3114457831325304,
      "grad_norm": 0.527151882648468,
      "learning_rate": 2.1106927710843375e-06,
      "loss": 0.1354,
      "step": 3837
    },
    {
      "epoch": 2.3120481927710843,
      "grad_norm": 0.6824550628662109,
      "learning_rate": 2.109939759036145e-06,
      "loss": 0.2088,
      "step": 3838
    },
    {
      "epoch": 2.3126506024096387,
      "grad_norm": 0.5490548014640808,
      "learning_rate": 2.109186746987952e-06,
      "loss": 0.1405,
      "step": 3839
    },
    {
      "epoch": 2.3132530120481927,
      "grad_norm": 0.4807148575782776,
      "learning_rate": 2.1084337349397595e-06,
      "loss": 0.1371,
      "step": 3840
    },
    {
      "epoch": 2.313855421686747,
      "grad_norm": 0.5237316489219666,
      "learning_rate": 2.1076807228915665e-06,
      "loss": 0.2034,
      "step": 3841
    },
    {
      "epoch": 2.314457831325301,
      "grad_norm": 0.7593772411346436,
      "learning_rate": 2.106927710843374e-06,
      "loss": 0.2553,
      "step": 3842
    },
    {
      "epoch": 2.3150602409638554,
      "grad_norm": 0.5986278057098389,
      "learning_rate": 2.1061746987951807e-06,
      "loss": 0.1604,
      "step": 3843
    },
    {
      "epoch": 2.31566265060241,
      "grad_norm": 0.5484005212783813,
      "learning_rate": 2.105421686746988e-06,
      "loss": 0.1502,
      "step": 3844
    },
    {
      "epoch": 2.316265060240964,
      "grad_norm": 0.6237608194351196,
      "learning_rate": 2.1046686746987954e-06,
      "loss": 0.1439,
      "step": 3845
    },
    {
      "epoch": 2.316867469879518,
      "grad_norm": 0.525370717048645,
      "learning_rate": 2.1039156626506028e-06,
      "loss": 0.1422,
      "step": 3846
    },
    {
      "epoch": 2.317469879518072,
      "grad_norm": 0.5598719120025635,
      "learning_rate": 2.1031626506024097e-06,
      "loss": 0.1124,
      "step": 3847
    },
    {
      "epoch": 2.3180722891566266,
      "grad_norm": 0.7758461833000183,
      "learning_rate": 2.102409638554217e-06,
      "loss": 0.2157,
      "step": 3848
    },
    {
      "epoch": 2.3186746987951805,
      "grad_norm": 0.5155596733093262,
      "learning_rate": 2.1016566265060244e-06,
      "loss": 0.1477,
      "step": 3849
    },
    {
      "epoch": 2.319277108433735,
      "grad_norm": 0.4534305930137634,
      "learning_rate": 2.1009036144578313e-06,
      "loss": 0.1455,
      "step": 3850
    },
    {
      "epoch": 2.3198795180722893,
      "grad_norm": 0.5687605142593384,
      "learning_rate": 2.1001506024096387e-06,
      "loss": 0.1676,
      "step": 3851
    },
    {
      "epoch": 2.3204819277108433,
      "grad_norm": 0.5699117183685303,
      "learning_rate": 2.099397590361446e-06,
      "loss": 0.1629,
      "step": 3852
    },
    {
      "epoch": 2.3210843373493977,
      "grad_norm": 0.4152139127254486,
      "learning_rate": 2.098644578313253e-06,
      "loss": 0.1218,
      "step": 3853
    },
    {
      "epoch": 2.3216867469879516,
      "grad_norm": 0.6618345975875854,
      "learning_rate": 2.0978915662650603e-06,
      "loss": 0.223,
      "step": 3854
    },
    {
      "epoch": 2.322289156626506,
      "grad_norm": 0.7037532925605774,
      "learning_rate": 2.0971385542168676e-06,
      "loss": 0.22,
      "step": 3855
    },
    {
      "epoch": 2.32289156626506,
      "grad_norm": 0.9255784749984741,
      "learning_rate": 2.096385542168675e-06,
      "loss": 0.1596,
      "step": 3856
    },
    {
      "epoch": 2.3234939759036144,
      "grad_norm": 0.5899505615234375,
      "learning_rate": 2.0956325301204823e-06,
      "loss": 0.1702,
      "step": 3857
    },
    {
      "epoch": 2.324096385542169,
      "grad_norm": 0.5260582566261292,
      "learning_rate": 2.0948795180722893e-06,
      "loss": 0.161,
      "step": 3858
    },
    {
      "epoch": 2.3246987951807228,
      "grad_norm": 0.5813360810279846,
      "learning_rate": 2.0941265060240966e-06,
      "loss": 0.1549,
      "step": 3859
    },
    {
      "epoch": 2.325301204819277,
      "grad_norm": 0.544918954372406,
      "learning_rate": 2.0933734939759035e-06,
      "loss": 0.179,
      "step": 3860
    },
    {
      "epoch": 2.3259036144578316,
      "grad_norm": 0.5524744391441345,
      "learning_rate": 2.092620481927711e-06,
      "loss": 0.1944,
      "step": 3861
    },
    {
      "epoch": 2.3265060240963855,
      "grad_norm": 0.49042975902557373,
      "learning_rate": 2.0918674698795182e-06,
      "loss": 0.1317,
      "step": 3862
    },
    {
      "epoch": 2.32710843373494,
      "grad_norm": 0.5285666584968567,
      "learning_rate": 2.0911144578313256e-06,
      "loss": 0.1319,
      "step": 3863
    },
    {
      "epoch": 2.327710843373494,
      "grad_norm": 0.6107312440872192,
      "learning_rate": 2.090361445783133e-06,
      "loss": 0.1385,
      "step": 3864
    },
    {
      "epoch": 2.3283132530120483,
      "grad_norm": 0.6431286334991455,
      "learning_rate": 2.08960843373494e-06,
      "loss": 0.1707,
      "step": 3865
    },
    {
      "epoch": 2.3289156626506022,
      "grad_norm": 0.6278249621391296,
      "learning_rate": 2.088855421686747e-06,
      "loss": 0.1862,
      "step": 3866
    },
    {
      "epoch": 2.3295180722891566,
      "grad_norm": 0.5594889521598816,
      "learning_rate": 2.0881024096385545e-06,
      "loss": 0.1699,
      "step": 3867
    },
    {
      "epoch": 2.330120481927711,
      "grad_norm": 0.49737492203712463,
      "learning_rate": 2.0873493975903615e-06,
      "loss": 0.1503,
      "step": 3868
    },
    {
      "epoch": 2.330722891566265,
      "grad_norm": 0.5209938883781433,
      "learning_rate": 2.086596385542169e-06,
      "loss": 0.1912,
      "step": 3869
    },
    {
      "epoch": 2.3313253012048194,
      "grad_norm": 0.8588172197341919,
      "learning_rate": 2.085843373493976e-06,
      "loss": 0.2292,
      "step": 3870
    },
    {
      "epoch": 2.3319277108433734,
      "grad_norm": 0.7309996485710144,
      "learning_rate": 2.085090361445783e-06,
      "loss": 0.1915,
      "step": 3871
    },
    {
      "epoch": 2.3325301204819278,
      "grad_norm": 0.5346444249153137,
      "learning_rate": 2.0843373493975904e-06,
      "loss": 0.1375,
      "step": 3872
    },
    {
      "epoch": 2.3331325301204817,
      "grad_norm": 0.48190703988075256,
      "learning_rate": 2.083584337349398e-06,
      "loss": 0.1386,
      "step": 3873
    },
    {
      "epoch": 2.333734939759036,
      "grad_norm": 0.7672138214111328,
      "learning_rate": 2.082831325301205e-06,
      "loss": 0.243,
      "step": 3874
    },
    {
      "epoch": 2.3343373493975905,
      "grad_norm": 0.5034777522087097,
      "learning_rate": 2.0820783132530125e-06,
      "loss": 0.1341,
      "step": 3875
    },
    {
      "epoch": 2.3349397590361445,
      "grad_norm": 0.5770953297615051,
      "learning_rate": 2.0813253012048194e-06,
      "loss": 0.1845,
      "step": 3876
    },
    {
      "epoch": 2.335542168674699,
      "grad_norm": 0.5070006251335144,
      "learning_rate": 2.0805722891566268e-06,
      "loss": 0.1558,
      "step": 3877
    },
    {
      "epoch": 2.336144578313253,
      "grad_norm": 0.5200784206390381,
      "learning_rate": 2.0798192771084337e-06,
      "loss": 0.1352,
      "step": 3878
    },
    {
      "epoch": 2.3367469879518072,
      "grad_norm": 0.5639057159423828,
      "learning_rate": 2.079066265060241e-06,
      "loss": 0.1155,
      "step": 3879
    },
    {
      "epoch": 2.337349397590361,
      "grad_norm": 0.4742205739021301,
      "learning_rate": 2.0783132530120484e-06,
      "loss": 0.1259,
      "step": 3880
    },
    {
      "epoch": 2.3379518072289156,
      "grad_norm": 0.4410831034183502,
      "learning_rate": 2.0775602409638557e-06,
      "loss": 0.1355,
      "step": 3881
    },
    {
      "epoch": 2.33855421686747,
      "grad_norm": 0.6473318338394165,
      "learning_rate": 2.076807228915663e-06,
      "loss": 0.1472,
      "step": 3882
    },
    {
      "epoch": 2.339156626506024,
      "grad_norm": 0.5364764332771301,
      "learning_rate": 2.07605421686747e-06,
      "loss": 0.1414,
      "step": 3883
    },
    {
      "epoch": 2.3397590361445784,
      "grad_norm": 0.5832414031028748,
      "learning_rate": 2.0753012048192774e-06,
      "loss": 0.1297,
      "step": 3884
    },
    {
      "epoch": 2.3403614457831328,
      "grad_norm": 0.5635790824890137,
      "learning_rate": 2.0745481927710847e-06,
      "loss": 0.1078,
      "step": 3885
    },
    {
      "epoch": 2.3409638554216867,
      "grad_norm": 0.6065757870674133,
      "learning_rate": 2.0737951807228916e-06,
      "loss": 0.1344,
      "step": 3886
    },
    {
      "epoch": 2.341566265060241,
      "grad_norm": 0.5111510157585144,
      "learning_rate": 2.073042168674699e-06,
      "loss": 0.1501,
      "step": 3887
    },
    {
      "epoch": 2.342168674698795,
      "grad_norm": 0.5860409140586853,
      "learning_rate": 2.0722891566265063e-06,
      "loss": 0.1643,
      "step": 3888
    },
    {
      "epoch": 2.3427710843373495,
      "grad_norm": 0.45544472336769104,
      "learning_rate": 2.0715361445783132e-06,
      "loss": 0.1384,
      "step": 3889
    },
    {
      "epoch": 2.3433734939759034,
      "grad_norm": 0.600497305393219,
      "learning_rate": 2.0707831325301206e-06,
      "loss": 0.2066,
      "step": 3890
    },
    {
      "epoch": 2.343975903614458,
      "grad_norm": 0.5820074081420898,
      "learning_rate": 2.070030120481928e-06,
      "loss": 0.1373,
      "step": 3891
    },
    {
      "epoch": 2.3445783132530122,
      "grad_norm": 0.5015455484390259,
      "learning_rate": 2.0692771084337353e-06,
      "loss": 0.1444,
      "step": 3892
    },
    {
      "epoch": 2.345180722891566,
      "grad_norm": 0.5056411623954773,
      "learning_rate": 2.0685240963855422e-06,
      "loss": 0.1394,
      "step": 3893
    },
    {
      "epoch": 2.3457831325301206,
      "grad_norm": 0.6781643033027649,
      "learning_rate": 2.0677710843373496e-06,
      "loss": 0.1923,
      "step": 3894
    },
    {
      "epoch": 2.3463855421686746,
      "grad_norm": 0.48895463347435,
      "learning_rate": 2.0670180722891565e-06,
      "loss": 0.1498,
      "step": 3895
    },
    {
      "epoch": 2.346987951807229,
      "grad_norm": 0.6316251754760742,
      "learning_rate": 2.066265060240964e-06,
      "loss": 0.1735,
      "step": 3896
    },
    {
      "epoch": 2.347590361445783,
      "grad_norm": 0.49613434076309204,
      "learning_rate": 2.065512048192771e-06,
      "loss": 0.1515,
      "step": 3897
    },
    {
      "epoch": 2.3481927710843373,
      "grad_norm": 0.5923159122467041,
      "learning_rate": 2.0647590361445785e-06,
      "loss": 0.1639,
      "step": 3898
    },
    {
      "epoch": 2.3487951807228917,
      "grad_norm": 0.7779830694198608,
      "learning_rate": 2.064006024096386e-06,
      "loss": 0.2186,
      "step": 3899
    },
    {
      "epoch": 2.3493975903614457,
      "grad_norm": 0.5170204043388367,
      "learning_rate": 2.0632530120481932e-06,
      "loss": 0.1704,
      "step": 3900
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.44843682646751404,
      "learning_rate": 2.0625e-06,
      "loss": 0.1403,
      "step": 3901
    },
    {
      "epoch": 2.350602409638554,
      "grad_norm": 0.6491746306419373,
      "learning_rate": 2.0617469879518075e-06,
      "loss": 0.1952,
      "step": 3902
    },
    {
      "epoch": 2.3512048192771084,
      "grad_norm": 0.41801580786705017,
      "learning_rate": 2.0609939759036144e-06,
      "loss": 0.0994,
      "step": 3903
    },
    {
      "epoch": 2.3518072289156624,
      "grad_norm": 0.47105786204338074,
      "learning_rate": 2.0602409638554218e-06,
      "loss": 0.1068,
      "step": 3904
    },
    {
      "epoch": 2.352409638554217,
      "grad_norm": 0.5077059268951416,
      "learning_rate": 2.059487951807229e-06,
      "loss": 0.1629,
      "step": 3905
    },
    {
      "epoch": 2.353012048192771,
      "grad_norm": 0.5062056183815002,
      "learning_rate": 2.0587349397590365e-06,
      "loss": 0.1332,
      "step": 3906
    },
    {
      "epoch": 2.353614457831325,
      "grad_norm": 0.5238388776779175,
      "learning_rate": 2.0579819277108434e-06,
      "loss": 0.1355,
      "step": 3907
    },
    {
      "epoch": 2.3542168674698796,
      "grad_norm": 0.760162889957428,
      "learning_rate": 2.0572289156626507e-06,
      "loss": 0.1887,
      "step": 3908
    },
    {
      "epoch": 2.354819277108434,
      "grad_norm": 0.689447283744812,
      "learning_rate": 2.056475903614458e-06,
      "loss": 0.1982,
      "step": 3909
    },
    {
      "epoch": 2.355421686746988,
      "grad_norm": 0.4859425127506256,
      "learning_rate": 2.0557228915662654e-06,
      "loss": 0.1424,
      "step": 3910
    },
    {
      "epoch": 2.3560240963855423,
      "grad_norm": 0.7004457712173462,
      "learning_rate": 2.0549698795180724e-06,
      "loss": 0.1901,
      "step": 3911
    },
    {
      "epoch": 2.3566265060240963,
      "grad_norm": 0.6597800254821777,
      "learning_rate": 2.0542168674698797e-06,
      "loss": 0.151,
      "step": 3912
    },
    {
      "epoch": 2.3572289156626507,
      "grad_norm": 0.7062252163887024,
      "learning_rate": 2.0534638554216866e-06,
      "loss": 0.2008,
      "step": 3913
    },
    {
      "epoch": 2.3578313253012047,
      "grad_norm": 0.5128737688064575,
      "learning_rate": 2.052710843373494e-06,
      "loss": 0.1864,
      "step": 3914
    },
    {
      "epoch": 2.358433734939759,
      "grad_norm": 0.5114588141441345,
      "learning_rate": 2.0519578313253013e-06,
      "loss": 0.1053,
      "step": 3915
    },
    {
      "epoch": 2.3590361445783135,
      "grad_norm": 0.4753018319606781,
      "learning_rate": 2.0512048192771087e-06,
      "loss": 0.1271,
      "step": 3916
    },
    {
      "epoch": 2.3596385542168674,
      "grad_norm": 0.6551634073257446,
      "learning_rate": 2.050451807228916e-06,
      "loss": 0.191,
      "step": 3917
    },
    {
      "epoch": 2.360240963855422,
      "grad_norm": 0.5695560574531555,
      "learning_rate": 2.0496987951807234e-06,
      "loss": 0.1372,
      "step": 3918
    },
    {
      "epoch": 2.3608433734939758,
      "grad_norm": 0.5306557416915894,
      "learning_rate": 2.0489457831325303e-06,
      "loss": 0.1407,
      "step": 3919
    },
    {
      "epoch": 2.36144578313253,
      "grad_norm": 0.4811969995498657,
      "learning_rate": 2.0481927710843377e-06,
      "loss": 0.1305,
      "step": 3920
    },
    {
      "epoch": 2.362048192771084,
      "grad_norm": 0.48168858885765076,
      "learning_rate": 2.0474397590361446e-06,
      "loss": 0.158,
      "step": 3921
    },
    {
      "epoch": 2.3626506024096385,
      "grad_norm": 0.6981278657913208,
      "learning_rate": 2.046686746987952e-06,
      "loss": 0.1749,
      "step": 3922
    },
    {
      "epoch": 2.363253012048193,
      "grad_norm": 0.7043485045433044,
      "learning_rate": 2.0459337349397593e-06,
      "loss": 0.1684,
      "step": 3923
    },
    {
      "epoch": 2.363855421686747,
      "grad_norm": 0.5257406234741211,
      "learning_rate": 2.0451807228915666e-06,
      "loss": 0.1692,
      "step": 3924
    },
    {
      "epoch": 2.3644578313253013,
      "grad_norm": 0.6178749203681946,
      "learning_rate": 2.0444277108433736e-06,
      "loss": 0.235,
      "step": 3925
    },
    {
      "epoch": 2.3650602409638553,
      "grad_norm": 0.5900364518165588,
      "learning_rate": 2.043674698795181e-06,
      "loss": 0.2054,
      "step": 3926
    },
    {
      "epoch": 2.3656626506024097,
      "grad_norm": 0.5153489112854004,
      "learning_rate": 2.0429216867469883e-06,
      "loss": 0.1539,
      "step": 3927
    },
    {
      "epoch": 2.3662650602409636,
      "grad_norm": 0.5771277546882629,
      "learning_rate": 2.042168674698795e-06,
      "loss": 0.1344,
      "step": 3928
    },
    {
      "epoch": 2.366867469879518,
      "grad_norm": 0.4735531806945801,
      "learning_rate": 2.0414156626506025e-06,
      "loss": 0.1434,
      "step": 3929
    },
    {
      "epoch": 2.3674698795180724,
      "grad_norm": 0.44649583101272583,
      "learning_rate": 2.04066265060241e-06,
      "loss": 0.1391,
      "step": 3930
    },
    {
      "epoch": 2.3680722891566264,
      "grad_norm": 0.5880042910575867,
      "learning_rate": 2.039909638554217e-06,
      "loss": 0.1568,
      "step": 3931
    },
    {
      "epoch": 2.3686746987951808,
      "grad_norm": 0.5254882574081421,
      "learning_rate": 2.039156626506024e-06,
      "loss": 0.1331,
      "step": 3932
    },
    {
      "epoch": 2.369277108433735,
      "grad_norm": 0.498384028673172,
      "learning_rate": 2.0384036144578315e-06,
      "loss": 0.1639,
      "step": 3933
    },
    {
      "epoch": 2.369879518072289,
      "grad_norm": 0.6080985069274902,
      "learning_rate": 2.037650602409639e-06,
      "loss": 0.208,
      "step": 3934
    },
    {
      "epoch": 2.3704819277108435,
      "grad_norm": 0.5353387594223022,
      "learning_rate": 2.036897590361446e-06,
      "loss": 0.1479,
      "step": 3935
    },
    {
      "epoch": 2.3710843373493975,
      "grad_norm": 0.5789424180984497,
      "learning_rate": 2.036144578313253e-06,
      "loss": 0.1993,
      "step": 3936
    },
    {
      "epoch": 2.371686746987952,
      "grad_norm": 0.47006556391716003,
      "learning_rate": 2.0353915662650605e-06,
      "loss": 0.1394,
      "step": 3937
    },
    {
      "epoch": 2.372289156626506,
      "grad_norm": 0.515400230884552,
      "learning_rate": 2.0346385542168674e-06,
      "loss": 0.135,
      "step": 3938
    },
    {
      "epoch": 2.3728915662650603,
      "grad_norm": 0.4881328344345093,
      "learning_rate": 2.0338855421686747e-06,
      "loss": 0.1282,
      "step": 3939
    },
    {
      "epoch": 2.3734939759036147,
      "grad_norm": 0.6556612849235535,
      "learning_rate": 2.033132530120482e-06,
      "loss": 0.1653,
      "step": 3940
    },
    {
      "epoch": 2.3740963855421686,
      "grad_norm": 0.6102291345596313,
      "learning_rate": 2.0323795180722894e-06,
      "loss": 0.1528,
      "step": 3941
    },
    {
      "epoch": 2.374698795180723,
      "grad_norm": 0.5208916664123535,
      "learning_rate": 2.0316265060240968e-06,
      "loss": 0.1626,
      "step": 3942
    },
    {
      "epoch": 2.375301204819277,
      "grad_norm": 0.5515953302383423,
      "learning_rate": 2.0308734939759037e-06,
      "loss": 0.1586,
      "step": 3943
    },
    {
      "epoch": 2.3759036144578314,
      "grad_norm": 0.5051334500312805,
      "learning_rate": 2.030120481927711e-06,
      "loss": 0.1432,
      "step": 3944
    },
    {
      "epoch": 2.3765060240963853,
      "grad_norm": 0.49828875064849854,
      "learning_rate": 2.0293674698795184e-06,
      "loss": 0.1475,
      "step": 3945
    },
    {
      "epoch": 2.3771084337349397,
      "grad_norm": 0.5342928767204285,
      "learning_rate": 2.0286144578313253e-06,
      "loss": 0.1514,
      "step": 3946
    },
    {
      "epoch": 2.377710843373494,
      "grad_norm": 0.5127840638160706,
      "learning_rate": 2.0278614457831327e-06,
      "loss": 0.1675,
      "step": 3947
    },
    {
      "epoch": 2.378313253012048,
      "grad_norm": 0.7225967645645142,
      "learning_rate": 2.02710843373494e-06,
      "loss": 0.1874,
      "step": 3948
    },
    {
      "epoch": 2.3789156626506025,
      "grad_norm": 0.7552552819252014,
      "learning_rate": 2.026355421686747e-06,
      "loss": 0.1863,
      "step": 3949
    },
    {
      "epoch": 2.3795180722891565,
      "grad_norm": 0.5291985869407654,
      "learning_rate": 2.0256024096385543e-06,
      "loss": 0.1368,
      "step": 3950
    },
    {
      "epoch": 2.380120481927711,
      "grad_norm": 0.5929490923881531,
      "learning_rate": 2.0248493975903616e-06,
      "loss": 0.1999,
      "step": 3951
    },
    {
      "epoch": 2.380722891566265,
      "grad_norm": 0.48561257123947144,
      "learning_rate": 2.024096385542169e-06,
      "loss": 0.1251,
      "step": 3952
    },
    {
      "epoch": 2.3813253012048192,
      "grad_norm": 0.4070686101913452,
      "learning_rate": 2.0233433734939763e-06,
      "loss": 0.1348,
      "step": 3953
    },
    {
      "epoch": 2.3819277108433736,
      "grad_norm": 0.5165770053863525,
      "learning_rate": 2.0225903614457833e-06,
      "loss": 0.1141,
      "step": 3954
    },
    {
      "epoch": 2.3825301204819276,
      "grad_norm": 0.4765014350414276,
      "learning_rate": 2.0218373493975906e-06,
      "loss": 0.1436,
      "step": 3955
    },
    {
      "epoch": 2.383132530120482,
      "grad_norm": 0.5767753720283508,
      "learning_rate": 2.0210843373493975e-06,
      "loss": 0.1591,
      "step": 3956
    },
    {
      "epoch": 2.3837349397590364,
      "grad_norm": 0.5535762310028076,
      "learning_rate": 2.020331325301205e-06,
      "loss": 0.1552,
      "step": 3957
    },
    {
      "epoch": 2.3843373493975903,
      "grad_norm": 0.5920224189758301,
      "learning_rate": 2.0195783132530122e-06,
      "loss": 0.1185,
      "step": 3958
    },
    {
      "epoch": 2.3849397590361447,
      "grad_norm": 0.5700750946998596,
      "learning_rate": 2.0188253012048196e-06,
      "loss": 0.1548,
      "step": 3959
    },
    {
      "epoch": 2.3855421686746987,
      "grad_norm": 0.5159188508987427,
      "learning_rate": 2.018072289156627e-06,
      "loss": 0.1588,
      "step": 3960
    },
    {
      "epoch": 2.386144578313253,
      "grad_norm": 0.5859742164611816,
      "learning_rate": 2.017319277108434e-06,
      "loss": 0.1692,
      "step": 3961
    },
    {
      "epoch": 2.386746987951807,
      "grad_norm": 0.5598260760307312,
      "learning_rate": 2.016566265060241e-06,
      "loss": 0.1732,
      "step": 3962
    },
    {
      "epoch": 2.3873493975903615,
      "grad_norm": 0.57221919298172,
      "learning_rate": 2.015813253012048e-06,
      "loss": 0.1503,
      "step": 3963
    },
    {
      "epoch": 2.387951807228916,
      "grad_norm": 0.5523272752761841,
      "learning_rate": 2.0150602409638555e-06,
      "loss": 0.1506,
      "step": 3964
    },
    {
      "epoch": 2.38855421686747,
      "grad_norm": 0.5626435279846191,
      "learning_rate": 2.014307228915663e-06,
      "loss": 0.2292,
      "step": 3965
    },
    {
      "epoch": 2.3891566265060242,
      "grad_norm": 0.5324121117591858,
      "learning_rate": 2.01355421686747e-06,
      "loss": 0.1396,
      "step": 3966
    },
    {
      "epoch": 2.389759036144578,
      "grad_norm": 0.6148520708084106,
      "learning_rate": 2.012801204819277e-06,
      "loss": 0.1538,
      "step": 3967
    },
    {
      "epoch": 2.3903614457831326,
      "grad_norm": 0.5461744666099548,
      "learning_rate": 2.0120481927710845e-06,
      "loss": 0.1548,
      "step": 3968
    },
    {
      "epoch": 2.3909638554216865,
      "grad_norm": 0.6465327739715576,
      "learning_rate": 2.011295180722892e-06,
      "loss": 0.1595,
      "step": 3969
    },
    {
      "epoch": 2.391566265060241,
      "grad_norm": 0.6293236613273621,
      "learning_rate": 2.010542168674699e-06,
      "loss": 0.2218,
      "step": 3970
    },
    {
      "epoch": 2.3921686746987953,
      "grad_norm": 0.5507731437683105,
      "learning_rate": 2.009789156626506e-06,
      "loss": 0.1613,
      "step": 3971
    },
    {
      "epoch": 2.3927710843373493,
      "grad_norm": 0.5075857639312744,
      "learning_rate": 2.0090361445783134e-06,
      "loss": 0.1255,
      "step": 3972
    },
    {
      "epoch": 2.3933734939759037,
      "grad_norm": 0.5174638628959656,
      "learning_rate": 2.0082831325301203e-06,
      "loss": 0.1657,
      "step": 3973
    },
    {
      "epoch": 2.3939759036144577,
      "grad_norm": 0.5935184955596924,
      "learning_rate": 2.0075301204819277e-06,
      "loss": 0.2007,
      "step": 3974
    },
    {
      "epoch": 2.394578313253012,
      "grad_norm": 0.5730900168418884,
      "learning_rate": 2.006777108433735e-06,
      "loss": 0.1915,
      "step": 3975
    },
    {
      "epoch": 2.395180722891566,
      "grad_norm": 0.49907392263412476,
      "learning_rate": 2.0060240963855424e-06,
      "loss": 0.1532,
      "step": 3976
    },
    {
      "epoch": 2.3957831325301204,
      "grad_norm": 0.4534881114959717,
      "learning_rate": 2.0052710843373497e-06,
      "loss": 0.1311,
      "step": 3977
    },
    {
      "epoch": 2.396385542168675,
      "grad_norm": 0.5602032542228699,
      "learning_rate": 2.004518072289157e-06,
      "loss": 0.1839,
      "step": 3978
    },
    {
      "epoch": 2.396987951807229,
      "grad_norm": 0.5700590014457703,
      "learning_rate": 2.003765060240964e-06,
      "loss": 0.149,
      "step": 3979
    },
    {
      "epoch": 2.397590361445783,
      "grad_norm": 0.8490465879440308,
      "learning_rate": 2.0030120481927714e-06,
      "loss": 0.2426,
      "step": 3980
    },
    {
      "epoch": 2.3981927710843376,
      "grad_norm": 1.2016218900680542,
      "learning_rate": 2.0022590361445783e-06,
      "loss": 0.2269,
      "step": 3981
    },
    {
      "epoch": 2.3987951807228916,
      "grad_norm": 1.0028245449066162,
      "learning_rate": 2.0015060240963856e-06,
      "loss": 0.2807,
      "step": 3982
    },
    {
      "epoch": 2.399397590361446,
      "grad_norm": 0.9152384400367737,
      "learning_rate": 2.000753012048193e-06,
      "loss": 0.2503,
      "step": 3983
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.8813669085502625,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.2695,
      "step": 3984
    },
    {
      "epoch": 2.4006024096385543,
      "grad_norm": 0.9657642245292664,
      "learning_rate": 1.9992469879518073e-06,
      "loss": 0.2775,
      "step": 3985
    },
    {
      "epoch": 2.4012048192771083,
      "grad_norm": 0.867294430732727,
      "learning_rate": 1.9984939759036146e-06,
      "loss": 0.3084,
      "step": 3986
    },
    {
      "epoch": 2.4018072289156627,
      "grad_norm": 0.7531641721725464,
      "learning_rate": 1.997740963855422e-06,
      "loss": 0.2784,
      "step": 3987
    },
    {
      "epoch": 2.402409638554217,
      "grad_norm": 0.7587413191795349,
      "learning_rate": 1.9969879518072293e-06,
      "loss": 0.2581,
      "step": 3988
    },
    {
      "epoch": 2.403012048192771,
      "grad_norm": 0.6594477891921997,
      "learning_rate": 1.9962349397590362e-06,
      "loss": 0.254,
      "step": 3989
    },
    {
      "epoch": 2.4036144578313254,
      "grad_norm": 0.6696134209632874,
      "learning_rate": 1.9954819277108436e-06,
      "loss": 0.2607,
      "step": 3990
    },
    {
      "epoch": 2.4042168674698794,
      "grad_norm": 0.7736864686012268,
      "learning_rate": 1.9947289156626505e-06,
      "loss": 0.2387,
      "step": 3991
    },
    {
      "epoch": 2.404819277108434,
      "grad_norm": 0.6984425187110901,
      "learning_rate": 1.993975903614458e-06,
      "loss": 0.2087,
      "step": 3992
    },
    {
      "epoch": 2.4054216867469878,
      "grad_norm": 0.552108108997345,
      "learning_rate": 1.993222891566265e-06,
      "loss": 0.2291,
      "step": 3993
    },
    {
      "epoch": 2.406024096385542,
      "grad_norm": 0.6088219881057739,
      "learning_rate": 1.9924698795180725e-06,
      "loss": 0.2227,
      "step": 3994
    },
    {
      "epoch": 2.4066265060240966,
      "grad_norm": 0.6873452067375183,
      "learning_rate": 1.99171686746988e-06,
      "loss": 0.206,
      "step": 3995
    },
    {
      "epoch": 2.4072289156626505,
      "grad_norm": 0.7313573360443115,
      "learning_rate": 1.990963855421687e-06,
      "loss": 0.261,
      "step": 3996
    },
    {
      "epoch": 2.407831325301205,
      "grad_norm": 0.6383541822433472,
      "learning_rate": 1.990210843373494e-06,
      "loss": 0.2194,
      "step": 3997
    },
    {
      "epoch": 2.408433734939759,
      "grad_norm": 0.6499564051628113,
      "learning_rate": 1.989457831325301e-06,
      "loss": 0.2294,
      "step": 3998
    },
    {
      "epoch": 2.4090361445783133,
      "grad_norm": 0.6169601082801819,
      "learning_rate": 1.9887048192771084e-06,
      "loss": 0.2247,
      "step": 3999
    },
    {
      "epoch": 2.4096385542168672,
      "grad_norm": 0.6436306238174438,
      "learning_rate": 1.987951807228916e-06,
      "loss": 0.21,
      "step": 4000
    }
  ],
  "logging_steps": 1,
  "max_steps": 6640,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2.79072158774408e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
