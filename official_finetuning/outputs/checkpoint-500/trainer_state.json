{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.7587253414264037,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0015174506828528073,
      "grad_norm": 1.2296100854873657,
      "learning_rate": 4.998103186646434e-06,
      "loss": 2.543,
      "step": 1
    },
    {
      "epoch": 0.0030349013657056147,
      "grad_norm": 1.145377516746521,
      "learning_rate": 4.996206373292868e-06,
      "loss": 2.5,
      "step": 2
    },
    {
      "epoch": 0.004552352048558422,
      "grad_norm": 1.2370086908340454,
      "learning_rate": 4.994309559939302e-06,
      "loss": 2.7604,
      "step": 3
    },
    {
      "epoch": 0.006069802731411229,
      "grad_norm": 1.521728515625,
      "learning_rate": 4.992412746585736e-06,
      "loss": 3.0212,
      "step": 4
    },
    {
      "epoch": 0.007587253414264037,
      "grad_norm": 1.2180225849151611,
      "learning_rate": 4.99051593323217e-06,
      "loss": 2.7215,
      "step": 5
    },
    {
      "epoch": 0.009104704097116844,
      "grad_norm": 1.269407868385315,
      "learning_rate": 4.988619119878604e-06,
      "loss": 2.8052,
      "step": 6
    },
    {
      "epoch": 0.010622154779969651,
      "grad_norm": 1.2483986616134644,
      "learning_rate": 4.986722306525038e-06,
      "loss": 2.6528,
      "step": 7
    },
    {
      "epoch": 0.012139605462822459,
      "grad_norm": 1.3500843048095703,
      "learning_rate": 4.984825493171473e-06,
      "loss": 2.9147,
      "step": 8
    },
    {
      "epoch": 0.013657056145675266,
      "grad_norm": 1.2383064031600952,
      "learning_rate": 4.982928679817906e-06,
      "loss": 2.7425,
      "step": 9
    },
    {
      "epoch": 0.015174506828528073,
      "grad_norm": 1.4451353549957275,
      "learning_rate": 4.9810318664643405e-06,
      "loss": 2.7475,
      "step": 10
    },
    {
      "epoch": 0.01669195751138088,
      "grad_norm": 1.1594111919403076,
      "learning_rate": 4.9791350531107744e-06,
      "loss": 2.5578,
      "step": 11
    },
    {
      "epoch": 0.018209408194233688,
      "grad_norm": 1.3190877437591553,
      "learning_rate": 4.977238239757208e-06,
      "loss": 2.8807,
      "step": 12
    },
    {
      "epoch": 0.019726858877086494,
      "grad_norm": 1.3993353843688965,
      "learning_rate": 4.975341426403642e-06,
      "loss": 2.9224,
      "step": 13
    },
    {
      "epoch": 0.021244309559939303,
      "grad_norm": 1.2011858224868774,
      "learning_rate": 4.973444613050076e-06,
      "loss": 2.6071,
      "step": 14
    },
    {
      "epoch": 0.02276176024279211,
      "grad_norm": 1.2973114252090454,
      "learning_rate": 4.97154779969651e-06,
      "loss": 2.6974,
      "step": 15
    },
    {
      "epoch": 0.024279210925644917,
      "grad_norm": 1.3878428936004639,
      "learning_rate": 4.969650986342944e-06,
      "loss": 2.8255,
      "step": 16
    },
    {
      "epoch": 0.025796661608497723,
      "grad_norm": 1.5073424577713013,
      "learning_rate": 4.967754172989378e-06,
      "loss": 2.9621,
      "step": 17
    },
    {
      "epoch": 0.027314112291350532,
      "grad_norm": 1.3009450435638428,
      "learning_rate": 4.965857359635812e-06,
      "loss": 2.8005,
      "step": 18
    },
    {
      "epoch": 0.028831562974203338,
      "grad_norm": 1.2101572751998901,
      "learning_rate": 4.963960546282246e-06,
      "loss": 2.5443,
      "step": 19
    },
    {
      "epoch": 0.030349013657056147,
      "grad_norm": 1.4805757999420166,
      "learning_rate": 4.962063732928681e-06,
      "loss": 3.0018,
      "step": 20
    },
    {
      "epoch": 0.03186646433990895,
      "grad_norm": 1.3378322124481201,
      "learning_rate": 4.960166919575114e-06,
      "loss": 2.7067,
      "step": 21
    },
    {
      "epoch": 0.03338391502276176,
      "grad_norm": 1.7017117738723755,
      "learning_rate": 4.9582701062215485e-06,
      "loss": 2.9837,
      "step": 22
    },
    {
      "epoch": 0.03490136570561457,
      "grad_norm": 1.3948395252227783,
      "learning_rate": 4.956373292867982e-06,
      "loss": 2.7968,
      "step": 23
    },
    {
      "epoch": 0.036418816388467376,
      "grad_norm": 1.3768593072891235,
      "learning_rate": 4.954476479514416e-06,
      "loss": 2.5307,
      "step": 24
    },
    {
      "epoch": 0.03793626707132018,
      "grad_norm": 1.565778136253357,
      "learning_rate": 4.95257966616085e-06,
      "loss": 3.0025,
      "step": 25
    },
    {
      "epoch": 0.03945371775417299,
      "grad_norm": 1.4931375980377197,
      "learning_rate": 4.950682852807284e-06,
      "loss": 2.899,
      "step": 26
    },
    {
      "epoch": 0.0409711684370258,
      "grad_norm": 1.382623314857483,
      "learning_rate": 4.948786039453718e-06,
      "loss": 2.6828,
      "step": 27
    },
    {
      "epoch": 0.042488619119878605,
      "grad_norm": 1.616318941116333,
      "learning_rate": 4.946889226100152e-06,
      "loss": 2.7557,
      "step": 28
    },
    {
      "epoch": 0.04400606980273141,
      "grad_norm": 1.7636715173721313,
      "learning_rate": 4.944992412746586e-06,
      "loss": 2.8293,
      "step": 29
    },
    {
      "epoch": 0.04552352048558422,
      "grad_norm": 1.5515614748001099,
      "learning_rate": 4.94309559939302e-06,
      "loss": 2.625,
      "step": 30
    },
    {
      "epoch": 0.04704097116843703,
      "grad_norm": 1.5387170314788818,
      "learning_rate": 4.941198786039454e-06,
      "loss": 2.675,
      "step": 31
    },
    {
      "epoch": 0.048558421851289835,
      "grad_norm": 1.5197559595108032,
      "learning_rate": 4.9393019726858886e-06,
      "loss": 2.8956,
      "step": 32
    },
    {
      "epoch": 0.05007587253414264,
      "grad_norm": 1.2622113227844238,
      "learning_rate": 4.937405159332322e-06,
      "loss": 2.462,
      "step": 33
    },
    {
      "epoch": 0.051593323216995446,
      "grad_norm": 1.5991828441619873,
      "learning_rate": 4.935508345978756e-06,
      "loss": 2.9048,
      "step": 34
    },
    {
      "epoch": 0.05311077389984825,
      "grad_norm": 1.496391773223877,
      "learning_rate": 4.9336115326251895e-06,
      "loss": 2.8618,
      "step": 35
    },
    {
      "epoch": 0.054628224582701064,
      "grad_norm": 1.6357301473617554,
      "learning_rate": 4.931714719271624e-06,
      "loss": 2.7141,
      "step": 36
    },
    {
      "epoch": 0.05614567526555387,
      "grad_norm": 1.3496685028076172,
      "learning_rate": 4.929817905918058e-06,
      "loss": 2.508,
      "step": 37
    },
    {
      "epoch": 0.057663125948406675,
      "grad_norm": 1.3136640787124634,
      "learning_rate": 4.927921092564492e-06,
      "loss": 2.4844,
      "step": 38
    },
    {
      "epoch": 0.05918057663125948,
      "grad_norm": 1.5625697374343872,
      "learning_rate": 4.926024279210926e-06,
      "loss": 2.843,
      "step": 39
    },
    {
      "epoch": 0.06069802731411229,
      "grad_norm": 1.3695666790008545,
      "learning_rate": 4.92412746585736e-06,
      "loss": 2.4112,
      "step": 40
    },
    {
      "epoch": 0.0622154779969651,
      "grad_norm": 1.4811420440673828,
      "learning_rate": 4.922230652503794e-06,
      "loss": 2.6638,
      "step": 41
    },
    {
      "epoch": 0.0637329286798179,
      "grad_norm": 1.4535053968429565,
      "learning_rate": 4.920333839150228e-06,
      "loss": 2.6469,
      "step": 42
    },
    {
      "epoch": 0.06525037936267071,
      "grad_norm": 1.545841932296753,
      "learning_rate": 4.918437025796662e-06,
      "loss": 2.7204,
      "step": 43
    },
    {
      "epoch": 0.06676783004552352,
      "grad_norm": 1.5925236940383911,
      "learning_rate": 4.916540212443096e-06,
      "loss": 2.7436,
      "step": 44
    },
    {
      "epoch": 0.06828528072837632,
      "grad_norm": 1.7303520441055298,
      "learning_rate": 4.91464339908953e-06,
      "loss": 2.5276,
      "step": 45
    },
    {
      "epoch": 0.06980273141122914,
      "grad_norm": 1.549386978149414,
      "learning_rate": 4.912746585735964e-06,
      "loss": 2.6785,
      "step": 46
    },
    {
      "epoch": 0.07132018209408195,
      "grad_norm": 1.5825550556182861,
      "learning_rate": 4.9108497723823974e-06,
      "loss": 2.5925,
      "step": 47
    },
    {
      "epoch": 0.07283763277693475,
      "grad_norm": 2.209886312484741,
      "learning_rate": 4.908952959028832e-06,
      "loss": 2.7396,
      "step": 48
    },
    {
      "epoch": 0.07435508345978756,
      "grad_norm": 1.6495764255523682,
      "learning_rate": 4.907056145675266e-06,
      "loss": 2.7408,
      "step": 49
    },
    {
      "epoch": 0.07587253414264036,
      "grad_norm": 1.5667551755905151,
      "learning_rate": 4.9051593323217e-06,
      "loss": 2.6933,
      "step": 50
    },
    {
      "epoch": 0.07738998482549317,
      "grad_norm": 1.6338387727737427,
      "learning_rate": 4.903262518968134e-06,
      "loss": 2.8305,
      "step": 51
    },
    {
      "epoch": 0.07890743550834597,
      "grad_norm": 1.3421189785003662,
      "learning_rate": 4.901365705614568e-06,
      "loss": 2.3223,
      "step": 52
    },
    {
      "epoch": 0.08042488619119878,
      "grad_norm": 1.5097326040267944,
      "learning_rate": 4.899468892261002e-06,
      "loss": 2.5304,
      "step": 53
    },
    {
      "epoch": 0.0819423368740516,
      "grad_norm": 1.6330476999282837,
      "learning_rate": 4.897572078907436e-06,
      "loss": 2.6407,
      "step": 54
    },
    {
      "epoch": 0.0834597875569044,
      "grad_norm": 1.5086435079574585,
      "learning_rate": 4.89567526555387e-06,
      "loss": 2.4356,
      "step": 55
    },
    {
      "epoch": 0.08497723823975721,
      "grad_norm": 1.583431601524353,
      "learning_rate": 4.893778452200304e-06,
      "loss": 2.6286,
      "step": 56
    },
    {
      "epoch": 0.08649468892261002,
      "grad_norm": 1.9110954999923706,
      "learning_rate": 4.8918816388467376e-06,
      "loss": 2.7878,
      "step": 57
    },
    {
      "epoch": 0.08801213960546282,
      "grad_norm": 1.8597239255905151,
      "learning_rate": 4.889984825493172e-06,
      "loss": 2.7653,
      "step": 58
    },
    {
      "epoch": 0.08952959028831563,
      "grad_norm": 1.7935107946395874,
      "learning_rate": 4.888088012139605e-06,
      "loss": 2.8694,
      "step": 59
    },
    {
      "epoch": 0.09104704097116843,
      "grad_norm": 1.7650842666625977,
      "learning_rate": 4.88619119878604e-06,
      "loss": 2.6,
      "step": 60
    },
    {
      "epoch": 0.09256449165402124,
      "grad_norm": 1.5878636837005615,
      "learning_rate": 4.884294385432474e-06,
      "loss": 2.5853,
      "step": 61
    },
    {
      "epoch": 0.09408194233687406,
      "grad_norm": 1.4179983139038086,
      "learning_rate": 4.882397572078908e-06,
      "loss": 2.3803,
      "step": 62
    },
    {
      "epoch": 0.09559939301972686,
      "grad_norm": 1.757156252861023,
      "learning_rate": 4.880500758725342e-06,
      "loss": 2.7451,
      "step": 63
    },
    {
      "epoch": 0.09711684370257967,
      "grad_norm": 1.6446622610092163,
      "learning_rate": 4.878603945371776e-06,
      "loss": 2.5447,
      "step": 64
    },
    {
      "epoch": 0.09863429438543247,
      "grad_norm": 1.7752546072006226,
      "learning_rate": 4.87670713201821e-06,
      "loss": 2.7742,
      "step": 65
    },
    {
      "epoch": 0.10015174506828528,
      "grad_norm": 1.7238361835479736,
      "learning_rate": 4.874810318664644e-06,
      "loss": 2.6561,
      "step": 66
    },
    {
      "epoch": 0.10166919575113809,
      "grad_norm": 1.8177186250686646,
      "learning_rate": 4.872913505311078e-06,
      "loss": 2.7642,
      "step": 67
    },
    {
      "epoch": 0.10318664643399089,
      "grad_norm": 1.7101749181747437,
      "learning_rate": 4.871016691957512e-06,
      "loss": 2.572,
      "step": 68
    },
    {
      "epoch": 0.1047040971168437,
      "grad_norm": 1.8339701890945435,
      "learning_rate": 4.8691198786039455e-06,
      "loss": 2.5973,
      "step": 69
    },
    {
      "epoch": 0.1062215477996965,
      "grad_norm": 1.67083740234375,
      "learning_rate": 4.86722306525038e-06,
      "loss": 2.4302,
      "step": 70
    },
    {
      "epoch": 0.10773899848254932,
      "grad_norm": 1.6370307207107544,
      "learning_rate": 4.865326251896813e-06,
      "loss": 2.4781,
      "step": 71
    },
    {
      "epoch": 0.10925644916540213,
      "grad_norm": 1.8731797933578491,
      "learning_rate": 4.863429438543248e-06,
      "loss": 2.7356,
      "step": 72
    },
    {
      "epoch": 0.11077389984825493,
      "grad_norm": 1.8222007751464844,
      "learning_rate": 4.861532625189681e-06,
      "loss": 2.6422,
      "step": 73
    },
    {
      "epoch": 0.11229135053110774,
      "grad_norm": 2.1893908977508545,
      "learning_rate": 4.859635811836116e-06,
      "loss": 2.7446,
      "step": 74
    },
    {
      "epoch": 0.11380880121396054,
      "grad_norm": 2.137599468231201,
      "learning_rate": 4.85773899848255e-06,
      "loss": 2.5622,
      "step": 75
    },
    {
      "epoch": 0.11532625189681335,
      "grad_norm": 1.6613123416900635,
      "learning_rate": 4.855842185128984e-06,
      "loss": 2.557,
      "step": 76
    },
    {
      "epoch": 0.11684370257966616,
      "grad_norm": 1.6124509572982788,
      "learning_rate": 4.853945371775418e-06,
      "loss": 2.4292,
      "step": 77
    },
    {
      "epoch": 0.11836115326251896,
      "grad_norm": 1.6773816347122192,
      "learning_rate": 4.852048558421852e-06,
      "loss": 2.5504,
      "step": 78
    },
    {
      "epoch": 0.11987860394537178,
      "grad_norm": 1.6578483581542969,
      "learning_rate": 4.850151745068286e-06,
      "loss": 2.5181,
      "step": 79
    },
    {
      "epoch": 0.12139605462822459,
      "grad_norm": 1.7653710842132568,
      "learning_rate": 4.8482549317147195e-06,
      "loss": 2.6582,
      "step": 80
    },
    {
      "epoch": 0.12291350531107739,
      "grad_norm": 1.8063796758651733,
      "learning_rate": 4.8463581183611535e-06,
      "loss": 2.5284,
      "step": 81
    },
    {
      "epoch": 0.1244309559939302,
      "grad_norm": 1.7706851959228516,
      "learning_rate": 4.844461305007588e-06,
      "loss": 2.6159,
      "step": 82
    },
    {
      "epoch": 0.125948406676783,
      "grad_norm": 1.6004217863082886,
      "learning_rate": 4.842564491654021e-06,
      "loss": 2.4233,
      "step": 83
    },
    {
      "epoch": 0.1274658573596358,
      "grad_norm": 1.7620840072631836,
      "learning_rate": 4.840667678300456e-06,
      "loss": 2.5243,
      "step": 84
    },
    {
      "epoch": 0.12898330804248861,
      "grad_norm": 1.6738554239273071,
      "learning_rate": 4.838770864946889e-06,
      "loss": 2.4312,
      "step": 85
    },
    {
      "epoch": 0.13050075872534142,
      "grad_norm": 1.9580169916152954,
      "learning_rate": 4.836874051593324e-06,
      "loss": 2.7399,
      "step": 86
    },
    {
      "epoch": 0.13201820940819423,
      "grad_norm": 1.8906543254852295,
      "learning_rate": 4.834977238239758e-06,
      "loss": 2.6992,
      "step": 87
    },
    {
      "epoch": 0.13353566009104703,
      "grad_norm": 2.0459909439086914,
      "learning_rate": 4.833080424886192e-06,
      "loss": 2.4593,
      "step": 88
    },
    {
      "epoch": 0.13505311077389984,
      "grad_norm": 1.7769277095794678,
      "learning_rate": 4.831183611532626e-06,
      "loss": 2.5526,
      "step": 89
    },
    {
      "epoch": 0.13657056145675264,
      "grad_norm": 1.8310178518295288,
      "learning_rate": 4.82928679817906e-06,
      "loss": 2.5688,
      "step": 90
    },
    {
      "epoch": 0.13808801213960548,
      "grad_norm": 1.4965262413024902,
      "learning_rate": 4.8273899848254936e-06,
      "loss": 2.154,
      "step": 91
    },
    {
      "epoch": 0.13960546282245828,
      "grad_norm": 1.5629067420959473,
      "learning_rate": 4.8254931714719275e-06,
      "loss": 2.2992,
      "step": 92
    },
    {
      "epoch": 0.1411229135053111,
      "grad_norm": 1.671036958694458,
      "learning_rate": 4.823596358118361e-06,
      "loss": 2.3575,
      "step": 93
    },
    {
      "epoch": 0.1426403641881639,
      "grad_norm": 1.560393214225769,
      "learning_rate": 4.821699544764795e-06,
      "loss": 2.1257,
      "step": 94
    },
    {
      "epoch": 0.1441578148710167,
      "grad_norm": 1.8713446855545044,
      "learning_rate": 4.819802731411229e-06,
      "loss": 2.5003,
      "step": 95
    },
    {
      "epoch": 0.1456752655538695,
      "grad_norm": 1.6972792148590088,
      "learning_rate": 4.817905918057664e-06,
      "loss": 2.3571,
      "step": 96
    },
    {
      "epoch": 0.1471927162367223,
      "grad_norm": 1.9290107488632202,
      "learning_rate": 4.816009104704097e-06,
      "loss": 2.5497,
      "step": 97
    },
    {
      "epoch": 0.14871016691957512,
      "grad_norm": 1.8083423376083374,
      "learning_rate": 4.814112291350532e-06,
      "loss": 2.4797,
      "step": 98
    },
    {
      "epoch": 0.15022761760242792,
      "grad_norm": 2.070162296295166,
      "learning_rate": 4.812215477996966e-06,
      "loss": 2.5869,
      "step": 99
    },
    {
      "epoch": 0.15174506828528073,
      "grad_norm": 1.7607768774032593,
      "learning_rate": 4.8103186646434e-06,
      "loss": 2.3919,
      "step": 100
    },
    {
      "epoch": 0.15326251896813353,
      "grad_norm": 1.9955432415008545,
      "learning_rate": 4.808421851289834e-06,
      "loss": 2.6112,
      "step": 101
    },
    {
      "epoch": 0.15477996965098634,
      "grad_norm": 1.6870702505111694,
      "learning_rate": 4.806525037936268e-06,
      "loss": 2.3246,
      "step": 102
    },
    {
      "epoch": 0.15629742033383914,
      "grad_norm": 1.7994812726974487,
      "learning_rate": 4.8046282245827015e-06,
      "loss": 2.4466,
      "step": 103
    },
    {
      "epoch": 0.15781487101669195,
      "grad_norm": 1.6542423963546753,
      "learning_rate": 4.8027314112291354e-06,
      "loss": 2.3006,
      "step": 104
    },
    {
      "epoch": 0.15933232169954475,
      "grad_norm": 1.8085426092147827,
      "learning_rate": 4.800834597875569e-06,
      "loss": 2.402,
      "step": 105
    },
    {
      "epoch": 0.16084977238239756,
      "grad_norm": 1.8828628063201904,
      "learning_rate": 4.798937784522003e-06,
      "loss": 2.472,
      "step": 106
    },
    {
      "epoch": 0.16236722306525037,
      "grad_norm": 1.7661021947860718,
      "learning_rate": 4.797040971168437e-06,
      "loss": 2.3524,
      "step": 107
    },
    {
      "epoch": 0.1638846737481032,
      "grad_norm": 1.6450202465057373,
      "learning_rate": 4.795144157814872e-06,
      "loss": 2.3313,
      "step": 108
    },
    {
      "epoch": 0.165402124430956,
      "grad_norm": 1.7230068445205688,
      "learning_rate": 4.793247344461305e-06,
      "loss": 2.286,
      "step": 109
    },
    {
      "epoch": 0.1669195751138088,
      "grad_norm": 1.5638422966003418,
      "learning_rate": 4.79135053110774e-06,
      "loss": 2.1131,
      "step": 110
    },
    {
      "epoch": 0.16843702579666162,
      "grad_norm": 1.9233044385910034,
      "learning_rate": 4.789453717754173e-06,
      "loss": 2.5089,
      "step": 111
    },
    {
      "epoch": 0.16995447647951442,
      "grad_norm": 1.2560926675796509,
      "learning_rate": 4.787556904400608e-06,
      "loss": 1.8277,
      "step": 112
    },
    {
      "epoch": 0.17147192716236723,
      "grad_norm": 1.8069604635238647,
      "learning_rate": 4.785660091047042e-06,
      "loss": 2.3653,
      "step": 113
    },
    {
      "epoch": 0.17298937784522003,
      "grad_norm": 1.6074119806289673,
      "learning_rate": 4.7837632776934755e-06,
      "loss": 2.2936,
      "step": 114
    },
    {
      "epoch": 0.17450682852807284,
      "grad_norm": 1.6495989561080933,
      "learning_rate": 4.7818664643399095e-06,
      "loss": 2.2697,
      "step": 115
    },
    {
      "epoch": 0.17602427921092564,
      "grad_norm": 1.6007108688354492,
      "learning_rate": 4.779969650986343e-06,
      "loss": 2.1329,
      "step": 116
    },
    {
      "epoch": 0.17754172989377845,
      "grad_norm": 1.5364031791687012,
      "learning_rate": 4.778072837632777e-06,
      "loss": 2.1355,
      "step": 117
    },
    {
      "epoch": 0.17905918057663125,
      "grad_norm": 1.5489548444747925,
      "learning_rate": 4.776176024279211e-06,
      "loss": 2.0527,
      "step": 118
    },
    {
      "epoch": 0.18057663125948406,
      "grad_norm": 1.6051255464553833,
      "learning_rate": 4.774279210925645e-06,
      "loss": 2.1953,
      "step": 119
    },
    {
      "epoch": 0.18209408194233687,
      "grad_norm": 1.6677589416503906,
      "learning_rate": 4.77238239757208e-06,
      "loss": 2.219,
      "step": 120
    },
    {
      "epoch": 0.18361153262518967,
      "grad_norm": 1.539976954460144,
      "learning_rate": 4.770485584218513e-06,
      "loss": 2.148,
      "step": 121
    },
    {
      "epoch": 0.18512898330804248,
      "grad_norm": 1.8917796611785889,
      "learning_rate": 4.768588770864948e-06,
      "loss": 2.4748,
      "step": 122
    },
    {
      "epoch": 0.18664643399089528,
      "grad_norm": 1.7332128286361694,
      "learning_rate": 4.766691957511381e-06,
      "loss": 2.3227,
      "step": 123
    },
    {
      "epoch": 0.18816388467374812,
      "grad_norm": 1.4659174680709839,
      "learning_rate": 4.764795144157816e-06,
      "loss": 1.9598,
      "step": 124
    },
    {
      "epoch": 0.18968133535660092,
      "grad_norm": 1.8245052099227905,
      "learning_rate": 4.7628983308042496e-06,
      "loss": 2.3087,
      "step": 125
    },
    {
      "epoch": 0.19119878603945373,
      "grad_norm": 1.5405339002609253,
      "learning_rate": 4.7610015174506835e-06,
      "loss": 2.1431,
      "step": 126
    },
    {
      "epoch": 0.19271623672230653,
      "grad_norm": 1.6003291606903076,
      "learning_rate": 4.759104704097117e-06,
      "loss": 2.0882,
      "step": 127
    },
    {
      "epoch": 0.19423368740515934,
      "grad_norm": 1.7538659572601318,
      "learning_rate": 4.757207890743551e-06,
      "loss": 2.3274,
      "step": 128
    },
    {
      "epoch": 0.19575113808801214,
      "grad_norm": 1.7648649215698242,
      "learning_rate": 4.755311077389985e-06,
      "loss": 2.3067,
      "step": 129
    },
    {
      "epoch": 0.19726858877086495,
      "grad_norm": 1.6103942394256592,
      "learning_rate": 4.753414264036419e-06,
      "loss": 2.1792,
      "step": 130
    },
    {
      "epoch": 0.19878603945371776,
      "grad_norm": 1.264354944229126,
      "learning_rate": 4.751517450682853e-06,
      "loss": 1.7866,
      "step": 131
    },
    {
      "epoch": 0.20030349013657056,
      "grad_norm": 1.670746088027954,
      "learning_rate": 4.749620637329287e-06,
      "loss": 2.2239,
      "step": 132
    },
    {
      "epoch": 0.20182094081942337,
      "grad_norm": 1.7092370986938477,
      "learning_rate": 4.747723823975721e-06,
      "loss": 2.2586,
      "step": 133
    },
    {
      "epoch": 0.20333839150227617,
      "grad_norm": 1.509729266166687,
      "learning_rate": 4.745827010622155e-06,
      "loss": 2.172,
      "step": 134
    },
    {
      "epoch": 0.20485584218512898,
      "grad_norm": 1.1190706491470337,
      "learning_rate": 4.743930197268589e-06,
      "loss": 1.6223,
      "step": 135
    },
    {
      "epoch": 0.20637329286798178,
      "grad_norm": 1.6933025121688843,
      "learning_rate": 4.742033383915023e-06,
      "loss": 2.2748,
      "step": 136
    },
    {
      "epoch": 0.2078907435508346,
      "grad_norm": 1.743527889251709,
      "learning_rate": 4.7401365705614575e-06,
      "loss": 2.2566,
      "step": 137
    },
    {
      "epoch": 0.2094081942336874,
      "grad_norm": 1.4296270608901978,
      "learning_rate": 4.738239757207891e-06,
      "loss": 1.9629,
      "step": 138
    },
    {
      "epoch": 0.2109256449165402,
      "grad_norm": 1.556756615638733,
      "learning_rate": 4.736342943854325e-06,
      "loss": 2.1553,
      "step": 139
    },
    {
      "epoch": 0.212443095599393,
      "grad_norm": 1.7096643447875977,
      "learning_rate": 4.7344461305007585e-06,
      "loss": 2.2276,
      "step": 140
    },
    {
      "epoch": 0.21396054628224584,
      "grad_norm": 1.2482569217681885,
      "learning_rate": 4.732549317147193e-06,
      "loss": 1.7357,
      "step": 141
    },
    {
      "epoch": 0.21547799696509864,
      "grad_norm": 1.624021291732788,
      "learning_rate": 4.730652503793627e-06,
      "loss": 2.2533,
      "step": 142
    },
    {
      "epoch": 0.21699544764795145,
      "grad_norm": 1.467234492301941,
      "learning_rate": 4.728755690440061e-06,
      "loss": 1.9622,
      "step": 143
    },
    {
      "epoch": 0.21851289833080426,
      "grad_norm": 1.5414761304855347,
      "learning_rate": 4.726858877086495e-06,
      "loss": 2.1367,
      "step": 144
    },
    {
      "epoch": 0.22003034901365706,
      "grad_norm": 1.5240756273269653,
      "learning_rate": 4.724962063732929e-06,
      "loss": 2.0415,
      "step": 145
    },
    {
      "epoch": 0.22154779969650987,
      "grad_norm": 1.5205750465393066,
      "learning_rate": 4.723065250379363e-06,
      "loss": 2.05,
      "step": 146
    },
    {
      "epoch": 0.22306525037936267,
      "grad_norm": 1.7188549041748047,
      "learning_rate": 4.721168437025797e-06,
      "loss": 2.2876,
      "step": 147
    },
    {
      "epoch": 0.22458270106221548,
      "grad_norm": 1.4150031805038452,
      "learning_rate": 4.719271623672231e-06,
      "loss": 1.938,
      "step": 148
    },
    {
      "epoch": 0.22610015174506828,
      "grad_norm": 1.5926215648651123,
      "learning_rate": 4.7173748103186655e-06,
      "loss": 2.1085,
      "step": 149
    },
    {
      "epoch": 0.2276176024279211,
      "grad_norm": 1.6348233222961426,
      "learning_rate": 4.7154779969650986e-06,
      "loss": 2.1934,
      "step": 150
    },
    {
      "epoch": 0.2291350531107739,
      "grad_norm": 1.5909978151321411,
      "learning_rate": 4.713581183611533e-06,
      "loss": 2.1288,
      "step": 151
    },
    {
      "epoch": 0.2306525037936267,
      "grad_norm": 1.4529144763946533,
      "learning_rate": 4.711684370257966e-06,
      "loss": 2.0636,
      "step": 152
    },
    {
      "epoch": 0.2321699544764795,
      "grad_norm": 1.3962119817733765,
      "learning_rate": 4.709787556904401e-06,
      "loss": 1.9554,
      "step": 153
    },
    {
      "epoch": 0.2336874051593323,
      "grad_norm": 1.4730618000030518,
      "learning_rate": 4.707890743550835e-06,
      "loss": 2.0616,
      "step": 154
    },
    {
      "epoch": 0.23520485584218512,
      "grad_norm": 1.1904081106185913,
      "learning_rate": 4.705993930197269e-06,
      "loss": 1.6726,
      "step": 155
    },
    {
      "epoch": 0.23672230652503792,
      "grad_norm": 1.429807424545288,
      "learning_rate": 4.704097116843703e-06,
      "loss": 1.936,
      "step": 156
    },
    {
      "epoch": 0.23823975720789076,
      "grad_norm": 1.6244840621948242,
      "learning_rate": 4.702200303490137e-06,
      "loss": 2.1656,
      "step": 157
    },
    {
      "epoch": 0.23975720789074356,
      "grad_norm": 1.4424347877502441,
      "learning_rate": 4.700303490136571e-06,
      "loss": 2.057,
      "step": 158
    },
    {
      "epoch": 0.24127465857359637,
      "grad_norm": 1.3128242492675781,
      "learning_rate": 4.698406676783005e-06,
      "loss": 1.8506,
      "step": 159
    },
    {
      "epoch": 0.24279210925644917,
      "grad_norm": 1.4419329166412354,
      "learning_rate": 4.696509863429439e-06,
      "loss": 2.0287,
      "step": 160
    },
    {
      "epoch": 0.24430955993930198,
      "grad_norm": 1.2898619174957275,
      "learning_rate": 4.694613050075873e-06,
      "loss": 1.8001,
      "step": 161
    },
    {
      "epoch": 0.24582701062215478,
      "grad_norm": 1.3028984069824219,
      "learning_rate": 4.6927162367223065e-06,
      "loss": 1.8427,
      "step": 162
    },
    {
      "epoch": 0.2473444613050076,
      "grad_norm": 1.3546850681304932,
      "learning_rate": 4.690819423368741e-06,
      "loss": 1.9491,
      "step": 163
    },
    {
      "epoch": 0.2488619119878604,
      "grad_norm": 1.8225573301315308,
      "learning_rate": 4.688922610015174e-06,
      "loss": 1.9993,
      "step": 164
    },
    {
      "epoch": 0.2503793626707132,
      "grad_norm": 1.2807976007461548,
      "learning_rate": 4.687025796661609e-06,
      "loss": 1.8407,
      "step": 165
    },
    {
      "epoch": 0.251896813353566,
      "grad_norm": 1.6566849946975708,
      "learning_rate": 4.685128983308043e-06,
      "loss": 1.9509,
      "step": 166
    },
    {
      "epoch": 0.2534142640364188,
      "grad_norm": 1.2932612895965576,
      "learning_rate": 4.683232169954477e-06,
      "loss": 1.9019,
      "step": 167
    },
    {
      "epoch": 0.2549317147192716,
      "grad_norm": 1.3724206686019897,
      "learning_rate": 4.681335356600911e-06,
      "loss": 2.015,
      "step": 168
    },
    {
      "epoch": 0.2564491654021244,
      "grad_norm": 1.2060550451278687,
      "learning_rate": 4.679438543247345e-06,
      "loss": 1.7887,
      "step": 169
    },
    {
      "epoch": 0.25796661608497723,
      "grad_norm": 1.2706100940704346,
      "learning_rate": 4.677541729893779e-06,
      "loss": 1.9232,
      "step": 170
    },
    {
      "epoch": 0.25948406676783003,
      "grad_norm": 1.351408839225769,
      "learning_rate": 4.675644916540213e-06,
      "loss": 1.9743,
      "step": 171
    },
    {
      "epoch": 0.26100151745068284,
      "grad_norm": 1.2413102388381958,
      "learning_rate": 4.673748103186647e-06,
      "loss": 1.8977,
      "step": 172
    },
    {
      "epoch": 0.26251896813353565,
      "grad_norm": 1.3321024179458618,
      "learning_rate": 4.6718512898330805e-06,
      "loss": 1.8982,
      "step": 173
    },
    {
      "epoch": 0.26403641881638845,
      "grad_norm": 1.7211295366287231,
      "learning_rate": 4.6699544764795145e-06,
      "loss": 1.7033,
      "step": 174
    },
    {
      "epoch": 0.26555386949924126,
      "grad_norm": 1.3274794816970825,
      "learning_rate": 4.668057663125949e-06,
      "loss": 1.9187,
      "step": 175
    },
    {
      "epoch": 0.26707132018209406,
      "grad_norm": 1.1590737104415894,
      "learning_rate": 4.666160849772382e-06,
      "loss": 1.8387,
      "step": 176
    },
    {
      "epoch": 0.26858877086494687,
      "grad_norm": 1.1518858671188354,
      "learning_rate": 4.664264036418817e-06,
      "loss": 1.7285,
      "step": 177
    },
    {
      "epoch": 0.2701062215477997,
      "grad_norm": 1.3349288702011108,
      "learning_rate": 4.66236722306525e-06,
      "loss": 1.9766,
      "step": 178
    },
    {
      "epoch": 0.2716236722306525,
      "grad_norm": 1.2497448921203613,
      "learning_rate": 4.660470409711685e-06,
      "loss": 1.8839,
      "step": 179
    },
    {
      "epoch": 0.2731411229135053,
      "grad_norm": 1.278490662574768,
      "learning_rate": 4.658573596358119e-06,
      "loss": 1.9232,
      "step": 180
    },
    {
      "epoch": 0.2746585735963581,
      "grad_norm": 1.4222418069839478,
      "learning_rate": 4.656676783004553e-06,
      "loss": 1.9597,
      "step": 181
    },
    {
      "epoch": 0.27617602427921095,
      "grad_norm": 0.9622682332992554,
      "learning_rate": 4.654779969650987e-06,
      "loss": 1.5176,
      "step": 182
    },
    {
      "epoch": 0.27769347496206376,
      "grad_norm": 1.2329496145248413,
      "learning_rate": 4.652883156297421e-06,
      "loss": 1.9833,
      "step": 183
    },
    {
      "epoch": 0.27921092564491656,
      "grad_norm": 1.3727004528045654,
      "learning_rate": 4.6509863429438546e-06,
      "loss": 2.0225,
      "step": 184
    },
    {
      "epoch": 0.28072837632776937,
      "grad_norm": 1.0548685789108276,
      "learning_rate": 4.6490895295902885e-06,
      "loss": 1.6745,
      "step": 185
    },
    {
      "epoch": 0.2822458270106222,
      "grad_norm": 1.19306218624115,
      "learning_rate": 4.647192716236722e-06,
      "loss": 1.8693,
      "step": 186
    },
    {
      "epoch": 0.283763277693475,
      "grad_norm": 1.0536706447601318,
      "learning_rate": 4.645295902883157e-06,
      "loss": 1.6836,
      "step": 187
    },
    {
      "epoch": 0.2852807283763278,
      "grad_norm": 1.2326853275299072,
      "learning_rate": 4.64339908952959e-06,
      "loss": 1.9389,
      "step": 188
    },
    {
      "epoch": 0.2867981790591806,
      "grad_norm": 1.2013968229293823,
      "learning_rate": 4.641502276176025e-06,
      "loss": 1.8592,
      "step": 189
    },
    {
      "epoch": 0.2883156297420334,
      "grad_norm": 1.1070467233657837,
      "learning_rate": 4.639605462822458e-06,
      "loss": 1.8925,
      "step": 190
    },
    {
      "epoch": 0.2898330804248862,
      "grad_norm": 1.0844887495040894,
      "learning_rate": 4.637708649468893e-06,
      "loss": 1.778,
      "step": 191
    },
    {
      "epoch": 0.291350531107739,
      "grad_norm": 1.0748296976089478,
      "learning_rate": 4.635811836115327e-06,
      "loss": 1.8245,
      "step": 192
    },
    {
      "epoch": 0.2928679817905918,
      "grad_norm": 1.1487575769424438,
      "learning_rate": 4.633915022761761e-06,
      "loss": 1.8182,
      "step": 193
    },
    {
      "epoch": 0.2943854324734446,
      "grad_norm": 1.0821006298065186,
      "learning_rate": 4.632018209408195e-06,
      "loss": 1.8209,
      "step": 194
    },
    {
      "epoch": 0.2959028831562974,
      "grad_norm": 1.0914114713668823,
      "learning_rate": 4.630121396054629e-06,
      "loss": 1.8477,
      "step": 195
    },
    {
      "epoch": 0.29742033383915023,
      "grad_norm": 1.160266399383545,
      "learning_rate": 4.6282245827010625e-06,
      "loss": 1.9103,
      "step": 196
    },
    {
      "epoch": 0.29893778452200304,
      "grad_norm": 1.0351605415344238,
      "learning_rate": 4.6263277693474964e-06,
      "loss": 1.89,
      "step": 197
    },
    {
      "epoch": 0.30045523520485584,
      "grad_norm": 1.0213708877563477,
      "learning_rate": 4.62443095599393e-06,
      "loss": 1.8812,
      "step": 198
    },
    {
      "epoch": 0.30197268588770865,
      "grad_norm": 1.0142707824707031,
      "learning_rate": 4.622534142640364e-06,
      "loss": 1.8085,
      "step": 199
    },
    {
      "epoch": 0.30349013657056145,
      "grad_norm": 1.1340233087539673,
      "learning_rate": 4.620637329286798e-06,
      "loss": 1.7665,
      "step": 200
    },
    {
      "epoch": 0.30500758725341426,
      "grad_norm": 0.9440214037895203,
      "learning_rate": 4.618740515933233e-06,
      "loss": 1.7901,
      "step": 201
    },
    {
      "epoch": 0.30652503793626706,
      "grad_norm": 0.9075629115104675,
      "learning_rate": 4.616843702579666e-06,
      "loss": 1.6295,
      "step": 202
    },
    {
      "epoch": 0.30804248861911987,
      "grad_norm": 0.9166465401649475,
      "learning_rate": 4.614946889226101e-06,
      "loss": 1.6512,
      "step": 203
    },
    {
      "epoch": 0.3095599393019727,
      "grad_norm": 0.8504083752632141,
      "learning_rate": 4.613050075872535e-06,
      "loss": 1.6313,
      "step": 204
    },
    {
      "epoch": 0.3110773899848255,
      "grad_norm": 0.9522998929023743,
      "learning_rate": 4.611153262518969e-06,
      "loss": 1.8097,
      "step": 205
    },
    {
      "epoch": 0.3125948406676783,
      "grad_norm": 0.9600613117218018,
      "learning_rate": 4.609256449165403e-06,
      "loss": 1.7349,
      "step": 206
    },
    {
      "epoch": 0.3141122913505311,
      "grad_norm": 0.9477100968360901,
      "learning_rate": 4.6073596358118365e-06,
      "loss": 1.8517,
      "step": 207
    },
    {
      "epoch": 0.3156297420333839,
      "grad_norm": 1.028922200202942,
      "learning_rate": 4.6054628224582705e-06,
      "loss": 1.8493,
      "step": 208
    },
    {
      "epoch": 0.3171471927162367,
      "grad_norm": 0.9665132164955139,
      "learning_rate": 4.603566009104704e-06,
      "loss": 1.7947,
      "step": 209
    },
    {
      "epoch": 0.3186646433990895,
      "grad_norm": 0.9483089447021484,
      "learning_rate": 4.601669195751138e-06,
      "loss": 1.8028,
      "step": 210
    },
    {
      "epoch": 0.3201820940819423,
      "grad_norm": 0.8424877524375916,
      "learning_rate": 4.599772382397572e-06,
      "loss": 1.7032,
      "step": 211
    },
    {
      "epoch": 0.3216995447647951,
      "grad_norm": 0.7557017803192139,
      "learning_rate": 4.597875569044006e-06,
      "loss": 1.4693,
      "step": 212
    },
    {
      "epoch": 0.3232169954476479,
      "grad_norm": 0.9225509762763977,
      "learning_rate": 4.595978755690441e-06,
      "loss": 1.7779,
      "step": 213
    },
    {
      "epoch": 0.32473444613050073,
      "grad_norm": 0.8795595169067383,
      "learning_rate": 4.594081942336874e-06,
      "loss": 1.7734,
      "step": 214
    },
    {
      "epoch": 0.3262518968133536,
      "grad_norm": 0.9041030406951904,
      "learning_rate": 4.592185128983309e-06,
      "loss": 1.8097,
      "step": 215
    },
    {
      "epoch": 0.3277693474962064,
      "grad_norm": 0.8540870547294617,
      "learning_rate": 4.590288315629743e-06,
      "loss": 1.7429,
      "step": 216
    },
    {
      "epoch": 0.3292867981790592,
      "grad_norm": 0.8875912427902222,
      "learning_rate": 4.588391502276177e-06,
      "loss": 1.8364,
      "step": 217
    },
    {
      "epoch": 0.330804248861912,
      "grad_norm": 0.9395864009857178,
      "learning_rate": 4.5864946889226106e-06,
      "loss": 1.8707,
      "step": 218
    },
    {
      "epoch": 0.3323216995447648,
      "grad_norm": 0.8605385422706604,
      "learning_rate": 4.5845978755690445e-06,
      "loss": 1.728,
      "step": 219
    },
    {
      "epoch": 0.3338391502276176,
      "grad_norm": 1.0024092197418213,
      "learning_rate": 4.582701062215478e-06,
      "loss": 1.8567,
      "step": 220
    },
    {
      "epoch": 0.3353566009104704,
      "grad_norm": 0.9037143588066101,
      "learning_rate": 4.580804248861912e-06,
      "loss": 1.7992,
      "step": 221
    },
    {
      "epoch": 0.33687405159332323,
      "grad_norm": 0.7638265490531921,
      "learning_rate": 4.578907435508346e-06,
      "loss": 1.6962,
      "step": 222
    },
    {
      "epoch": 0.33839150227617604,
      "grad_norm": 0.759544849395752,
      "learning_rate": 4.57701062215478e-06,
      "loss": 1.6146,
      "step": 223
    },
    {
      "epoch": 0.33990895295902884,
      "grad_norm": 0.6839285492897034,
      "learning_rate": 4.575113808801214e-06,
      "loss": 1.4171,
      "step": 224
    },
    {
      "epoch": 0.34142640364188165,
      "grad_norm": 0.7583320736885071,
      "learning_rate": 4.573216995447649e-06,
      "loss": 1.6634,
      "step": 225
    },
    {
      "epoch": 0.34294385432473445,
      "grad_norm": 0.7534310221672058,
      "learning_rate": 4.571320182094082e-06,
      "loss": 1.6962,
      "step": 226
    },
    {
      "epoch": 0.34446130500758726,
      "grad_norm": 0.8407227993011475,
      "learning_rate": 4.569423368740517e-06,
      "loss": 1.696,
      "step": 227
    },
    {
      "epoch": 0.34597875569044007,
      "grad_norm": 0.7586120367050171,
      "learning_rate": 4.56752655538695e-06,
      "loss": 1.6649,
      "step": 228
    },
    {
      "epoch": 0.34749620637329287,
      "grad_norm": 0.7961316704750061,
      "learning_rate": 4.565629742033385e-06,
      "loss": 1.6997,
      "step": 229
    },
    {
      "epoch": 0.3490136570561457,
      "grad_norm": 0.7867332100868225,
      "learning_rate": 4.5637329286798185e-06,
      "loss": 1.7057,
      "step": 230
    },
    {
      "epoch": 0.3505311077389985,
      "grad_norm": 0.7489578723907471,
      "learning_rate": 4.5618361153262524e-06,
      "loss": 1.6946,
      "step": 231
    },
    {
      "epoch": 0.3520485584218513,
      "grad_norm": 0.7921286225318909,
      "learning_rate": 4.559939301972686e-06,
      "loss": 1.7626,
      "step": 232
    },
    {
      "epoch": 0.3535660091047041,
      "grad_norm": 0.7463523149490356,
      "learning_rate": 4.55804248861912e-06,
      "loss": 1.6869,
      "step": 233
    },
    {
      "epoch": 0.3550834597875569,
      "grad_norm": 0.7653331756591797,
      "learning_rate": 4.556145675265554e-06,
      "loss": 1.7146,
      "step": 234
    },
    {
      "epoch": 0.3566009104704097,
      "grad_norm": 0.811520516872406,
      "learning_rate": 4.554248861911988e-06,
      "loss": 1.7669,
      "step": 235
    },
    {
      "epoch": 0.3581183611532625,
      "grad_norm": 0.6037833094596863,
      "learning_rate": 4.552352048558422e-06,
      "loss": 1.4121,
      "step": 236
    },
    {
      "epoch": 0.3596358118361153,
      "grad_norm": 0.7463830709457397,
      "learning_rate": 4.550455235204857e-06,
      "loss": 1.4742,
      "step": 237
    },
    {
      "epoch": 0.3611532625189681,
      "grad_norm": 0.676983654499054,
      "learning_rate": 4.54855842185129e-06,
      "loss": 1.6082,
      "step": 238
    },
    {
      "epoch": 0.3626707132018209,
      "grad_norm": 0.6406673789024353,
      "learning_rate": 4.546661608497725e-06,
      "loss": 1.3501,
      "step": 239
    },
    {
      "epoch": 0.36418816388467373,
      "grad_norm": 0.7165535092353821,
      "learning_rate": 4.544764795144158e-06,
      "loss": 1.664,
      "step": 240
    },
    {
      "epoch": 0.36570561456752654,
      "grad_norm": 0.6555314064025879,
      "learning_rate": 4.5428679817905926e-06,
      "loss": 1.5698,
      "step": 241
    },
    {
      "epoch": 0.36722306525037934,
      "grad_norm": 0.7273505330085754,
      "learning_rate": 4.5409711684370265e-06,
      "loss": 1.7161,
      "step": 242
    },
    {
      "epoch": 0.36874051593323215,
      "grad_norm": 0.778892993927002,
      "learning_rate": 4.53907435508346e-06,
      "loss": 1.8381,
      "step": 243
    },
    {
      "epoch": 0.37025796661608495,
      "grad_norm": 0.8184201717376709,
      "learning_rate": 4.537177541729894e-06,
      "loss": 1.7959,
      "step": 244
    },
    {
      "epoch": 0.37177541729893776,
      "grad_norm": 0.6690226197242737,
      "learning_rate": 4.535280728376328e-06,
      "loss": 1.6266,
      "step": 245
    },
    {
      "epoch": 0.37329286798179057,
      "grad_norm": 0.727482795715332,
      "learning_rate": 4.533383915022762e-06,
      "loss": 1.718,
      "step": 246
    },
    {
      "epoch": 0.37481031866464337,
      "grad_norm": 0.7129247188568115,
      "learning_rate": 4.531487101669196e-06,
      "loss": 1.7276,
      "step": 247
    },
    {
      "epoch": 0.37632776934749623,
      "grad_norm": 0.6813459396362305,
      "learning_rate": 4.52959028831563e-06,
      "loss": 1.6575,
      "step": 248
    },
    {
      "epoch": 0.37784522003034904,
      "grad_norm": 0.6502346992492676,
      "learning_rate": 4.527693474962064e-06,
      "loss": 1.6113,
      "step": 249
    },
    {
      "epoch": 0.37936267071320184,
      "grad_norm": 0.5612689852714539,
      "learning_rate": 4.525796661608498e-06,
      "loss": 1.3899,
      "step": 250
    },
    {
      "epoch": 0.38088012139605465,
      "grad_norm": 0.7948272824287415,
      "learning_rate": 4.523899848254933e-06,
      "loss": 1.7862,
      "step": 251
    },
    {
      "epoch": 0.38239757207890746,
      "grad_norm": 0.7175472974777222,
      "learning_rate": 4.522003034901366e-06,
      "loss": 1.7384,
      "step": 252
    },
    {
      "epoch": 0.38391502276176026,
      "grad_norm": 0.8448014855384827,
      "learning_rate": 4.5201062215478005e-06,
      "loss": 1.6782,
      "step": 253
    },
    {
      "epoch": 0.38543247344461307,
      "grad_norm": 0.6463996767997742,
      "learning_rate": 4.5182094081942344e-06,
      "loss": 1.5445,
      "step": 254
    },
    {
      "epoch": 0.38694992412746587,
      "grad_norm": 0.6482776403427124,
      "learning_rate": 4.516312594840668e-06,
      "loss": 1.5233,
      "step": 255
    },
    {
      "epoch": 0.3884673748103187,
      "grad_norm": 0.7124293446540833,
      "learning_rate": 4.514415781487102e-06,
      "loss": 1.6339,
      "step": 256
    },
    {
      "epoch": 0.3899848254931715,
      "grad_norm": 0.6895076632499695,
      "learning_rate": 4.512518968133536e-06,
      "loss": 1.6522,
      "step": 257
    },
    {
      "epoch": 0.3915022761760243,
      "grad_norm": 0.6682535409927368,
      "learning_rate": 4.51062215477997e-06,
      "loss": 1.69,
      "step": 258
    },
    {
      "epoch": 0.3930197268588771,
      "grad_norm": 0.7031059861183167,
      "learning_rate": 4.508725341426404e-06,
      "loss": 1.7842,
      "step": 259
    },
    {
      "epoch": 0.3945371775417299,
      "grad_norm": 0.7328448295593262,
      "learning_rate": 4.506828528072838e-06,
      "loss": 1.5789,
      "step": 260
    },
    {
      "epoch": 0.3960546282245827,
      "grad_norm": 0.6091205477714539,
      "learning_rate": 4.504931714719272e-06,
      "loss": 1.5694,
      "step": 261
    },
    {
      "epoch": 0.3975720789074355,
      "grad_norm": 0.6856762766838074,
      "learning_rate": 4.503034901365706e-06,
      "loss": 1.6089,
      "step": 262
    },
    {
      "epoch": 0.3990895295902883,
      "grad_norm": 0.6023194193840027,
      "learning_rate": 4.501138088012141e-06,
      "loss": 1.5262,
      "step": 263
    },
    {
      "epoch": 0.4006069802731411,
      "grad_norm": 0.6661161780357361,
      "learning_rate": 4.499241274658574e-06,
      "loss": 1.6776,
      "step": 264
    },
    {
      "epoch": 0.40212443095599393,
      "grad_norm": 0.6994673013687134,
      "learning_rate": 4.497344461305008e-06,
      "loss": 1.7318,
      "step": 265
    },
    {
      "epoch": 0.40364188163884673,
      "grad_norm": 0.733079731464386,
      "learning_rate": 4.4954476479514415e-06,
      "loss": 1.762,
      "step": 266
    },
    {
      "epoch": 0.40515933232169954,
      "grad_norm": 0.7290741801261902,
      "learning_rate": 4.4935508345978755e-06,
      "loss": 1.5935,
      "step": 267
    },
    {
      "epoch": 0.40667678300455234,
      "grad_norm": 0.6454800367355347,
      "learning_rate": 4.49165402124431e-06,
      "loss": 1.7276,
      "step": 268
    },
    {
      "epoch": 0.40819423368740515,
      "grad_norm": 0.6923502683639526,
      "learning_rate": 4.489757207890743e-06,
      "loss": 1.6077,
      "step": 269
    },
    {
      "epoch": 0.40971168437025796,
      "grad_norm": 0.6698258519172668,
      "learning_rate": 4.487860394537178e-06,
      "loss": 1.6654,
      "step": 270
    },
    {
      "epoch": 0.41122913505311076,
      "grad_norm": 0.6251970529556274,
      "learning_rate": 4.485963581183612e-06,
      "loss": 1.6774,
      "step": 271
    },
    {
      "epoch": 0.41274658573596357,
      "grad_norm": 0.7134875655174255,
      "learning_rate": 4.484066767830046e-06,
      "loss": 1.7781,
      "step": 272
    },
    {
      "epoch": 0.4142640364188164,
      "grad_norm": 0.6270570158958435,
      "learning_rate": 4.48216995447648e-06,
      "loss": 1.6279,
      "step": 273
    },
    {
      "epoch": 0.4157814871016692,
      "grad_norm": 0.7383782267570496,
      "learning_rate": 4.480273141122914e-06,
      "loss": 1.7337,
      "step": 274
    },
    {
      "epoch": 0.417298937784522,
      "grad_norm": 0.682374119758606,
      "learning_rate": 4.478376327769348e-06,
      "loss": 1.7108,
      "step": 275
    },
    {
      "epoch": 0.4188163884673748,
      "grad_norm": 0.6371250748634338,
      "learning_rate": 4.476479514415782e-06,
      "loss": 1.6171,
      "step": 276
    },
    {
      "epoch": 0.4203338391502276,
      "grad_norm": 0.5635488629341125,
      "learning_rate": 4.4745827010622156e-06,
      "loss": 1.4765,
      "step": 277
    },
    {
      "epoch": 0.4218512898330804,
      "grad_norm": 0.7518844604492188,
      "learning_rate": 4.4726858877086495e-06,
      "loss": 1.7189,
      "step": 278
    },
    {
      "epoch": 0.4233687405159332,
      "grad_norm": 0.6932361721992493,
      "learning_rate": 4.470789074355083e-06,
      "loss": 1.7133,
      "step": 279
    },
    {
      "epoch": 0.424886191198786,
      "grad_norm": 0.6024936437606812,
      "learning_rate": 4.468892261001518e-06,
      "loss": 1.5319,
      "step": 280
    },
    {
      "epoch": 0.4264036418816389,
      "grad_norm": 0.6698088049888611,
      "learning_rate": 4.466995447647951e-06,
      "loss": 1.6117,
      "step": 281
    },
    {
      "epoch": 0.4279210925644917,
      "grad_norm": 0.6805720329284668,
      "learning_rate": 4.465098634294386e-06,
      "loss": 1.756,
      "step": 282
    },
    {
      "epoch": 0.4294385432473445,
      "grad_norm": 0.6549474596977234,
      "learning_rate": 4.46320182094082e-06,
      "loss": 1.597,
      "step": 283
    },
    {
      "epoch": 0.4309559939301973,
      "grad_norm": 0.6891216039657593,
      "learning_rate": 4.461305007587254e-06,
      "loss": 1.7095,
      "step": 284
    },
    {
      "epoch": 0.4324734446130501,
      "grad_norm": 0.6396589279174805,
      "learning_rate": 4.459408194233688e-06,
      "loss": 1.5392,
      "step": 285
    },
    {
      "epoch": 0.4339908952959029,
      "grad_norm": 0.6449142098426819,
      "learning_rate": 4.457511380880122e-06,
      "loss": 1.6843,
      "step": 286
    },
    {
      "epoch": 0.4355083459787557,
      "grad_norm": 0.7474581003189087,
      "learning_rate": 4.455614567526556e-06,
      "loss": 1.5867,
      "step": 287
    },
    {
      "epoch": 0.4370257966616085,
      "grad_norm": 0.6382227540016174,
      "learning_rate": 4.45371775417299e-06,
      "loss": 1.6125,
      "step": 288
    },
    {
      "epoch": 0.4385432473444613,
      "grad_norm": 0.5860352516174316,
      "learning_rate": 4.4518209408194235e-06,
      "loss": 1.5229,
      "step": 289
    },
    {
      "epoch": 0.4400606980273141,
      "grad_norm": 0.6173549294471741,
      "learning_rate": 4.4499241274658574e-06,
      "loss": 1.6002,
      "step": 290
    },
    {
      "epoch": 0.44157814871016693,
      "grad_norm": 0.7263356447219849,
      "learning_rate": 4.448027314112291e-06,
      "loss": 1.6308,
      "step": 291
    },
    {
      "epoch": 0.44309559939301973,
      "grad_norm": 0.7004325985908508,
      "learning_rate": 4.446130500758726e-06,
      "loss": 1.6365,
      "step": 292
    },
    {
      "epoch": 0.44461305007587254,
      "grad_norm": 0.5995455384254456,
      "learning_rate": 4.444233687405159e-06,
      "loss": 1.5612,
      "step": 293
    },
    {
      "epoch": 0.44613050075872535,
      "grad_norm": 0.5806179642677307,
      "learning_rate": 4.442336874051594e-06,
      "loss": 1.5718,
      "step": 294
    },
    {
      "epoch": 0.44764795144157815,
      "grad_norm": 0.5942299962043762,
      "learning_rate": 4.440440060698027e-06,
      "loss": 1.6212,
      "step": 295
    },
    {
      "epoch": 0.44916540212443096,
      "grad_norm": 0.6263571977615356,
      "learning_rate": 4.438543247344462e-06,
      "loss": 1.5959,
      "step": 296
    },
    {
      "epoch": 0.45068285280728376,
      "grad_norm": 0.6709257960319519,
      "learning_rate": 4.436646433990896e-06,
      "loss": 1.7135,
      "step": 297
    },
    {
      "epoch": 0.45220030349013657,
      "grad_norm": 0.6300745606422424,
      "learning_rate": 4.43474962063733e-06,
      "loss": 1.5444,
      "step": 298
    },
    {
      "epoch": 0.4537177541729894,
      "grad_norm": 0.6544375419616699,
      "learning_rate": 4.432852807283764e-06,
      "loss": 1.6546,
      "step": 299
    },
    {
      "epoch": 0.4552352048558422,
      "grad_norm": 0.6862886548042297,
      "learning_rate": 4.4309559939301975e-06,
      "loss": 1.4746,
      "step": 300
    },
    {
      "epoch": 0.456752655538695,
      "grad_norm": 0.6507607698440552,
      "learning_rate": 4.4290591805766315e-06,
      "loss": 1.6124,
      "step": 301
    },
    {
      "epoch": 0.4582701062215478,
      "grad_norm": 0.6257960200309753,
      "learning_rate": 4.427162367223065e-06,
      "loss": 1.6371,
      "step": 302
    },
    {
      "epoch": 0.4597875569044006,
      "grad_norm": 0.6678638458251953,
      "learning_rate": 4.425265553869499e-06,
      "loss": 1.6746,
      "step": 303
    },
    {
      "epoch": 0.4613050075872534,
      "grad_norm": 0.6769396662712097,
      "learning_rate": 4.423368740515934e-06,
      "loss": 1.6711,
      "step": 304
    },
    {
      "epoch": 0.4628224582701062,
      "grad_norm": 0.6222069263458252,
      "learning_rate": 4.421471927162367e-06,
      "loss": 1.5486,
      "step": 305
    },
    {
      "epoch": 0.464339908952959,
      "grad_norm": 0.5828348398208618,
      "learning_rate": 4.419575113808802e-06,
      "loss": 1.5311,
      "step": 306
    },
    {
      "epoch": 0.4658573596358118,
      "grad_norm": 0.5915746688842773,
      "learning_rate": 4.417678300455235e-06,
      "loss": 1.393,
      "step": 307
    },
    {
      "epoch": 0.4673748103186646,
      "grad_norm": 0.6565119624137878,
      "learning_rate": 4.41578148710167e-06,
      "loss": 1.429,
      "step": 308
    },
    {
      "epoch": 0.46889226100151743,
      "grad_norm": 0.6431642770767212,
      "learning_rate": 4.413884673748104e-06,
      "loss": 1.6678,
      "step": 309
    },
    {
      "epoch": 0.47040971168437024,
      "grad_norm": 0.5368162393569946,
      "learning_rate": 4.411987860394538e-06,
      "loss": 1.4738,
      "step": 310
    },
    {
      "epoch": 0.47192716236722304,
      "grad_norm": 0.607896625995636,
      "learning_rate": 4.4100910470409716e-06,
      "loss": 1.5851,
      "step": 311
    },
    {
      "epoch": 0.47344461305007585,
      "grad_norm": 0.656377375125885,
      "learning_rate": 4.4081942336874055e-06,
      "loss": 1.6345,
      "step": 312
    },
    {
      "epoch": 0.47496206373292865,
      "grad_norm": 0.6604123115539551,
      "learning_rate": 4.406297420333839e-06,
      "loss": 1.6715,
      "step": 313
    },
    {
      "epoch": 0.4764795144157815,
      "grad_norm": 0.5649489164352417,
      "learning_rate": 4.404400606980273e-06,
      "loss": 1.4805,
      "step": 314
    },
    {
      "epoch": 0.4779969650986343,
      "grad_norm": 0.5791256427764893,
      "learning_rate": 4.402503793626707e-06,
      "loss": 1.4711,
      "step": 315
    },
    {
      "epoch": 0.4795144157814871,
      "grad_norm": 0.6056892275810242,
      "learning_rate": 4.400606980273141e-06,
      "loss": 1.5976,
      "step": 316
    },
    {
      "epoch": 0.48103186646433993,
      "grad_norm": 0.5920920372009277,
      "learning_rate": 4.398710166919575e-06,
      "loss": 1.5325,
      "step": 317
    },
    {
      "epoch": 0.48254931714719274,
      "grad_norm": 0.5900841951370239,
      "learning_rate": 4.39681335356601e-06,
      "loss": 1.4368,
      "step": 318
    },
    {
      "epoch": 0.48406676783004554,
      "grad_norm": 0.5513509511947632,
      "learning_rate": 4.394916540212443e-06,
      "loss": 1.5463,
      "step": 319
    },
    {
      "epoch": 0.48558421851289835,
      "grad_norm": 0.5559934377670288,
      "learning_rate": 4.393019726858878e-06,
      "loss": 1.497,
      "step": 320
    },
    {
      "epoch": 0.48710166919575115,
      "grad_norm": 0.5739576816558838,
      "learning_rate": 4.391122913505312e-06,
      "loss": 1.5317,
      "step": 321
    },
    {
      "epoch": 0.48861911987860396,
      "grad_norm": 0.621339738368988,
      "learning_rate": 4.389226100151746e-06,
      "loss": 1.5647,
      "step": 322
    },
    {
      "epoch": 0.49013657056145676,
      "grad_norm": 0.5411561131477356,
      "learning_rate": 4.3873292867981795e-06,
      "loss": 1.4771,
      "step": 323
    },
    {
      "epoch": 0.49165402124430957,
      "grad_norm": 0.539316713809967,
      "learning_rate": 4.3854324734446134e-06,
      "loss": 1.2411,
      "step": 324
    },
    {
      "epoch": 0.4931714719271624,
      "grad_norm": 0.6225400567054749,
      "learning_rate": 4.383535660091047e-06,
      "loss": 1.606,
      "step": 325
    },
    {
      "epoch": 0.4946889226100152,
      "grad_norm": 0.5934780240058899,
      "learning_rate": 4.381638846737481e-06,
      "loss": 1.4464,
      "step": 326
    },
    {
      "epoch": 0.496206373292868,
      "grad_norm": 0.6879992485046387,
      "learning_rate": 4.379742033383915e-06,
      "loss": 1.5816,
      "step": 327
    },
    {
      "epoch": 0.4977238239757208,
      "grad_norm": 0.640099287033081,
      "learning_rate": 4.377845220030349e-06,
      "loss": 1.6544,
      "step": 328
    },
    {
      "epoch": 0.4992412746585736,
      "grad_norm": 0.5341420769691467,
      "learning_rate": 4.375948406676783e-06,
      "loss": 1.4902,
      "step": 329
    },
    {
      "epoch": 0.5007587253414264,
      "grad_norm": 0.6039739847183228,
      "learning_rate": 4.374051593323218e-06,
      "loss": 1.6415,
      "step": 330
    },
    {
      "epoch": 0.5022761760242792,
      "grad_norm": 0.47283196449279785,
      "learning_rate": 4.372154779969651e-06,
      "loss": 1.2187,
      "step": 331
    },
    {
      "epoch": 0.503793626707132,
      "grad_norm": 0.5269982218742371,
      "learning_rate": 4.370257966616086e-06,
      "loss": 1.4469,
      "step": 332
    },
    {
      "epoch": 0.5053110773899848,
      "grad_norm": 0.6039966940879822,
      "learning_rate": 4.368361153262519e-06,
      "loss": 1.5749,
      "step": 333
    },
    {
      "epoch": 0.5068285280728376,
      "grad_norm": 0.5686982274055481,
      "learning_rate": 4.3664643399089536e-06,
      "loss": 1.5411,
      "step": 334
    },
    {
      "epoch": 0.5083459787556904,
      "grad_norm": 0.6026314496994019,
      "learning_rate": 4.3645675265553875e-06,
      "loss": 1.476,
      "step": 335
    },
    {
      "epoch": 0.5098634294385432,
      "grad_norm": 0.6377545595169067,
      "learning_rate": 4.362670713201821e-06,
      "loss": 1.6189,
      "step": 336
    },
    {
      "epoch": 0.511380880121396,
      "grad_norm": 0.5221042633056641,
      "learning_rate": 4.360773899848255e-06,
      "loss": 1.4637,
      "step": 337
    },
    {
      "epoch": 0.5128983308042488,
      "grad_norm": 0.6348833441734314,
      "learning_rate": 4.358877086494689e-06,
      "loss": 1.6695,
      "step": 338
    },
    {
      "epoch": 0.5144157814871017,
      "grad_norm": 0.6248000860214233,
      "learning_rate": 4.356980273141123e-06,
      "loss": 1.6875,
      "step": 339
    },
    {
      "epoch": 0.5159332321699545,
      "grad_norm": 0.6159707903862,
      "learning_rate": 4.355083459787557e-06,
      "loss": 1.6149,
      "step": 340
    },
    {
      "epoch": 0.5174506828528073,
      "grad_norm": 0.629008948802948,
      "learning_rate": 4.353186646433991e-06,
      "loss": 1.5596,
      "step": 341
    },
    {
      "epoch": 0.5189681335356601,
      "grad_norm": 0.5674412846565247,
      "learning_rate": 4.351289833080426e-06,
      "loss": 1.556,
      "step": 342
    },
    {
      "epoch": 0.5204855842185129,
      "grad_norm": 0.6316165924072266,
      "learning_rate": 4.349393019726859e-06,
      "loss": 1.588,
      "step": 343
    },
    {
      "epoch": 0.5220030349013657,
      "grad_norm": 0.6546992659568787,
      "learning_rate": 4.347496206373294e-06,
      "loss": 1.5751,
      "step": 344
    },
    {
      "epoch": 0.5235204855842185,
      "grad_norm": 0.5448107123374939,
      "learning_rate": 4.345599393019727e-06,
      "loss": 1.5136,
      "step": 345
    },
    {
      "epoch": 0.5250379362670713,
      "grad_norm": 0.6148433089256287,
      "learning_rate": 4.3437025796661615e-06,
      "loss": 1.6177,
      "step": 346
    },
    {
      "epoch": 0.5265553869499241,
      "grad_norm": 0.5003474950790405,
      "learning_rate": 4.3418057663125954e-06,
      "loss": 1.4505,
      "step": 347
    },
    {
      "epoch": 0.5280728376327769,
      "grad_norm": 0.6357369422912598,
      "learning_rate": 4.339908952959029e-06,
      "loss": 1.6333,
      "step": 348
    },
    {
      "epoch": 0.5295902883156297,
      "grad_norm": 0.5947277545928955,
      "learning_rate": 4.338012139605463e-06,
      "loss": 1.5235,
      "step": 349
    },
    {
      "epoch": 0.5311077389984825,
      "grad_norm": 0.5818940997123718,
      "learning_rate": 4.336115326251897e-06,
      "loss": 1.5431,
      "step": 350
    },
    {
      "epoch": 0.5326251896813353,
      "grad_norm": 0.6041730046272278,
      "learning_rate": 4.334218512898331e-06,
      "loss": 1.5737,
      "step": 351
    },
    {
      "epoch": 0.5341426403641881,
      "grad_norm": 0.6039009690284729,
      "learning_rate": 4.332321699544765e-06,
      "loss": 1.6319,
      "step": 352
    },
    {
      "epoch": 0.5356600910470409,
      "grad_norm": 0.5340460538864136,
      "learning_rate": 4.330424886191199e-06,
      "loss": 1.4312,
      "step": 353
    },
    {
      "epoch": 0.5371775417298937,
      "grad_norm": 0.5981981754302979,
      "learning_rate": 4.328528072837633e-06,
      "loss": 1.5653,
      "step": 354
    },
    {
      "epoch": 0.5386949924127465,
      "grad_norm": 0.6118205189704895,
      "learning_rate": 4.326631259484067e-06,
      "loss": 1.586,
      "step": 355
    },
    {
      "epoch": 0.5402124430955993,
      "grad_norm": 0.5704741477966309,
      "learning_rate": 4.324734446130502e-06,
      "loss": 1.5239,
      "step": 356
    },
    {
      "epoch": 0.5417298937784522,
      "grad_norm": 0.5773799419403076,
      "learning_rate": 4.322837632776935e-06,
      "loss": 1.5813,
      "step": 357
    },
    {
      "epoch": 0.543247344461305,
      "grad_norm": 0.5947864055633545,
      "learning_rate": 4.3209408194233695e-06,
      "loss": 1.5401,
      "step": 358
    },
    {
      "epoch": 0.5447647951441578,
      "grad_norm": 0.526710033416748,
      "learning_rate": 4.319044006069803e-06,
      "loss": 1.4376,
      "step": 359
    },
    {
      "epoch": 0.5462822458270106,
      "grad_norm": 0.5983788967132568,
      "learning_rate": 4.317147192716237e-06,
      "loss": 1.6355,
      "step": 360
    },
    {
      "epoch": 0.5477996965098634,
      "grad_norm": 0.5097243785858154,
      "learning_rate": 4.315250379362671e-06,
      "loss": 1.3633,
      "step": 361
    },
    {
      "epoch": 0.5493171471927162,
      "grad_norm": 0.5372440814971924,
      "learning_rate": 4.313353566009105e-06,
      "loss": 1.4779,
      "step": 362
    },
    {
      "epoch": 0.5508345978755691,
      "grad_norm": 0.5431463122367859,
      "learning_rate": 4.311456752655539e-06,
      "loss": 1.4059,
      "step": 363
    },
    {
      "epoch": 0.5523520485584219,
      "grad_norm": 0.5251713395118713,
      "learning_rate": 4.309559939301973e-06,
      "loss": 1.3281,
      "step": 364
    },
    {
      "epoch": 0.5538694992412747,
      "grad_norm": 0.5596709847450256,
      "learning_rate": 4.307663125948407e-06,
      "loss": 1.3896,
      "step": 365
    },
    {
      "epoch": 0.5553869499241275,
      "grad_norm": 0.5759207010269165,
      "learning_rate": 4.305766312594841e-06,
      "loss": 1.5542,
      "step": 366
    },
    {
      "epoch": 0.5569044006069803,
      "grad_norm": 0.6063926815986633,
      "learning_rate": 4.303869499241275e-06,
      "loss": 1.5598,
      "step": 367
    },
    {
      "epoch": 0.5584218512898331,
      "grad_norm": 0.5655776858329773,
      "learning_rate": 4.3019726858877096e-06,
      "loss": 1.5393,
      "step": 368
    },
    {
      "epoch": 0.5599393019726859,
      "grad_norm": 0.5337826013565063,
      "learning_rate": 4.300075872534143e-06,
      "loss": 1.4272,
      "step": 369
    },
    {
      "epoch": 0.5614567526555387,
      "grad_norm": 0.5345029830932617,
      "learning_rate": 4.298179059180577e-06,
      "loss": 1.4592,
      "step": 370
    },
    {
      "epoch": 0.5629742033383915,
      "grad_norm": 0.5669544339179993,
      "learning_rate": 4.296282245827011e-06,
      "loss": 1.4995,
      "step": 371
    },
    {
      "epoch": 0.5644916540212443,
      "grad_norm": 0.5549417734146118,
      "learning_rate": 4.294385432473445e-06,
      "loss": 1.4412,
      "step": 372
    },
    {
      "epoch": 0.5660091047040972,
      "grad_norm": 0.5613023042678833,
      "learning_rate": 4.292488619119879e-06,
      "loss": 1.5664,
      "step": 373
    },
    {
      "epoch": 0.56752655538695,
      "grad_norm": 0.5973164439201355,
      "learning_rate": 4.290591805766313e-06,
      "loss": 1.6008,
      "step": 374
    },
    {
      "epoch": 0.5690440060698028,
      "grad_norm": 0.6398727297782898,
      "learning_rate": 4.288694992412747e-06,
      "loss": 1.5964,
      "step": 375
    },
    {
      "epoch": 0.5705614567526556,
      "grad_norm": 0.6034932732582092,
      "learning_rate": 4.286798179059181e-06,
      "loss": 1.574,
      "step": 376
    },
    {
      "epoch": 0.5720789074355084,
      "grad_norm": 0.5680099129676819,
      "learning_rate": 4.284901365705615e-06,
      "loss": 1.4148,
      "step": 377
    },
    {
      "epoch": 0.5735963581183612,
      "grad_norm": 0.5267028212547302,
      "learning_rate": 4.283004552352049e-06,
      "loss": 1.4375,
      "step": 378
    },
    {
      "epoch": 0.575113808801214,
      "grad_norm": 0.5374861359596252,
      "learning_rate": 4.281107738998483e-06,
      "loss": 1.4015,
      "step": 379
    },
    {
      "epoch": 0.5766312594840668,
      "grad_norm": 0.6280297636985779,
      "learning_rate": 4.2792109256449175e-06,
      "loss": 1.6314,
      "step": 380
    },
    {
      "epoch": 0.5781487101669196,
      "grad_norm": 0.5112261176109314,
      "learning_rate": 4.277314112291351e-06,
      "loss": 1.2869,
      "step": 381
    },
    {
      "epoch": 0.5796661608497724,
      "grad_norm": 0.543584942817688,
      "learning_rate": 4.275417298937785e-06,
      "loss": 1.4995,
      "step": 382
    },
    {
      "epoch": 0.5811836115326252,
      "grad_norm": 0.5986610651016235,
      "learning_rate": 4.2735204855842184e-06,
      "loss": 1.4887,
      "step": 383
    },
    {
      "epoch": 0.582701062215478,
      "grad_norm": 0.535126805305481,
      "learning_rate": 4.271623672230653e-06,
      "loss": 1.4933,
      "step": 384
    },
    {
      "epoch": 0.5842185128983308,
      "grad_norm": 0.5898280143737793,
      "learning_rate": 4.269726858877087e-06,
      "loss": 1.5241,
      "step": 385
    },
    {
      "epoch": 0.5857359635811836,
      "grad_norm": 0.5706352591514587,
      "learning_rate": 4.267830045523521e-06,
      "loss": 1.5089,
      "step": 386
    },
    {
      "epoch": 0.5872534142640364,
      "grad_norm": 0.7310394048690796,
      "learning_rate": 4.265933232169955e-06,
      "loss": 1.5774,
      "step": 387
    },
    {
      "epoch": 0.5887708649468892,
      "grad_norm": 0.611628532409668,
      "learning_rate": 4.264036418816389e-06,
      "loss": 1.5579,
      "step": 388
    },
    {
      "epoch": 0.590288315629742,
      "grad_norm": 0.6000181436538696,
      "learning_rate": 4.262139605462823e-06,
      "loss": 1.4628,
      "step": 389
    },
    {
      "epoch": 0.5918057663125948,
      "grad_norm": 0.551677942276001,
      "learning_rate": 4.260242792109257e-06,
      "loss": 1.358,
      "step": 390
    },
    {
      "epoch": 0.5933232169954477,
      "grad_norm": 0.5693620443344116,
      "learning_rate": 4.258345978755691e-06,
      "loss": 1.4223,
      "step": 391
    },
    {
      "epoch": 0.5948406676783005,
      "grad_norm": 0.5624873638153076,
      "learning_rate": 4.2564491654021255e-06,
      "loss": 1.4506,
      "step": 392
    },
    {
      "epoch": 0.5963581183611533,
      "grad_norm": 0.5493528842926025,
      "learning_rate": 4.2545523520485585e-06,
      "loss": 1.1984,
      "step": 393
    },
    {
      "epoch": 0.5978755690440061,
      "grad_norm": 0.557110071182251,
      "learning_rate": 4.252655538694993e-06,
      "loss": 1.5242,
      "step": 394
    },
    {
      "epoch": 0.5993930197268589,
      "grad_norm": 0.5433549880981445,
      "learning_rate": 4.250758725341426e-06,
      "loss": 1.4271,
      "step": 395
    },
    {
      "epoch": 0.6009104704097117,
      "grad_norm": 0.5263792872428894,
      "learning_rate": 4.24886191198786e-06,
      "loss": 1.3816,
      "step": 396
    },
    {
      "epoch": 0.6024279210925645,
      "grad_norm": 0.5964055061340332,
      "learning_rate": 4.246965098634295e-06,
      "loss": 1.5163,
      "step": 397
    },
    {
      "epoch": 0.6039453717754173,
      "grad_norm": 0.4954032599925995,
      "learning_rate": 4.245068285280728e-06,
      "loss": 1.3144,
      "step": 398
    },
    {
      "epoch": 0.6054628224582701,
      "grad_norm": 0.604634165763855,
      "learning_rate": 4.243171471927163e-06,
      "loss": 1.5565,
      "step": 399
    },
    {
      "epoch": 0.6069802731411229,
      "grad_norm": 0.49928390979766846,
      "learning_rate": 4.241274658573596e-06,
      "loss": 1.3523,
      "step": 400
    },
    {
      "epoch": 0.6084977238239757,
      "grad_norm": 0.5421729683876038,
      "learning_rate": 4.239377845220031e-06,
      "loss": 1.4907,
      "step": 401
    },
    {
      "epoch": 0.6100151745068285,
      "grad_norm": 0.5622231960296631,
      "learning_rate": 4.237481031866465e-06,
      "loss": 1.4901,
      "step": 402
    },
    {
      "epoch": 0.6115326251896813,
      "grad_norm": 0.455873042345047,
      "learning_rate": 4.235584218512899e-06,
      "loss": 1.1994,
      "step": 403
    },
    {
      "epoch": 0.6130500758725341,
      "grad_norm": 0.6127259731292725,
      "learning_rate": 4.2336874051593326e-06,
      "loss": 1.5477,
      "step": 404
    },
    {
      "epoch": 0.6145675265553869,
      "grad_norm": 0.566137969493866,
      "learning_rate": 4.2317905918057665e-06,
      "loss": 1.478,
      "step": 405
    },
    {
      "epoch": 0.6160849772382397,
      "grad_norm": 0.5281153321266174,
      "learning_rate": 4.2298937784522004e-06,
      "loss": 1.3986,
      "step": 406
    },
    {
      "epoch": 0.6176024279210925,
      "grad_norm": 0.4907263219356537,
      "learning_rate": 4.227996965098634e-06,
      "loss": 1.322,
      "step": 407
    },
    {
      "epoch": 0.6191198786039454,
      "grad_norm": 0.5937967300415039,
      "learning_rate": 4.226100151745068e-06,
      "loss": 1.4733,
      "step": 408
    },
    {
      "epoch": 0.6206373292867982,
      "grad_norm": 0.5622734427452087,
      "learning_rate": 4.224203338391503e-06,
      "loss": 1.5215,
      "step": 409
    },
    {
      "epoch": 0.622154779969651,
      "grad_norm": 0.5772116184234619,
      "learning_rate": 4.222306525037936e-06,
      "loss": 1.4661,
      "step": 410
    },
    {
      "epoch": 0.6236722306525038,
      "grad_norm": 0.5607485771179199,
      "learning_rate": 4.220409711684371e-06,
      "loss": 1.4161,
      "step": 411
    },
    {
      "epoch": 0.6251896813353566,
      "grad_norm": 0.5763262510299683,
      "learning_rate": 4.218512898330804e-06,
      "loss": 1.5283,
      "step": 412
    },
    {
      "epoch": 0.6267071320182094,
      "grad_norm": 0.534227192401886,
      "learning_rate": 4.216616084977239e-06,
      "loss": 1.3359,
      "step": 413
    },
    {
      "epoch": 0.6282245827010622,
      "grad_norm": 0.49940866231918335,
      "learning_rate": 4.214719271623673e-06,
      "loss": 1.3678,
      "step": 414
    },
    {
      "epoch": 0.629742033383915,
      "grad_norm": 0.5653464794158936,
      "learning_rate": 4.212822458270107e-06,
      "loss": 1.4693,
      "step": 415
    },
    {
      "epoch": 0.6312594840667678,
      "grad_norm": 0.5381935238838196,
      "learning_rate": 4.2109256449165405e-06,
      "loss": 1.4128,
      "step": 416
    },
    {
      "epoch": 0.6327769347496206,
      "grad_norm": 0.7321341633796692,
      "learning_rate": 4.2090288315629745e-06,
      "loss": 1.5258,
      "step": 417
    },
    {
      "epoch": 0.6342943854324734,
      "grad_norm": 0.49959489703178406,
      "learning_rate": 4.207132018209408e-06,
      "loss": 1.3451,
      "step": 418
    },
    {
      "epoch": 0.6358118361153262,
      "grad_norm": 0.5754705667495728,
      "learning_rate": 4.205235204855842e-06,
      "loss": 1.4525,
      "step": 419
    },
    {
      "epoch": 0.637329286798179,
      "grad_norm": 0.5571062564849854,
      "learning_rate": 4.203338391502276e-06,
      "loss": 1.4471,
      "step": 420
    },
    {
      "epoch": 0.6388467374810318,
      "grad_norm": 0.4880090057849884,
      "learning_rate": 4.20144157814871e-06,
      "loss": 1.2586,
      "step": 421
    },
    {
      "epoch": 0.6403641881638846,
      "grad_norm": 0.5454453825950623,
      "learning_rate": 4.199544764795144e-06,
      "loss": 1.4197,
      "step": 422
    },
    {
      "epoch": 0.6418816388467374,
      "grad_norm": 0.5665869116783142,
      "learning_rate": 4.197647951441579e-06,
      "loss": 1.3844,
      "step": 423
    },
    {
      "epoch": 0.6433990895295902,
      "grad_norm": 0.5569076538085938,
      "learning_rate": 4.195751138088012e-06,
      "loss": 1.4706,
      "step": 424
    },
    {
      "epoch": 0.644916540212443,
      "grad_norm": 0.5874656438827515,
      "learning_rate": 4.193854324734447e-06,
      "loss": 1.4706,
      "step": 425
    },
    {
      "epoch": 0.6464339908952959,
      "grad_norm": 0.5947632789611816,
      "learning_rate": 4.191957511380881e-06,
      "loss": 1.5445,
      "step": 426
    },
    {
      "epoch": 0.6479514415781487,
      "grad_norm": 0.5843673944473267,
      "learning_rate": 4.1900606980273146e-06,
      "loss": 1.4651,
      "step": 427
    },
    {
      "epoch": 0.6494688922610015,
      "grad_norm": 0.6201871633529663,
      "learning_rate": 4.1881638846737485e-06,
      "loss": 1.4466,
      "step": 428
    },
    {
      "epoch": 0.6509863429438544,
      "grad_norm": 0.5590775012969971,
      "learning_rate": 4.186267071320182e-06,
      "loss": 1.4154,
      "step": 429
    },
    {
      "epoch": 0.6525037936267072,
      "grad_norm": 0.6429518461227417,
      "learning_rate": 4.184370257966616e-06,
      "loss": 1.3915,
      "step": 430
    },
    {
      "epoch": 0.65402124430956,
      "grad_norm": 0.6168590188026428,
      "learning_rate": 4.18247344461305e-06,
      "loss": 1.524,
      "step": 431
    },
    {
      "epoch": 0.6555386949924128,
      "grad_norm": 0.5458989143371582,
      "learning_rate": 4.180576631259484e-06,
      "loss": 1.3496,
      "step": 432
    },
    {
      "epoch": 0.6570561456752656,
      "grad_norm": 0.5254637598991394,
      "learning_rate": 4.178679817905918e-06,
      "loss": 1.4041,
      "step": 433
    },
    {
      "epoch": 0.6585735963581184,
      "grad_norm": 0.6290822625160217,
      "learning_rate": 4.176783004552352e-06,
      "loss": 1.525,
      "step": 434
    },
    {
      "epoch": 0.6600910470409712,
      "grad_norm": 0.51552414894104,
      "learning_rate": 4.174886191198787e-06,
      "loss": 1.2929,
      "step": 435
    },
    {
      "epoch": 0.661608497723824,
      "grad_norm": 0.5317790508270264,
      "learning_rate": 4.17298937784522e-06,
      "loss": 1.4006,
      "step": 436
    },
    {
      "epoch": 0.6631259484066768,
      "grad_norm": 0.5863569378852844,
      "learning_rate": 4.171092564491655e-06,
      "loss": 1.514,
      "step": 437
    },
    {
      "epoch": 0.6646433990895296,
      "grad_norm": 0.5978503823280334,
      "learning_rate": 4.169195751138089e-06,
      "loss": 1.5157,
      "step": 438
    },
    {
      "epoch": 0.6661608497723824,
      "grad_norm": 0.49966782331466675,
      "learning_rate": 4.1672989377845225e-06,
      "loss": 1.2509,
      "step": 439
    },
    {
      "epoch": 0.6676783004552352,
      "grad_norm": 0.6166907548904419,
      "learning_rate": 4.1654021244309564e-06,
      "loss": 1.4841,
      "step": 440
    },
    {
      "epoch": 0.669195751138088,
      "grad_norm": 0.5208405256271362,
      "learning_rate": 4.16350531107739e-06,
      "loss": 1.3073,
      "step": 441
    },
    {
      "epoch": 0.6707132018209409,
      "grad_norm": 0.563643217086792,
      "learning_rate": 4.161608497723824e-06,
      "loss": 1.346,
      "step": 442
    },
    {
      "epoch": 0.6722306525037937,
      "grad_norm": 0.5620986223220825,
      "learning_rate": 4.159711684370258e-06,
      "loss": 1.4223,
      "step": 443
    },
    {
      "epoch": 0.6737481031866465,
      "grad_norm": 0.6089151501655579,
      "learning_rate": 4.157814871016692e-06,
      "loss": 1.5104,
      "step": 444
    },
    {
      "epoch": 0.6752655538694993,
      "grad_norm": 0.5502729415893555,
      "learning_rate": 4.155918057663126e-06,
      "loss": 1.3744,
      "step": 445
    },
    {
      "epoch": 0.6767830045523521,
      "grad_norm": 0.6057721376419067,
      "learning_rate": 4.15402124430956e-06,
      "loss": 1.4936,
      "step": 446
    },
    {
      "epoch": 0.6783004552352049,
      "grad_norm": 0.5744244456291199,
      "learning_rate": 4.152124430955995e-06,
      "loss": 1.4308,
      "step": 447
    },
    {
      "epoch": 0.6798179059180577,
      "grad_norm": 0.5685344338417053,
      "learning_rate": 4.150227617602428e-06,
      "loss": 1.4295,
      "step": 448
    },
    {
      "epoch": 0.6813353566009105,
      "grad_norm": 0.5779551267623901,
      "learning_rate": 4.148330804248863e-06,
      "loss": 1.3701,
      "step": 449
    },
    {
      "epoch": 0.6828528072837633,
      "grad_norm": 0.5613082051277161,
      "learning_rate": 4.146433990895296e-06,
      "loss": 1.3036,
      "step": 450
    },
    {
      "epoch": 0.6843702579666161,
      "grad_norm": 0.668230414390564,
      "learning_rate": 4.1445371775417305e-06,
      "loss": 1.4198,
      "step": 451
    },
    {
      "epoch": 0.6858877086494689,
      "grad_norm": 0.5357564687728882,
      "learning_rate": 4.142640364188164e-06,
      "loss": 1.3605,
      "step": 452
    },
    {
      "epoch": 0.6874051593323217,
      "grad_norm": 0.5597037672996521,
      "learning_rate": 4.140743550834598e-06,
      "loss": 1.3554,
      "step": 453
    },
    {
      "epoch": 0.6889226100151745,
      "grad_norm": 0.5845338106155396,
      "learning_rate": 4.138846737481032e-06,
      "loss": 1.2758,
      "step": 454
    },
    {
      "epoch": 0.6904400606980273,
      "grad_norm": 0.5538659691810608,
      "learning_rate": 4.136949924127466e-06,
      "loss": 1.3762,
      "step": 455
    },
    {
      "epoch": 0.6919575113808801,
      "grad_norm": 0.6102843880653381,
      "learning_rate": 4.1350531107739e-06,
      "loss": 1.3954,
      "step": 456
    },
    {
      "epoch": 0.6934749620637329,
      "grad_norm": 0.5929787755012512,
      "learning_rate": 4.133156297420334e-06,
      "loss": 1.444,
      "step": 457
    },
    {
      "epoch": 0.6949924127465857,
      "grad_norm": 0.4879250228404999,
      "learning_rate": 4.131259484066768e-06,
      "loss": 1.1886,
      "step": 458
    },
    {
      "epoch": 0.6965098634294385,
      "grad_norm": 0.720162034034729,
      "learning_rate": 4.129362670713203e-06,
      "loss": 1.3789,
      "step": 459
    },
    {
      "epoch": 0.6980273141122914,
      "grad_norm": 0.5712143778800964,
      "learning_rate": 4.127465857359636e-06,
      "loss": 1.3938,
      "step": 460
    },
    {
      "epoch": 0.6995447647951442,
      "grad_norm": 0.6945801973342896,
      "learning_rate": 4.1255690440060706e-06,
      "loss": 1.3043,
      "step": 461
    },
    {
      "epoch": 0.701062215477997,
      "grad_norm": 0.5791314244270325,
      "learning_rate": 4.123672230652504e-06,
      "loss": 1.3537,
      "step": 462
    },
    {
      "epoch": 0.7025796661608498,
      "grad_norm": 0.514592170715332,
      "learning_rate": 4.121775417298938e-06,
      "loss": 1.3275,
      "step": 463
    },
    {
      "epoch": 0.7040971168437026,
      "grad_norm": 0.6030213832855225,
      "learning_rate": 4.119878603945372e-06,
      "loss": 1.3267,
      "step": 464
    },
    {
      "epoch": 0.7056145675265554,
      "grad_norm": 0.5351337790489197,
      "learning_rate": 4.117981790591806e-06,
      "loss": 1.3214,
      "step": 465
    },
    {
      "epoch": 0.7071320182094082,
      "grad_norm": 0.6597126722335815,
      "learning_rate": 4.11608497723824e-06,
      "loss": 1.4733,
      "step": 466
    },
    {
      "epoch": 0.708649468892261,
      "grad_norm": 0.5972892642021179,
      "learning_rate": 4.114188163884674e-06,
      "loss": 1.4286,
      "step": 467
    },
    {
      "epoch": 0.7101669195751138,
      "grad_norm": 0.5242651104927063,
      "learning_rate": 4.112291350531108e-06,
      "loss": 1.3223,
      "step": 468
    },
    {
      "epoch": 0.7116843702579666,
      "grad_norm": 0.5747799277305603,
      "learning_rate": 4.110394537177542e-06,
      "loss": 1.4173,
      "step": 469
    },
    {
      "epoch": 0.7132018209408194,
      "grad_norm": 0.6069474220275879,
      "learning_rate": 4.108497723823976e-06,
      "loss": 1.3409,
      "step": 470
    },
    {
      "epoch": 0.7147192716236722,
      "grad_norm": 0.6043670177459717,
      "learning_rate": 4.10660091047041e-06,
      "loss": 1.3155,
      "step": 471
    },
    {
      "epoch": 0.716236722306525,
      "grad_norm": 0.5714666247367859,
      "learning_rate": 4.104704097116844e-06,
      "loss": 1.3863,
      "step": 472
    },
    {
      "epoch": 0.7177541729893778,
      "grad_norm": 0.5791792869567871,
      "learning_rate": 4.1028072837632785e-06,
      "loss": 1.3398,
      "step": 473
    },
    {
      "epoch": 0.7192716236722306,
      "grad_norm": 0.656827449798584,
      "learning_rate": 4.100910470409712e-06,
      "loss": 1.3589,
      "step": 474
    },
    {
      "epoch": 0.7207890743550834,
      "grad_norm": 0.5827882885932922,
      "learning_rate": 4.099013657056146e-06,
      "loss": 1.3461,
      "step": 475
    },
    {
      "epoch": 0.7223065250379362,
      "grad_norm": 0.5464465618133545,
      "learning_rate": 4.09711684370258e-06,
      "loss": 1.2828,
      "step": 476
    },
    {
      "epoch": 0.723823975720789,
      "grad_norm": 0.5064337849617004,
      "learning_rate": 4.095220030349014e-06,
      "loss": 1.123,
      "step": 477
    },
    {
      "epoch": 0.7253414264036419,
      "grad_norm": 0.5905984044075012,
      "learning_rate": 4.093323216995448e-06,
      "loss": 1.3723,
      "step": 478
    },
    {
      "epoch": 0.7268588770864947,
      "grad_norm": 0.605913519859314,
      "learning_rate": 4.091426403641882e-06,
      "loss": 1.4082,
      "step": 479
    },
    {
      "epoch": 0.7283763277693475,
      "grad_norm": 0.5312521457672119,
      "learning_rate": 4.089529590288316e-06,
      "loss": 1.3023,
      "step": 480
    },
    {
      "epoch": 0.7298937784522003,
      "grad_norm": 0.5919853448867798,
      "learning_rate": 4.08763277693475e-06,
      "loss": 1.4491,
      "step": 481
    },
    {
      "epoch": 0.7314112291350531,
      "grad_norm": 0.8036760687828064,
      "learning_rate": 4.085735963581184e-06,
      "loss": 1.4703,
      "step": 482
    },
    {
      "epoch": 0.7329286798179059,
      "grad_norm": 0.5746173858642578,
      "learning_rate": 4.083839150227618e-06,
      "loss": 1.3924,
      "step": 483
    },
    {
      "epoch": 0.7344461305007587,
      "grad_norm": 0.6384495496749878,
      "learning_rate": 4.081942336874052e-06,
      "loss": 1.4382,
      "step": 484
    },
    {
      "epoch": 0.7359635811836115,
      "grad_norm": 0.6528049111366272,
      "learning_rate": 4.0800455235204865e-06,
      "loss": 1.3985,
      "step": 485
    },
    {
      "epoch": 0.7374810318664643,
      "grad_norm": 0.5686211585998535,
      "learning_rate": 4.0781487101669195e-06,
      "loss": 1.3371,
      "step": 486
    },
    {
      "epoch": 0.7389984825493171,
      "grad_norm": 0.5533775091171265,
      "learning_rate": 4.076251896813354e-06,
      "loss": 1.2848,
      "step": 487
    },
    {
      "epoch": 0.7405159332321699,
      "grad_norm": 0.5539667010307312,
      "learning_rate": 4.074355083459787e-06,
      "loss": 1.3247,
      "step": 488
    },
    {
      "epoch": 0.7420333839150227,
      "grad_norm": 0.5494842529296875,
      "learning_rate": 4.072458270106222e-06,
      "loss": 1.2866,
      "step": 489
    },
    {
      "epoch": 0.7435508345978755,
      "grad_norm": 0.5410556197166443,
      "learning_rate": 4.070561456752656e-06,
      "loss": 1.1601,
      "step": 490
    },
    {
      "epoch": 0.7450682852807283,
      "grad_norm": 0.5904690027236938,
      "learning_rate": 4.06866464339909e-06,
      "loss": 1.3999,
      "step": 491
    },
    {
      "epoch": 0.7465857359635811,
      "grad_norm": 0.5558508038520813,
      "learning_rate": 4.066767830045524e-06,
      "loss": 1.292,
      "step": 492
    },
    {
      "epoch": 0.7481031866464339,
      "grad_norm": 0.6429516673088074,
      "learning_rate": 4.064871016691958e-06,
      "loss": 1.3913,
      "step": 493
    },
    {
      "epoch": 0.7496206373292867,
      "grad_norm": 0.5553253889083862,
      "learning_rate": 4.062974203338392e-06,
      "loss": 1.327,
      "step": 494
    },
    {
      "epoch": 0.7511380880121397,
      "grad_norm": 0.5266602039337158,
      "learning_rate": 4.061077389984826e-06,
      "loss": 1.226,
      "step": 495
    },
    {
      "epoch": 0.7526555386949925,
      "grad_norm": 0.5489621758460999,
      "learning_rate": 4.05918057663126e-06,
      "loss": 1.1249,
      "step": 496
    },
    {
      "epoch": 0.7541729893778453,
      "grad_norm": 0.5787691473960876,
      "learning_rate": 4.057283763277694e-06,
      "loss": 1.3184,
      "step": 497
    },
    {
      "epoch": 0.7556904400606981,
      "grad_norm": 0.6036232709884644,
      "learning_rate": 4.0553869499241275e-06,
      "loss": 1.3527,
      "step": 498
    },
    {
      "epoch": 0.7572078907435509,
      "grad_norm": 0.5443717241287231,
      "learning_rate": 4.053490136570562e-06,
      "loss": 1.2655,
      "step": 499
    },
    {
      "epoch": 0.7587253414264037,
      "grad_norm": 0.5390751361846924,
      "learning_rate": 4.051593323216995e-06,
      "loss": 1.1065,
      "step": 500
    }
  ],
  "logging_steps": 1,
  "max_steps": 2636,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.74441904472064e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
