{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 3.9156626506024095,
  "eval_steps": 500,
  "global_step": 6500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0006024096385542169,
      "grad_norm": 1.473740577697754,
      "learning_rate": 4.999246987951807e-06,
      "loss": 3.1348,
      "step": 1
    },
    {
      "epoch": 0.0012048192771084338,
      "grad_norm": 1.4747812747955322,
      "learning_rate": 4.998493975903615e-06,
      "loss": 3.0872,
      "step": 2
    },
    {
      "epoch": 0.0018072289156626507,
      "grad_norm": 1.4424713850021362,
      "learning_rate": 4.997740963855422e-06,
      "loss": 3.1008,
      "step": 3
    },
    {
      "epoch": 0.0024096385542168677,
      "grad_norm": 1.3801730871200562,
      "learning_rate": 4.99698795180723e-06,
      "loss": 2.919,
      "step": 4
    },
    {
      "epoch": 0.0030120481927710845,
      "grad_norm": 1.4852893352508545,
      "learning_rate": 4.996234939759037e-06,
      "loss": 3.081,
      "step": 5
    },
    {
      "epoch": 0.0036144578313253013,
      "grad_norm": 1.5137826204299927,
      "learning_rate": 4.995481927710844e-06,
      "loss": 3.0792,
      "step": 6
    },
    {
      "epoch": 0.004216867469879518,
      "grad_norm": 1.4194889068603516,
      "learning_rate": 4.9947289156626514e-06,
      "loss": 3.0358,
      "step": 7
    },
    {
      "epoch": 0.004819277108433735,
      "grad_norm": 1.4966731071472168,
      "learning_rate": 4.993975903614458e-06,
      "loss": 3.0494,
      "step": 8
    },
    {
      "epoch": 0.005421686746987952,
      "grad_norm": 1.4340115785598755,
      "learning_rate": 4.993222891566265e-06,
      "loss": 2.9788,
      "step": 9
    },
    {
      "epoch": 0.006024096385542169,
      "grad_norm": 1.4976229667663574,
      "learning_rate": 4.992469879518072e-06,
      "loss": 3.125,
      "step": 10
    },
    {
      "epoch": 0.006626506024096385,
      "grad_norm": 1.4902578592300415,
      "learning_rate": 4.99171686746988e-06,
      "loss": 3.0341,
      "step": 11
    },
    {
      "epoch": 0.007228915662650603,
      "grad_norm": 1.486533284187317,
      "learning_rate": 4.990963855421687e-06,
      "loss": 3.0247,
      "step": 12
    },
    {
      "epoch": 0.00783132530120482,
      "grad_norm": 1.412873387336731,
      "learning_rate": 4.990210843373494e-06,
      "loss": 2.9421,
      "step": 13
    },
    {
      "epoch": 0.008433734939759036,
      "grad_norm": 1.5661983489990234,
      "learning_rate": 4.989457831325302e-06,
      "loss": 3.0958,
      "step": 14
    },
    {
      "epoch": 0.009036144578313253,
      "grad_norm": 1.4612163305282593,
      "learning_rate": 4.9887048192771085e-06,
      "loss": 2.9777,
      "step": 15
    },
    {
      "epoch": 0.00963855421686747,
      "grad_norm": 1.5731759071350098,
      "learning_rate": 4.987951807228916e-06,
      "loss": 3.1209,
      "step": 16
    },
    {
      "epoch": 0.010240963855421687,
      "grad_norm": 1.754318356513977,
      "learning_rate": 4.987198795180723e-06,
      "loss": 2.9918,
      "step": 17
    },
    {
      "epoch": 0.010843373493975903,
      "grad_norm": 1.5088142156600952,
      "learning_rate": 4.986445783132531e-06,
      "loss": 2.9968,
      "step": 18
    },
    {
      "epoch": 0.01144578313253012,
      "grad_norm": 1.4607973098754883,
      "learning_rate": 4.985692771084338e-06,
      "loss": 2.942,
      "step": 19
    },
    {
      "epoch": 0.012048192771084338,
      "grad_norm": 1.540770173072815,
      "learning_rate": 4.984939759036145e-06,
      "loss": 2.9179,
      "step": 20
    },
    {
      "epoch": 0.012650602409638554,
      "grad_norm": 1.565718173980713,
      "learning_rate": 4.984186746987953e-06,
      "loss": 3.0175,
      "step": 21
    },
    {
      "epoch": 0.01325301204819277,
      "grad_norm": 1.6376641988754272,
      "learning_rate": 4.9834337349397595e-06,
      "loss": 3.0746,
      "step": 22
    },
    {
      "epoch": 0.013855421686746987,
      "grad_norm": 1.535663366317749,
      "learning_rate": 4.982680722891567e-06,
      "loss": 2.9844,
      "step": 23
    },
    {
      "epoch": 0.014457831325301205,
      "grad_norm": 1.6042248010635376,
      "learning_rate": 4.981927710843374e-06,
      "loss": 2.9934,
      "step": 24
    },
    {
      "epoch": 0.015060240963855422,
      "grad_norm": 1.704008936882019,
      "learning_rate": 4.981174698795181e-06,
      "loss": 2.9837,
      "step": 25
    },
    {
      "epoch": 0.01566265060240964,
      "grad_norm": 1.5935983657836914,
      "learning_rate": 4.980421686746988e-06,
      "loss": 2.9995,
      "step": 26
    },
    {
      "epoch": 0.016265060240963854,
      "grad_norm": 1.625032663345337,
      "learning_rate": 4.979668674698796e-06,
      "loss": 2.9215,
      "step": 27
    },
    {
      "epoch": 0.016867469879518072,
      "grad_norm": 1.6691863536834717,
      "learning_rate": 4.978915662650603e-06,
      "loss": 2.999,
      "step": 28
    },
    {
      "epoch": 0.01746987951807229,
      "grad_norm": 2.006518840789795,
      "learning_rate": 4.97816265060241e-06,
      "loss": 2.9524,
      "step": 29
    },
    {
      "epoch": 0.018072289156626505,
      "grad_norm": 1.969132423400879,
      "learning_rate": 4.9774096385542175e-06,
      "loss": 3.0297,
      "step": 30
    },
    {
      "epoch": 0.018674698795180723,
      "grad_norm": 1.7055975198745728,
      "learning_rate": 4.976656626506024e-06,
      "loss": 3.0185,
      "step": 31
    },
    {
      "epoch": 0.01927710843373494,
      "grad_norm": 1.650692105293274,
      "learning_rate": 4.975903614457831e-06,
      "loss": 2.9986,
      "step": 32
    },
    {
      "epoch": 0.019879518072289156,
      "grad_norm": 2.550161838531494,
      "learning_rate": 4.975150602409639e-06,
      "loss": 2.9903,
      "step": 33
    },
    {
      "epoch": 0.020481927710843374,
      "grad_norm": 1.6015815734863281,
      "learning_rate": 4.974397590361446e-06,
      "loss": 2.9555,
      "step": 34
    },
    {
      "epoch": 0.02108433734939759,
      "grad_norm": 1.7236346006393433,
      "learning_rate": 4.973644578313254e-06,
      "loss": 3.0156,
      "step": 35
    },
    {
      "epoch": 0.021686746987951807,
      "grad_norm": 1.6021451950073242,
      "learning_rate": 4.972891566265061e-06,
      "loss": 2.8815,
      "step": 36
    },
    {
      "epoch": 0.022289156626506025,
      "grad_norm": 1.7612340450286865,
      "learning_rate": 4.972138554216868e-06,
      "loss": 2.8865,
      "step": 37
    },
    {
      "epoch": 0.02289156626506024,
      "grad_norm": 1.6199023723602295,
      "learning_rate": 4.971385542168675e-06,
      "loss": 2.9298,
      "step": 38
    },
    {
      "epoch": 0.023493975903614458,
      "grad_norm": 1.7079846858978271,
      "learning_rate": 4.970632530120482e-06,
      "loss": 2.9558,
      "step": 39
    },
    {
      "epoch": 0.024096385542168676,
      "grad_norm": 1.7215967178344727,
      "learning_rate": 4.96987951807229e-06,
      "loss": 2.9865,
      "step": 40
    },
    {
      "epoch": 0.02469879518072289,
      "grad_norm": 1.9738972187042236,
      "learning_rate": 4.969126506024097e-06,
      "loss": 2.9504,
      "step": 41
    },
    {
      "epoch": 0.02530120481927711,
      "grad_norm": 1.7214441299438477,
      "learning_rate": 4.968373493975904e-06,
      "loss": 2.8726,
      "step": 42
    },
    {
      "epoch": 0.025903614457831327,
      "grad_norm": 1.6974633932113647,
      "learning_rate": 4.967620481927711e-06,
      "loss": 2.8846,
      "step": 43
    },
    {
      "epoch": 0.02650602409638554,
      "grad_norm": 1.5904995203018188,
      "learning_rate": 4.966867469879519e-06,
      "loss": 2.7622,
      "step": 44
    },
    {
      "epoch": 0.02710843373493976,
      "grad_norm": 1.7613439559936523,
      "learning_rate": 4.966114457831326e-06,
      "loss": 2.8873,
      "step": 45
    },
    {
      "epoch": 0.027710843373493974,
      "grad_norm": 1.636739730834961,
      "learning_rate": 4.9653614457831325e-06,
      "loss": 2.8282,
      "step": 46
    },
    {
      "epoch": 0.028313253012048192,
      "grad_norm": 1.7522393465042114,
      "learning_rate": 4.96460843373494e-06,
      "loss": 2.8216,
      "step": 47
    },
    {
      "epoch": 0.02891566265060241,
      "grad_norm": 1.779678463935852,
      "learning_rate": 4.963855421686747e-06,
      "loss": 2.8863,
      "step": 48
    },
    {
      "epoch": 0.029518072289156625,
      "grad_norm": 1.8429738283157349,
      "learning_rate": 4.963102409638554e-06,
      "loss": 2.8981,
      "step": 49
    },
    {
      "epoch": 0.030120481927710843,
      "grad_norm": 1.8048309087753296,
      "learning_rate": 4.962349397590362e-06,
      "loss": 2.8496,
      "step": 50
    },
    {
      "epoch": 0.03072289156626506,
      "grad_norm": 1.857170820236206,
      "learning_rate": 4.961596385542169e-06,
      "loss": 2.903,
      "step": 51
    },
    {
      "epoch": 0.03132530120481928,
      "grad_norm": 1.7957650423049927,
      "learning_rate": 4.960843373493977e-06,
      "loss": 2.8482,
      "step": 52
    },
    {
      "epoch": 0.031927710843373494,
      "grad_norm": 2.0291588306427,
      "learning_rate": 4.9600903614457835e-06,
      "loss": 2.8912,
      "step": 53
    },
    {
      "epoch": 0.03253012048192771,
      "grad_norm": 1.8417772054672241,
      "learning_rate": 4.959337349397591e-06,
      "loss": 2.8569,
      "step": 54
    },
    {
      "epoch": 0.03313253012048193,
      "grad_norm": 1.9789530038833618,
      "learning_rate": 4.958584337349398e-06,
      "loss": 2.9424,
      "step": 55
    },
    {
      "epoch": 0.033734939759036145,
      "grad_norm": 1.8783278465270996,
      "learning_rate": 4.957831325301205e-06,
      "loss": 2.8678,
      "step": 56
    },
    {
      "epoch": 0.03433734939759036,
      "grad_norm": 1.9034353494644165,
      "learning_rate": 4.957078313253013e-06,
      "loss": 2.9186,
      "step": 57
    },
    {
      "epoch": 0.03493975903614458,
      "grad_norm": 1.835208773612976,
      "learning_rate": 4.95632530120482e-06,
      "loss": 2.801,
      "step": 58
    },
    {
      "epoch": 0.035542168674698796,
      "grad_norm": 1.9433399438858032,
      "learning_rate": 4.955572289156627e-06,
      "loss": 2.9268,
      "step": 59
    },
    {
      "epoch": 0.03614457831325301,
      "grad_norm": 1.872772216796875,
      "learning_rate": 4.9548192771084345e-06,
      "loss": 2.8414,
      "step": 60
    },
    {
      "epoch": 0.03674698795180723,
      "grad_norm": 1.9383940696716309,
      "learning_rate": 4.9540662650602415e-06,
      "loss": 2.9157,
      "step": 61
    },
    {
      "epoch": 0.03734939759036145,
      "grad_norm": 1.8429044485092163,
      "learning_rate": 4.953313253012048e-06,
      "loss": 2.7457,
      "step": 62
    },
    {
      "epoch": 0.03795180722891566,
      "grad_norm": 1.8404359817504883,
      "learning_rate": 4.952560240963855e-06,
      "loss": 2.79,
      "step": 63
    },
    {
      "epoch": 0.03855421686746988,
      "grad_norm": 1.8242859840393066,
      "learning_rate": 4.951807228915663e-06,
      "loss": 2.8098,
      "step": 64
    },
    {
      "epoch": 0.0391566265060241,
      "grad_norm": 2.6848158836364746,
      "learning_rate": 4.95105421686747e-06,
      "loss": 2.8277,
      "step": 65
    },
    {
      "epoch": 0.03975903614457831,
      "grad_norm": 1.8670793771743774,
      "learning_rate": 4.950301204819278e-06,
      "loss": 2.7951,
      "step": 66
    },
    {
      "epoch": 0.04036144578313253,
      "grad_norm": 1.9470345973968506,
      "learning_rate": 4.949548192771085e-06,
      "loss": 2.7731,
      "step": 67
    },
    {
      "epoch": 0.04096385542168675,
      "grad_norm": 2.2263574600219727,
      "learning_rate": 4.948795180722892e-06,
      "loss": 2.7721,
      "step": 68
    },
    {
      "epoch": 0.04156626506024096,
      "grad_norm": 1.9051399230957031,
      "learning_rate": 4.948042168674699e-06,
      "loss": 2.7183,
      "step": 69
    },
    {
      "epoch": 0.04216867469879518,
      "grad_norm": 1.9903534650802612,
      "learning_rate": 4.947289156626506e-06,
      "loss": 2.801,
      "step": 70
    },
    {
      "epoch": 0.0427710843373494,
      "grad_norm": 1.7365846633911133,
      "learning_rate": 4.946536144578314e-06,
      "loss": 2.6404,
      "step": 71
    },
    {
      "epoch": 0.043373493975903614,
      "grad_norm": 1.9861185550689697,
      "learning_rate": 4.945783132530121e-06,
      "loss": 2.8174,
      "step": 72
    },
    {
      "epoch": 0.04397590361445783,
      "grad_norm": 1.8458343744277954,
      "learning_rate": 4.945030120481928e-06,
      "loss": 2.7475,
      "step": 73
    },
    {
      "epoch": 0.04457831325301205,
      "grad_norm": 1.9032632112503052,
      "learning_rate": 4.944277108433736e-06,
      "loss": 2.707,
      "step": 74
    },
    {
      "epoch": 0.045180722891566265,
      "grad_norm": 1.9599093198776245,
      "learning_rate": 4.943524096385543e-06,
      "loss": 2.6694,
      "step": 75
    },
    {
      "epoch": 0.04578313253012048,
      "grad_norm": 2.004028558731079,
      "learning_rate": 4.9427710843373496e-06,
      "loss": 2.7501,
      "step": 76
    },
    {
      "epoch": 0.0463855421686747,
      "grad_norm": 1.873877763748169,
      "learning_rate": 4.942018072289157e-06,
      "loss": 2.6985,
      "step": 77
    },
    {
      "epoch": 0.046987951807228916,
      "grad_norm": 2.001469373703003,
      "learning_rate": 4.941265060240964e-06,
      "loss": 2.6939,
      "step": 78
    },
    {
      "epoch": 0.04759036144578313,
      "grad_norm": 2.03161883354187,
      "learning_rate": 4.940512048192771e-06,
      "loss": 2.693,
      "step": 79
    },
    {
      "epoch": 0.04819277108433735,
      "grad_norm": 1.9754451513290405,
      "learning_rate": 4.939759036144578e-06,
      "loss": 2.699,
      "step": 80
    },
    {
      "epoch": 0.04879518072289157,
      "grad_norm": 2.01879620552063,
      "learning_rate": 4.939006024096386e-06,
      "loss": 2.6982,
      "step": 81
    },
    {
      "epoch": 0.04939759036144578,
      "grad_norm": 1.9582531452178955,
      "learning_rate": 4.938253012048193e-06,
      "loss": 2.6839,
      "step": 82
    },
    {
      "epoch": 0.05,
      "grad_norm": 1.9701021909713745,
      "learning_rate": 4.937500000000001e-06,
      "loss": 2.7169,
      "step": 83
    },
    {
      "epoch": 0.05060240963855422,
      "grad_norm": 1.8917077779769897,
      "learning_rate": 4.9367469879518075e-06,
      "loss": 2.6248,
      "step": 84
    },
    {
      "epoch": 0.05120481927710843,
      "grad_norm": 1.9316285848617554,
      "learning_rate": 4.9359939759036144e-06,
      "loss": 2.6465,
      "step": 85
    },
    {
      "epoch": 0.051807228915662654,
      "grad_norm": 1.978715419769287,
      "learning_rate": 4.935240963855422e-06,
      "loss": 2.621,
      "step": 86
    },
    {
      "epoch": 0.05240963855421687,
      "grad_norm": 1.9492319822311401,
      "learning_rate": 4.934487951807229e-06,
      "loss": 2.5716,
      "step": 87
    },
    {
      "epoch": 0.05301204819277108,
      "grad_norm": 1.9757020473480225,
      "learning_rate": 4.933734939759037e-06,
      "loss": 2.6228,
      "step": 88
    },
    {
      "epoch": 0.053614457831325305,
      "grad_norm": 1.9418715238571167,
      "learning_rate": 4.932981927710844e-06,
      "loss": 2.6106,
      "step": 89
    },
    {
      "epoch": 0.05421686746987952,
      "grad_norm": 1.933706283569336,
      "learning_rate": 4.932228915662652e-06,
      "loss": 2.6018,
      "step": 90
    },
    {
      "epoch": 0.054819277108433734,
      "grad_norm": 1.9495391845703125,
      "learning_rate": 4.9314759036144585e-06,
      "loss": 2.6195,
      "step": 91
    },
    {
      "epoch": 0.05542168674698795,
      "grad_norm": 1.9512412548065186,
      "learning_rate": 4.9307228915662654e-06,
      "loss": 2.5641,
      "step": 92
    },
    {
      "epoch": 0.05602409638554217,
      "grad_norm": 1.9239850044250488,
      "learning_rate": 4.929969879518073e-06,
      "loss": 2.5893,
      "step": 93
    },
    {
      "epoch": 0.056626506024096385,
      "grad_norm": 1.8520278930664062,
      "learning_rate": 4.92921686746988e-06,
      "loss": 2.5251,
      "step": 94
    },
    {
      "epoch": 0.0572289156626506,
      "grad_norm": 2.0181539058685303,
      "learning_rate": 4.928463855421687e-06,
      "loss": 2.5568,
      "step": 95
    },
    {
      "epoch": 0.05783132530120482,
      "grad_norm": 1.9635249376296997,
      "learning_rate": 4.927710843373494e-06,
      "loss": 2.5604,
      "step": 96
    },
    {
      "epoch": 0.058433734939759036,
      "grad_norm": 1.9368311166763306,
      "learning_rate": 4.926957831325302e-06,
      "loss": 2.5741,
      "step": 97
    },
    {
      "epoch": 0.05903614457831325,
      "grad_norm": 1.9514737129211426,
      "learning_rate": 4.926204819277109e-06,
      "loss": 2.5503,
      "step": 98
    },
    {
      "epoch": 0.05963855421686747,
      "grad_norm": 1.944197654724121,
      "learning_rate": 4.925451807228916e-06,
      "loss": 2.5346,
      "step": 99
    },
    {
      "epoch": 0.060240963855421686,
      "grad_norm": 1.9432839155197144,
      "learning_rate": 4.924698795180723e-06,
      "loss": 2.545,
      "step": 100
    },
    {
      "epoch": 0.0608433734939759,
      "grad_norm": 2.4351277351379395,
      "learning_rate": 4.92394578313253e-06,
      "loss": 2.5633,
      "step": 101
    },
    {
      "epoch": 0.06144578313253012,
      "grad_norm": 1.9407269954681396,
      "learning_rate": 4.923192771084338e-06,
      "loss": 2.5454,
      "step": 102
    },
    {
      "epoch": 0.06204819277108434,
      "grad_norm": 1.9103487730026245,
      "learning_rate": 4.922439759036145e-06,
      "loss": 2.4921,
      "step": 103
    },
    {
      "epoch": 0.06265060240963856,
      "grad_norm": 2.0310845375061035,
      "learning_rate": 4.921686746987952e-06,
      "loss": 2.4952,
      "step": 104
    },
    {
      "epoch": 0.06325301204819277,
      "grad_norm": 1.9880471229553223,
      "learning_rate": 4.92093373493976e-06,
      "loss": 2.5261,
      "step": 105
    },
    {
      "epoch": 0.06385542168674699,
      "grad_norm": 1.9818381071090698,
      "learning_rate": 4.920180722891567e-06,
      "loss": 2.5571,
      "step": 106
    },
    {
      "epoch": 0.06445783132530121,
      "grad_norm": 1.92890202999115,
      "learning_rate": 4.919427710843374e-06,
      "loss": 2.461,
      "step": 107
    },
    {
      "epoch": 0.06506024096385542,
      "grad_norm": 1.8091654777526855,
      "learning_rate": 4.918674698795181e-06,
      "loss": 2.4532,
      "step": 108
    },
    {
      "epoch": 0.06566265060240964,
      "grad_norm": 2.071336030960083,
      "learning_rate": 4.917921686746988e-06,
      "loss": 2.4692,
      "step": 109
    },
    {
      "epoch": 0.06626506024096386,
      "grad_norm": 1.8897559642791748,
      "learning_rate": 4.917168674698796e-06,
      "loss": 2.4916,
      "step": 110
    },
    {
      "epoch": 0.06686746987951807,
      "grad_norm": 1.8858671188354492,
      "learning_rate": 4.916415662650603e-06,
      "loss": 2.4089,
      "step": 111
    },
    {
      "epoch": 0.06746987951807229,
      "grad_norm": 2.057424545288086,
      "learning_rate": 4.91566265060241e-06,
      "loss": 2.4985,
      "step": 112
    },
    {
      "epoch": 0.06807228915662651,
      "grad_norm": 1.9049299955368042,
      "learning_rate": 4.914909638554217e-06,
      "loss": 2.4241,
      "step": 113
    },
    {
      "epoch": 0.06867469879518072,
      "grad_norm": 1.963156819343567,
      "learning_rate": 4.9141566265060246e-06,
      "loss": 2.4726,
      "step": 114
    },
    {
      "epoch": 0.06927710843373494,
      "grad_norm": 1.8943158388137817,
      "learning_rate": 4.9134036144578315e-06,
      "loss": 2.3883,
      "step": 115
    },
    {
      "epoch": 0.06987951807228916,
      "grad_norm": 1.8814094066619873,
      "learning_rate": 4.912650602409638e-06,
      "loss": 2.4412,
      "step": 116
    },
    {
      "epoch": 0.07048192771084337,
      "grad_norm": 1.922216773033142,
      "learning_rate": 4.911897590361446e-06,
      "loss": 2.3972,
      "step": 117
    },
    {
      "epoch": 0.07108433734939759,
      "grad_norm": 2.0009446144104004,
      "learning_rate": 4.911144578313253e-06,
      "loss": 2.4212,
      "step": 118
    },
    {
      "epoch": 0.07168674698795181,
      "grad_norm": 1.8443005084991455,
      "learning_rate": 4.910391566265061e-06,
      "loss": 2.3541,
      "step": 119
    },
    {
      "epoch": 0.07228915662650602,
      "grad_norm": 1.954594612121582,
      "learning_rate": 4.909638554216868e-06,
      "loss": 2.3404,
      "step": 120
    },
    {
      "epoch": 0.07289156626506024,
      "grad_norm": 2.1541054248809814,
      "learning_rate": 4.908885542168675e-06,
      "loss": 2.3936,
      "step": 121
    },
    {
      "epoch": 0.07349397590361446,
      "grad_norm": 1.8508579730987549,
      "learning_rate": 4.9081325301204825e-06,
      "loss": 2.3971,
      "step": 122
    },
    {
      "epoch": 0.07409638554216867,
      "grad_norm": 1.808905839920044,
      "learning_rate": 4.9073795180722894e-06,
      "loss": 2.3069,
      "step": 123
    },
    {
      "epoch": 0.0746987951807229,
      "grad_norm": 2.0047147274017334,
      "learning_rate": 4.906626506024097e-06,
      "loss": 2.4361,
      "step": 124
    },
    {
      "epoch": 0.07530120481927711,
      "grad_norm": 2.1422369480133057,
      "learning_rate": 4.905873493975904e-06,
      "loss": 2.3731,
      "step": 125
    },
    {
      "epoch": 0.07590361445783132,
      "grad_norm": 1.795076847076416,
      "learning_rate": 4.905120481927712e-06,
      "loss": 2.3497,
      "step": 126
    },
    {
      "epoch": 0.07650602409638554,
      "grad_norm": 1.6871236562728882,
      "learning_rate": 4.904367469879519e-06,
      "loss": 2.2504,
      "step": 127
    },
    {
      "epoch": 0.07710843373493977,
      "grad_norm": 1.874390959739685,
      "learning_rate": 4.903614457831326e-06,
      "loss": 2.3499,
      "step": 128
    },
    {
      "epoch": 0.07771084337349397,
      "grad_norm": 1.7345837354660034,
      "learning_rate": 4.902861445783133e-06,
      "loss": 2.2352,
      "step": 129
    },
    {
      "epoch": 0.0783132530120482,
      "grad_norm": 1.6911994218826294,
      "learning_rate": 4.9021084337349405e-06,
      "loss": 2.1987,
      "step": 130
    },
    {
      "epoch": 0.0789156626506024,
      "grad_norm": 1.7713083028793335,
      "learning_rate": 4.901355421686747e-06,
      "loss": 2.2679,
      "step": 131
    },
    {
      "epoch": 0.07951807228915662,
      "grad_norm": 1.7190380096435547,
      "learning_rate": 4.900602409638554e-06,
      "loss": 2.263,
      "step": 132
    },
    {
      "epoch": 0.08012048192771085,
      "grad_norm": 1.7694402933120728,
      "learning_rate": 4.899849397590361e-06,
      "loss": 2.2921,
      "step": 133
    },
    {
      "epoch": 0.08072289156626505,
      "grad_norm": 1.7882152795791626,
      "learning_rate": 4.899096385542169e-06,
      "loss": 2.2819,
      "step": 134
    },
    {
      "epoch": 0.08132530120481928,
      "grad_norm": 1.794653296470642,
      "learning_rate": 4.898343373493976e-06,
      "loss": 2.277,
      "step": 135
    },
    {
      "epoch": 0.0819277108433735,
      "grad_norm": 1.7778522968292236,
      "learning_rate": 4.897590361445784e-06,
      "loss": 2.2266,
      "step": 136
    },
    {
      "epoch": 0.0825301204819277,
      "grad_norm": 1.694179892539978,
      "learning_rate": 4.896837349397591e-06,
      "loss": 2.214,
      "step": 137
    },
    {
      "epoch": 0.08313253012048193,
      "grad_norm": 1.7486155033111572,
      "learning_rate": 4.896084337349398e-06,
      "loss": 2.2603,
      "step": 138
    },
    {
      "epoch": 0.08373493975903615,
      "grad_norm": 1.7560853958129883,
      "learning_rate": 4.895331325301205e-06,
      "loss": 2.2442,
      "step": 139
    },
    {
      "epoch": 0.08433734939759036,
      "grad_norm": 1.6624503135681152,
      "learning_rate": 4.894578313253012e-06,
      "loss": 2.189,
      "step": 140
    },
    {
      "epoch": 0.08493975903614458,
      "grad_norm": 1.6971596479415894,
      "learning_rate": 4.89382530120482e-06,
      "loss": 2.1953,
      "step": 141
    },
    {
      "epoch": 0.0855421686746988,
      "grad_norm": 1.7242510318756104,
      "learning_rate": 4.893072289156627e-06,
      "loss": 2.2044,
      "step": 142
    },
    {
      "epoch": 0.086144578313253,
      "grad_norm": 1.6905677318572998,
      "learning_rate": 4.892319277108435e-06,
      "loss": 2.1698,
      "step": 143
    },
    {
      "epoch": 0.08674698795180723,
      "grad_norm": 1.6370210647583008,
      "learning_rate": 4.891566265060242e-06,
      "loss": 2.2041,
      "step": 144
    },
    {
      "epoch": 0.08734939759036145,
      "grad_norm": 1.7600444555282593,
      "learning_rate": 4.8908132530120486e-06,
      "loss": 2.1849,
      "step": 145
    },
    {
      "epoch": 0.08795180722891566,
      "grad_norm": 1.6222892999649048,
      "learning_rate": 4.8900602409638555e-06,
      "loss": 2.1211,
      "step": 146
    },
    {
      "epoch": 0.08855421686746988,
      "grad_norm": 1.724839448928833,
      "learning_rate": 4.889307228915663e-06,
      "loss": 2.1977,
      "step": 147
    },
    {
      "epoch": 0.0891566265060241,
      "grad_norm": 1.6800349950790405,
      "learning_rate": 4.88855421686747e-06,
      "loss": 2.2406,
      "step": 148
    },
    {
      "epoch": 0.08975903614457831,
      "grad_norm": 1.6775932312011719,
      "learning_rate": 4.887801204819277e-06,
      "loss": 2.1723,
      "step": 149
    },
    {
      "epoch": 0.09036144578313253,
      "grad_norm": 1.6793549060821533,
      "learning_rate": 4.887048192771085e-06,
      "loss": 2.2018,
      "step": 150
    },
    {
      "epoch": 0.09096385542168675,
      "grad_norm": 1.6732984781265259,
      "learning_rate": 4.886295180722892e-06,
      "loss": 2.1889,
      "step": 151
    },
    {
      "epoch": 0.09156626506024096,
      "grad_norm": 1.5455031394958496,
      "learning_rate": 4.885542168674699e-06,
      "loss": 2.1362,
      "step": 152
    },
    {
      "epoch": 0.09216867469879518,
      "grad_norm": 1.6271357536315918,
      "learning_rate": 4.8847891566265065e-06,
      "loss": 2.1267,
      "step": 153
    },
    {
      "epoch": 0.0927710843373494,
      "grad_norm": 1.6043084859848022,
      "learning_rate": 4.8840361445783134e-06,
      "loss": 2.1358,
      "step": 154
    },
    {
      "epoch": 0.09337349397590361,
      "grad_norm": 1.4855022430419922,
      "learning_rate": 4.883283132530121e-06,
      "loss": 2.0811,
      "step": 155
    },
    {
      "epoch": 0.09397590361445783,
      "grad_norm": 1.5488998889923096,
      "learning_rate": 4.882530120481928e-06,
      "loss": 2.1251,
      "step": 156
    },
    {
      "epoch": 0.09457831325301205,
      "grad_norm": 1.6124851703643799,
      "learning_rate": 4.881777108433735e-06,
      "loss": 2.1506,
      "step": 157
    },
    {
      "epoch": 0.09518072289156626,
      "grad_norm": 1.6023409366607666,
      "learning_rate": 4.881024096385543e-06,
      "loss": 2.1106,
      "step": 158
    },
    {
      "epoch": 0.09578313253012048,
      "grad_norm": 1.559129238128662,
      "learning_rate": 4.88027108433735e-06,
      "loss": 2.0869,
      "step": 159
    },
    {
      "epoch": 0.0963855421686747,
      "grad_norm": 1.491356611251831,
      "learning_rate": 4.8795180722891575e-06,
      "loss": 2.0678,
      "step": 160
    },
    {
      "epoch": 0.09698795180722891,
      "grad_norm": 1.5758033990859985,
      "learning_rate": 4.8787650602409644e-06,
      "loss": 2.1259,
      "step": 161
    },
    {
      "epoch": 0.09759036144578313,
      "grad_norm": 1.5489639043807983,
      "learning_rate": 4.878012048192771e-06,
      "loss": 2.1218,
      "step": 162
    },
    {
      "epoch": 0.09819277108433735,
      "grad_norm": 1.4820585250854492,
      "learning_rate": 4.877259036144579e-06,
      "loss": 2.065,
      "step": 163
    },
    {
      "epoch": 0.09879518072289156,
      "grad_norm": 1.474873661994934,
      "learning_rate": 4.876506024096386e-06,
      "loss": 2.0096,
      "step": 164
    },
    {
      "epoch": 0.09939759036144578,
      "grad_norm": 1.4372928142547607,
      "learning_rate": 4.875753012048193e-06,
      "loss": 2.0396,
      "step": 165
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.5288587808609009,
      "learning_rate": 4.875e-06,
      "loss": 2.075,
      "step": 166
    },
    {
      "epoch": 0.10060240963855421,
      "grad_norm": 1.4783271551132202,
      "learning_rate": 4.874246987951808e-06,
      "loss": 2.0369,
      "step": 167
    },
    {
      "epoch": 0.10120481927710843,
      "grad_norm": 1.5354979038238525,
      "learning_rate": 4.873493975903615e-06,
      "loss": 2.0599,
      "step": 168
    },
    {
      "epoch": 0.10180722891566266,
      "grad_norm": 1.4715347290039062,
      "learning_rate": 4.8727409638554215e-06,
      "loss": 2.0796,
      "step": 169
    },
    {
      "epoch": 0.10240963855421686,
      "grad_norm": 1.4246761798858643,
      "learning_rate": 4.871987951807229e-06,
      "loss": 1.9957,
      "step": 170
    },
    {
      "epoch": 0.10301204819277109,
      "grad_norm": 1.4608674049377441,
      "learning_rate": 4.871234939759036e-06,
      "loss": 2.0363,
      "step": 171
    },
    {
      "epoch": 0.10361445783132531,
      "grad_norm": 1.4859869480133057,
      "learning_rate": 4.870481927710844e-06,
      "loss": 2.0264,
      "step": 172
    },
    {
      "epoch": 0.10421686746987951,
      "grad_norm": 1.3803449869155884,
      "learning_rate": 4.869728915662651e-06,
      "loss": 1.9844,
      "step": 173
    },
    {
      "epoch": 0.10481927710843374,
      "grad_norm": 1.380644679069519,
      "learning_rate": 4.868975903614459e-06,
      "loss": 2.0533,
      "step": 174
    },
    {
      "epoch": 0.10542168674698796,
      "grad_norm": 1.3377189636230469,
      "learning_rate": 4.868222891566266e-06,
      "loss": 1.97,
      "step": 175
    },
    {
      "epoch": 0.10602409638554217,
      "grad_norm": 1.409239649772644,
      "learning_rate": 4.8674698795180725e-06,
      "loss": 1.9866,
      "step": 176
    },
    {
      "epoch": 0.10662650602409639,
      "grad_norm": 1.394515872001648,
      "learning_rate": 4.86671686746988e-06,
      "loss": 1.9856,
      "step": 177
    },
    {
      "epoch": 0.10722891566265061,
      "grad_norm": 1.2693562507629395,
      "learning_rate": 4.865963855421687e-06,
      "loss": 1.8959,
      "step": 178
    },
    {
      "epoch": 0.10783132530120482,
      "grad_norm": 1.4128996133804321,
      "learning_rate": 4.865210843373494e-06,
      "loss": 2.0283,
      "step": 179
    },
    {
      "epoch": 0.10843373493975904,
      "grad_norm": 1.3271598815917969,
      "learning_rate": 4.864457831325302e-06,
      "loss": 1.9375,
      "step": 180
    },
    {
      "epoch": 0.10903614457831326,
      "grad_norm": 1.2907016277313232,
      "learning_rate": 4.863704819277109e-06,
      "loss": 1.9336,
      "step": 181
    },
    {
      "epoch": 0.10963855421686747,
      "grad_norm": 1.3166767358779907,
      "learning_rate": 4.862951807228916e-06,
      "loss": 1.9641,
      "step": 182
    },
    {
      "epoch": 0.11024096385542169,
      "grad_norm": 1.5335756540298462,
      "learning_rate": 4.862198795180723e-06,
      "loss": 1.9287,
      "step": 183
    },
    {
      "epoch": 0.1108433734939759,
      "grad_norm": 1.2912899255752563,
      "learning_rate": 4.8614457831325305e-06,
      "loss": 1.9707,
      "step": 184
    },
    {
      "epoch": 0.11144578313253012,
      "grad_norm": 1.269958257675171,
      "learning_rate": 4.860692771084337e-06,
      "loss": 1.98,
      "step": 185
    },
    {
      "epoch": 0.11204819277108434,
      "grad_norm": 1.2407171726226807,
      "learning_rate": 4.859939759036145e-06,
      "loss": 1.8997,
      "step": 186
    },
    {
      "epoch": 0.11265060240963855,
      "grad_norm": 1.3027952909469604,
      "learning_rate": 4.859186746987952e-06,
      "loss": 1.9861,
      "step": 187
    },
    {
      "epoch": 0.11325301204819277,
      "grad_norm": 1.1954265832901,
      "learning_rate": 4.858433734939759e-06,
      "loss": 1.8946,
      "step": 188
    },
    {
      "epoch": 0.11385542168674699,
      "grad_norm": 1.2401341199874878,
      "learning_rate": 4.857680722891567e-06,
      "loss": 1.9352,
      "step": 189
    },
    {
      "epoch": 0.1144578313253012,
      "grad_norm": 1.2804239988327026,
      "learning_rate": 4.856927710843374e-06,
      "loss": 1.9664,
      "step": 190
    },
    {
      "epoch": 0.11506024096385542,
      "grad_norm": 1.665408968925476,
      "learning_rate": 4.8561746987951815e-06,
      "loss": 1.941,
      "step": 191
    },
    {
      "epoch": 0.11566265060240964,
      "grad_norm": 1.2245901823043823,
      "learning_rate": 4.8554216867469884e-06,
      "loss": 1.9214,
      "step": 192
    },
    {
      "epoch": 0.11626506024096385,
      "grad_norm": 1.13723623752594,
      "learning_rate": 4.854668674698795e-06,
      "loss": 1.91,
      "step": 193
    },
    {
      "epoch": 0.11686746987951807,
      "grad_norm": 1.1623296737670898,
      "learning_rate": 4.853915662650603e-06,
      "loss": 1.8801,
      "step": 194
    },
    {
      "epoch": 0.11746987951807229,
      "grad_norm": 1.1651372909545898,
      "learning_rate": 4.85316265060241e-06,
      "loss": 1.8965,
      "step": 195
    },
    {
      "epoch": 0.1180722891566265,
      "grad_norm": 1.1593002080917358,
      "learning_rate": 4.852409638554218e-06,
      "loss": 1.9139,
      "step": 196
    },
    {
      "epoch": 0.11867469879518072,
      "grad_norm": 1.0648528337478638,
      "learning_rate": 4.851656626506025e-06,
      "loss": 1.8374,
      "step": 197
    },
    {
      "epoch": 0.11927710843373494,
      "grad_norm": 1.2154555320739746,
      "learning_rate": 4.850903614457832e-06,
      "loss": 1.8943,
      "step": 198
    },
    {
      "epoch": 0.11987951807228915,
      "grad_norm": 1.0764330625534058,
      "learning_rate": 4.850150602409639e-06,
      "loss": 1.8192,
      "step": 199
    },
    {
      "epoch": 0.12048192771084337,
      "grad_norm": 1.0981032848358154,
      "learning_rate": 4.849397590361446e-06,
      "loss": 1.8603,
      "step": 200
    },
    {
      "epoch": 0.1210843373493976,
      "grad_norm": 1.1300582885742188,
      "learning_rate": 4.848644578313253e-06,
      "loss": 1.8514,
      "step": 201
    },
    {
      "epoch": 0.1216867469879518,
      "grad_norm": 1.2305117845535278,
      "learning_rate": 4.84789156626506e-06,
      "loss": 1.9025,
      "step": 202
    },
    {
      "epoch": 0.12228915662650602,
      "grad_norm": 1.0266355276107788,
      "learning_rate": 4.847138554216868e-06,
      "loss": 1.8178,
      "step": 203
    },
    {
      "epoch": 0.12289156626506025,
      "grad_norm": 1.0954228639602661,
      "learning_rate": 4.846385542168675e-06,
      "loss": 1.8633,
      "step": 204
    },
    {
      "epoch": 0.12349397590361445,
      "grad_norm": 0.9696114659309387,
      "learning_rate": 4.845632530120482e-06,
      "loss": 1.7962,
      "step": 205
    },
    {
      "epoch": 0.12409638554216867,
      "grad_norm": 0.9872890114784241,
      "learning_rate": 4.84487951807229e-06,
      "loss": 1.8206,
      "step": 206
    },
    {
      "epoch": 0.1246987951807229,
      "grad_norm": 0.9578582644462585,
      "learning_rate": 4.8441265060240965e-06,
      "loss": 1.7759,
      "step": 207
    },
    {
      "epoch": 0.12530120481927712,
      "grad_norm": 0.9917846322059631,
      "learning_rate": 4.843373493975904e-06,
      "loss": 1.8212,
      "step": 208
    },
    {
      "epoch": 0.12590361445783133,
      "grad_norm": 1.000888466835022,
      "learning_rate": 4.842620481927711e-06,
      "loss": 1.8485,
      "step": 209
    },
    {
      "epoch": 0.12650602409638553,
      "grad_norm": 0.986721932888031,
      "learning_rate": 4.841867469879519e-06,
      "loss": 1.836,
      "step": 210
    },
    {
      "epoch": 0.12710843373493977,
      "grad_norm": 1.020324468612671,
      "learning_rate": 4.841114457831326e-06,
      "loss": 1.8313,
      "step": 211
    },
    {
      "epoch": 0.12771084337349398,
      "grad_norm": 0.9209928512573242,
      "learning_rate": 4.840361445783133e-06,
      "loss": 1.768,
      "step": 212
    },
    {
      "epoch": 0.12831325301204818,
      "grad_norm": 1.0388987064361572,
      "learning_rate": 4.839608433734941e-06,
      "loss": 1.8012,
      "step": 213
    },
    {
      "epoch": 0.12891566265060242,
      "grad_norm": 0.9404631853103638,
      "learning_rate": 4.8388554216867476e-06,
      "loss": 1.7706,
      "step": 214
    },
    {
      "epoch": 0.12951807228915663,
      "grad_norm": 0.9837149977684021,
      "learning_rate": 4.8381024096385545e-06,
      "loss": 1.8186,
      "step": 215
    },
    {
      "epoch": 0.13012048192771083,
      "grad_norm": 0.9033177495002747,
      "learning_rate": 4.837349397590361e-06,
      "loss": 1.7516,
      "step": 216
    },
    {
      "epoch": 0.13072289156626507,
      "grad_norm": 0.893429696559906,
      "learning_rate": 4.836596385542169e-06,
      "loss": 1.8012,
      "step": 217
    },
    {
      "epoch": 0.13132530120481928,
      "grad_norm": 0.8881344795227051,
      "learning_rate": 4.835843373493976e-06,
      "loss": 1.7948,
      "step": 218
    },
    {
      "epoch": 0.13192771084337349,
      "grad_norm": 0.8772730827331543,
      "learning_rate": 4.835090361445783e-06,
      "loss": 1.8104,
      "step": 219
    },
    {
      "epoch": 0.13253012048192772,
      "grad_norm": 0.8172335624694824,
      "learning_rate": 4.834337349397591e-06,
      "loss": 1.717,
      "step": 220
    },
    {
      "epoch": 0.13313253012048193,
      "grad_norm": 0.8400413990020752,
      "learning_rate": 4.833584337349398e-06,
      "loss": 1.7807,
      "step": 221
    },
    {
      "epoch": 0.13373493975903614,
      "grad_norm": 0.8863494992256165,
      "learning_rate": 4.8328313253012055e-06,
      "loss": 1.7727,
      "step": 222
    },
    {
      "epoch": 0.13433734939759037,
      "grad_norm": 0.9909966588020325,
      "learning_rate": 4.832078313253012e-06,
      "loss": 1.7628,
      "step": 223
    },
    {
      "epoch": 0.13493975903614458,
      "grad_norm": 0.8525331616401672,
      "learning_rate": 4.831325301204819e-06,
      "loss": 1.7783,
      "step": 224
    },
    {
      "epoch": 0.1355421686746988,
      "grad_norm": 0.8585079908370972,
      "learning_rate": 4.830572289156627e-06,
      "loss": 1.7473,
      "step": 225
    },
    {
      "epoch": 0.13614457831325302,
      "grad_norm": 0.8243316411972046,
      "learning_rate": 4.829819277108434e-06,
      "loss": 1.7819,
      "step": 226
    },
    {
      "epoch": 0.13674698795180723,
      "grad_norm": 0.8228163719177246,
      "learning_rate": 4.829066265060242e-06,
      "loss": 1.731,
      "step": 227
    },
    {
      "epoch": 0.13734939759036144,
      "grad_norm": 0.8049022555351257,
      "learning_rate": 4.828313253012049e-06,
      "loss": 1.742,
      "step": 228
    },
    {
      "epoch": 0.13795180722891567,
      "grad_norm": 0.8398966789245605,
      "learning_rate": 4.827560240963856e-06,
      "loss": 1.7708,
      "step": 229
    },
    {
      "epoch": 0.13855421686746988,
      "grad_norm": 0.8050366640090942,
      "learning_rate": 4.8268072289156634e-06,
      "loss": 1.7537,
      "step": 230
    },
    {
      "epoch": 0.1391566265060241,
      "grad_norm": 0.7946657538414001,
      "learning_rate": 4.82605421686747e-06,
      "loss": 1.774,
      "step": 231
    },
    {
      "epoch": 0.13975903614457832,
      "grad_norm": 0.8327892422676086,
      "learning_rate": 4.825301204819277e-06,
      "loss": 1.7746,
      "step": 232
    },
    {
      "epoch": 0.14036144578313253,
      "grad_norm": 0.7673815488815308,
      "learning_rate": 4.824548192771085e-06,
      "loss": 1.7135,
      "step": 233
    },
    {
      "epoch": 0.14096385542168674,
      "grad_norm": 0.7602956891059875,
      "learning_rate": 4.823795180722892e-06,
      "loss": 1.7322,
      "step": 234
    },
    {
      "epoch": 0.14156626506024098,
      "grad_norm": 0.7782509326934814,
      "learning_rate": 4.823042168674699e-06,
      "loss": 1.7059,
      "step": 235
    },
    {
      "epoch": 0.14216867469879518,
      "grad_norm": 0.7631418704986572,
      "learning_rate": 4.822289156626506e-06,
      "loss": 1.7509,
      "step": 236
    },
    {
      "epoch": 0.1427710843373494,
      "grad_norm": 0.7750449180603027,
      "learning_rate": 4.821536144578314e-06,
      "loss": 1.7262,
      "step": 237
    },
    {
      "epoch": 0.14337349397590363,
      "grad_norm": 0.765663206577301,
      "learning_rate": 4.8207831325301205e-06,
      "loss": 1.7323,
      "step": 238
    },
    {
      "epoch": 0.14397590361445783,
      "grad_norm": 0.741476833820343,
      "learning_rate": 4.820030120481928e-06,
      "loss": 1.7568,
      "step": 239
    },
    {
      "epoch": 0.14457831325301204,
      "grad_norm": 0.7734804749488831,
      "learning_rate": 4.819277108433735e-06,
      "loss": 1.7452,
      "step": 240
    },
    {
      "epoch": 0.14518072289156628,
      "grad_norm": 0.7453473806381226,
      "learning_rate": 4.818524096385542e-06,
      "loss": 1.7193,
      "step": 241
    },
    {
      "epoch": 0.14578313253012049,
      "grad_norm": 0.7575656175613403,
      "learning_rate": 4.81777108433735e-06,
      "loss": 1.7355,
      "step": 242
    },
    {
      "epoch": 0.1463855421686747,
      "grad_norm": 0.7615200281143188,
      "learning_rate": 4.817018072289157e-06,
      "loss": 1.7268,
      "step": 243
    },
    {
      "epoch": 0.14698795180722893,
      "grad_norm": 0.7498297691345215,
      "learning_rate": 4.816265060240965e-06,
      "loss": 1.7343,
      "step": 244
    },
    {
      "epoch": 0.14759036144578314,
      "grad_norm": 0.7488420605659485,
      "learning_rate": 4.8155120481927715e-06,
      "loss": 1.7388,
      "step": 245
    },
    {
      "epoch": 0.14819277108433734,
      "grad_norm": 0.72989821434021,
      "learning_rate": 4.814759036144579e-06,
      "loss": 1.6905,
      "step": 246
    },
    {
      "epoch": 0.14879518072289158,
      "grad_norm": 0.7123001217842102,
      "learning_rate": 4.814006024096386e-06,
      "loss": 1.6943,
      "step": 247
    },
    {
      "epoch": 0.1493975903614458,
      "grad_norm": 0.7553150653839111,
      "learning_rate": 4.813253012048193e-06,
      "loss": 1.7053,
      "step": 248
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.713471531867981,
      "learning_rate": 4.8125e-06,
      "loss": 1.6567,
      "step": 249
    },
    {
      "epoch": 0.15060240963855423,
      "grad_norm": 0.7307718992233276,
      "learning_rate": 4.811746987951808e-06,
      "loss": 1.7007,
      "step": 250
    },
    {
      "epoch": 0.15120481927710844,
      "grad_norm": 0.7311794757843018,
      "learning_rate": 4.810993975903615e-06,
      "loss": 1.7056,
      "step": 251
    },
    {
      "epoch": 0.15180722891566265,
      "grad_norm": 0.7625172734260559,
      "learning_rate": 4.810240963855422e-06,
      "loss": 1.7039,
      "step": 252
    },
    {
      "epoch": 0.15240963855421688,
      "grad_norm": 0.7785393595695496,
      "learning_rate": 4.809487951807229e-06,
      "loss": 1.7381,
      "step": 253
    },
    {
      "epoch": 0.1530120481927711,
      "grad_norm": 0.7344098091125488,
      "learning_rate": 4.808734939759036e-06,
      "loss": 1.7311,
      "step": 254
    },
    {
      "epoch": 0.1536144578313253,
      "grad_norm": 0.7868589162826538,
      "learning_rate": 4.807981927710843e-06,
      "loss": 1.6812,
      "step": 255
    },
    {
      "epoch": 0.15421686746987953,
      "grad_norm": 0.6652498841285706,
      "learning_rate": 4.807228915662651e-06,
      "loss": 1.5736,
      "step": 256
    },
    {
      "epoch": 0.15481927710843374,
      "grad_norm": 0.7033169269561768,
      "learning_rate": 4.806475903614458e-06,
      "loss": 1.7236,
      "step": 257
    },
    {
      "epoch": 0.15542168674698795,
      "grad_norm": 0.7170470356941223,
      "learning_rate": 4.805722891566266e-06,
      "loss": 1.6599,
      "step": 258
    },
    {
      "epoch": 0.15602409638554218,
      "grad_norm": 0.6867480278015137,
      "learning_rate": 4.804969879518073e-06,
      "loss": 1.6448,
      "step": 259
    },
    {
      "epoch": 0.1566265060240964,
      "grad_norm": 0.6744500398635864,
      "learning_rate": 4.80421686746988e-06,
      "loss": 1.6445,
      "step": 260
    },
    {
      "epoch": 0.1572289156626506,
      "grad_norm": 0.7147858142852783,
      "learning_rate": 4.803463855421687e-06,
      "loss": 1.6474,
      "step": 261
    },
    {
      "epoch": 0.1578313253012048,
      "grad_norm": 0.7288215756416321,
      "learning_rate": 4.802710843373494e-06,
      "loss": 1.6891,
      "step": 262
    },
    {
      "epoch": 0.15843373493975904,
      "grad_norm": 0.7007225751876831,
      "learning_rate": 4.801957831325302e-06,
      "loss": 1.6811,
      "step": 263
    },
    {
      "epoch": 0.15903614457831325,
      "grad_norm": 0.7068501710891724,
      "learning_rate": 4.801204819277109e-06,
      "loss": 1.6696,
      "step": 264
    },
    {
      "epoch": 0.15963855421686746,
      "grad_norm": 0.6887246370315552,
      "learning_rate": 4.800451807228916e-06,
      "loss": 1.6249,
      "step": 265
    },
    {
      "epoch": 0.1602409638554217,
      "grad_norm": 0.6977202296257019,
      "learning_rate": 4.799698795180724e-06,
      "loss": 1.6655,
      "step": 266
    },
    {
      "epoch": 0.1608433734939759,
      "grad_norm": 0.6817418336868286,
      "learning_rate": 4.798945783132531e-06,
      "loss": 1.6714,
      "step": 267
    },
    {
      "epoch": 0.1614457831325301,
      "grad_norm": 0.686543345451355,
      "learning_rate": 4.798192771084338e-06,
      "loss": 1.6408,
      "step": 268
    },
    {
      "epoch": 0.16204819277108434,
      "grad_norm": 0.7135939598083496,
      "learning_rate": 4.7974397590361445e-06,
      "loss": 1.6654,
      "step": 269
    },
    {
      "epoch": 0.16265060240963855,
      "grad_norm": 0.7083780765533447,
      "learning_rate": 4.796686746987952e-06,
      "loss": 1.6782,
      "step": 270
    },
    {
      "epoch": 0.16325301204819276,
      "grad_norm": 0.7175024151802063,
      "learning_rate": 4.795933734939759e-06,
      "loss": 1.6318,
      "step": 271
    },
    {
      "epoch": 0.163855421686747,
      "grad_norm": 0.6701497435569763,
      "learning_rate": 4.795180722891566e-06,
      "loss": 1.6414,
      "step": 272
    },
    {
      "epoch": 0.1644578313253012,
      "grad_norm": 0.6988034844398499,
      "learning_rate": 4.794427710843374e-06,
      "loss": 1.6565,
      "step": 273
    },
    {
      "epoch": 0.1650602409638554,
      "grad_norm": 0.7012876868247986,
      "learning_rate": 4.793674698795181e-06,
      "loss": 1.644,
      "step": 274
    },
    {
      "epoch": 0.16566265060240964,
      "grad_norm": 0.6780220866203308,
      "learning_rate": 4.792921686746989e-06,
      "loss": 1.6402,
      "step": 275
    },
    {
      "epoch": 0.16626506024096385,
      "grad_norm": 0.7401126027107239,
      "learning_rate": 4.7921686746987955e-06,
      "loss": 1.6518,
      "step": 276
    },
    {
      "epoch": 0.16686746987951806,
      "grad_norm": 0.6798343658447266,
      "learning_rate": 4.7914156626506025e-06,
      "loss": 1.6596,
      "step": 277
    },
    {
      "epoch": 0.1674698795180723,
      "grad_norm": 0.6503322720527649,
      "learning_rate": 4.79066265060241e-06,
      "loss": 1.6066,
      "step": 278
    },
    {
      "epoch": 0.1680722891566265,
      "grad_norm": 0.6418917179107666,
      "learning_rate": 4.789909638554217e-06,
      "loss": 1.6208,
      "step": 279
    },
    {
      "epoch": 0.1686746987951807,
      "grad_norm": 0.6618983745574951,
      "learning_rate": 4.789156626506025e-06,
      "loss": 1.6256,
      "step": 280
    },
    {
      "epoch": 0.16927710843373495,
      "grad_norm": 0.6828663945198059,
      "learning_rate": 4.788403614457832e-06,
      "loss": 1.6004,
      "step": 281
    },
    {
      "epoch": 0.16987951807228915,
      "grad_norm": 0.6781529784202576,
      "learning_rate": 4.787650602409639e-06,
      "loss": 1.6317,
      "step": 282
    },
    {
      "epoch": 0.17048192771084336,
      "grad_norm": 0.6674323081970215,
      "learning_rate": 4.7868975903614465e-06,
      "loss": 1.619,
      "step": 283
    },
    {
      "epoch": 0.1710843373493976,
      "grad_norm": 0.651633620262146,
      "learning_rate": 4.7861445783132535e-06,
      "loss": 1.6327,
      "step": 284
    },
    {
      "epoch": 0.1716867469879518,
      "grad_norm": 0.6679467558860779,
      "learning_rate": 4.78539156626506e-06,
      "loss": 1.6277,
      "step": 285
    },
    {
      "epoch": 0.172289156626506,
      "grad_norm": 0.6723544001579285,
      "learning_rate": 4.784638554216867e-06,
      "loss": 1.6486,
      "step": 286
    },
    {
      "epoch": 0.17289156626506025,
      "grad_norm": 0.6982719898223877,
      "learning_rate": 4.783885542168675e-06,
      "loss": 1.6473,
      "step": 287
    },
    {
      "epoch": 0.17349397590361446,
      "grad_norm": 0.6932685375213623,
      "learning_rate": 4.783132530120482e-06,
      "loss": 1.6154,
      "step": 288
    },
    {
      "epoch": 0.17409638554216866,
      "grad_norm": 0.6223523020744324,
      "learning_rate": 4.782379518072289e-06,
      "loss": 1.5463,
      "step": 289
    },
    {
      "epoch": 0.1746987951807229,
      "grad_norm": 0.6461967825889587,
      "learning_rate": 4.781626506024097e-06,
      "loss": 1.6105,
      "step": 290
    },
    {
      "epoch": 0.1753012048192771,
      "grad_norm": 0.6662501096725464,
      "learning_rate": 4.780873493975904e-06,
      "loss": 1.5946,
      "step": 291
    },
    {
      "epoch": 0.17590361445783131,
      "grad_norm": 0.6728113293647766,
      "learning_rate": 4.780120481927711e-06,
      "loss": 1.6325,
      "step": 292
    },
    {
      "epoch": 0.17650602409638555,
      "grad_norm": 0.6636098623275757,
      "learning_rate": 4.779367469879518e-06,
      "loss": 1.6081,
      "step": 293
    },
    {
      "epoch": 0.17710843373493976,
      "grad_norm": 0.6523126363754272,
      "learning_rate": 4.778614457831326e-06,
      "loss": 1.5923,
      "step": 294
    },
    {
      "epoch": 0.17771084337349397,
      "grad_norm": 0.6664504408836365,
      "learning_rate": 4.777861445783133e-06,
      "loss": 1.6155,
      "step": 295
    },
    {
      "epoch": 0.1783132530120482,
      "grad_norm": 0.6312705874443054,
      "learning_rate": 4.77710843373494e-06,
      "loss": 1.5547,
      "step": 296
    },
    {
      "epoch": 0.1789156626506024,
      "grad_norm": 0.6612650752067566,
      "learning_rate": 4.776355421686748e-06,
      "loss": 1.6198,
      "step": 297
    },
    {
      "epoch": 0.17951807228915662,
      "grad_norm": 0.659209668636322,
      "learning_rate": 4.775602409638555e-06,
      "loss": 1.6074,
      "step": 298
    },
    {
      "epoch": 0.18012048192771085,
      "grad_norm": 0.6165990829467773,
      "learning_rate": 4.7748493975903624e-06,
      "loss": 1.5485,
      "step": 299
    },
    {
      "epoch": 0.18072289156626506,
      "grad_norm": 0.6521856784820557,
      "learning_rate": 4.774096385542169e-06,
      "loss": 1.5813,
      "step": 300
    },
    {
      "epoch": 0.18132530120481927,
      "grad_norm": 0.6347154974937439,
      "learning_rate": 4.773343373493976e-06,
      "loss": 1.5918,
      "step": 301
    },
    {
      "epoch": 0.1819277108433735,
      "grad_norm": 0.6403963565826416,
      "learning_rate": 4.772590361445783e-06,
      "loss": 1.5772,
      "step": 302
    },
    {
      "epoch": 0.1825301204819277,
      "grad_norm": 0.6578680276870728,
      "learning_rate": 4.771837349397591e-06,
      "loss": 1.5872,
      "step": 303
    },
    {
      "epoch": 0.18313253012048192,
      "grad_norm": 0.6100031733512878,
      "learning_rate": 4.771084337349398e-06,
      "loss": 1.5595,
      "step": 304
    },
    {
      "epoch": 0.18373493975903615,
      "grad_norm": 0.6260285973548889,
      "learning_rate": 4.770331325301205e-06,
      "loss": 1.5757,
      "step": 305
    },
    {
      "epoch": 0.18433734939759036,
      "grad_norm": 0.6456859707832336,
      "learning_rate": 4.769578313253013e-06,
      "loss": 1.5878,
      "step": 306
    },
    {
      "epoch": 0.18493975903614457,
      "grad_norm": 0.6364273428916931,
      "learning_rate": 4.7688253012048195e-06,
      "loss": 1.5537,
      "step": 307
    },
    {
      "epoch": 0.1855421686746988,
      "grad_norm": 0.6614553928375244,
      "learning_rate": 4.7680722891566264e-06,
      "loss": 1.5906,
      "step": 308
    },
    {
      "epoch": 0.186144578313253,
      "grad_norm": 0.680141031742096,
      "learning_rate": 4.767319277108434e-06,
      "loss": 1.5662,
      "step": 309
    },
    {
      "epoch": 0.18674698795180722,
      "grad_norm": 0.6465786695480347,
      "learning_rate": 4.766566265060241e-06,
      "loss": 1.5959,
      "step": 310
    },
    {
      "epoch": 0.18734939759036146,
      "grad_norm": 0.6303747296333313,
      "learning_rate": 4.765813253012049e-06,
      "loss": 1.5397,
      "step": 311
    },
    {
      "epoch": 0.18795180722891566,
      "grad_norm": 0.6537888050079346,
      "learning_rate": 4.765060240963856e-06,
      "loss": 1.5636,
      "step": 312
    },
    {
      "epoch": 0.18855421686746987,
      "grad_norm": 0.6520653367042542,
      "learning_rate": 4.764307228915663e-06,
      "loss": 1.5704,
      "step": 313
    },
    {
      "epoch": 0.1891566265060241,
      "grad_norm": 0.6491609811782837,
      "learning_rate": 4.7635542168674705e-06,
      "loss": 1.5712,
      "step": 314
    },
    {
      "epoch": 0.1897590361445783,
      "grad_norm": 0.6224614977836609,
      "learning_rate": 4.7628012048192775e-06,
      "loss": 1.5351,
      "step": 315
    },
    {
      "epoch": 0.19036144578313252,
      "grad_norm": 0.6187222003936768,
      "learning_rate": 4.762048192771085e-06,
      "loss": 1.5486,
      "step": 316
    },
    {
      "epoch": 0.19096385542168676,
      "grad_norm": 0.6230939030647278,
      "learning_rate": 4.761295180722892e-06,
      "loss": 1.5315,
      "step": 317
    },
    {
      "epoch": 0.19156626506024096,
      "grad_norm": 0.6235955357551575,
      "learning_rate": 4.760542168674699e-06,
      "loss": 1.5575,
      "step": 318
    },
    {
      "epoch": 0.19216867469879517,
      "grad_norm": 0.6413629055023193,
      "learning_rate": 4.759789156626506e-06,
      "loss": 1.5581,
      "step": 319
    },
    {
      "epoch": 0.1927710843373494,
      "grad_norm": 0.653306245803833,
      "learning_rate": 4.759036144578314e-06,
      "loss": 1.5846,
      "step": 320
    },
    {
      "epoch": 0.19337349397590362,
      "grad_norm": 0.6563746333122253,
      "learning_rate": 4.758283132530121e-06,
      "loss": 1.5782,
      "step": 321
    },
    {
      "epoch": 0.19397590361445782,
      "grad_norm": 0.6224275231361389,
      "learning_rate": 4.757530120481928e-06,
      "loss": 1.4901,
      "step": 322
    },
    {
      "epoch": 0.19457831325301206,
      "grad_norm": 0.6679585576057434,
      "learning_rate": 4.756777108433735e-06,
      "loss": 1.5426,
      "step": 323
    },
    {
      "epoch": 0.19518072289156627,
      "grad_norm": 0.6160849928855896,
      "learning_rate": 4.756024096385542e-06,
      "loss": 1.5484,
      "step": 324
    },
    {
      "epoch": 0.19578313253012047,
      "grad_norm": 0.825554370880127,
      "learning_rate": 4.755271084337349e-06,
      "loss": 1.5753,
      "step": 325
    },
    {
      "epoch": 0.1963855421686747,
      "grad_norm": 0.6330503821372986,
      "learning_rate": 4.754518072289157e-06,
      "loss": 1.5308,
      "step": 326
    },
    {
      "epoch": 0.19698795180722892,
      "grad_norm": 0.6340656280517578,
      "learning_rate": 4.753765060240964e-06,
      "loss": 1.5084,
      "step": 327
    },
    {
      "epoch": 0.19759036144578312,
      "grad_norm": 0.6422789096832275,
      "learning_rate": 4.753012048192772e-06,
      "loss": 1.533,
      "step": 328
    },
    {
      "epoch": 0.19819277108433736,
      "grad_norm": 0.6656094193458557,
      "learning_rate": 4.752259036144579e-06,
      "loss": 1.5321,
      "step": 329
    },
    {
      "epoch": 0.19879518072289157,
      "grad_norm": 0.6251810193061829,
      "learning_rate": 4.751506024096386e-06,
      "loss": 1.5206,
      "step": 330
    },
    {
      "epoch": 0.19939759036144578,
      "grad_norm": 0.6450276374816895,
      "learning_rate": 4.750753012048193e-06,
      "loss": 1.5724,
      "step": 331
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6403321623802185,
      "learning_rate": 4.75e-06,
      "loss": 1.5496,
      "step": 332
    },
    {
      "epoch": 0.20060240963855422,
      "grad_norm": 0.6244162321090698,
      "learning_rate": 4.749246987951808e-06,
      "loss": 1.5279,
      "step": 333
    },
    {
      "epoch": 0.20120481927710843,
      "grad_norm": 0.6277642846107483,
      "learning_rate": 4.748493975903615e-06,
      "loss": 1.5126,
      "step": 334
    },
    {
      "epoch": 0.20180722891566266,
      "grad_norm": 0.603257954120636,
      "learning_rate": 4.747740963855422e-06,
      "loss": 1.5214,
      "step": 335
    },
    {
      "epoch": 0.20240963855421687,
      "grad_norm": 0.6357108354568481,
      "learning_rate": 4.74698795180723e-06,
      "loss": 1.5195,
      "step": 336
    },
    {
      "epoch": 0.20301204819277108,
      "grad_norm": 0.6353623867034912,
      "learning_rate": 4.746234939759037e-06,
      "loss": 1.5074,
      "step": 337
    },
    {
      "epoch": 0.2036144578313253,
      "grad_norm": 0.6504127383232117,
      "learning_rate": 4.7454819277108435e-06,
      "loss": 1.5226,
      "step": 338
    },
    {
      "epoch": 0.20421686746987952,
      "grad_norm": 0.6555492877960205,
      "learning_rate": 4.7447289156626504e-06,
      "loss": 1.5477,
      "step": 339
    },
    {
      "epoch": 0.20481927710843373,
      "grad_norm": 0.6293894648551941,
      "learning_rate": 4.743975903614458e-06,
      "loss": 1.5194,
      "step": 340
    },
    {
      "epoch": 0.20542168674698796,
      "grad_norm": 0.6484460234642029,
      "learning_rate": 4.743222891566265e-06,
      "loss": 1.4976,
      "step": 341
    },
    {
      "epoch": 0.20602409638554217,
      "grad_norm": 0.6341803669929504,
      "learning_rate": 4.742469879518073e-06,
      "loss": 1.508,
      "step": 342
    },
    {
      "epoch": 0.20662650602409638,
      "grad_norm": 0.641331672668457,
      "learning_rate": 4.74171686746988e-06,
      "loss": 1.4985,
      "step": 343
    },
    {
      "epoch": 0.20722891566265061,
      "grad_norm": 0.6322843432426453,
      "learning_rate": 4.740963855421687e-06,
      "loss": 1.5147,
      "step": 344
    },
    {
      "epoch": 0.20783132530120482,
      "grad_norm": 0.6105960011482239,
      "learning_rate": 4.7402108433734945e-06,
      "loss": 1.4782,
      "step": 345
    },
    {
      "epoch": 0.20843373493975903,
      "grad_norm": 0.602277398109436,
      "learning_rate": 4.7394578313253014e-06,
      "loss": 1.4727,
      "step": 346
    },
    {
      "epoch": 0.20903614457831327,
      "grad_norm": 0.6308878064155579,
      "learning_rate": 4.738704819277109e-06,
      "loss": 1.5354,
      "step": 347
    },
    {
      "epoch": 0.20963855421686747,
      "grad_norm": 0.6364786028862,
      "learning_rate": 4.737951807228916e-06,
      "loss": 1.5163,
      "step": 348
    },
    {
      "epoch": 0.21024096385542168,
      "grad_norm": 0.6155357360839844,
      "learning_rate": 4.737198795180723e-06,
      "loss": 1.4466,
      "step": 349
    },
    {
      "epoch": 0.21084337349397592,
      "grad_norm": 0.642551839351654,
      "learning_rate": 4.736445783132531e-06,
      "loss": 1.4871,
      "step": 350
    },
    {
      "epoch": 0.21144578313253012,
      "grad_norm": 0.6344416737556458,
      "learning_rate": 4.735692771084338e-06,
      "loss": 1.5245,
      "step": 351
    },
    {
      "epoch": 0.21204819277108433,
      "grad_norm": 0.6066713333129883,
      "learning_rate": 4.734939759036145e-06,
      "loss": 1.4559,
      "step": 352
    },
    {
      "epoch": 0.21265060240963857,
      "grad_norm": 0.5916743874549866,
      "learning_rate": 4.7341867469879525e-06,
      "loss": 1.4746,
      "step": 353
    },
    {
      "epoch": 0.21325301204819277,
      "grad_norm": 0.6337381601333618,
      "learning_rate": 4.733433734939759e-06,
      "loss": 1.4603,
      "step": 354
    },
    {
      "epoch": 0.21385542168674698,
      "grad_norm": 0.6421207785606384,
      "learning_rate": 4.732680722891566e-06,
      "loss": 1.4652,
      "step": 355
    },
    {
      "epoch": 0.21445783132530122,
      "grad_norm": 0.6392531394958496,
      "learning_rate": 4.731927710843373e-06,
      "loss": 1.4521,
      "step": 356
    },
    {
      "epoch": 0.21506024096385543,
      "grad_norm": 0.6268361806869507,
      "learning_rate": 4.731174698795181e-06,
      "loss": 1.4586,
      "step": 357
    },
    {
      "epoch": 0.21566265060240963,
      "grad_norm": 0.612407386302948,
      "learning_rate": 4.730421686746988e-06,
      "loss": 1.4588,
      "step": 358
    },
    {
      "epoch": 0.21626506024096387,
      "grad_norm": 0.6424269080162048,
      "learning_rate": 4.729668674698796e-06,
      "loss": 1.4456,
      "step": 359
    },
    {
      "epoch": 0.21686746987951808,
      "grad_norm": 0.7704424262046814,
      "learning_rate": 4.728915662650603e-06,
      "loss": 1.4981,
      "step": 360
    },
    {
      "epoch": 0.21746987951807228,
      "grad_norm": 0.7144001126289368,
      "learning_rate": 4.7281626506024096e-06,
      "loss": 1.509,
      "step": 361
    },
    {
      "epoch": 0.21807228915662652,
      "grad_norm": 0.6408788561820984,
      "learning_rate": 4.727409638554217e-06,
      "loss": 1.4523,
      "step": 362
    },
    {
      "epoch": 0.21867469879518073,
      "grad_norm": 0.6352127194404602,
      "learning_rate": 4.726656626506024e-06,
      "loss": 1.463,
      "step": 363
    },
    {
      "epoch": 0.21927710843373494,
      "grad_norm": 0.6153895854949951,
      "learning_rate": 4.725903614457832e-06,
      "loss": 1.4792,
      "step": 364
    },
    {
      "epoch": 0.21987951807228914,
      "grad_norm": 0.6368789076805115,
      "learning_rate": 4.725150602409639e-06,
      "loss": 1.4591,
      "step": 365
    },
    {
      "epoch": 0.22048192771084338,
      "grad_norm": 0.6379714012145996,
      "learning_rate": 4.724397590361447e-06,
      "loss": 1.4643,
      "step": 366
    },
    {
      "epoch": 0.22108433734939759,
      "grad_norm": 0.6261733770370483,
      "learning_rate": 4.723644578313254e-06,
      "loss": 1.4392,
      "step": 367
    },
    {
      "epoch": 0.2216867469879518,
      "grad_norm": 0.6274462938308716,
      "learning_rate": 4.7228915662650606e-06,
      "loss": 1.4477,
      "step": 368
    },
    {
      "epoch": 0.22228915662650603,
      "grad_norm": 0.6333312392234802,
      "learning_rate": 4.722138554216868e-06,
      "loss": 1.46,
      "step": 369
    },
    {
      "epoch": 0.22289156626506024,
      "grad_norm": 0.7191333770751953,
      "learning_rate": 4.721385542168675e-06,
      "loss": 1.482,
      "step": 370
    },
    {
      "epoch": 0.22349397590361444,
      "grad_norm": 0.5841360092163086,
      "learning_rate": 4.720632530120482e-06,
      "loss": 1.4342,
      "step": 371
    },
    {
      "epoch": 0.22409638554216868,
      "grad_norm": 0.6095926761627197,
      "learning_rate": 4.719879518072289e-06,
      "loss": 1.4366,
      "step": 372
    },
    {
      "epoch": 0.2246987951807229,
      "grad_norm": 0.6386562585830688,
      "learning_rate": 4.719126506024097e-06,
      "loss": 1.4597,
      "step": 373
    },
    {
      "epoch": 0.2253012048192771,
      "grad_norm": 0.6346952319145203,
      "learning_rate": 4.718373493975904e-06,
      "loss": 1.4462,
      "step": 374
    },
    {
      "epoch": 0.22590361445783133,
      "grad_norm": 0.6672772169113159,
      "learning_rate": 4.717620481927711e-06,
      "loss": 1.4568,
      "step": 375
    },
    {
      "epoch": 0.22650602409638554,
      "grad_norm": 0.6520745158195496,
      "learning_rate": 4.7168674698795185e-06,
      "loss": 1.4446,
      "step": 376
    },
    {
      "epoch": 0.22710843373493975,
      "grad_norm": 0.6350225806236267,
      "learning_rate": 4.7161144578313254e-06,
      "loss": 1.4537,
      "step": 377
    },
    {
      "epoch": 0.22771084337349398,
      "grad_norm": 0.6168689131736755,
      "learning_rate": 4.715361445783133e-06,
      "loss": 1.4375,
      "step": 378
    },
    {
      "epoch": 0.2283132530120482,
      "grad_norm": 0.644926905632019,
      "learning_rate": 4.71460843373494e-06,
      "loss": 1.4585,
      "step": 379
    },
    {
      "epoch": 0.2289156626506024,
      "grad_norm": 0.6660984754562378,
      "learning_rate": 4.713855421686747e-06,
      "loss": 1.4602,
      "step": 380
    },
    {
      "epoch": 0.22951807228915663,
      "grad_norm": 0.6645481586456299,
      "learning_rate": 4.713102409638555e-06,
      "loss": 1.4553,
      "step": 381
    },
    {
      "epoch": 0.23012048192771084,
      "grad_norm": 0.6541915535926819,
      "learning_rate": 4.712349397590362e-06,
      "loss": 1.4359,
      "step": 382
    },
    {
      "epoch": 0.23072289156626505,
      "grad_norm": 0.6309393644332886,
      "learning_rate": 4.7115963855421695e-06,
      "loss": 1.4236,
      "step": 383
    },
    {
      "epoch": 0.23132530120481928,
      "grad_norm": 0.6497915387153625,
      "learning_rate": 4.7108433734939764e-06,
      "loss": 1.418,
      "step": 384
    },
    {
      "epoch": 0.2319277108433735,
      "grad_norm": 0.600816011428833,
      "learning_rate": 4.710090361445783e-06,
      "loss": 1.4152,
      "step": 385
    },
    {
      "epoch": 0.2325301204819277,
      "grad_norm": 0.6516527533531189,
      "learning_rate": 4.709337349397591e-06,
      "loss": 1.4609,
      "step": 386
    },
    {
      "epoch": 0.23313253012048193,
      "grad_norm": 0.6584140062332153,
      "learning_rate": 4.708584337349398e-06,
      "loss": 1.4314,
      "step": 387
    },
    {
      "epoch": 0.23373493975903614,
      "grad_norm": 0.6199894547462463,
      "learning_rate": 4.707831325301205e-06,
      "loss": 1.4178,
      "step": 388
    },
    {
      "epoch": 0.23433734939759035,
      "grad_norm": 0.6462453007698059,
      "learning_rate": 4.707078313253013e-06,
      "loss": 1.4194,
      "step": 389
    },
    {
      "epoch": 0.23493975903614459,
      "grad_norm": 0.6618443131446838,
      "learning_rate": 4.70632530120482e-06,
      "loss": 1.4279,
      "step": 390
    },
    {
      "epoch": 0.2355421686746988,
      "grad_norm": 0.6546756029129028,
      "learning_rate": 4.705572289156627e-06,
      "loss": 1.4072,
      "step": 391
    },
    {
      "epoch": 0.236144578313253,
      "grad_norm": 0.6192677617073059,
      "learning_rate": 4.7048192771084335e-06,
      "loss": 1.3794,
      "step": 392
    },
    {
      "epoch": 0.23674698795180724,
      "grad_norm": 0.6528082489967346,
      "learning_rate": 4.704066265060241e-06,
      "loss": 1.3875,
      "step": 393
    },
    {
      "epoch": 0.23734939759036144,
      "grad_norm": 0.65110844373703,
      "learning_rate": 4.703313253012048e-06,
      "loss": 1.4078,
      "step": 394
    },
    {
      "epoch": 0.23795180722891565,
      "grad_norm": 0.6746704578399658,
      "learning_rate": 4.702560240963856e-06,
      "loss": 1.4339,
      "step": 395
    },
    {
      "epoch": 0.2385542168674699,
      "grad_norm": 0.6184611916542053,
      "learning_rate": 4.701807228915663e-06,
      "loss": 1.3897,
      "step": 396
    },
    {
      "epoch": 0.2391566265060241,
      "grad_norm": 0.7287032008171082,
      "learning_rate": 4.70105421686747e-06,
      "loss": 1.4431,
      "step": 397
    },
    {
      "epoch": 0.2397590361445783,
      "grad_norm": 0.642220675945282,
      "learning_rate": 4.700301204819278e-06,
      "loss": 1.4244,
      "step": 398
    },
    {
      "epoch": 0.24036144578313254,
      "grad_norm": 0.6729488372802734,
      "learning_rate": 4.6995481927710846e-06,
      "loss": 1.425,
      "step": 399
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 0.6432154178619385,
      "learning_rate": 4.698795180722892e-06,
      "loss": 1.4029,
      "step": 400
    },
    {
      "epoch": 0.24156626506024095,
      "grad_norm": 0.6297951340675354,
      "learning_rate": 4.698042168674699e-06,
      "loss": 1.393,
      "step": 401
    },
    {
      "epoch": 0.2421686746987952,
      "grad_norm": 0.6074402332305908,
      "learning_rate": 4.697289156626507e-06,
      "loss": 1.3294,
      "step": 402
    },
    {
      "epoch": 0.2427710843373494,
      "grad_norm": 0.6134657263755798,
      "learning_rate": 4.696536144578314e-06,
      "loss": 1.3417,
      "step": 403
    },
    {
      "epoch": 0.2433734939759036,
      "grad_norm": 0.685746431350708,
      "learning_rate": 4.695783132530121e-06,
      "loss": 1.3849,
      "step": 404
    },
    {
      "epoch": 0.24397590361445784,
      "grad_norm": 0.6510821580886841,
      "learning_rate": 4.695030120481928e-06,
      "loss": 1.3835,
      "step": 405
    },
    {
      "epoch": 0.24457831325301205,
      "grad_norm": 0.6784501075744629,
      "learning_rate": 4.6942771084337356e-06,
      "loss": 1.4062,
      "step": 406
    },
    {
      "epoch": 0.24518072289156626,
      "grad_norm": 0.6459832191467285,
      "learning_rate": 4.6935240963855425e-06,
      "loss": 1.3758,
      "step": 407
    },
    {
      "epoch": 0.2457831325301205,
      "grad_norm": 0.6256124377250671,
      "learning_rate": 4.692771084337349e-06,
      "loss": 1.3566,
      "step": 408
    },
    {
      "epoch": 0.2463855421686747,
      "grad_norm": 0.6524090766906738,
      "learning_rate": 4.692018072289156e-06,
      "loss": 1.3736,
      "step": 409
    },
    {
      "epoch": 0.2469879518072289,
      "grad_norm": 0.7491938471794128,
      "learning_rate": 4.691265060240964e-06,
      "loss": 1.3792,
      "step": 410
    },
    {
      "epoch": 0.24759036144578314,
      "grad_norm": 0.6368998885154724,
      "learning_rate": 4.690512048192771e-06,
      "loss": 1.3586,
      "step": 411
    },
    {
      "epoch": 0.24819277108433735,
      "grad_norm": 0.6606225371360779,
      "learning_rate": 4.689759036144579e-06,
      "loss": 1.386,
      "step": 412
    },
    {
      "epoch": 0.24879518072289156,
      "grad_norm": 0.6357008814811707,
      "learning_rate": 4.689006024096386e-06,
      "loss": 1.3646,
      "step": 413
    },
    {
      "epoch": 0.2493975903614458,
      "grad_norm": 0.6497612595558167,
      "learning_rate": 4.6882530120481935e-06,
      "loss": 1.3868,
      "step": 414
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6428272724151611,
      "learning_rate": 4.6875000000000004e-06,
      "loss": 1.3506,
      "step": 415
    },
    {
      "epoch": 0.25060240963855424,
      "grad_norm": 0.6612029671669006,
      "learning_rate": 4.686746987951807e-06,
      "loss": 1.375,
      "step": 416
    },
    {
      "epoch": 0.2512048192771084,
      "grad_norm": 0.6559531092643738,
      "learning_rate": 4.685993975903615e-06,
      "loss": 1.3618,
      "step": 417
    },
    {
      "epoch": 0.25180722891566265,
      "grad_norm": 0.6473674178123474,
      "learning_rate": 4.685240963855422e-06,
      "loss": 1.3507,
      "step": 418
    },
    {
      "epoch": 0.2524096385542169,
      "grad_norm": 0.6254408955574036,
      "learning_rate": 4.68448795180723e-06,
      "loss": 1.3406,
      "step": 419
    },
    {
      "epoch": 0.25301204819277107,
      "grad_norm": 0.639141857624054,
      "learning_rate": 4.683734939759037e-06,
      "loss": 1.3338,
      "step": 420
    },
    {
      "epoch": 0.2536144578313253,
      "grad_norm": 0.6584200859069824,
      "learning_rate": 4.682981927710844e-06,
      "loss": 1.3334,
      "step": 421
    },
    {
      "epoch": 0.25421686746987954,
      "grad_norm": 0.7064493298530579,
      "learning_rate": 4.6822289156626515e-06,
      "loss": 1.3876,
      "step": 422
    },
    {
      "epoch": 0.2548192771084337,
      "grad_norm": 0.6526504158973694,
      "learning_rate": 4.681475903614458e-06,
      "loss": 1.322,
      "step": 423
    },
    {
      "epoch": 0.25542168674698795,
      "grad_norm": 0.6836284399032593,
      "learning_rate": 4.680722891566265e-06,
      "loss": 1.3641,
      "step": 424
    },
    {
      "epoch": 0.2560240963855422,
      "grad_norm": 0.6590929627418518,
      "learning_rate": 4.679969879518072e-06,
      "loss": 1.3604,
      "step": 425
    },
    {
      "epoch": 0.25662650602409637,
      "grad_norm": 0.6832489967346191,
      "learning_rate": 4.67921686746988e-06,
      "loss": 1.3551,
      "step": 426
    },
    {
      "epoch": 0.2572289156626506,
      "grad_norm": 0.6621153950691223,
      "learning_rate": 4.678463855421687e-06,
      "loss": 1.3815,
      "step": 427
    },
    {
      "epoch": 0.25783132530120484,
      "grad_norm": 0.6535840630531311,
      "learning_rate": 4.677710843373494e-06,
      "loss": 1.3493,
      "step": 428
    },
    {
      "epoch": 0.258433734939759,
      "grad_norm": 0.645634114742279,
      "learning_rate": 4.676957831325302e-06,
      "loss": 1.3203,
      "step": 429
    },
    {
      "epoch": 0.25903614457831325,
      "grad_norm": 0.6622574925422668,
      "learning_rate": 4.6762048192771085e-06,
      "loss": 1.3138,
      "step": 430
    },
    {
      "epoch": 0.2596385542168675,
      "grad_norm": 0.6293851733207703,
      "learning_rate": 4.675451807228916e-06,
      "loss": 1.3363,
      "step": 431
    },
    {
      "epoch": 0.26024096385542167,
      "grad_norm": 0.6446045637130737,
      "learning_rate": 4.674698795180723e-06,
      "loss": 1.3654,
      "step": 432
    },
    {
      "epoch": 0.2608433734939759,
      "grad_norm": 0.6908028721809387,
      "learning_rate": 4.673945783132531e-06,
      "loss": 1.3169,
      "step": 433
    },
    {
      "epoch": 0.26144578313253014,
      "grad_norm": 0.9223051071166992,
      "learning_rate": 4.673192771084338e-06,
      "loss": 1.3294,
      "step": 434
    },
    {
      "epoch": 0.2620481927710843,
      "grad_norm": 0.6753144264221191,
      "learning_rate": 4.672439759036145e-06,
      "loss": 1.327,
      "step": 435
    },
    {
      "epoch": 0.26265060240963856,
      "grad_norm": 0.6677996516227722,
      "learning_rate": 4.671686746987953e-06,
      "loss": 1.3128,
      "step": 436
    },
    {
      "epoch": 0.2632530120481928,
      "grad_norm": 0.6614099740982056,
      "learning_rate": 4.6709337349397596e-06,
      "loss": 1.3485,
      "step": 437
    },
    {
      "epoch": 0.26385542168674697,
      "grad_norm": 0.6674147248268127,
      "learning_rate": 4.6701807228915665e-06,
      "loss": 1.32,
      "step": 438
    },
    {
      "epoch": 0.2644578313253012,
      "grad_norm": 0.7128778100013733,
      "learning_rate": 4.669427710843374e-06,
      "loss": 1.2987,
      "step": 439
    },
    {
      "epoch": 0.26506024096385544,
      "grad_norm": 0.710616946220398,
      "learning_rate": 4.668674698795181e-06,
      "loss": 1.3444,
      "step": 440
    },
    {
      "epoch": 0.2656626506024096,
      "grad_norm": 0.6815958023071289,
      "learning_rate": 4.667921686746988e-06,
      "loss": 1.308,
      "step": 441
    },
    {
      "epoch": 0.26626506024096386,
      "grad_norm": 0.6912776231765747,
      "learning_rate": 4.667168674698795e-06,
      "loss": 1.3332,
      "step": 442
    },
    {
      "epoch": 0.2668674698795181,
      "grad_norm": 0.6830790638923645,
      "learning_rate": 4.666415662650603e-06,
      "loss": 1.3041,
      "step": 443
    },
    {
      "epoch": 0.2674698795180723,
      "grad_norm": 0.6750925183296204,
      "learning_rate": 4.66566265060241e-06,
      "loss": 1.3343,
      "step": 444
    },
    {
      "epoch": 0.2680722891566265,
      "grad_norm": 0.686276376247406,
      "learning_rate": 4.6649096385542175e-06,
      "loss": 1.2842,
      "step": 445
    },
    {
      "epoch": 0.26867469879518074,
      "grad_norm": 0.6884699463844299,
      "learning_rate": 4.6641566265060244e-06,
      "loss": 1.3217,
      "step": 446
    },
    {
      "epoch": 0.2692771084337349,
      "grad_norm": 0.6877424120903015,
      "learning_rate": 4.663403614457831e-06,
      "loss": 1.3073,
      "step": 447
    },
    {
      "epoch": 0.26987951807228916,
      "grad_norm": 0.7200512290000916,
      "learning_rate": 4.662650602409639e-06,
      "loss": 1.3249,
      "step": 448
    },
    {
      "epoch": 0.2704819277108434,
      "grad_norm": 0.6656315922737122,
      "learning_rate": 4.661897590361446e-06,
      "loss": 1.2966,
      "step": 449
    },
    {
      "epoch": 0.2710843373493976,
      "grad_norm": 0.7276847958564758,
      "learning_rate": 4.661144578313254e-06,
      "loss": 1.2998,
      "step": 450
    },
    {
      "epoch": 0.2716867469879518,
      "grad_norm": 0.7223863005638123,
      "learning_rate": 4.660391566265061e-06,
      "loss": 1.3132,
      "step": 451
    },
    {
      "epoch": 0.27228915662650605,
      "grad_norm": 0.7315244078636169,
      "learning_rate": 4.659638554216868e-06,
      "loss": 1.3155,
      "step": 452
    },
    {
      "epoch": 0.2728915662650602,
      "grad_norm": 0.7454656362533569,
      "learning_rate": 4.6588855421686754e-06,
      "loss": 1.3018,
      "step": 453
    },
    {
      "epoch": 0.27349397590361446,
      "grad_norm": 0.706108033657074,
      "learning_rate": 4.658132530120482e-06,
      "loss": 1.2744,
      "step": 454
    },
    {
      "epoch": 0.2740963855421687,
      "grad_norm": 0.6452051401138306,
      "learning_rate": 4.65737951807229e-06,
      "loss": 1.2746,
      "step": 455
    },
    {
      "epoch": 0.2746987951807229,
      "grad_norm": 0.7260199785232544,
      "learning_rate": 4.656626506024097e-06,
      "loss": 1.3104,
      "step": 456
    },
    {
      "epoch": 0.2753012048192771,
      "grad_norm": 0.6723315715789795,
      "learning_rate": 4.655873493975904e-06,
      "loss": 1.2757,
      "step": 457
    },
    {
      "epoch": 0.27590361445783135,
      "grad_norm": 0.6911063194274902,
      "learning_rate": 4.655120481927711e-06,
      "loss": 1.2763,
      "step": 458
    },
    {
      "epoch": 0.2765060240963855,
      "grad_norm": 0.672784686088562,
      "learning_rate": 4.654367469879519e-06,
      "loss": 1.2659,
      "step": 459
    },
    {
      "epoch": 0.27710843373493976,
      "grad_norm": 0.7133693099021912,
      "learning_rate": 4.653614457831326e-06,
      "loss": 1.2889,
      "step": 460
    },
    {
      "epoch": 0.277710843373494,
      "grad_norm": 0.7149325609207153,
      "learning_rate": 4.6528614457831325e-06,
      "loss": 1.3006,
      "step": 461
    },
    {
      "epoch": 0.2783132530120482,
      "grad_norm": 0.6761752367019653,
      "learning_rate": 4.65210843373494e-06,
      "loss": 1.2691,
      "step": 462
    },
    {
      "epoch": 0.2789156626506024,
      "grad_norm": 0.6940613985061646,
      "learning_rate": 4.651355421686747e-06,
      "loss": 1.2956,
      "step": 463
    },
    {
      "epoch": 0.27951807228915665,
      "grad_norm": 0.678714394569397,
      "learning_rate": 4.650602409638554e-06,
      "loss": 1.2569,
      "step": 464
    },
    {
      "epoch": 0.28012048192771083,
      "grad_norm": 0.6937147378921509,
      "learning_rate": 4.649849397590362e-06,
      "loss": 1.2866,
      "step": 465
    },
    {
      "epoch": 0.28072289156626506,
      "grad_norm": 0.7353542447090149,
      "learning_rate": 4.649096385542169e-06,
      "loss": 1.2889,
      "step": 466
    },
    {
      "epoch": 0.2813253012048193,
      "grad_norm": 0.7408084869384766,
      "learning_rate": 4.648343373493977e-06,
      "loss": 1.2801,
      "step": 467
    },
    {
      "epoch": 0.2819277108433735,
      "grad_norm": 0.7216913104057312,
      "learning_rate": 4.6475903614457835e-06,
      "loss": 1.2812,
      "step": 468
    },
    {
      "epoch": 0.2825301204819277,
      "grad_norm": 0.7195177674293518,
      "learning_rate": 4.646837349397591e-06,
      "loss": 1.2937,
      "step": 469
    },
    {
      "epoch": 0.28313253012048195,
      "grad_norm": 0.7052258253097534,
      "learning_rate": 4.646084337349398e-06,
      "loss": 1.2559,
      "step": 470
    },
    {
      "epoch": 0.28373493975903613,
      "grad_norm": 0.771229088306427,
      "learning_rate": 4.645331325301205e-06,
      "loss": 1.273,
      "step": 471
    },
    {
      "epoch": 0.28433734939759037,
      "grad_norm": 0.7329566478729248,
      "learning_rate": 4.644578313253013e-06,
      "loss": 1.2604,
      "step": 472
    },
    {
      "epoch": 0.2849397590361446,
      "grad_norm": 0.8567209839820862,
      "learning_rate": 4.64382530120482e-06,
      "loss": 1.2558,
      "step": 473
    },
    {
      "epoch": 0.2855421686746988,
      "grad_norm": 0.7164388298988342,
      "learning_rate": 4.643072289156627e-06,
      "loss": 1.2661,
      "step": 474
    },
    {
      "epoch": 0.286144578313253,
      "grad_norm": 0.7328698039054871,
      "learning_rate": 4.642319277108434e-06,
      "loss": 1.2473,
      "step": 475
    },
    {
      "epoch": 0.28674698795180725,
      "grad_norm": 0.7389503121376038,
      "learning_rate": 4.6415662650602415e-06,
      "loss": 1.2489,
      "step": 476
    },
    {
      "epoch": 0.28734939759036143,
      "grad_norm": 0.7524943947792053,
      "learning_rate": 4.640813253012048e-06,
      "loss": 1.2256,
      "step": 477
    },
    {
      "epoch": 0.28795180722891567,
      "grad_norm": 0.719539225101471,
      "learning_rate": 4.640060240963855e-06,
      "loss": 1.2234,
      "step": 478
    },
    {
      "epoch": 0.2885542168674699,
      "grad_norm": 0.7186351418495178,
      "learning_rate": 4.639307228915663e-06,
      "loss": 1.2438,
      "step": 479
    },
    {
      "epoch": 0.2891566265060241,
      "grad_norm": 0.7489399313926697,
      "learning_rate": 4.63855421686747e-06,
      "loss": 1.2658,
      "step": 480
    },
    {
      "epoch": 0.2897590361445783,
      "grad_norm": 0.7756184935569763,
      "learning_rate": 4.637801204819278e-06,
      "loss": 1.2213,
      "step": 481
    },
    {
      "epoch": 0.29036144578313255,
      "grad_norm": 0.7671425342559814,
      "learning_rate": 4.637048192771085e-06,
      "loss": 1.221,
      "step": 482
    },
    {
      "epoch": 0.29096385542168673,
      "grad_norm": 0.7466318607330322,
      "learning_rate": 4.636295180722892e-06,
      "loss": 1.2424,
      "step": 483
    },
    {
      "epoch": 0.29156626506024097,
      "grad_norm": 0.7561440467834473,
      "learning_rate": 4.6355421686746994e-06,
      "loss": 1.2081,
      "step": 484
    },
    {
      "epoch": 0.2921686746987952,
      "grad_norm": 0.7540988326072693,
      "learning_rate": 4.634789156626506e-06,
      "loss": 1.2498,
      "step": 485
    },
    {
      "epoch": 0.2927710843373494,
      "grad_norm": 0.8176242113113403,
      "learning_rate": 4.634036144578314e-06,
      "loss": 1.2283,
      "step": 486
    },
    {
      "epoch": 0.2933734939759036,
      "grad_norm": 0.7305704355239868,
      "learning_rate": 4.633283132530121e-06,
      "loss": 1.2148,
      "step": 487
    },
    {
      "epoch": 0.29397590361445786,
      "grad_norm": 0.7556591033935547,
      "learning_rate": 4.632530120481928e-06,
      "loss": 1.2099,
      "step": 488
    },
    {
      "epoch": 0.29457831325301204,
      "grad_norm": 0.7583631873130798,
      "learning_rate": 4.631777108433736e-06,
      "loss": 1.1997,
      "step": 489
    },
    {
      "epoch": 0.29518072289156627,
      "grad_norm": 0.7480889558792114,
      "learning_rate": 4.631024096385543e-06,
      "loss": 1.2139,
      "step": 490
    },
    {
      "epoch": 0.2957831325301205,
      "grad_norm": 0.7059411406517029,
      "learning_rate": 4.63027108433735e-06,
      "loss": 1.1888,
      "step": 491
    },
    {
      "epoch": 0.2963855421686747,
      "grad_norm": 0.7075276374816895,
      "learning_rate": 4.629518072289157e-06,
      "loss": 1.1933,
      "step": 492
    },
    {
      "epoch": 0.2969879518072289,
      "grad_norm": 0.7904917001724243,
      "learning_rate": 4.628765060240964e-06,
      "loss": 1.1979,
      "step": 493
    },
    {
      "epoch": 0.29759036144578316,
      "grad_norm": 0.7569703459739685,
      "learning_rate": 4.628012048192771e-06,
      "loss": 1.2082,
      "step": 494
    },
    {
      "epoch": 0.29819277108433734,
      "grad_norm": 0.8090049028396606,
      "learning_rate": 4.627259036144578e-06,
      "loss": 1.2189,
      "step": 495
    },
    {
      "epoch": 0.2987951807228916,
      "grad_norm": 0.8234100937843323,
      "learning_rate": 4.626506024096386e-06,
      "loss": 1.1795,
      "step": 496
    },
    {
      "epoch": 0.2993975903614458,
      "grad_norm": 0.8175089359283447,
      "learning_rate": 4.625753012048193e-06,
      "loss": 1.1992,
      "step": 497
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7967278361320496,
      "learning_rate": 4.625000000000001e-06,
      "loss": 1.2157,
      "step": 498
    },
    {
      "epoch": 0.3006024096385542,
      "grad_norm": 0.7595409154891968,
      "learning_rate": 4.6242469879518075e-06,
      "loss": 1.1583,
      "step": 499
    },
    {
      "epoch": 0.30120481927710846,
      "grad_norm": 0.8082883954048157,
      "learning_rate": 4.6234939759036145e-06,
      "loss": 1.1759,
      "step": 500
    },
    {
      "epoch": 0.30180722891566264,
      "grad_norm": 0.7454391121864319,
      "learning_rate": 4.622740963855422e-06,
      "loss": 1.18,
      "step": 501
    },
    {
      "epoch": 0.3024096385542169,
      "grad_norm": 0.7492027878761292,
      "learning_rate": 4.621987951807229e-06,
      "loss": 1.1795,
      "step": 502
    },
    {
      "epoch": 0.3030120481927711,
      "grad_norm": 0.8003729581832886,
      "learning_rate": 4.621234939759037e-06,
      "loss": 1.1923,
      "step": 503
    },
    {
      "epoch": 0.3036144578313253,
      "grad_norm": 0.8372066020965576,
      "learning_rate": 4.620481927710844e-06,
      "loss": 1.2009,
      "step": 504
    },
    {
      "epoch": 0.3042168674698795,
      "grad_norm": 0.790095329284668,
      "learning_rate": 4.619728915662652e-06,
      "loss": 1.1585,
      "step": 505
    },
    {
      "epoch": 0.30481927710843376,
      "grad_norm": 0.7633000612258911,
      "learning_rate": 4.6189759036144586e-06,
      "loss": 1.155,
      "step": 506
    },
    {
      "epoch": 0.30542168674698794,
      "grad_norm": 0.7380251288414001,
      "learning_rate": 4.6182228915662655e-06,
      "loss": 1.179,
      "step": 507
    },
    {
      "epoch": 0.3060240963855422,
      "grad_norm": 0.7651327848434448,
      "learning_rate": 4.617469879518072e-06,
      "loss": 1.1754,
      "step": 508
    },
    {
      "epoch": 0.3066265060240964,
      "grad_norm": 0.8397035598754883,
      "learning_rate": 4.61671686746988e-06,
      "loss": 1.1261,
      "step": 509
    },
    {
      "epoch": 0.3072289156626506,
      "grad_norm": 0.752021849155426,
      "learning_rate": 4.615963855421687e-06,
      "loss": 1.1378,
      "step": 510
    },
    {
      "epoch": 0.30783132530120483,
      "grad_norm": 0.7667669057846069,
      "learning_rate": 4.615210843373494e-06,
      "loss": 1.169,
      "step": 511
    },
    {
      "epoch": 0.30843373493975906,
      "grad_norm": 0.7769167423248291,
      "learning_rate": 4.614457831325301e-06,
      "loss": 1.168,
      "step": 512
    },
    {
      "epoch": 0.30903614457831324,
      "grad_norm": 0.7425531148910522,
      "learning_rate": 4.613704819277109e-06,
      "loss": 1.143,
      "step": 513
    },
    {
      "epoch": 0.3096385542168675,
      "grad_norm": 0.8274052739143372,
      "learning_rate": 4.612951807228916e-06,
      "loss": 1.1465,
      "step": 514
    },
    {
      "epoch": 0.3102409638554217,
      "grad_norm": 1.6008063554763794,
      "learning_rate": 4.612198795180723e-06,
      "loss": 1.1318,
      "step": 515
    },
    {
      "epoch": 0.3108433734939759,
      "grad_norm": 0.7985171675682068,
      "learning_rate": 4.61144578313253e-06,
      "loss": 1.152,
      "step": 516
    },
    {
      "epoch": 0.31144578313253013,
      "grad_norm": 0.8232523202896118,
      "learning_rate": 4.610692771084338e-06,
      "loss": 1.1435,
      "step": 517
    },
    {
      "epoch": 0.31204819277108437,
      "grad_norm": 0.7856816053390503,
      "learning_rate": 4.609939759036145e-06,
      "loss": 1.1818,
      "step": 518
    },
    {
      "epoch": 0.31265060240963854,
      "grad_norm": 1.1465102434158325,
      "learning_rate": 4.609186746987952e-06,
      "loss": 1.0955,
      "step": 519
    },
    {
      "epoch": 0.3132530120481928,
      "grad_norm": 0.8099993467330933,
      "learning_rate": 4.60843373493976e-06,
      "loss": 1.1333,
      "step": 520
    },
    {
      "epoch": 0.31385542168674696,
      "grad_norm": 0.7175696492195129,
      "learning_rate": 4.607680722891567e-06,
      "loss": 1.1243,
      "step": 521
    },
    {
      "epoch": 0.3144578313253012,
      "grad_norm": 0.8137258887290955,
      "learning_rate": 4.6069277108433744e-06,
      "loss": 1.1597,
      "step": 522
    },
    {
      "epoch": 0.31506024096385543,
      "grad_norm": 0.8002985715866089,
      "learning_rate": 4.606174698795181e-06,
      "loss": 1.1363,
      "step": 523
    },
    {
      "epoch": 0.3156626506024096,
      "grad_norm": 0.8019974827766418,
      "learning_rate": 4.605421686746988e-06,
      "loss": 1.1337,
      "step": 524
    },
    {
      "epoch": 0.31626506024096385,
      "grad_norm": 0.8031078577041626,
      "learning_rate": 4.604668674698796e-06,
      "loss": 1.1039,
      "step": 525
    },
    {
      "epoch": 0.3168674698795181,
      "grad_norm": 0.7890410423278809,
      "learning_rate": 4.603915662650603e-06,
      "loss": 1.1279,
      "step": 526
    },
    {
      "epoch": 0.31746987951807226,
      "grad_norm": 0.7995169162750244,
      "learning_rate": 4.60316265060241e-06,
      "loss": 1.1005,
      "step": 527
    },
    {
      "epoch": 0.3180722891566265,
      "grad_norm": 0.8057255148887634,
      "learning_rate": 4.602409638554217e-06,
      "loss": 1.1538,
      "step": 528
    },
    {
      "epoch": 0.31867469879518073,
      "grad_norm": 0.8614428639411926,
      "learning_rate": 4.601656626506025e-06,
      "loss": 1.0864,
      "step": 529
    },
    {
      "epoch": 0.3192771084337349,
      "grad_norm": 0.7864918112754822,
      "learning_rate": 4.6009036144578315e-06,
      "loss": 1.0939,
      "step": 530
    },
    {
      "epoch": 0.31987951807228915,
      "grad_norm": 0.8994051218032837,
      "learning_rate": 4.6001506024096384e-06,
      "loss": 1.118,
      "step": 531
    },
    {
      "epoch": 0.3204819277108434,
      "grad_norm": 0.8140515685081482,
      "learning_rate": 4.599397590361446e-06,
      "loss": 1.1104,
      "step": 532
    },
    {
      "epoch": 0.32108433734939756,
      "grad_norm": 0.8136924505233765,
      "learning_rate": 4.598644578313253e-06,
      "loss": 1.0804,
      "step": 533
    },
    {
      "epoch": 0.3216867469879518,
      "grad_norm": 0.8099343180656433,
      "learning_rate": 4.597891566265061e-06,
      "loss": 1.1287,
      "step": 534
    },
    {
      "epoch": 0.32228915662650603,
      "grad_norm": 0.7928326725959778,
      "learning_rate": 4.597138554216868e-06,
      "loss": 1.1328,
      "step": 535
    },
    {
      "epoch": 0.3228915662650602,
      "grad_norm": 0.8063804507255554,
      "learning_rate": 4.596385542168675e-06,
      "loss": 1.0906,
      "step": 536
    },
    {
      "epoch": 0.32349397590361445,
      "grad_norm": 0.8306028842926025,
      "learning_rate": 4.5956325301204825e-06,
      "loss": 1.0974,
      "step": 537
    },
    {
      "epoch": 0.3240963855421687,
      "grad_norm": 0.8332862257957458,
      "learning_rate": 4.5948795180722895e-06,
      "loss": 1.1073,
      "step": 538
    },
    {
      "epoch": 0.32469879518072287,
      "grad_norm": 0.813503086566925,
      "learning_rate": 4.594126506024097e-06,
      "loss": 1.093,
      "step": 539
    },
    {
      "epoch": 0.3253012048192771,
      "grad_norm": 0.8339914679527283,
      "learning_rate": 4.593373493975904e-06,
      "loss": 1.1028,
      "step": 540
    },
    {
      "epoch": 0.32590361445783134,
      "grad_norm": 0.9993857145309448,
      "learning_rate": 4.592620481927711e-06,
      "loss": 1.1268,
      "step": 541
    },
    {
      "epoch": 0.3265060240963855,
      "grad_norm": 0.8917161822319031,
      "learning_rate": 4.591867469879519e-06,
      "loss": 1.0719,
      "step": 542
    },
    {
      "epoch": 0.32710843373493975,
      "grad_norm": 0.8462717533111572,
      "learning_rate": 4.591114457831326e-06,
      "loss": 1.0674,
      "step": 543
    },
    {
      "epoch": 0.327710843373494,
      "grad_norm": 1.0687875747680664,
      "learning_rate": 4.590361445783133e-06,
      "loss": 1.0583,
      "step": 544
    },
    {
      "epoch": 0.32831325301204817,
      "grad_norm": 0.8134668469429016,
      "learning_rate": 4.58960843373494e-06,
      "loss": 1.0574,
      "step": 545
    },
    {
      "epoch": 0.3289156626506024,
      "grad_norm": 0.8262046575546265,
      "learning_rate": 4.588855421686747e-06,
      "loss": 1.0749,
      "step": 546
    },
    {
      "epoch": 0.32951807228915664,
      "grad_norm": 0.9147099852561951,
      "learning_rate": 4.588102409638554e-06,
      "loss": 1.0797,
      "step": 547
    },
    {
      "epoch": 0.3301204819277108,
      "grad_norm": 0.8510633111000061,
      "learning_rate": 4.587349397590361e-06,
      "loss": 1.0754,
      "step": 548
    },
    {
      "epoch": 0.33072289156626505,
      "grad_norm": 0.7794294953346252,
      "learning_rate": 4.586596385542169e-06,
      "loss": 1.0579,
      "step": 549
    },
    {
      "epoch": 0.3313253012048193,
      "grad_norm": 0.7738134264945984,
      "learning_rate": 4.585843373493976e-06,
      "loss": 1.0469,
      "step": 550
    },
    {
      "epoch": 0.33192771084337347,
      "grad_norm": 0.8296244740486145,
      "learning_rate": 4.585090361445784e-06,
      "loss": 1.0869,
      "step": 551
    },
    {
      "epoch": 0.3325301204819277,
      "grad_norm": 0.8794206380844116,
      "learning_rate": 4.584337349397591e-06,
      "loss": 1.0154,
      "step": 552
    },
    {
      "epoch": 0.33313253012048194,
      "grad_norm": 0.8910216689109802,
      "learning_rate": 4.583584337349398e-06,
      "loss": 1.0379,
      "step": 553
    },
    {
      "epoch": 0.3337349397590361,
      "grad_norm": 0.8590061068534851,
      "learning_rate": 4.582831325301205e-06,
      "loss": 1.0799,
      "step": 554
    },
    {
      "epoch": 0.33433734939759036,
      "grad_norm": 0.8788748979568481,
      "learning_rate": 4.582078313253012e-06,
      "loss": 1.0272,
      "step": 555
    },
    {
      "epoch": 0.3349397590361446,
      "grad_norm": 0.8865940570831299,
      "learning_rate": 4.58132530120482e-06,
      "loss": 1.067,
      "step": 556
    },
    {
      "epoch": 0.33554216867469877,
      "grad_norm": 0.8577322363853455,
      "learning_rate": 4.580572289156627e-06,
      "loss": 1.0143,
      "step": 557
    },
    {
      "epoch": 0.336144578313253,
      "grad_norm": 0.9324508309364319,
      "learning_rate": 4.579819277108435e-06,
      "loss": 1.0183,
      "step": 558
    },
    {
      "epoch": 0.33674698795180724,
      "grad_norm": 0.9491841793060303,
      "learning_rate": 4.579066265060242e-06,
      "loss": 1.0274,
      "step": 559
    },
    {
      "epoch": 0.3373493975903614,
      "grad_norm": 0.9048909544944763,
      "learning_rate": 4.578313253012049e-06,
      "loss": 1.0178,
      "step": 560
    },
    {
      "epoch": 0.33795180722891566,
      "grad_norm": 0.8817954659461975,
      "learning_rate": 4.5775602409638555e-06,
      "loss": 1.011,
      "step": 561
    },
    {
      "epoch": 0.3385542168674699,
      "grad_norm": 0.9615432024002075,
      "learning_rate": 4.576807228915663e-06,
      "loss": 1.0369,
      "step": 562
    },
    {
      "epoch": 0.3391566265060241,
      "grad_norm": 0.8535183668136597,
      "learning_rate": 4.57605421686747e-06,
      "loss": 1.0178,
      "step": 563
    },
    {
      "epoch": 0.3397590361445783,
      "grad_norm": 0.9814767837524414,
      "learning_rate": 4.575301204819277e-06,
      "loss": 1.006,
      "step": 564
    },
    {
      "epoch": 0.34036144578313254,
      "grad_norm": 0.882534921169281,
      "learning_rate": 4.574548192771085e-06,
      "loss": 0.9888,
      "step": 565
    },
    {
      "epoch": 0.3409638554216867,
      "grad_norm": 0.8681419491767883,
      "learning_rate": 4.573795180722892e-06,
      "loss": 0.9919,
      "step": 566
    },
    {
      "epoch": 0.34156626506024096,
      "grad_norm": 0.9057894945144653,
      "learning_rate": 4.573042168674699e-06,
      "loss": 0.9934,
      "step": 567
    },
    {
      "epoch": 0.3421686746987952,
      "grad_norm": 0.8694475889205933,
      "learning_rate": 4.5722891566265065e-06,
      "loss": 1.0,
      "step": 568
    },
    {
      "epoch": 0.3427710843373494,
      "grad_norm": 0.9099330902099609,
      "learning_rate": 4.5715361445783135e-06,
      "loss": 0.9799,
      "step": 569
    },
    {
      "epoch": 0.3433734939759036,
      "grad_norm": 0.8328333497047424,
      "learning_rate": 4.570783132530121e-06,
      "loss": 1.0405,
      "step": 570
    },
    {
      "epoch": 0.34397590361445785,
      "grad_norm": 0.9287550449371338,
      "learning_rate": 4.570030120481928e-06,
      "loss": 0.9911,
      "step": 571
    },
    {
      "epoch": 0.344578313253012,
      "grad_norm": 0.862338125705719,
      "learning_rate": 4.569277108433735e-06,
      "loss": 0.9903,
      "step": 572
    },
    {
      "epoch": 0.34518072289156626,
      "grad_norm": 0.9282112121582031,
      "learning_rate": 4.568524096385543e-06,
      "loss": 0.9574,
      "step": 573
    },
    {
      "epoch": 0.3457831325301205,
      "grad_norm": 0.8905463218688965,
      "learning_rate": 4.56777108433735e-06,
      "loss": 0.9967,
      "step": 574
    },
    {
      "epoch": 0.3463855421686747,
      "grad_norm": 0.8808298110961914,
      "learning_rate": 4.5670180722891575e-06,
      "loss": 0.968,
      "step": 575
    },
    {
      "epoch": 0.3469879518072289,
      "grad_norm": 0.8901328444480896,
      "learning_rate": 4.5662650602409645e-06,
      "loss": 0.9936,
      "step": 576
    },
    {
      "epoch": 0.34759036144578315,
      "grad_norm": 0.9009279012680054,
      "learning_rate": 4.565512048192771e-06,
      "loss": 0.9656,
      "step": 577
    },
    {
      "epoch": 0.3481927710843373,
      "grad_norm": 0.8769810199737549,
      "learning_rate": 4.564759036144578e-06,
      "loss": 0.9642,
      "step": 578
    },
    {
      "epoch": 0.34879518072289156,
      "grad_norm": 0.9731817245483398,
      "learning_rate": 4.564006024096386e-06,
      "loss": 1.0062,
      "step": 579
    },
    {
      "epoch": 0.3493975903614458,
      "grad_norm": 0.9255688786506653,
      "learning_rate": 4.563253012048193e-06,
      "loss": 0.9733,
      "step": 580
    },
    {
      "epoch": 0.35,
      "grad_norm": 0.9204980134963989,
      "learning_rate": 4.5625e-06,
      "loss": 0.9265,
      "step": 581
    },
    {
      "epoch": 0.3506024096385542,
      "grad_norm": 0.9825111627578735,
      "learning_rate": 4.561746987951808e-06,
      "loss": 0.9838,
      "step": 582
    },
    {
      "epoch": 0.35120481927710845,
      "grad_norm": 0.9375790357589722,
      "learning_rate": 4.560993975903615e-06,
      "loss": 0.9304,
      "step": 583
    },
    {
      "epoch": 0.35180722891566263,
      "grad_norm": 0.9558883309364319,
      "learning_rate": 4.5602409638554216e-06,
      "loss": 0.9341,
      "step": 584
    },
    {
      "epoch": 0.35240963855421686,
      "grad_norm": 0.9476211071014404,
      "learning_rate": 4.559487951807229e-06,
      "loss": 0.9479,
      "step": 585
    },
    {
      "epoch": 0.3530120481927711,
      "grad_norm": 0.9789583683013916,
      "learning_rate": 4.558734939759036e-06,
      "loss": 0.9392,
      "step": 586
    },
    {
      "epoch": 0.3536144578313253,
      "grad_norm": 1.0323759317398071,
      "learning_rate": 4.557981927710844e-06,
      "loss": 0.9519,
      "step": 587
    },
    {
      "epoch": 0.3542168674698795,
      "grad_norm": 0.9491678476333618,
      "learning_rate": 4.557228915662651e-06,
      "loss": 0.9806,
      "step": 588
    },
    {
      "epoch": 0.35481927710843375,
      "grad_norm": 0.8710739612579346,
      "learning_rate": 4.556475903614459e-06,
      "loss": 0.9402,
      "step": 589
    },
    {
      "epoch": 0.35542168674698793,
      "grad_norm": 0.909956693649292,
      "learning_rate": 4.555722891566266e-06,
      "loss": 0.9217,
      "step": 590
    },
    {
      "epoch": 0.35602409638554217,
      "grad_norm": 0.8869108557701111,
      "learning_rate": 4.5549698795180726e-06,
      "loss": 0.954,
      "step": 591
    },
    {
      "epoch": 0.3566265060240964,
      "grad_norm": 0.9693204760551453,
      "learning_rate": 4.55421686746988e-06,
      "loss": 0.9179,
      "step": 592
    },
    {
      "epoch": 0.3572289156626506,
      "grad_norm": 0.9338054060935974,
      "learning_rate": 4.553463855421687e-06,
      "loss": 0.9577,
      "step": 593
    },
    {
      "epoch": 0.3578313253012048,
      "grad_norm": 0.9699175357818604,
      "learning_rate": 4.552710843373494e-06,
      "loss": 0.9308,
      "step": 594
    },
    {
      "epoch": 0.35843373493975905,
      "grad_norm": 1.003976583480835,
      "learning_rate": 4.551957831325302e-06,
      "loss": 0.8975,
      "step": 595
    },
    {
      "epoch": 0.35903614457831323,
      "grad_norm": 0.9842025637626648,
      "learning_rate": 4.551204819277109e-06,
      "loss": 0.9054,
      "step": 596
    },
    {
      "epoch": 0.35963855421686747,
      "grad_norm": 0.9319078922271729,
      "learning_rate": 4.550451807228916e-06,
      "loss": 0.9272,
      "step": 597
    },
    {
      "epoch": 0.3602409638554217,
      "grad_norm": 1.0650275945663452,
      "learning_rate": 4.549698795180723e-06,
      "loss": 0.9075,
      "step": 598
    },
    {
      "epoch": 0.3608433734939759,
      "grad_norm": 0.9960916042327881,
      "learning_rate": 4.5489457831325305e-06,
      "loss": 0.8718,
      "step": 599
    },
    {
      "epoch": 0.3614457831325301,
      "grad_norm": 1.001706838607788,
      "learning_rate": 4.5481927710843374e-06,
      "loss": 0.8936,
      "step": 600
    },
    {
      "epoch": 0.36204819277108435,
      "grad_norm": 0.9815955758094788,
      "learning_rate": 4.547439759036145e-06,
      "loss": 0.9019,
      "step": 601
    },
    {
      "epoch": 0.36265060240963853,
      "grad_norm": 0.9800592064857483,
      "learning_rate": 4.546686746987952e-06,
      "loss": 0.9255,
      "step": 602
    },
    {
      "epoch": 0.36325301204819277,
      "grad_norm": 0.988575279712677,
      "learning_rate": 4.545933734939759e-06,
      "loss": 0.9027,
      "step": 603
    },
    {
      "epoch": 0.363855421686747,
      "grad_norm": 0.985105574131012,
      "learning_rate": 4.545180722891567e-06,
      "loss": 0.8928,
      "step": 604
    },
    {
      "epoch": 0.3644578313253012,
      "grad_norm": 0.908420205116272,
      "learning_rate": 4.544427710843374e-06,
      "loss": 0.9175,
      "step": 605
    },
    {
      "epoch": 0.3650602409638554,
      "grad_norm": 0.9181346297264099,
      "learning_rate": 4.5436746987951815e-06,
      "loss": 0.9098,
      "step": 606
    },
    {
      "epoch": 0.36566265060240966,
      "grad_norm": 1.002541184425354,
      "learning_rate": 4.5429216867469885e-06,
      "loss": 0.9019,
      "step": 607
    },
    {
      "epoch": 0.36626506024096384,
      "grad_norm": 0.9376067519187927,
      "learning_rate": 4.542168674698795e-06,
      "loss": 0.8461,
      "step": 608
    },
    {
      "epoch": 0.36686746987951807,
      "grad_norm": 0.9519748687744141,
      "learning_rate": 4.541415662650603e-06,
      "loss": 0.8432,
      "step": 609
    },
    {
      "epoch": 0.3674698795180723,
      "grad_norm": 1.136351227760315,
      "learning_rate": 4.54066265060241e-06,
      "loss": 0.8102,
      "step": 610
    },
    {
      "epoch": 0.3680722891566265,
      "grad_norm": 0.9343248605728149,
      "learning_rate": 4.539909638554217e-06,
      "loss": 0.8452,
      "step": 611
    },
    {
      "epoch": 0.3686746987951807,
      "grad_norm": 0.9426173567771912,
      "learning_rate": 4.539156626506025e-06,
      "loss": 0.8373,
      "step": 612
    },
    {
      "epoch": 0.36927710843373496,
      "grad_norm": 0.9152857661247253,
      "learning_rate": 4.538403614457832e-06,
      "loss": 0.8594,
      "step": 613
    },
    {
      "epoch": 0.36987951807228914,
      "grad_norm": 0.9090049266815186,
      "learning_rate": 4.537650602409639e-06,
      "loss": 0.8805,
      "step": 614
    },
    {
      "epoch": 0.3704819277108434,
      "grad_norm": 0.9620448350906372,
      "learning_rate": 4.5368975903614455e-06,
      "loss": 0.866,
      "step": 615
    },
    {
      "epoch": 0.3710843373493976,
      "grad_norm": 0.9901975989341736,
      "learning_rate": 4.536144578313253e-06,
      "loss": 0.8637,
      "step": 616
    },
    {
      "epoch": 0.3716867469879518,
      "grad_norm": 0.9469422101974487,
      "learning_rate": 4.53539156626506e-06,
      "loss": 0.8289,
      "step": 617
    },
    {
      "epoch": 0.372289156626506,
      "grad_norm": 1.0357321500778198,
      "learning_rate": 4.534638554216868e-06,
      "loss": 0.8376,
      "step": 618
    },
    {
      "epoch": 0.37289156626506026,
      "grad_norm": 0.999031126499176,
      "learning_rate": 4.533885542168675e-06,
      "loss": 0.8445,
      "step": 619
    },
    {
      "epoch": 0.37349397590361444,
      "grad_norm": 0.9613181352615356,
      "learning_rate": 4.533132530120482e-06,
      "loss": 0.8255,
      "step": 620
    },
    {
      "epoch": 0.3740963855421687,
      "grad_norm": 0.9610326290130615,
      "learning_rate": 4.53237951807229e-06,
      "loss": 0.8342,
      "step": 621
    },
    {
      "epoch": 0.3746987951807229,
      "grad_norm": 1.0821201801300049,
      "learning_rate": 4.5316265060240966e-06,
      "loss": 0.8356,
      "step": 622
    },
    {
      "epoch": 0.3753012048192771,
      "grad_norm": 1.047034740447998,
      "learning_rate": 4.530873493975904e-06,
      "loss": 0.817,
      "step": 623
    },
    {
      "epoch": 0.3759036144578313,
      "grad_norm": 0.9263137578964233,
      "learning_rate": 4.530120481927711e-06,
      "loss": 0.7894,
      "step": 624
    },
    {
      "epoch": 0.37650602409638556,
      "grad_norm": 0.9721913933753967,
      "learning_rate": 4.529367469879519e-06,
      "loss": 0.8198,
      "step": 625
    },
    {
      "epoch": 0.37710843373493974,
      "grad_norm": 0.9413060545921326,
      "learning_rate": 4.528614457831326e-06,
      "loss": 0.7946,
      "step": 626
    },
    {
      "epoch": 0.377710843373494,
      "grad_norm": 0.954142689704895,
      "learning_rate": 4.527861445783133e-06,
      "loss": 0.8136,
      "step": 627
    },
    {
      "epoch": 0.3783132530120482,
      "grad_norm": 1.1040890216827393,
      "learning_rate": 4.527108433734941e-06,
      "loss": 0.8331,
      "step": 628
    },
    {
      "epoch": 0.3789156626506024,
      "grad_norm": 1.0288211107254028,
      "learning_rate": 4.526355421686748e-06,
      "loss": 0.8124,
      "step": 629
    },
    {
      "epoch": 0.3795180722891566,
      "grad_norm": 0.9828630089759827,
      "learning_rate": 4.5256024096385545e-06,
      "loss": 0.8077,
      "step": 630
    },
    {
      "epoch": 0.38012048192771086,
      "grad_norm": 0.964911699295044,
      "learning_rate": 4.5248493975903614e-06,
      "loss": 0.8012,
      "step": 631
    },
    {
      "epoch": 0.38072289156626504,
      "grad_norm": 0.9970154166221619,
      "learning_rate": 4.524096385542169e-06,
      "loss": 0.7621,
      "step": 632
    },
    {
      "epoch": 0.3813253012048193,
      "grad_norm": 1.0088462829589844,
      "learning_rate": 4.523343373493976e-06,
      "loss": 0.7747,
      "step": 633
    },
    {
      "epoch": 0.3819277108433735,
      "grad_norm": 0.9924386143684387,
      "learning_rate": 4.522590361445783e-06,
      "loss": 0.7601,
      "step": 634
    },
    {
      "epoch": 0.3825301204819277,
      "grad_norm": 1.0044641494750977,
      "learning_rate": 4.521837349397591e-06,
      "loss": 0.7776,
      "step": 635
    },
    {
      "epoch": 0.38313253012048193,
      "grad_norm": 0.9805490374565125,
      "learning_rate": 4.521084337349398e-06,
      "loss": 0.7965,
      "step": 636
    },
    {
      "epoch": 0.38373493975903616,
      "grad_norm": 0.966906726360321,
      "learning_rate": 4.5203313253012055e-06,
      "loss": 0.7631,
      "step": 637
    },
    {
      "epoch": 0.38433734939759034,
      "grad_norm": 1.1182326078414917,
      "learning_rate": 4.5195783132530124e-06,
      "loss": 0.7531,
      "step": 638
    },
    {
      "epoch": 0.3849397590361446,
      "grad_norm": 1.0099408626556396,
      "learning_rate": 4.518825301204819e-06,
      "loss": 0.7624,
      "step": 639
    },
    {
      "epoch": 0.3855421686746988,
      "grad_norm": 0.9878208637237549,
      "learning_rate": 4.518072289156627e-06,
      "loss": 0.7601,
      "step": 640
    },
    {
      "epoch": 0.386144578313253,
      "grad_norm": 1.125728726387024,
      "learning_rate": 4.517319277108434e-06,
      "loss": 0.7822,
      "step": 641
    },
    {
      "epoch": 0.38674698795180723,
      "grad_norm": 1.0349582433700562,
      "learning_rate": 4.516566265060242e-06,
      "loss": 0.7747,
      "step": 642
    },
    {
      "epoch": 0.38734939759036147,
      "grad_norm": 1.0631352663040161,
      "learning_rate": 4.515813253012049e-06,
      "loss": 0.7723,
      "step": 643
    },
    {
      "epoch": 0.38795180722891565,
      "grad_norm": 1.0718674659729004,
      "learning_rate": 4.515060240963856e-06,
      "loss": 0.7715,
      "step": 644
    },
    {
      "epoch": 0.3885542168674699,
      "grad_norm": 1.0990155935287476,
      "learning_rate": 4.5143072289156635e-06,
      "loss": 0.8042,
      "step": 645
    },
    {
      "epoch": 0.3891566265060241,
      "grad_norm": 1.0174449682235718,
      "learning_rate": 4.51355421686747e-06,
      "loss": 0.7595,
      "step": 646
    },
    {
      "epoch": 0.3897590361445783,
      "grad_norm": 1.1837811470031738,
      "learning_rate": 4.512801204819277e-06,
      "loss": 0.7464,
      "step": 647
    },
    {
      "epoch": 0.39036144578313253,
      "grad_norm": 1.1599847078323364,
      "learning_rate": 4.512048192771084e-06,
      "loss": 0.7587,
      "step": 648
    },
    {
      "epoch": 0.39096385542168677,
      "grad_norm": 1.0774868726730347,
      "learning_rate": 4.511295180722892e-06,
      "loss": 0.725,
      "step": 649
    },
    {
      "epoch": 0.39156626506024095,
      "grad_norm": 0.9660741090774536,
      "learning_rate": 4.510542168674699e-06,
      "loss": 0.7875,
      "step": 650
    },
    {
      "epoch": 0.3921686746987952,
      "grad_norm": 1.0221377611160278,
      "learning_rate": 4.509789156626506e-06,
      "loss": 0.7498,
      "step": 651
    },
    {
      "epoch": 0.3927710843373494,
      "grad_norm": 1.0415996313095093,
      "learning_rate": 4.509036144578314e-06,
      "loss": 0.702,
      "step": 652
    },
    {
      "epoch": 0.3933734939759036,
      "grad_norm": 1.0113518238067627,
      "learning_rate": 4.5082831325301206e-06,
      "loss": 0.737,
      "step": 653
    },
    {
      "epoch": 0.39397590361445783,
      "grad_norm": 1.1010925769805908,
      "learning_rate": 4.507530120481928e-06,
      "loss": 0.752,
      "step": 654
    },
    {
      "epoch": 0.39457831325301207,
      "grad_norm": 1.0029491186141968,
      "learning_rate": 4.506777108433735e-06,
      "loss": 0.7445,
      "step": 655
    },
    {
      "epoch": 0.39518072289156625,
      "grad_norm": 1.1449438333511353,
      "learning_rate": 4.506024096385542e-06,
      "loss": 0.7078,
      "step": 656
    },
    {
      "epoch": 0.3957831325301205,
      "grad_norm": 1.0588957071304321,
      "learning_rate": 4.50527108433735e-06,
      "loss": 0.7135,
      "step": 657
    },
    {
      "epoch": 0.3963855421686747,
      "grad_norm": 1.0264630317687988,
      "learning_rate": 4.504518072289157e-06,
      "loss": 0.7432,
      "step": 658
    },
    {
      "epoch": 0.3969879518072289,
      "grad_norm": 0.9456748366355896,
      "learning_rate": 4.503765060240965e-06,
      "loss": 0.7136,
      "step": 659
    },
    {
      "epoch": 0.39759036144578314,
      "grad_norm": 1.0326026678085327,
      "learning_rate": 4.5030120481927716e-06,
      "loss": 0.7882,
      "step": 660
    },
    {
      "epoch": 0.39819277108433737,
      "grad_norm": 1.026642084121704,
      "learning_rate": 4.502259036144579e-06,
      "loss": 0.7063,
      "step": 661
    },
    {
      "epoch": 0.39879518072289155,
      "grad_norm": 1.1484055519104004,
      "learning_rate": 4.501506024096386e-06,
      "loss": 0.7575,
      "step": 662
    },
    {
      "epoch": 0.3993975903614458,
      "grad_norm": 0.9679239392280579,
      "learning_rate": 4.500753012048193e-06,
      "loss": 0.752,
      "step": 663
    },
    {
      "epoch": 0.4,
      "grad_norm": 1.031883716583252,
      "learning_rate": 4.5e-06,
      "loss": 0.7625,
      "step": 664
    },
    {
      "epoch": 0.4006024096385542,
      "grad_norm": 0.9326608777046204,
      "learning_rate": 4.499246987951808e-06,
      "loss": 0.7539,
      "step": 665
    },
    {
      "epoch": 0.40120481927710844,
      "grad_norm": 0.9804477691650391,
      "learning_rate": 4.498493975903615e-06,
      "loss": 0.7797,
      "step": 666
    },
    {
      "epoch": 0.4018072289156627,
      "grad_norm": 0.9202876091003418,
      "learning_rate": 4.497740963855422e-06,
      "loss": 0.7471,
      "step": 667
    },
    {
      "epoch": 0.40240963855421685,
      "grad_norm": 1.0226390361785889,
      "learning_rate": 4.496987951807229e-06,
      "loss": 0.7713,
      "step": 668
    },
    {
      "epoch": 0.4030120481927711,
      "grad_norm": 1.0094815492630005,
      "learning_rate": 4.4962349397590364e-06,
      "loss": 0.7396,
      "step": 669
    },
    {
      "epoch": 0.4036144578313253,
      "grad_norm": 0.8498848080635071,
      "learning_rate": 4.495481927710843e-06,
      "loss": 0.7481,
      "step": 670
    },
    {
      "epoch": 0.4042168674698795,
      "grad_norm": 0.8926054239273071,
      "learning_rate": 4.494728915662651e-06,
      "loss": 0.7034,
      "step": 671
    },
    {
      "epoch": 0.40481927710843374,
      "grad_norm": 1.01282799243927,
      "learning_rate": 4.493975903614458e-06,
      "loss": 0.6883,
      "step": 672
    },
    {
      "epoch": 0.405421686746988,
      "grad_norm": 0.9260305762290955,
      "learning_rate": 4.493222891566266e-06,
      "loss": 0.7298,
      "step": 673
    },
    {
      "epoch": 0.40602409638554215,
      "grad_norm": 0.9207394123077393,
      "learning_rate": 4.492469879518073e-06,
      "loss": 0.7108,
      "step": 674
    },
    {
      "epoch": 0.4066265060240964,
      "grad_norm": 0.9619960784912109,
      "learning_rate": 4.49171686746988e-06,
      "loss": 0.6785,
      "step": 675
    },
    {
      "epoch": 0.4072289156626506,
      "grad_norm": 0.9400011897087097,
      "learning_rate": 4.4909638554216874e-06,
      "loss": 0.7147,
      "step": 676
    },
    {
      "epoch": 0.4078313253012048,
      "grad_norm": 0.911755383014679,
      "learning_rate": 4.490210843373494e-06,
      "loss": 0.7024,
      "step": 677
    },
    {
      "epoch": 0.40843373493975904,
      "grad_norm": 0.8969728350639343,
      "learning_rate": 4.489457831325302e-06,
      "loss": 0.6864,
      "step": 678
    },
    {
      "epoch": 0.4090361445783133,
      "grad_norm": 1.1272653341293335,
      "learning_rate": 4.488704819277109e-06,
      "loss": 0.6898,
      "step": 679
    },
    {
      "epoch": 0.40963855421686746,
      "grad_norm": 0.9585755467414856,
      "learning_rate": 4.487951807228916e-06,
      "loss": 0.6776,
      "step": 680
    },
    {
      "epoch": 0.4102409638554217,
      "grad_norm": 1.0780611038208008,
      "learning_rate": 4.487198795180723e-06,
      "loss": 0.7071,
      "step": 681
    },
    {
      "epoch": 0.4108433734939759,
      "grad_norm": 1.102491855621338,
      "learning_rate": 4.486445783132531e-06,
      "loss": 0.6778,
      "step": 682
    },
    {
      "epoch": 0.4114457831325301,
      "grad_norm": 0.9309822916984558,
      "learning_rate": 4.485692771084338e-06,
      "loss": 0.6902,
      "step": 683
    },
    {
      "epoch": 0.41204819277108434,
      "grad_norm": 0.9775459170341492,
      "learning_rate": 4.4849397590361445e-06,
      "loss": 0.6976,
      "step": 684
    },
    {
      "epoch": 0.4126506024096386,
      "grad_norm": 0.9899704456329346,
      "learning_rate": 4.484186746987952e-06,
      "loss": 0.666,
      "step": 685
    },
    {
      "epoch": 0.41325301204819276,
      "grad_norm": 1.0712119340896606,
      "learning_rate": 4.483433734939759e-06,
      "loss": 0.7253,
      "step": 686
    },
    {
      "epoch": 0.413855421686747,
      "grad_norm": 0.9476547241210938,
      "learning_rate": 4.482680722891566e-06,
      "loss": 0.6993,
      "step": 687
    },
    {
      "epoch": 0.41445783132530123,
      "grad_norm": 0.9115734696388245,
      "learning_rate": 4.481927710843374e-06,
      "loss": 0.6932,
      "step": 688
    },
    {
      "epoch": 0.4150602409638554,
      "grad_norm": 1.7077184915542603,
      "learning_rate": 4.481174698795181e-06,
      "loss": 0.695,
      "step": 689
    },
    {
      "epoch": 0.41566265060240964,
      "grad_norm": 1.043157696723938,
      "learning_rate": 4.480421686746989e-06,
      "loss": 0.702,
      "step": 690
    },
    {
      "epoch": 0.4162650602409639,
      "grad_norm": 1.0398238897323608,
      "learning_rate": 4.4796686746987956e-06,
      "loss": 0.6591,
      "step": 691
    },
    {
      "epoch": 0.41686746987951806,
      "grad_norm": 0.9030842781066895,
      "learning_rate": 4.4789156626506025e-06,
      "loss": 0.666,
      "step": 692
    },
    {
      "epoch": 0.4174698795180723,
      "grad_norm": 1.0230324268341064,
      "learning_rate": 4.47816265060241e-06,
      "loss": 0.6817,
      "step": 693
    },
    {
      "epoch": 0.41807228915662653,
      "grad_norm": 0.9749019742012024,
      "learning_rate": 4.477409638554217e-06,
      "loss": 0.6899,
      "step": 694
    },
    {
      "epoch": 0.4186746987951807,
      "grad_norm": 1.0223050117492676,
      "learning_rate": 4.476656626506025e-06,
      "loss": 0.6755,
      "step": 695
    },
    {
      "epoch": 0.41927710843373495,
      "grad_norm": 1.1057755947113037,
      "learning_rate": 4.475903614457832e-06,
      "loss": 0.6335,
      "step": 696
    },
    {
      "epoch": 0.4198795180722892,
      "grad_norm": 1.0513943433761597,
      "learning_rate": 4.475150602409639e-06,
      "loss": 0.6901,
      "step": 697
    },
    {
      "epoch": 0.42048192771084336,
      "grad_norm": 0.9192396402359009,
      "learning_rate": 4.4743975903614466e-06,
      "loss": 0.6568,
      "step": 698
    },
    {
      "epoch": 0.4210843373493976,
      "grad_norm": 1.0096818208694458,
      "learning_rate": 4.4736445783132535e-06,
      "loss": 0.6635,
      "step": 699
    },
    {
      "epoch": 0.42168674698795183,
      "grad_norm": 0.9889012575149536,
      "learning_rate": 4.47289156626506e-06,
      "loss": 0.6482,
      "step": 700
    },
    {
      "epoch": 0.422289156626506,
      "grad_norm": 0.9985100626945496,
      "learning_rate": 4.472138554216867e-06,
      "loss": 0.6881,
      "step": 701
    },
    {
      "epoch": 0.42289156626506025,
      "grad_norm": 1.0344470739364624,
      "learning_rate": 4.471385542168675e-06,
      "loss": 0.6334,
      "step": 702
    },
    {
      "epoch": 0.4234939759036145,
      "grad_norm": 0.9842323064804077,
      "learning_rate": 4.470632530120482e-06,
      "loss": 0.6661,
      "step": 703
    },
    {
      "epoch": 0.42409638554216866,
      "grad_norm": 0.9014646410942078,
      "learning_rate": 4.469879518072289e-06,
      "loss": 0.6623,
      "step": 704
    },
    {
      "epoch": 0.4246987951807229,
      "grad_norm": 0.9486470222473145,
      "learning_rate": 4.469126506024097e-06,
      "loss": 0.6664,
      "step": 705
    },
    {
      "epoch": 0.42530120481927713,
      "grad_norm": 1.0533274412155151,
      "learning_rate": 4.468373493975904e-06,
      "loss": 0.6377,
      "step": 706
    },
    {
      "epoch": 0.4259036144578313,
      "grad_norm": 1.0267809629440308,
      "learning_rate": 4.4676204819277114e-06,
      "loss": 0.6852,
      "step": 707
    },
    {
      "epoch": 0.42650602409638555,
      "grad_norm": 1.0292917490005493,
      "learning_rate": 4.466867469879518e-06,
      "loss": 0.6255,
      "step": 708
    },
    {
      "epoch": 0.4271084337349398,
      "grad_norm": 0.9228330850601196,
      "learning_rate": 4.466114457831326e-06,
      "loss": 0.6267,
      "step": 709
    },
    {
      "epoch": 0.42771084337349397,
      "grad_norm": 1.1929038763046265,
      "learning_rate": 4.465361445783133e-06,
      "loss": 0.6742,
      "step": 710
    },
    {
      "epoch": 0.4283132530120482,
      "grad_norm": 0.8751698732376099,
      "learning_rate": 4.46460843373494e-06,
      "loss": 0.6371,
      "step": 711
    },
    {
      "epoch": 0.42891566265060244,
      "grad_norm": 0.9583964347839355,
      "learning_rate": 4.463855421686748e-06,
      "loss": 0.6595,
      "step": 712
    },
    {
      "epoch": 0.4295180722891566,
      "grad_norm": 0.8990480899810791,
      "learning_rate": 4.463102409638555e-06,
      "loss": 0.6355,
      "step": 713
    },
    {
      "epoch": 0.43012048192771085,
      "grad_norm": 0.9760796427726746,
      "learning_rate": 4.462349397590362e-06,
      "loss": 0.6294,
      "step": 714
    },
    {
      "epoch": 0.4307228915662651,
      "grad_norm": 0.8755533695220947,
      "learning_rate": 4.461596385542169e-06,
      "loss": 0.6425,
      "step": 715
    },
    {
      "epoch": 0.43132530120481927,
      "grad_norm": 0.9539238810539246,
      "learning_rate": 4.460843373493976e-06,
      "loss": 0.6155,
      "step": 716
    },
    {
      "epoch": 0.4319277108433735,
      "grad_norm": 0.9495978355407715,
      "learning_rate": 4.460090361445783e-06,
      "loss": 0.6143,
      "step": 717
    },
    {
      "epoch": 0.43253012048192774,
      "grad_norm": 0.910720705986023,
      "learning_rate": 4.45933734939759e-06,
      "loss": 0.5568,
      "step": 718
    },
    {
      "epoch": 0.4331325301204819,
      "grad_norm": 0.9646309614181519,
      "learning_rate": 4.458584337349398e-06,
      "loss": 0.6044,
      "step": 719
    },
    {
      "epoch": 0.43373493975903615,
      "grad_norm": 1.2737126350402832,
      "learning_rate": 4.457831325301205e-06,
      "loss": 0.6685,
      "step": 720
    },
    {
      "epoch": 0.4343373493975904,
      "grad_norm": 0.9361264109611511,
      "learning_rate": 4.457078313253013e-06,
      "loss": 0.6171,
      "step": 721
    },
    {
      "epoch": 0.43493975903614457,
      "grad_norm": 0.8227005004882812,
      "learning_rate": 4.4563253012048195e-06,
      "loss": 0.6427,
      "step": 722
    },
    {
      "epoch": 0.4355421686746988,
      "grad_norm": 0.994440495967865,
      "learning_rate": 4.4555722891566265e-06,
      "loss": 0.588,
      "step": 723
    },
    {
      "epoch": 0.43614457831325304,
      "grad_norm": 0.9769623875617981,
      "learning_rate": 4.454819277108434e-06,
      "loss": 0.6412,
      "step": 724
    },
    {
      "epoch": 0.4367469879518072,
      "grad_norm": 1.0083932876586914,
      "learning_rate": 4.454066265060241e-06,
      "loss": 0.5943,
      "step": 725
    },
    {
      "epoch": 0.43734939759036146,
      "grad_norm": 0.9585238695144653,
      "learning_rate": 4.453313253012049e-06,
      "loss": 0.607,
      "step": 726
    },
    {
      "epoch": 0.43795180722891563,
      "grad_norm": 0.9229143857955933,
      "learning_rate": 4.452560240963856e-06,
      "loss": 0.6423,
      "step": 727
    },
    {
      "epoch": 0.43855421686746987,
      "grad_norm": 1.02794349193573,
      "learning_rate": 4.451807228915663e-06,
      "loss": 0.6156,
      "step": 728
    },
    {
      "epoch": 0.4391566265060241,
      "grad_norm": 0.9746854901313782,
      "learning_rate": 4.4510542168674706e-06,
      "loss": 0.5547,
      "step": 729
    },
    {
      "epoch": 0.4397590361445783,
      "grad_norm": 1.0333980321884155,
      "learning_rate": 4.4503012048192775e-06,
      "loss": 0.5804,
      "step": 730
    },
    {
      "epoch": 0.4403614457831325,
      "grad_norm": 0.9143245220184326,
      "learning_rate": 4.449548192771085e-06,
      "loss": 0.6191,
      "step": 731
    },
    {
      "epoch": 0.44096385542168676,
      "grad_norm": 0.9375326037406921,
      "learning_rate": 4.448795180722892e-06,
      "loss": 0.5873,
      "step": 732
    },
    {
      "epoch": 0.44156626506024094,
      "grad_norm": 0.9180657863616943,
      "learning_rate": 4.448042168674699e-06,
      "loss": 0.6351,
      "step": 733
    },
    {
      "epoch": 0.44216867469879517,
      "grad_norm": 0.9116321206092834,
      "learning_rate": 4.447289156626506e-06,
      "loss": 0.5777,
      "step": 734
    },
    {
      "epoch": 0.4427710843373494,
      "grad_norm": 0.94403076171875,
      "learning_rate": 4.446536144578314e-06,
      "loss": 0.5907,
      "step": 735
    },
    {
      "epoch": 0.4433734939759036,
      "grad_norm": 1.0800135135650635,
      "learning_rate": 4.445783132530121e-06,
      "loss": 0.5928,
      "step": 736
    },
    {
      "epoch": 0.4439759036144578,
      "grad_norm": 0.9354470372200012,
      "learning_rate": 4.445030120481928e-06,
      "loss": 0.6598,
      "step": 737
    },
    {
      "epoch": 0.44457831325301206,
      "grad_norm": 0.8613961338996887,
      "learning_rate": 4.4442771084337354e-06,
      "loss": 0.6041,
      "step": 738
    },
    {
      "epoch": 0.44518072289156624,
      "grad_norm": 0.9568660855293274,
      "learning_rate": 4.443524096385542e-06,
      "loss": 0.6016,
      "step": 739
    },
    {
      "epoch": 0.4457831325301205,
      "grad_norm": 0.94954913854599,
      "learning_rate": 4.442771084337349e-06,
      "loss": 0.5819,
      "step": 740
    },
    {
      "epoch": 0.4463855421686747,
      "grad_norm": 0.9143937230110168,
      "learning_rate": 4.442018072289157e-06,
      "loss": 0.5314,
      "step": 741
    },
    {
      "epoch": 0.4469879518072289,
      "grad_norm": 0.8926975131034851,
      "learning_rate": 4.441265060240964e-06,
      "loss": 0.5564,
      "step": 742
    },
    {
      "epoch": 0.4475903614457831,
      "grad_norm": 0.9002459645271301,
      "learning_rate": 4.440512048192772e-06,
      "loss": 0.5585,
      "step": 743
    },
    {
      "epoch": 0.44819277108433736,
      "grad_norm": 0.9211053848266602,
      "learning_rate": 4.439759036144579e-06,
      "loss": 0.5697,
      "step": 744
    },
    {
      "epoch": 0.44879518072289154,
      "grad_norm": 0.862062394618988,
      "learning_rate": 4.4390060240963864e-06,
      "loss": 0.5598,
      "step": 745
    },
    {
      "epoch": 0.4493975903614458,
      "grad_norm": 0.9581020474433899,
      "learning_rate": 4.438253012048193e-06,
      "loss": 0.571,
      "step": 746
    },
    {
      "epoch": 0.45,
      "grad_norm": 0.9433762431144714,
      "learning_rate": 4.4375e-06,
      "loss": 0.5991,
      "step": 747
    },
    {
      "epoch": 0.4506024096385542,
      "grad_norm": 0.8838898539543152,
      "learning_rate": 4.436746987951808e-06,
      "loss": 0.5814,
      "step": 748
    },
    {
      "epoch": 0.4512048192771084,
      "grad_norm": 0.8996318578720093,
      "learning_rate": 4.435993975903615e-06,
      "loss": 0.5696,
      "step": 749
    },
    {
      "epoch": 0.45180722891566266,
      "grad_norm": 0.931672215461731,
      "learning_rate": 4.435240963855422e-06,
      "loss": 0.5305,
      "step": 750
    },
    {
      "epoch": 0.45240963855421684,
      "grad_norm": 0.936844527721405,
      "learning_rate": 4.434487951807229e-06,
      "loss": 0.5667,
      "step": 751
    },
    {
      "epoch": 0.4530120481927711,
      "grad_norm": 1.020194411277771,
      "learning_rate": 4.433734939759037e-06,
      "loss": 0.5895,
      "step": 752
    },
    {
      "epoch": 0.4536144578313253,
      "grad_norm": 0.9936975836753845,
      "learning_rate": 4.4329819277108435e-06,
      "loss": 0.5716,
      "step": 753
    },
    {
      "epoch": 0.4542168674698795,
      "grad_norm": 0.9872843623161316,
      "learning_rate": 4.4322289156626505e-06,
      "loss": 0.53,
      "step": 754
    },
    {
      "epoch": 0.45481927710843373,
      "grad_norm": 0.9138345718383789,
      "learning_rate": 4.431475903614458e-06,
      "loss": 0.6431,
      "step": 755
    },
    {
      "epoch": 0.45542168674698796,
      "grad_norm": 1.04710853099823,
      "learning_rate": 4.430722891566265e-06,
      "loss": 0.5417,
      "step": 756
    },
    {
      "epoch": 0.45602409638554214,
      "grad_norm": 0.8972265124320984,
      "learning_rate": 4.429969879518073e-06,
      "loss": 0.5924,
      "step": 757
    },
    {
      "epoch": 0.4566265060240964,
      "grad_norm": 0.9210885167121887,
      "learning_rate": 4.42921686746988e-06,
      "loss": 0.5361,
      "step": 758
    },
    {
      "epoch": 0.4572289156626506,
      "grad_norm": 0.9498475790023804,
      "learning_rate": 4.428463855421687e-06,
      "loss": 0.5412,
      "step": 759
    },
    {
      "epoch": 0.4578313253012048,
      "grad_norm": 0.8670477271080017,
      "learning_rate": 4.4277108433734945e-06,
      "loss": 0.5808,
      "step": 760
    },
    {
      "epoch": 0.45843373493975903,
      "grad_norm": 0.8222115635871887,
      "learning_rate": 4.4269578313253015e-06,
      "loss": 0.5537,
      "step": 761
    },
    {
      "epoch": 0.45903614457831327,
      "grad_norm": 0.8547554016113281,
      "learning_rate": 4.426204819277109e-06,
      "loss": 0.5573,
      "step": 762
    },
    {
      "epoch": 0.45963855421686745,
      "grad_norm": 0.9777780771255493,
      "learning_rate": 4.425451807228916e-06,
      "loss": 0.5392,
      "step": 763
    },
    {
      "epoch": 0.4602409638554217,
      "grad_norm": 0.971968412399292,
      "learning_rate": 4.424698795180723e-06,
      "loss": 0.584,
      "step": 764
    },
    {
      "epoch": 0.4608433734939759,
      "grad_norm": 0.8879720568656921,
      "learning_rate": 4.423945783132531e-06,
      "loss": 0.5118,
      "step": 765
    },
    {
      "epoch": 0.4614457831325301,
      "grad_norm": 0.905521810054779,
      "learning_rate": 4.423192771084338e-06,
      "loss": 0.5674,
      "step": 766
    },
    {
      "epoch": 0.46204819277108433,
      "grad_norm": 0.8956527709960938,
      "learning_rate": 4.422439759036145e-06,
      "loss": 0.5312,
      "step": 767
    },
    {
      "epoch": 0.46265060240963857,
      "grad_norm": 0.9621406197547913,
      "learning_rate": 4.4216867469879525e-06,
      "loss": 0.5749,
      "step": 768
    },
    {
      "epoch": 0.46325301204819275,
      "grad_norm": 0.9208889007568359,
      "learning_rate": 4.420933734939759e-06,
      "loss": 0.5331,
      "step": 769
    },
    {
      "epoch": 0.463855421686747,
      "grad_norm": 0.8904247283935547,
      "learning_rate": 4.420180722891566e-06,
      "loss": 0.5575,
      "step": 770
    },
    {
      "epoch": 0.4644578313253012,
      "grad_norm": 1.0006369352340698,
      "learning_rate": 4.419427710843373e-06,
      "loss": 0.551,
      "step": 771
    },
    {
      "epoch": 0.4650602409638554,
      "grad_norm": 1.020616888999939,
      "learning_rate": 4.418674698795181e-06,
      "loss": 0.5519,
      "step": 772
    },
    {
      "epoch": 0.46566265060240963,
      "grad_norm": 0.859223484992981,
      "learning_rate": 4.417921686746988e-06,
      "loss": 0.5139,
      "step": 773
    },
    {
      "epoch": 0.46626506024096387,
      "grad_norm": 0.8742741346359253,
      "learning_rate": 4.417168674698796e-06,
      "loss": 0.4962,
      "step": 774
    },
    {
      "epoch": 0.46686746987951805,
      "grad_norm": 0.9250572919845581,
      "learning_rate": 4.416415662650603e-06,
      "loss": 0.4829,
      "step": 775
    },
    {
      "epoch": 0.4674698795180723,
      "grad_norm": 0.826255202293396,
      "learning_rate": 4.41566265060241e-06,
      "loss": 0.5095,
      "step": 776
    },
    {
      "epoch": 0.4680722891566265,
      "grad_norm": 0.8889195919036865,
      "learning_rate": 4.414909638554217e-06,
      "loss": 0.5342,
      "step": 777
    },
    {
      "epoch": 0.4686746987951807,
      "grad_norm": 0.8370757699012756,
      "learning_rate": 4.414156626506024e-06,
      "loss": 0.5147,
      "step": 778
    },
    {
      "epoch": 0.46927710843373494,
      "grad_norm": 0.8637650609016418,
      "learning_rate": 4.413403614457832e-06,
      "loss": 0.4943,
      "step": 779
    },
    {
      "epoch": 0.46987951807228917,
      "grad_norm": 0.981637179851532,
      "learning_rate": 4.412650602409639e-06,
      "loss": 0.5673,
      "step": 780
    },
    {
      "epoch": 0.47048192771084335,
      "grad_norm": 1.0625932216644287,
      "learning_rate": 4.411897590361447e-06,
      "loss": 0.5243,
      "step": 781
    },
    {
      "epoch": 0.4710843373493976,
      "grad_norm": 0.8619560599327087,
      "learning_rate": 4.411144578313254e-06,
      "loss": 0.5054,
      "step": 782
    },
    {
      "epoch": 0.4716867469879518,
      "grad_norm": 0.9234750270843506,
      "learning_rate": 4.410391566265061e-06,
      "loss": 0.5116,
      "step": 783
    },
    {
      "epoch": 0.472289156626506,
      "grad_norm": 0.8960304260253906,
      "learning_rate": 4.4096385542168675e-06,
      "loss": 0.515,
      "step": 784
    },
    {
      "epoch": 0.47289156626506024,
      "grad_norm": 0.9217971563339233,
      "learning_rate": 4.408885542168675e-06,
      "loss": 0.5015,
      "step": 785
    },
    {
      "epoch": 0.4734939759036145,
      "grad_norm": 0.8694425225257874,
      "learning_rate": 4.408132530120482e-06,
      "loss": 0.5079,
      "step": 786
    },
    {
      "epoch": 0.47409638554216865,
      "grad_norm": 0.8410780429840088,
      "learning_rate": 4.407379518072289e-06,
      "loss": 0.4958,
      "step": 787
    },
    {
      "epoch": 0.4746987951807229,
      "grad_norm": 0.9259112477302551,
      "learning_rate": 4.406626506024096e-06,
      "loss": 0.5332,
      "step": 788
    },
    {
      "epoch": 0.4753012048192771,
      "grad_norm": 0.8892222046852112,
      "learning_rate": 4.405873493975904e-06,
      "loss": 0.5011,
      "step": 789
    },
    {
      "epoch": 0.4759036144578313,
      "grad_norm": 0.9058607220649719,
      "learning_rate": 4.405120481927711e-06,
      "loss": 0.4766,
      "step": 790
    },
    {
      "epoch": 0.47650602409638554,
      "grad_norm": 0.8970216512680054,
      "learning_rate": 4.4043674698795185e-06,
      "loss": 0.5247,
      "step": 791
    },
    {
      "epoch": 0.4771084337349398,
      "grad_norm": 0.9919549226760864,
      "learning_rate": 4.4036144578313255e-06,
      "loss": 0.5378,
      "step": 792
    },
    {
      "epoch": 0.47771084337349395,
      "grad_norm": 0.8798623085021973,
      "learning_rate": 4.402861445783133e-06,
      "loss": 0.4803,
      "step": 793
    },
    {
      "epoch": 0.4783132530120482,
      "grad_norm": 0.9225683808326721,
      "learning_rate": 4.40210843373494e-06,
      "loss": 0.5229,
      "step": 794
    },
    {
      "epoch": 0.4789156626506024,
      "grad_norm": 0.9390084743499756,
      "learning_rate": 4.401355421686747e-06,
      "loss": 0.4413,
      "step": 795
    },
    {
      "epoch": 0.4795180722891566,
      "grad_norm": 0.8461403846740723,
      "learning_rate": 4.400602409638555e-06,
      "loss": 0.5403,
      "step": 796
    },
    {
      "epoch": 0.48012048192771084,
      "grad_norm": 1.0186222791671753,
      "learning_rate": 4.399849397590362e-06,
      "loss": 0.473,
      "step": 797
    },
    {
      "epoch": 0.4807228915662651,
      "grad_norm": 1.6233899593353271,
      "learning_rate": 4.3990963855421696e-06,
      "loss": 0.5583,
      "step": 798
    },
    {
      "epoch": 0.48132530120481926,
      "grad_norm": 1.0425585508346558,
      "learning_rate": 4.3983433734939765e-06,
      "loss": 0.5211,
      "step": 799
    },
    {
      "epoch": 0.4819277108433735,
      "grad_norm": 0.8595830202102661,
      "learning_rate": 4.397590361445783e-06,
      "loss": 0.4674,
      "step": 800
    },
    {
      "epoch": 0.4825301204819277,
      "grad_norm": 0.8353645205497742,
      "learning_rate": 4.396837349397591e-06,
      "loss": 0.534,
      "step": 801
    },
    {
      "epoch": 0.4831325301204819,
      "grad_norm": 0.8940737247467041,
      "learning_rate": 4.396084337349398e-06,
      "loss": 0.4624,
      "step": 802
    },
    {
      "epoch": 0.48373493975903614,
      "grad_norm": 0.8384044170379639,
      "learning_rate": 4.395331325301205e-06,
      "loss": 0.4594,
      "step": 803
    },
    {
      "epoch": 0.4843373493975904,
      "grad_norm": 0.9220396876335144,
      "learning_rate": 4.394578313253012e-06,
      "loss": 0.492,
      "step": 804
    },
    {
      "epoch": 0.48493975903614456,
      "grad_norm": 0.877571165561676,
      "learning_rate": 4.39382530120482e-06,
      "loss": 0.468,
      "step": 805
    },
    {
      "epoch": 0.4855421686746988,
      "grad_norm": 0.8074085116386414,
      "learning_rate": 4.393072289156627e-06,
      "loss": 0.5347,
      "step": 806
    },
    {
      "epoch": 0.48614457831325303,
      "grad_norm": 0.9848712086677551,
      "learning_rate": 4.3923192771084336e-06,
      "loss": 0.5242,
      "step": 807
    },
    {
      "epoch": 0.4867469879518072,
      "grad_norm": 0.8245373964309692,
      "learning_rate": 4.391566265060241e-06,
      "loss": 0.4322,
      "step": 808
    },
    {
      "epoch": 0.48734939759036144,
      "grad_norm": 0.8395320773124695,
      "learning_rate": 4.390813253012048e-06,
      "loss": 0.5317,
      "step": 809
    },
    {
      "epoch": 0.4879518072289157,
      "grad_norm": 0.9135757684707642,
      "learning_rate": 4.390060240963856e-06,
      "loss": 0.4538,
      "step": 810
    },
    {
      "epoch": 0.48855421686746986,
      "grad_norm": 0.9059491753578186,
      "learning_rate": 4.389307228915663e-06,
      "loss": 0.4714,
      "step": 811
    },
    {
      "epoch": 0.4891566265060241,
      "grad_norm": 0.8512129187583923,
      "learning_rate": 4.38855421686747e-06,
      "loss": 0.4708,
      "step": 812
    },
    {
      "epoch": 0.48975903614457833,
      "grad_norm": 1.007010817527771,
      "learning_rate": 4.387801204819278e-06,
      "loss": 0.502,
      "step": 813
    },
    {
      "epoch": 0.4903614457831325,
      "grad_norm": 0.8526752591133118,
      "learning_rate": 4.387048192771085e-06,
      "loss": 0.4346,
      "step": 814
    },
    {
      "epoch": 0.49096385542168675,
      "grad_norm": 0.8140800595283508,
      "learning_rate": 4.386295180722892e-06,
      "loss": 0.464,
      "step": 815
    },
    {
      "epoch": 0.491566265060241,
      "grad_norm": 1.0066548585891724,
      "learning_rate": 4.385542168674699e-06,
      "loss": 0.5057,
      "step": 816
    },
    {
      "epoch": 0.49216867469879516,
      "grad_norm": 0.9289240837097168,
      "learning_rate": 4.384789156626506e-06,
      "loss": 0.4885,
      "step": 817
    },
    {
      "epoch": 0.4927710843373494,
      "grad_norm": 0.8303787112236023,
      "learning_rate": 4.384036144578314e-06,
      "loss": 0.5219,
      "step": 818
    },
    {
      "epoch": 0.49337349397590363,
      "grad_norm": 0.9355288147926331,
      "learning_rate": 4.383283132530121e-06,
      "loss": 0.4875,
      "step": 819
    },
    {
      "epoch": 0.4939759036144578,
      "grad_norm": 0.8053423166275024,
      "learning_rate": 4.382530120481928e-06,
      "loss": 0.4594,
      "step": 820
    },
    {
      "epoch": 0.49457831325301205,
      "grad_norm": 0.8500730395317078,
      "learning_rate": 4.381777108433735e-06,
      "loss": 0.489,
      "step": 821
    },
    {
      "epoch": 0.4951807228915663,
      "grad_norm": 0.8741005063056946,
      "learning_rate": 4.3810240963855425e-06,
      "loss": 0.5445,
      "step": 822
    },
    {
      "epoch": 0.49578313253012046,
      "grad_norm": 0.8961488604545593,
      "learning_rate": 4.3802710843373494e-06,
      "loss": 0.4539,
      "step": 823
    },
    {
      "epoch": 0.4963855421686747,
      "grad_norm": 0.8381823897361755,
      "learning_rate": 4.379518072289156e-06,
      "loss": 0.4419,
      "step": 824
    },
    {
      "epoch": 0.49698795180722893,
      "grad_norm": 0.8166192173957825,
      "learning_rate": 4.378765060240964e-06,
      "loss": 0.4892,
      "step": 825
    },
    {
      "epoch": 0.4975903614457831,
      "grad_norm": 0.8568537831306458,
      "learning_rate": 4.378012048192771e-06,
      "loss": 0.5137,
      "step": 826
    },
    {
      "epoch": 0.49819277108433735,
      "grad_norm": 0.8609552979469299,
      "learning_rate": 4.377259036144579e-06,
      "loss": 0.4581,
      "step": 827
    },
    {
      "epoch": 0.4987951807228916,
      "grad_norm": 0.8258835077285767,
      "learning_rate": 4.376506024096386e-06,
      "loss": 0.4359,
      "step": 828
    },
    {
      "epoch": 0.49939759036144576,
      "grad_norm": 0.8820326328277588,
      "learning_rate": 4.3757530120481935e-06,
      "loss": 0.4537,
      "step": 829
    },
    {
      "epoch": 0.5,
      "grad_norm": 0.9478237628936768,
      "learning_rate": 4.3750000000000005e-06,
      "loss": 0.4491,
      "step": 830
    },
    {
      "epoch": 0.5006024096385542,
      "grad_norm": 0.8308257460594177,
      "learning_rate": 4.374246987951807e-06,
      "loss": 0.4293,
      "step": 831
    },
    {
      "epoch": 0.5012048192771085,
      "grad_norm": 0.8911095261573792,
      "learning_rate": 4.373493975903615e-06,
      "loss": 0.439,
      "step": 832
    },
    {
      "epoch": 0.5018072289156627,
      "grad_norm": 0.7860403656959534,
      "learning_rate": 4.372740963855422e-06,
      "loss": 0.4266,
      "step": 833
    },
    {
      "epoch": 0.5024096385542168,
      "grad_norm": 0.9084836840629578,
      "learning_rate": 4.37198795180723e-06,
      "loss": 0.4599,
      "step": 834
    },
    {
      "epoch": 0.5030120481927711,
      "grad_norm": 0.9454955458641052,
      "learning_rate": 4.371234939759037e-06,
      "loss": 0.458,
      "step": 835
    },
    {
      "epoch": 0.5036144578313253,
      "grad_norm": 0.8724521994590759,
      "learning_rate": 4.370481927710844e-06,
      "loss": 0.451,
      "step": 836
    },
    {
      "epoch": 0.5042168674698795,
      "grad_norm": 0.7946798205375671,
      "learning_rate": 4.369728915662651e-06,
      "loss": 0.4188,
      "step": 837
    },
    {
      "epoch": 0.5048192771084338,
      "grad_norm": 0.8337303996086121,
      "learning_rate": 4.368975903614458e-06,
      "loss": 0.4835,
      "step": 838
    },
    {
      "epoch": 0.505421686746988,
      "grad_norm": 0.7714263796806335,
      "learning_rate": 4.368222891566265e-06,
      "loss": 0.4424,
      "step": 839
    },
    {
      "epoch": 0.5060240963855421,
      "grad_norm": 0.7719920873641968,
      "learning_rate": 4.367469879518072e-06,
      "loss": 0.4212,
      "step": 840
    },
    {
      "epoch": 0.5066265060240964,
      "grad_norm": 0.8134554028511047,
      "learning_rate": 4.36671686746988e-06,
      "loss": 0.436,
      "step": 841
    },
    {
      "epoch": 0.5072289156626506,
      "grad_norm": 0.8611939549446106,
      "learning_rate": 4.365963855421687e-06,
      "loss": 0.4246,
      "step": 842
    },
    {
      "epoch": 0.5078313253012048,
      "grad_norm": 0.8500586748123169,
      "learning_rate": 4.365210843373494e-06,
      "loss": 0.4098,
      "step": 843
    },
    {
      "epoch": 0.5084337349397591,
      "grad_norm": 0.9387107491493225,
      "learning_rate": 4.364457831325302e-06,
      "loss": 0.4306,
      "step": 844
    },
    {
      "epoch": 0.5090361445783133,
      "grad_norm": 0.8165612816810608,
      "learning_rate": 4.3637048192771086e-06,
      "loss": 0.4512,
      "step": 845
    },
    {
      "epoch": 0.5096385542168674,
      "grad_norm": 0.8268747925758362,
      "learning_rate": 4.362951807228916e-06,
      "loss": 0.4428,
      "step": 846
    },
    {
      "epoch": 0.5102409638554217,
      "grad_norm": 0.8284243941307068,
      "learning_rate": 4.362198795180723e-06,
      "loss": 0.4489,
      "step": 847
    },
    {
      "epoch": 0.5108433734939759,
      "grad_norm": 0.819239616394043,
      "learning_rate": 4.361445783132531e-06,
      "loss": 0.4763,
      "step": 848
    },
    {
      "epoch": 0.5114457831325301,
      "grad_norm": 0.7279148697853088,
      "learning_rate": 4.360692771084338e-06,
      "loss": 0.4479,
      "step": 849
    },
    {
      "epoch": 0.5120481927710844,
      "grad_norm": 0.7785976529121399,
      "learning_rate": 4.359939759036145e-06,
      "loss": 0.432,
      "step": 850
    },
    {
      "epoch": 0.5126506024096386,
      "grad_norm": 0.8366201519966125,
      "learning_rate": 4.359186746987953e-06,
      "loss": 0.4526,
      "step": 851
    },
    {
      "epoch": 0.5132530120481927,
      "grad_norm": 0.8758049607276917,
      "learning_rate": 4.35843373493976e-06,
      "loss": 0.4321,
      "step": 852
    },
    {
      "epoch": 0.513855421686747,
      "grad_norm": 0.7876024842262268,
      "learning_rate": 4.3576807228915665e-06,
      "loss": 0.4226,
      "step": 853
    },
    {
      "epoch": 0.5144578313253012,
      "grad_norm": 0.8127527236938477,
      "learning_rate": 4.3569277108433734e-06,
      "loss": 0.4649,
      "step": 854
    },
    {
      "epoch": 0.5150602409638554,
      "grad_norm": 0.8468538522720337,
      "learning_rate": 4.356174698795181e-06,
      "loss": 0.4254,
      "step": 855
    },
    {
      "epoch": 0.5156626506024097,
      "grad_norm": 0.7570654153823853,
      "learning_rate": 4.355421686746988e-06,
      "loss": 0.4349,
      "step": 856
    },
    {
      "epoch": 0.5162650602409639,
      "grad_norm": 0.7648956775665283,
      "learning_rate": 4.354668674698795e-06,
      "loss": 0.3949,
      "step": 857
    },
    {
      "epoch": 0.516867469879518,
      "grad_norm": 0.8621246218681335,
      "learning_rate": 4.353915662650603e-06,
      "loss": 0.4488,
      "step": 858
    },
    {
      "epoch": 0.5174698795180723,
      "grad_norm": 0.9242040514945984,
      "learning_rate": 4.35316265060241e-06,
      "loss": 0.4539,
      "step": 859
    },
    {
      "epoch": 0.5180722891566265,
      "grad_norm": 0.8289987444877625,
      "learning_rate": 4.3524096385542175e-06,
      "loss": 0.4111,
      "step": 860
    },
    {
      "epoch": 0.5186746987951807,
      "grad_norm": 0.8043241500854492,
      "learning_rate": 4.3516566265060245e-06,
      "loss": 0.402,
      "step": 861
    },
    {
      "epoch": 0.519277108433735,
      "grad_norm": 0.8070041537284851,
      "learning_rate": 4.350903614457831e-06,
      "loss": 0.4106,
      "step": 862
    },
    {
      "epoch": 0.5198795180722892,
      "grad_norm": 0.8589888215065002,
      "learning_rate": 4.350150602409639e-06,
      "loss": 0.4195,
      "step": 863
    },
    {
      "epoch": 0.5204819277108433,
      "grad_norm": 0.8025203347206116,
      "learning_rate": 4.349397590361446e-06,
      "loss": 0.4575,
      "step": 864
    },
    {
      "epoch": 0.5210843373493976,
      "grad_norm": 0.8255767226219177,
      "learning_rate": 4.348644578313254e-06,
      "loss": 0.4026,
      "step": 865
    },
    {
      "epoch": 0.5216867469879518,
      "grad_norm": 0.7913536429405212,
      "learning_rate": 4.347891566265061e-06,
      "loss": 0.423,
      "step": 866
    },
    {
      "epoch": 0.522289156626506,
      "grad_norm": 0.8950340747833252,
      "learning_rate": 4.347138554216868e-06,
      "loss": 0.4959,
      "step": 867
    },
    {
      "epoch": 0.5228915662650603,
      "grad_norm": 0.7893226742744446,
      "learning_rate": 4.3463855421686755e-06,
      "loss": 0.4419,
      "step": 868
    },
    {
      "epoch": 0.5234939759036145,
      "grad_norm": 0.7645740509033203,
      "learning_rate": 4.345632530120482e-06,
      "loss": 0.4853,
      "step": 869
    },
    {
      "epoch": 0.5240963855421686,
      "grad_norm": 0.8077744841575623,
      "learning_rate": 4.344879518072289e-06,
      "loss": 0.3858,
      "step": 870
    },
    {
      "epoch": 0.5246987951807229,
      "grad_norm": 0.889937698841095,
      "learning_rate": 4.344126506024097e-06,
      "loss": 0.4389,
      "step": 871
    },
    {
      "epoch": 0.5253012048192771,
      "grad_norm": 0.854813277721405,
      "learning_rate": 4.343373493975904e-06,
      "loss": 0.4476,
      "step": 872
    },
    {
      "epoch": 0.5259036144578313,
      "grad_norm": 0.8685604333877563,
      "learning_rate": 4.342620481927711e-06,
      "loss": 0.4235,
      "step": 873
    },
    {
      "epoch": 0.5265060240963856,
      "grad_norm": 0.8481271862983704,
      "learning_rate": 4.341867469879518e-06,
      "loss": 0.4086,
      "step": 874
    },
    {
      "epoch": 0.5271084337349398,
      "grad_norm": 0.7809633016586304,
      "learning_rate": 4.341114457831326e-06,
      "loss": 0.4718,
      "step": 875
    },
    {
      "epoch": 0.5277108433734939,
      "grad_norm": 0.7809087634086609,
      "learning_rate": 4.3403614457831326e-06,
      "loss": 0.4478,
      "step": 876
    },
    {
      "epoch": 0.5283132530120482,
      "grad_norm": 0.7725089192390442,
      "learning_rate": 4.33960843373494e-06,
      "loss": 0.3602,
      "step": 877
    },
    {
      "epoch": 0.5289156626506024,
      "grad_norm": 0.7976964116096497,
      "learning_rate": 4.338855421686747e-06,
      "loss": 0.4,
      "step": 878
    },
    {
      "epoch": 0.5295180722891566,
      "grad_norm": 0.7837836742401123,
      "learning_rate": 4.338102409638554e-06,
      "loss": 0.4511,
      "step": 879
    },
    {
      "epoch": 0.5301204819277109,
      "grad_norm": 0.8589077591896057,
      "learning_rate": 4.337349397590362e-06,
      "loss": 0.4395,
      "step": 880
    },
    {
      "epoch": 0.5307228915662651,
      "grad_norm": 0.7532952427864075,
      "learning_rate": 4.336596385542169e-06,
      "loss": 0.4354,
      "step": 881
    },
    {
      "epoch": 0.5313253012048192,
      "grad_norm": 0.7978301048278809,
      "learning_rate": 4.335843373493977e-06,
      "loss": 0.4127,
      "step": 882
    },
    {
      "epoch": 0.5319277108433735,
      "grad_norm": 0.791192889213562,
      "learning_rate": 4.3350903614457836e-06,
      "loss": 0.4687,
      "step": 883
    },
    {
      "epoch": 0.5325301204819277,
      "grad_norm": 0.7697460055351257,
      "learning_rate": 4.334337349397591e-06,
      "loss": 0.4466,
      "step": 884
    },
    {
      "epoch": 0.5331325301204819,
      "grad_norm": 0.747159481048584,
      "learning_rate": 4.333584337349398e-06,
      "loss": 0.3768,
      "step": 885
    },
    {
      "epoch": 0.5337349397590362,
      "grad_norm": 0.8109819293022156,
      "learning_rate": 4.332831325301205e-06,
      "loss": 0.4189,
      "step": 886
    },
    {
      "epoch": 0.5343373493975904,
      "grad_norm": 0.801983654499054,
      "learning_rate": 4.332078313253012e-06,
      "loss": 0.3661,
      "step": 887
    },
    {
      "epoch": 0.5349397590361445,
      "grad_norm": 0.7872856259346008,
      "learning_rate": 4.33132530120482e-06,
      "loss": 0.4264,
      "step": 888
    },
    {
      "epoch": 0.5355421686746988,
      "grad_norm": 0.7103592157363892,
      "learning_rate": 4.330572289156627e-06,
      "loss": 0.4024,
      "step": 889
    },
    {
      "epoch": 0.536144578313253,
      "grad_norm": 0.9163087606430054,
      "learning_rate": 4.329819277108434e-06,
      "loss": 0.4329,
      "step": 890
    },
    {
      "epoch": 0.5367469879518072,
      "grad_norm": 0.8233628273010254,
      "learning_rate": 4.329066265060241e-06,
      "loss": 0.4438,
      "step": 891
    },
    {
      "epoch": 0.5373493975903615,
      "grad_norm": 0.8702658414840698,
      "learning_rate": 4.3283132530120484e-06,
      "loss": 0.3972,
      "step": 892
    },
    {
      "epoch": 0.5379518072289157,
      "grad_norm": 0.7793692350387573,
      "learning_rate": 4.327560240963855e-06,
      "loss": 0.4229,
      "step": 893
    },
    {
      "epoch": 0.5385542168674698,
      "grad_norm": 0.898735761642456,
      "learning_rate": 4.326807228915663e-06,
      "loss": 0.4242,
      "step": 894
    },
    {
      "epoch": 0.5391566265060241,
      "grad_norm": 0.7567571997642517,
      "learning_rate": 4.32605421686747e-06,
      "loss": 0.4399,
      "step": 895
    },
    {
      "epoch": 0.5397590361445783,
      "grad_norm": 0.728022575378418,
      "learning_rate": 4.325301204819278e-06,
      "loss": 0.4058,
      "step": 896
    },
    {
      "epoch": 0.5403614457831325,
      "grad_norm": 0.7490084171295166,
      "learning_rate": 4.324548192771085e-06,
      "loss": 0.3913,
      "step": 897
    },
    {
      "epoch": 0.5409638554216868,
      "grad_norm": 0.756706714630127,
      "learning_rate": 4.323795180722892e-06,
      "loss": 0.4104,
      "step": 898
    },
    {
      "epoch": 0.541566265060241,
      "grad_norm": 0.7040330767631531,
      "learning_rate": 4.3230421686746995e-06,
      "loss": 0.427,
      "step": 899
    },
    {
      "epoch": 0.5421686746987951,
      "grad_norm": 0.7740331888198853,
      "learning_rate": 4.322289156626506e-06,
      "loss": 0.4522,
      "step": 900
    },
    {
      "epoch": 0.5427710843373494,
      "grad_norm": 0.77347731590271,
      "learning_rate": 4.321536144578314e-06,
      "loss": 0.4177,
      "step": 901
    },
    {
      "epoch": 0.5433734939759036,
      "grad_norm": 0.7620518803596497,
      "learning_rate": 4.320783132530121e-06,
      "loss": 0.3814,
      "step": 902
    },
    {
      "epoch": 0.5439759036144578,
      "grad_norm": 0.8443256616592407,
      "learning_rate": 4.320030120481928e-06,
      "loss": 0.4178,
      "step": 903
    },
    {
      "epoch": 0.5445783132530121,
      "grad_norm": 0.7521129250526428,
      "learning_rate": 4.319277108433736e-06,
      "loss": 0.4463,
      "step": 904
    },
    {
      "epoch": 0.5451807228915663,
      "grad_norm": 0.7458223700523376,
      "learning_rate": 4.318524096385543e-06,
      "loss": 0.4256,
      "step": 905
    },
    {
      "epoch": 0.5457831325301205,
      "grad_norm": 0.7762418985366821,
      "learning_rate": 4.31777108433735e-06,
      "loss": 0.4391,
      "step": 906
    },
    {
      "epoch": 0.5463855421686747,
      "grad_norm": 0.7956472039222717,
      "learning_rate": 4.3170180722891565e-06,
      "loss": 0.4249,
      "step": 907
    },
    {
      "epoch": 0.5469879518072289,
      "grad_norm": 0.7703011631965637,
      "learning_rate": 4.316265060240964e-06,
      "loss": 0.366,
      "step": 908
    },
    {
      "epoch": 0.5475903614457831,
      "grad_norm": 2.76875901222229,
      "learning_rate": 4.315512048192771e-06,
      "loss": 0.5203,
      "step": 909
    },
    {
      "epoch": 0.5481927710843374,
      "grad_norm": 0.7585433721542358,
      "learning_rate": 4.314759036144578e-06,
      "loss": 0.3967,
      "step": 910
    },
    {
      "epoch": 0.5487951807228916,
      "grad_norm": 0.7242310047149658,
      "learning_rate": 4.314006024096386e-06,
      "loss": 0.3916,
      "step": 911
    },
    {
      "epoch": 0.5493975903614458,
      "grad_norm": 0.6951138377189636,
      "learning_rate": 4.313253012048193e-06,
      "loss": 0.405,
      "step": 912
    },
    {
      "epoch": 0.55,
      "grad_norm": 0.7247406244277954,
      "learning_rate": 4.312500000000001e-06,
      "loss": 0.4109,
      "step": 913
    },
    {
      "epoch": 0.5506024096385542,
      "grad_norm": 1.5602473020553589,
      "learning_rate": 4.3117469879518076e-06,
      "loss": 0.4983,
      "step": 914
    },
    {
      "epoch": 0.5512048192771084,
      "grad_norm": 0.7763420343399048,
      "learning_rate": 4.3109939759036145e-06,
      "loss": 0.4389,
      "step": 915
    },
    {
      "epoch": 0.5518072289156627,
      "grad_norm": 0.8975186347961426,
      "learning_rate": 4.310240963855422e-06,
      "loss": 0.3928,
      "step": 916
    },
    {
      "epoch": 0.5524096385542169,
      "grad_norm": 0.7616184949874878,
      "learning_rate": 4.309487951807229e-06,
      "loss": 0.4923,
      "step": 917
    },
    {
      "epoch": 0.553012048192771,
      "grad_norm": 0.7527912259101868,
      "learning_rate": 4.308734939759037e-06,
      "loss": 0.386,
      "step": 918
    },
    {
      "epoch": 0.5536144578313253,
      "grad_norm": 0.7431317567825317,
      "learning_rate": 4.307981927710844e-06,
      "loss": 0.3909,
      "step": 919
    },
    {
      "epoch": 0.5542168674698795,
      "grad_norm": 0.8612467646598816,
      "learning_rate": 4.307228915662651e-06,
      "loss": 0.4059,
      "step": 920
    },
    {
      "epoch": 0.5548192771084337,
      "grad_norm": 0.6779335737228394,
      "learning_rate": 4.306475903614459e-06,
      "loss": 0.3985,
      "step": 921
    },
    {
      "epoch": 0.555421686746988,
      "grad_norm": 0.7587804794311523,
      "learning_rate": 4.3057228915662655e-06,
      "loss": 0.4342,
      "step": 922
    },
    {
      "epoch": 0.5560240963855422,
      "grad_norm": 0.7712708115577698,
      "learning_rate": 4.3049698795180724e-06,
      "loss": 0.3735,
      "step": 923
    },
    {
      "epoch": 0.5566265060240964,
      "grad_norm": 0.7755638360977173,
      "learning_rate": 4.304216867469879e-06,
      "loss": 0.389,
      "step": 924
    },
    {
      "epoch": 0.5572289156626506,
      "grad_norm": 0.725884199142456,
      "learning_rate": 4.303463855421687e-06,
      "loss": 0.3927,
      "step": 925
    },
    {
      "epoch": 0.5578313253012048,
      "grad_norm": 0.7515182495117188,
      "learning_rate": 4.302710843373494e-06,
      "loss": 0.3719,
      "step": 926
    },
    {
      "epoch": 0.558433734939759,
      "grad_norm": 0.7528185248374939,
      "learning_rate": 4.301957831325301e-06,
      "loss": 0.3635,
      "step": 927
    },
    {
      "epoch": 0.5590361445783133,
      "grad_norm": 0.7803112864494324,
      "learning_rate": 4.301204819277109e-06,
      "loss": 0.3991,
      "step": 928
    },
    {
      "epoch": 0.5596385542168675,
      "grad_norm": 0.757688581943512,
      "learning_rate": 4.300451807228916e-06,
      "loss": 0.3801,
      "step": 929
    },
    {
      "epoch": 0.5602409638554217,
      "grad_norm": 0.7228885293006897,
      "learning_rate": 4.2996987951807234e-06,
      "loss": 0.3589,
      "step": 930
    },
    {
      "epoch": 0.560843373493976,
      "grad_norm": 0.7398354411125183,
      "learning_rate": 4.29894578313253e-06,
      "loss": 0.3457,
      "step": 931
    },
    {
      "epoch": 0.5614457831325301,
      "grad_norm": 0.7415940165519714,
      "learning_rate": 4.298192771084338e-06,
      "loss": 0.389,
      "step": 932
    },
    {
      "epoch": 0.5620481927710843,
      "grad_norm": 0.67811518907547,
      "learning_rate": 4.297439759036145e-06,
      "loss": 0.3889,
      "step": 933
    },
    {
      "epoch": 0.5626506024096386,
      "grad_norm": 0.7798686623573303,
      "learning_rate": 4.296686746987952e-06,
      "loss": 0.3597,
      "step": 934
    },
    {
      "epoch": 0.5632530120481928,
      "grad_norm": 0.7076371908187866,
      "learning_rate": 4.29593373493976e-06,
      "loss": 0.3569,
      "step": 935
    },
    {
      "epoch": 0.563855421686747,
      "grad_norm": 0.7034572958946228,
      "learning_rate": 4.295180722891567e-06,
      "loss": 0.3328,
      "step": 936
    },
    {
      "epoch": 0.5644578313253013,
      "grad_norm": 0.8550699353218079,
      "learning_rate": 4.2944277108433745e-06,
      "loss": 0.3542,
      "step": 937
    },
    {
      "epoch": 0.5650602409638554,
      "grad_norm": 0.7882698774337769,
      "learning_rate": 4.293674698795181e-06,
      "loss": 0.3566,
      "step": 938
    },
    {
      "epoch": 0.5656626506024096,
      "grad_norm": 0.763667643070221,
      "learning_rate": 4.292921686746988e-06,
      "loss": 0.3586,
      "step": 939
    },
    {
      "epoch": 0.5662650602409639,
      "grad_norm": 0.7616035342216492,
      "learning_rate": 4.292168674698795e-06,
      "loss": 0.4185,
      "step": 940
    },
    {
      "epoch": 0.5668674698795181,
      "grad_norm": 0.6692790985107422,
      "learning_rate": 4.291415662650603e-06,
      "loss": 0.3948,
      "step": 941
    },
    {
      "epoch": 0.5674698795180723,
      "grad_norm": 1.2474620342254639,
      "learning_rate": 4.29066265060241e-06,
      "loss": 0.381,
      "step": 942
    },
    {
      "epoch": 0.5680722891566266,
      "grad_norm": 0.7150376439094543,
      "learning_rate": 4.289909638554217e-06,
      "loss": 0.3878,
      "step": 943
    },
    {
      "epoch": 0.5686746987951807,
      "grad_norm": 0.7788494825363159,
      "learning_rate": 4.289156626506025e-06,
      "loss": 0.3953,
      "step": 944
    },
    {
      "epoch": 0.5692771084337349,
      "grad_norm": 0.7402669191360474,
      "learning_rate": 4.2884036144578316e-06,
      "loss": 0.3589,
      "step": 945
    },
    {
      "epoch": 0.5698795180722892,
      "grad_norm": 0.6882504224777222,
      "learning_rate": 4.2876506024096385e-06,
      "loss": 0.4167,
      "step": 946
    },
    {
      "epoch": 0.5704819277108434,
      "grad_norm": 0.743391215801239,
      "learning_rate": 4.286897590361446e-06,
      "loss": 0.4167,
      "step": 947
    },
    {
      "epoch": 0.5710843373493976,
      "grad_norm": 0.7819777131080627,
      "learning_rate": 4.286144578313253e-06,
      "loss": 0.3491,
      "step": 948
    },
    {
      "epoch": 0.5716867469879519,
      "grad_norm": 0.7761412262916565,
      "learning_rate": 4.285391566265061e-06,
      "loss": 0.4384,
      "step": 949
    },
    {
      "epoch": 0.572289156626506,
      "grad_norm": 0.713735818862915,
      "learning_rate": 4.284638554216868e-06,
      "loss": 0.3701,
      "step": 950
    },
    {
      "epoch": 0.5728915662650602,
      "grad_norm": 0.6958031058311462,
      "learning_rate": 4.283885542168675e-06,
      "loss": 0.3777,
      "step": 951
    },
    {
      "epoch": 0.5734939759036145,
      "grad_norm": 0.8020367622375488,
      "learning_rate": 4.2831325301204826e-06,
      "loss": 0.3512,
      "step": 952
    },
    {
      "epoch": 0.5740963855421687,
      "grad_norm": 0.7627357840538025,
      "learning_rate": 4.2823795180722895e-06,
      "loss": 0.3557,
      "step": 953
    },
    {
      "epoch": 0.5746987951807229,
      "grad_norm": 0.7070096135139465,
      "learning_rate": 4.281626506024097e-06,
      "loss": 0.3931,
      "step": 954
    },
    {
      "epoch": 0.5753012048192772,
      "grad_norm": 0.7142391204833984,
      "learning_rate": 4.280873493975904e-06,
      "loss": 0.3697,
      "step": 955
    },
    {
      "epoch": 0.5759036144578313,
      "grad_norm": 0.6912004947662354,
      "learning_rate": 4.280120481927711e-06,
      "loss": 0.3334,
      "step": 956
    },
    {
      "epoch": 0.5765060240963855,
      "grad_norm": 0.7116250991821289,
      "learning_rate": 4.279367469879518e-06,
      "loss": 0.3408,
      "step": 957
    },
    {
      "epoch": 0.5771084337349398,
      "grad_norm": 0.7619776725769043,
      "learning_rate": 4.278614457831326e-06,
      "loss": 0.3914,
      "step": 958
    },
    {
      "epoch": 0.577710843373494,
      "grad_norm": 0.6691693663597107,
      "learning_rate": 4.277861445783133e-06,
      "loss": 0.338,
      "step": 959
    },
    {
      "epoch": 0.5783132530120482,
      "grad_norm": 0.6661312580108643,
      "learning_rate": 4.27710843373494e-06,
      "loss": 0.3869,
      "step": 960
    },
    {
      "epoch": 0.5789156626506025,
      "grad_norm": 0.8463139533996582,
      "learning_rate": 4.2763554216867474e-06,
      "loss": 0.3804,
      "step": 961
    },
    {
      "epoch": 0.5795180722891566,
      "grad_norm": 0.723332405090332,
      "learning_rate": 4.275602409638554e-06,
      "loss": 0.3958,
      "step": 962
    },
    {
      "epoch": 0.5801204819277108,
      "grad_norm": 0.7827841639518738,
      "learning_rate": 4.274849397590361e-06,
      "loss": 0.3641,
      "step": 963
    },
    {
      "epoch": 0.5807228915662651,
      "grad_norm": 0.7277905941009521,
      "learning_rate": 4.274096385542169e-06,
      "loss": 0.379,
      "step": 964
    },
    {
      "epoch": 0.5813253012048193,
      "grad_norm": 0.6435388326644897,
      "learning_rate": 4.273343373493976e-06,
      "loss": 0.3635,
      "step": 965
    },
    {
      "epoch": 0.5819277108433735,
      "grad_norm": 0.7749106287956238,
      "learning_rate": 4.272590361445784e-06,
      "loss": 0.3712,
      "step": 966
    },
    {
      "epoch": 0.5825301204819278,
      "grad_norm": 0.6583210825920105,
      "learning_rate": 4.271837349397591e-06,
      "loss": 0.3929,
      "step": 967
    },
    {
      "epoch": 0.5831325301204819,
      "grad_norm": 0.7435518503189087,
      "learning_rate": 4.2710843373493984e-06,
      "loss": 0.348,
      "step": 968
    },
    {
      "epoch": 0.5837349397590361,
      "grad_norm": 0.7098272442817688,
      "learning_rate": 4.270331325301205e-06,
      "loss": 0.4122,
      "step": 969
    },
    {
      "epoch": 0.5843373493975904,
      "grad_norm": 0.6944602727890015,
      "learning_rate": 4.269578313253012e-06,
      "loss": 0.3763,
      "step": 970
    },
    {
      "epoch": 0.5849397590361446,
      "grad_norm": 0.6551894545555115,
      "learning_rate": 4.26882530120482e-06,
      "loss": 0.3786,
      "step": 971
    },
    {
      "epoch": 0.5855421686746988,
      "grad_norm": 0.7569825053215027,
      "learning_rate": 4.268072289156627e-06,
      "loss": 0.4192,
      "step": 972
    },
    {
      "epoch": 0.5861445783132531,
      "grad_norm": 0.6757923364639282,
      "learning_rate": 4.267319277108434e-06,
      "loss": 0.3641,
      "step": 973
    },
    {
      "epoch": 0.5867469879518072,
      "grad_norm": 1.0137137174606323,
      "learning_rate": 4.266566265060242e-06,
      "loss": 0.3892,
      "step": 974
    },
    {
      "epoch": 0.5873493975903614,
      "grad_norm": 0.7723792195320129,
      "learning_rate": 4.265813253012049e-06,
      "loss": 0.401,
      "step": 975
    },
    {
      "epoch": 0.5879518072289157,
      "grad_norm": 0.7240537405014038,
      "learning_rate": 4.2650602409638555e-06,
      "loss": 0.4193,
      "step": 976
    },
    {
      "epoch": 0.5885542168674699,
      "grad_norm": 0.7204244136810303,
      "learning_rate": 4.2643072289156625e-06,
      "loss": 0.3705,
      "step": 977
    },
    {
      "epoch": 0.5891566265060241,
      "grad_norm": 0.7468684911727905,
      "learning_rate": 4.26355421686747e-06,
      "loss": 0.3856,
      "step": 978
    },
    {
      "epoch": 0.5897590361445784,
      "grad_norm": 0.6780726909637451,
      "learning_rate": 4.262801204819277e-06,
      "loss": 0.3313,
      "step": 979
    },
    {
      "epoch": 0.5903614457831325,
      "grad_norm": 0.6781066656112671,
      "learning_rate": 4.262048192771085e-06,
      "loss": 0.3791,
      "step": 980
    },
    {
      "epoch": 0.5909638554216867,
      "grad_norm": 0.7417112588882446,
      "learning_rate": 4.261295180722892e-06,
      "loss": 0.3991,
      "step": 981
    },
    {
      "epoch": 0.591566265060241,
      "grad_norm": 0.7315050959587097,
      "learning_rate": 4.260542168674699e-06,
      "loss": 0.3673,
      "step": 982
    },
    {
      "epoch": 0.5921686746987952,
      "grad_norm": 0.7675021886825562,
      "learning_rate": 4.2597891566265066e-06,
      "loss": 0.3505,
      "step": 983
    },
    {
      "epoch": 0.5927710843373494,
      "grad_norm": 0.6921820044517517,
      "learning_rate": 4.2590361445783135e-06,
      "loss": 0.3889,
      "step": 984
    },
    {
      "epoch": 0.5933734939759037,
      "grad_norm": 0.6872013211250305,
      "learning_rate": 4.258283132530121e-06,
      "loss": 0.3612,
      "step": 985
    },
    {
      "epoch": 0.5939759036144578,
      "grad_norm": 0.7211378812789917,
      "learning_rate": 4.257530120481928e-06,
      "loss": 0.3799,
      "step": 986
    },
    {
      "epoch": 0.594578313253012,
      "grad_norm": 0.7020621299743652,
      "learning_rate": 4.256777108433735e-06,
      "loss": 0.3768,
      "step": 987
    },
    {
      "epoch": 0.5951807228915663,
      "grad_norm": 0.7114576101303101,
      "learning_rate": 4.256024096385543e-06,
      "loss": 0.3643,
      "step": 988
    },
    {
      "epoch": 0.5957831325301205,
      "grad_norm": 0.6991768479347229,
      "learning_rate": 4.25527108433735e-06,
      "loss": 0.3706,
      "step": 989
    },
    {
      "epoch": 0.5963855421686747,
      "grad_norm": 0.6980689764022827,
      "learning_rate": 4.254518072289157e-06,
      "loss": 0.3595,
      "step": 990
    },
    {
      "epoch": 0.596987951807229,
      "grad_norm": 0.6639752984046936,
      "learning_rate": 4.2537650602409645e-06,
      "loss": 0.3735,
      "step": 991
    },
    {
      "epoch": 0.5975903614457831,
      "grad_norm": 0.6763629913330078,
      "learning_rate": 4.253012048192771e-06,
      "loss": 0.3475,
      "step": 992
    },
    {
      "epoch": 0.5981927710843373,
      "grad_norm": 0.6860172748565674,
      "learning_rate": 4.252259036144578e-06,
      "loss": 0.4058,
      "step": 993
    },
    {
      "epoch": 0.5987951807228916,
      "grad_norm": 0.6260606646537781,
      "learning_rate": 4.251506024096385e-06,
      "loss": 0.3593,
      "step": 994
    },
    {
      "epoch": 0.5993975903614458,
      "grad_norm": 0.6889044642448425,
      "learning_rate": 4.250753012048193e-06,
      "loss": 0.3526,
      "step": 995
    },
    {
      "epoch": 0.6,
      "grad_norm": 0.7136476039886475,
      "learning_rate": 4.25e-06,
      "loss": 0.3472,
      "step": 996
    },
    {
      "epoch": 0.6006024096385543,
      "grad_norm": 0.7861083745956421,
      "learning_rate": 4.249246987951808e-06,
      "loss": 0.3958,
      "step": 997
    },
    {
      "epoch": 0.6012048192771084,
      "grad_norm": 0.687587559223175,
      "learning_rate": 4.248493975903615e-06,
      "loss": 0.3779,
      "step": 998
    },
    {
      "epoch": 0.6018072289156626,
      "grad_norm": 0.7171517014503479,
      "learning_rate": 4.247740963855422e-06,
      "loss": 0.3611,
      "step": 999
    },
    {
      "epoch": 0.6024096385542169,
      "grad_norm": 0.688416063785553,
      "learning_rate": 4.246987951807229e-06,
      "loss": 0.3297,
      "step": 1000
    },
    {
      "epoch": 0.6030120481927711,
      "grad_norm": 0.7024797201156616,
      "learning_rate": 4.246234939759036e-06,
      "loss": 0.3698,
      "step": 1001
    },
    {
      "epoch": 0.6036144578313253,
      "grad_norm": 0.7120327949523926,
      "learning_rate": 4.245481927710844e-06,
      "loss": 0.4072,
      "step": 1002
    },
    {
      "epoch": 0.6042168674698796,
      "grad_norm": 0.6905835270881653,
      "learning_rate": 4.244728915662651e-06,
      "loss": 0.4045,
      "step": 1003
    },
    {
      "epoch": 0.6048192771084338,
      "grad_norm": 0.6408528685569763,
      "learning_rate": 4.243975903614459e-06,
      "loss": 0.3118,
      "step": 1004
    },
    {
      "epoch": 0.6054216867469879,
      "grad_norm": 0.6852465867996216,
      "learning_rate": 4.243222891566266e-06,
      "loss": 0.3515,
      "step": 1005
    },
    {
      "epoch": 0.6060240963855422,
      "grad_norm": 0.7029289603233337,
      "learning_rate": 4.242469879518073e-06,
      "loss": 0.3391,
      "step": 1006
    },
    {
      "epoch": 0.6066265060240964,
      "grad_norm": 0.6532825827598572,
      "learning_rate": 4.24171686746988e-06,
      "loss": 0.3961,
      "step": 1007
    },
    {
      "epoch": 0.6072289156626506,
      "grad_norm": 0.6549494862556458,
      "learning_rate": 4.240963855421687e-06,
      "loss": 0.3853,
      "step": 1008
    },
    {
      "epoch": 0.6078313253012049,
      "grad_norm": 0.6402273774147034,
      "learning_rate": 4.240210843373494e-06,
      "loss": 0.3814,
      "step": 1009
    },
    {
      "epoch": 0.608433734939759,
      "grad_norm": 0.7285925149917603,
      "learning_rate": 4.239457831325301e-06,
      "loss": 0.3507,
      "step": 1010
    },
    {
      "epoch": 0.6090361445783132,
      "grad_norm": 0.6622280478477478,
      "learning_rate": 4.238704819277109e-06,
      "loss": 0.3436,
      "step": 1011
    },
    {
      "epoch": 0.6096385542168675,
      "grad_norm": 0.6758617758750916,
      "learning_rate": 4.237951807228916e-06,
      "loss": 0.3432,
      "step": 1012
    },
    {
      "epoch": 0.6102409638554217,
      "grad_norm": 0.7075384259223938,
      "learning_rate": 4.237198795180723e-06,
      "loss": 0.3911,
      "step": 1013
    },
    {
      "epoch": 0.6108433734939759,
      "grad_norm": 0.6861165761947632,
      "learning_rate": 4.2364457831325305e-06,
      "loss": 0.2774,
      "step": 1014
    },
    {
      "epoch": 0.6114457831325302,
      "grad_norm": 0.681966245174408,
      "learning_rate": 4.2356927710843375e-06,
      "loss": 0.3252,
      "step": 1015
    },
    {
      "epoch": 0.6120481927710844,
      "grad_norm": 0.7415159344673157,
      "learning_rate": 4.234939759036145e-06,
      "loss": 0.3523,
      "step": 1016
    },
    {
      "epoch": 0.6126506024096385,
      "grad_norm": 0.6941502094268799,
      "learning_rate": 4.234186746987952e-06,
      "loss": 0.3618,
      "step": 1017
    },
    {
      "epoch": 0.6132530120481928,
      "grad_norm": 0.6881455183029175,
      "learning_rate": 4.233433734939759e-06,
      "loss": 0.3605,
      "step": 1018
    },
    {
      "epoch": 0.613855421686747,
      "grad_norm": 0.6806015372276306,
      "learning_rate": 4.232680722891567e-06,
      "loss": 0.3328,
      "step": 1019
    },
    {
      "epoch": 0.6144578313253012,
      "grad_norm": 0.6394650936126709,
      "learning_rate": 4.231927710843374e-06,
      "loss": 0.3388,
      "step": 1020
    },
    {
      "epoch": 0.6150602409638555,
      "grad_norm": 0.7935373783111572,
      "learning_rate": 4.2311746987951816e-06,
      "loss": 0.3895,
      "step": 1021
    },
    {
      "epoch": 0.6156626506024097,
      "grad_norm": 0.6661940217018127,
      "learning_rate": 4.2304216867469885e-06,
      "loss": 0.31,
      "step": 1022
    },
    {
      "epoch": 0.6162650602409638,
      "grad_norm": 0.6693207621574402,
      "learning_rate": 4.229668674698795e-06,
      "loss": 0.4042,
      "step": 1023
    },
    {
      "epoch": 0.6168674698795181,
      "grad_norm": 0.6657373309135437,
      "learning_rate": 4.228915662650603e-06,
      "loss": 0.3137,
      "step": 1024
    },
    {
      "epoch": 0.6174698795180723,
      "grad_norm": 0.6660506725311279,
      "learning_rate": 4.22816265060241e-06,
      "loss": 0.3795,
      "step": 1025
    },
    {
      "epoch": 0.6180722891566265,
      "grad_norm": 0.6822868585586548,
      "learning_rate": 4.227409638554217e-06,
      "loss": 0.3429,
      "step": 1026
    },
    {
      "epoch": 0.6186746987951808,
      "grad_norm": 0.6136929988861084,
      "learning_rate": 4.226656626506024e-06,
      "loss": 0.4087,
      "step": 1027
    },
    {
      "epoch": 0.619277108433735,
      "grad_norm": 0.6588791608810425,
      "learning_rate": 4.225903614457832e-06,
      "loss": 0.3901,
      "step": 1028
    },
    {
      "epoch": 0.6198795180722891,
      "grad_norm": 0.737399160861969,
      "learning_rate": 4.225150602409639e-06,
      "loss": 0.3941,
      "step": 1029
    },
    {
      "epoch": 0.6204819277108434,
      "grad_norm": 0.6286519765853882,
      "learning_rate": 4.2243975903614456e-06,
      "loss": 0.3311,
      "step": 1030
    },
    {
      "epoch": 0.6210843373493976,
      "grad_norm": 0.7255479693412781,
      "learning_rate": 4.223644578313253e-06,
      "loss": 0.3098,
      "step": 1031
    },
    {
      "epoch": 0.6216867469879518,
      "grad_norm": 0.6787152886390686,
      "learning_rate": 4.22289156626506e-06,
      "loss": 0.3094,
      "step": 1032
    },
    {
      "epoch": 0.6222891566265061,
      "grad_norm": 0.6686118841171265,
      "learning_rate": 4.222138554216868e-06,
      "loss": 0.3545,
      "step": 1033
    },
    {
      "epoch": 0.6228915662650603,
      "grad_norm": 0.6818909049034119,
      "learning_rate": 4.221385542168675e-06,
      "loss": 0.3593,
      "step": 1034
    },
    {
      "epoch": 0.6234939759036144,
      "grad_norm": 0.7070595622062683,
      "learning_rate": 4.220632530120482e-06,
      "loss": 0.3977,
      "step": 1035
    },
    {
      "epoch": 0.6240963855421687,
      "grad_norm": 0.6930844783782959,
      "learning_rate": 4.21987951807229e-06,
      "loss": 0.3193,
      "step": 1036
    },
    {
      "epoch": 0.6246987951807229,
      "grad_norm": 0.6151359677314758,
      "learning_rate": 4.219126506024097e-06,
      "loss": 0.3335,
      "step": 1037
    },
    {
      "epoch": 0.6253012048192771,
      "grad_norm": 0.7027848362922668,
      "learning_rate": 4.218373493975904e-06,
      "loss": 0.3754,
      "step": 1038
    },
    {
      "epoch": 0.6259036144578313,
      "grad_norm": 0.6600651741027832,
      "learning_rate": 4.217620481927711e-06,
      "loss": 0.3427,
      "step": 1039
    },
    {
      "epoch": 0.6265060240963856,
      "grad_norm": 0.6257359981536865,
      "learning_rate": 4.216867469879519e-06,
      "loss": 0.3235,
      "step": 1040
    },
    {
      "epoch": 0.6271084337349397,
      "grad_norm": 0.737470269203186,
      "learning_rate": 4.216114457831326e-06,
      "loss": 0.3994,
      "step": 1041
    },
    {
      "epoch": 0.6277108433734939,
      "grad_norm": 0.6814212203025818,
      "learning_rate": 4.215361445783133e-06,
      "loss": 0.3192,
      "step": 1042
    },
    {
      "epoch": 0.6283132530120482,
      "grad_norm": 0.6611950397491455,
      "learning_rate": 4.21460843373494e-06,
      "loss": 0.3439,
      "step": 1043
    },
    {
      "epoch": 0.6289156626506024,
      "grad_norm": 0.8053423166275024,
      "learning_rate": 4.213855421686748e-06,
      "loss": 0.3704,
      "step": 1044
    },
    {
      "epoch": 0.6295180722891566,
      "grad_norm": 0.6867537498474121,
      "learning_rate": 4.2131024096385545e-06,
      "loss": 0.3988,
      "step": 1045
    },
    {
      "epoch": 0.6301204819277109,
      "grad_norm": 0.7212349772453308,
      "learning_rate": 4.2123493975903615e-06,
      "loss": 0.3438,
      "step": 1046
    },
    {
      "epoch": 0.630722891566265,
      "grad_norm": 0.6595363020896912,
      "learning_rate": 4.211596385542168e-06,
      "loss": 0.3413,
      "step": 1047
    },
    {
      "epoch": 0.6313253012048192,
      "grad_norm": 0.6555273532867432,
      "learning_rate": 4.210843373493976e-06,
      "loss": 0.2878,
      "step": 1048
    },
    {
      "epoch": 0.6319277108433735,
      "grad_norm": 0.6773706674575806,
      "learning_rate": 4.210090361445783e-06,
      "loss": 0.3504,
      "step": 1049
    },
    {
      "epoch": 0.6325301204819277,
      "grad_norm": 0.6616544723510742,
      "learning_rate": 4.209337349397591e-06,
      "loss": 0.3083,
      "step": 1050
    },
    {
      "epoch": 0.6331325301204819,
      "grad_norm": 0.668819785118103,
      "learning_rate": 4.208584337349398e-06,
      "loss": 0.3335,
      "step": 1051
    },
    {
      "epoch": 0.6337349397590362,
      "grad_norm": 0.627885639667511,
      "learning_rate": 4.2078313253012055e-06,
      "loss": 0.305,
      "step": 1052
    },
    {
      "epoch": 0.6343373493975903,
      "grad_norm": 0.6990445852279663,
      "learning_rate": 4.2070783132530125e-06,
      "loss": 0.3183,
      "step": 1053
    },
    {
      "epoch": 0.6349397590361445,
      "grad_norm": 0.6365576982498169,
      "learning_rate": 4.206325301204819e-06,
      "loss": 0.3377,
      "step": 1054
    },
    {
      "epoch": 0.6355421686746988,
      "grad_norm": 0.6080365777015686,
      "learning_rate": 4.205572289156627e-06,
      "loss": 0.3167,
      "step": 1055
    },
    {
      "epoch": 0.636144578313253,
      "grad_norm": 0.7472244501113892,
      "learning_rate": 4.204819277108434e-06,
      "loss": 0.3604,
      "step": 1056
    },
    {
      "epoch": 0.6367469879518072,
      "grad_norm": 0.6572127938270569,
      "learning_rate": 4.204066265060242e-06,
      "loss": 0.3199,
      "step": 1057
    },
    {
      "epoch": 0.6373493975903615,
      "grad_norm": 0.6823880672454834,
      "learning_rate": 4.203313253012049e-06,
      "loss": 0.3201,
      "step": 1058
    },
    {
      "epoch": 0.6379518072289156,
      "grad_norm": 0.6583378314971924,
      "learning_rate": 4.202560240963856e-06,
      "loss": 0.3581,
      "step": 1059
    },
    {
      "epoch": 0.6385542168674698,
      "grad_norm": 0.657699465751648,
      "learning_rate": 4.201807228915663e-06,
      "loss": 0.3197,
      "step": 1060
    },
    {
      "epoch": 0.6391566265060241,
      "grad_norm": 0.783771276473999,
      "learning_rate": 4.20105421686747e-06,
      "loss": 0.3825,
      "step": 1061
    },
    {
      "epoch": 0.6397590361445783,
      "grad_norm": 0.6541932225227356,
      "learning_rate": 4.200301204819277e-06,
      "loss": 0.3467,
      "step": 1062
    },
    {
      "epoch": 0.6403614457831325,
      "grad_norm": 0.682585597038269,
      "learning_rate": 4.199548192771084e-06,
      "loss": 0.317,
      "step": 1063
    },
    {
      "epoch": 0.6409638554216868,
      "grad_norm": 0.6969208121299744,
      "learning_rate": 4.198795180722892e-06,
      "loss": 0.3598,
      "step": 1064
    },
    {
      "epoch": 0.641566265060241,
      "grad_norm": 0.6820161938667297,
      "learning_rate": 4.198042168674699e-06,
      "loss": 0.3208,
      "step": 1065
    },
    {
      "epoch": 0.6421686746987951,
      "grad_norm": 0.6808528304100037,
      "learning_rate": 4.197289156626506e-06,
      "loss": 0.3259,
      "step": 1066
    },
    {
      "epoch": 0.6427710843373494,
      "grad_norm": 0.6555874347686768,
      "learning_rate": 4.196536144578314e-06,
      "loss": 0.331,
      "step": 1067
    },
    {
      "epoch": 0.6433734939759036,
      "grad_norm": 0.6512388586997986,
      "learning_rate": 4.195783132530121e-06,
      "loss": 0.3531,
      "step": 1068
    },
    {
      "epoch": 0.6439759036144578,
      "grad_norm": 0.7080109119415283,
      "learning_rate": 4.195030120481928e-06,
      "loss": 0.3149,
      "step": 1069
    },
    {
      "epoch": 0.6445783132530121,
      "grad_norm": 0.6983137130737305,
      "learning_rate": 4.194277108433735e-06,
      "loss": 0.3347,
      "step": 1070
    },
    {
      "epoch": 0.6451807228915662,
      "grad_norm": 0.6175503134727478,
      "learning_rate": 4.193524096385542e-06,
      "loss": 0.2917,
      "step": 1071
    },
    {
      "epoch": 0.6457831325301204,
      "grad_norm": 0.6853642463684082,
      "learning_rate": 4.19277108433735e-06,
      "loss": 0.3803,
      "step": 1072
    },
    {
      "epoch": 0.6463855421686747,
      "grad_norm": 0.6399030089378357,
      "learning_rate": 4.192018072289157e-06,
      "loss": 0.361,
      "step": 1073
    },
    {
      "epoch": 0.6469879518072289,
      "grad_norm": 0.6154062151908875,
      "learning_rate": 4.191265060240965e-06,
      "loss": 0.3093,
      "step": 1074
    },
    {
      "epoch": 0.6475903614457831,
      "grad_norm": 0.637287974357605,
      "learning_rate": 4.190512048192772e-06,
      "loss": 0.328,
      "step": 1075
    },
    {
      "epoch": 0.6481927710843374,
      "grad_norm": 0.6774003505706787,
      "learning_rate": 4.1897590361445785e-06,
      "loss": 0.3065,
      "step": 1076
    },
    {
      "epoch": 0.6487951807228916,
      "grad_norm": 0.6730077266693115,
      "learning_rate": 4.189006024096386e-06,
      "loss": 0.3052,
      "step": 1077
    },
    {
      "epoch": 0.6493975903614457,
      "grad_norm": 0.6419311761856079,
      "learning_rate": 4.188253012048193e-06,
      "loss": 0.3297,
      "step": 1078
    },
    {
      "epoch": 0.65,
      "grad_norm": 0.6740551590919495,
      "learning_rate": 4.1875e-06,
      "loss": 0.3486,
      "step": 1079
    },
    {
      "epoch": 0.6506024096385542,
      "grad_norm": 0.8006681203842163,
      "learning_rate": 4.186746987951807e-06,
      "loss": 0.3595,
      "step": 1080
    },
    {
      "epoch": 0.6512048192771084,
      "grad_norm": 0.9339956045150757,
      "learning_rate": 4.185993975903615e-06,
      "loss": 0.3808,
      "step": 1081
    },
    {
      "epoch": 0.6518072289156627,
      "grad_norm": 0.7639572620391846,
      "learning_rate": 4.185240963855422e-06,
      "loss": 0.4193,
      "step": 1082
    },
    {
      "epoch": 0.6524096385542169,
      "grad_norm": 0.8281978368759155,
      "learning_rate": 4.184487951807229e-06,
      "loss": 0.3355,
      "step": 1083
    },
    {
      "epoch": 0.653012048192771,
      "grad_norm": 0.8713392615318298,
      "learning_rate": 4.1837349397590365e-06,
      "loss": 0.3711,
      "step": 1084
    },
    {
      "epoch": 0.6536144578313253,
      "grad_norm": 0.7703314423561096,
      "learning_rate": 4.182981927710843e-06,
      "loss": 0.3759,
      "step": 1085
    },
    {
      "epoch": 0.6542168674698795,
      "grad_norm": 0.7633914947509766,
      "learning_rate": 4.182228915662651e-06,
      "loss": 0.4168,
      "step": 1086
    },
    {
      "epoch": 0.6548192771084337,
      "grad_norm": 0.747061550617218,
      "learning_rate": 4.181475903614458e-06,
      "loss": 0.4171,
      "step": 1087
    },
    {
      "epoch": 0.655421686746988,
      "grad_norm": 0.7647647857666016,
      "learning_rate": 4.180722891566266e-06,
      "loss": 0.4857,
      "step": 1088
    },
    {
      "epoch": 0.6560240963855422,
      "grad_norm": 0.7324094176292419,
      "learning_rate": 4.179969879518073e-06,
      "loss": 0.3981,
      "step": 1089
    },
    {
      "epoch": 0.6566265060240963,
      "grad_norm": 0.8207620978355408,
      "learning_rate": 4.17921686746988e-06,
      "loss": 0.3391,
      "step": 1090
    },
    {
      "epoch": 0.6572289156626506,
      "grad_norm": 0.7174896597862244,
      "learning_rate": 4.1784638554216875e-06,
      "loss": 0.3603,
      "step": 1091
    },
    {
      "epoch": 0.6578313253012048,
      "grad_norm": 0.6909661293029785,
      "learning_rate": 4.177710843373494e-06,
      "loss": 0.373,
      "step": 1092
    },
    {
      "epoch": 0.658433734939759,
      "grad_norm": 0.8079960942268372,
      "learning_rate": 4.176957831325302e-06,
      "loss": 0.4159,
      "step": 1093
    },
    {
      "epoch": 0.6590361445783133,
      "grad_norm": 0.8421658277511597,
      "learning_rate": 4.176204819277109e-06,
      "loss": 0.4065,
      "step": 1094
    },
    {
      "epoch": 0.6596385542168675,
      "grad_norm": 0.7300800085067749,
      "learning_rate": 4.175451807228916e-06,
      "loss": 0.3679,
      "step": 1095
    },
    {
      "epoch": 0.6602409638554216,
      "grad_norm": 0.6991647481918335,
      "learning_rate": 4.174698795180723e-06,
      "loss": 0.3572,
      "step": 1096
    },
    {
      "epoch": 0.6608433734939759,
      "grad_norm": 0.7091929912567139,
      "learning_rate": 4.17394578313253e-06,
      "loss": 0.3379,
      "step": 1097
    },
    {
      "epoch": 0.6614457831325301,
      "grad_norm": 0.7214727401733398,
      "learning_rate": 4.173192771084338e-06,
      "loss": 0.3977,
      "step": 1098
    },
    {
      "epoch": 0.6620481927710843,
      "grad_norm": 0.7247477769851685,
      "learning_rate": 4.1724397590361446e-06,
      "loss": 0.3959,
      "step": 1099
    },
    {
      "epoch": 0.6626506024096386,
      "grad_norm": 0.7160807251930237,
      "learning_rate": 4.171686746987952e-06,
      "loss": 0.3891,
      "step": 1100
    },
    {
      "epoch": 0.6632530120481928,
      "grad_norm": 0.736232578754425,
      "learning_rate": 4.170933734939759e-06,
      "loss": 0.3573,
      "step": 1101
    },
    {
      "epoch": 0.6638554216867469,
      "grad_norm": 0.682445764541626,
      "learning_rate": 4.170180722891566e-06,
      "loss": 0.4005,
      "step": 1102
    },
    {
      "epoch": 0.6644578313253012,
      "grad_norm": 0.6999887228012085,
      "learning_rate": 4.169427710843374e-06,
      "loss": 0.3615,
      "step": 1103
    },
    {
      "epoch": 0.6650602409638554,
      "grad_norm": 0.7178047299385071,
      "learning_rate": 4.168674698795181e-06,
      "loss": 0.3906,
      "step": 1104
    },
    {
      "epoch": 0.6656626506024096,
      "grad_norm": 0.757752537727356,
      "learning_rate": 4.167921686746989e-06,
      "loss": 0.3725,
      "step": 1105
    },
    {
      "epoch": 0.6662650602409639,
      "grad_norm": 0.7007893919944763,
      "learning_rate": 4.167168674698796e-06,
      "loss": 0.3563,
      "step": 1106
    },
    {
      "epoch": 0.6668674698795181,
      "grad_norm": 0.7432811260223389,
      "learning_rate": 4.1664156626506025e-06,
      "loss": 0.3831,
      "step": 1107
    },
    {
      "epoch": 0.6674698795180722,
      "grad_norm": 0.670624852180481,
      "learning_rate": 4.16566265060241e-06,
      "loss": 0.4208,
      "step": 1108
    },
    {
      "epoch": 0.6680722891566265,
      "grad_norm": 0.7965717315673828,
      "learning_rate": 4.164909638554217e-06,
      "loss": 0.327,
      "step": 1109
    },
    {
      "epoch": 0.6686746987951807,
      "grad_norm": 0.7291350364685059,
      "learning_rate": 4.164156626506025e-06,
      "loss": 0.4216,
      "step": 1110
    },
    {
      "epoch": 0.6692771084337349,
      "grad_norm": 0.7325938940048218,
      "learning_rate": 4.163403614457832e-06,
      "loss": 0.3575,
      "step": 1111
    },
    {
      "epoch": 0.6698795180722892,
      "grad_norm": 0.7062926292419434,
      "learning_rate": 4.162650602409639e-06,
      "loss": 0.3987,
      "step": 1112
    },
    {
      "epoch": 0.6704819277108434,
      "grad_norm": 0.7038694620132446,
      "learning_rate": 4.161897590361446e-06,
      "loss": 0.3831,
      "step": 1113
    },
    {
      "epoch": 0.6710843373493975,
      "grad_norm": 0.8355485200881958,
      "learning_rate": 4.1611445783132535e-06,
      "loss": 0.3239,
      "step": 1114
    },
    {
      "epoch": 0.6716867469879518,
      "grad_norm": 0.6619731187820435,
      "learning_rate": 4.1603915662650604e-06,
      "loss": 0.4188,
      "step": 1115
    },
    {
      "epoch": 0.672289156626506,
      "grad_norm": 0.6976242661476135,
      "learning_rate": 4.159638554216867e-06,
      "loss": 0.4158,
      "step": 1116
    },
    {
      "epoch": 0.6728915662650602,
      "grad_norm": 0.7014606595039368,
      "learning_rate": 4.158885542168675e-06,
      "loss": 0.3688,
      "step": 1117
    },
    {
      "epoch": 0.6734939759036145,
      "grad_norm": 0.6920532584190369,
      "learning_rate": 4.158132530120482e-06,
      "loss": 0.3863,
      "step": 1118
    },
    {
      "epoch": 0.6740963855421687,
      "grad_norm": 0.6732757687568665,
      "learning_rate": 4.157379518072289e-06,
      "loss": 0.3331,
      "step": 1119
    },
    {
      "epoch": 0.6746987951807228,
      "grad_norm": 0.6780493259429932,
      "learning_rate": 4.156626506024097e-06,
      "loss": 0.4264,
      "step": 1120
    },
    {
      "epoch": 0.6753012048192771,
      "grad_norm": 0.678541362285614,
      "learning_rate": 4.155873493975904e-06,
      "loss": 0.3756,
      "step": 1121
    },
    {
      "epoch": 0.6759036144578313,
      "grad_norm": 0.6709573268890381,
      "learning_rate": 4.1551204819277115e-06,
      "loss": 0.3721,
      "step": 1122
    },
    {
      "epoch": 0.6765060240963855,
      "grad_norm": 0.6125470399856567,
      "learning_rate": 4.154367469879518e-06,
      "loss": 0.376,
      "step": 1123
    },
    {
      "epoch": 0.6771084337349398,
      "grad_norm": 0.7463022470474243,
      "learning_rate": 4.153614457831326e-06,
      "loss": 0.3754,
      "step": 1124
    },
    {
      "epoch": 0.677710843373494,
      "grad_norm": 0.6742141246795654,
      "learning_rate": 4.152861445783133e-06,
      "loss": 0.3979,
      "step": 1125
    },
    {
      "epoch": 0.6783132530120481,
      "grad_norm": 0.6951873898506165,
      "learning_rate": 4.15210843373494e-06,
      "loss": 0.3446,
      "step": 1126
    },
    {
      "epoch": 0.6789156626506024,
      "grad_norm": 0.7092046141624451,
      "learning_rate": 4.151355421686748e-06,
      "loss": 0.3585,
      "step": 1127
    },
    {
      "epoch": 0.6795180722891566,
      "grad_norm": 0.699679970741272,
      "learning_rate": 4.150602409638555e-06,
      "loss": 0.376,
      "step": 1128
    },
    {
      "epoch": 0.6801204819277108,
      "grad_norm": 0.6939918994903564,
      "learning_rate": 4.149849397590362e-06,
      "loss": 0.3296,
      "step": 1129
    },
    {
      "epoch": 0.6807228915662651,
      "grad_norm": 0.7415961623191833,
      "learning_rate": 4.149096385542169e-06,
      "loss": 0.3365,
      "step": 1130
    },
    {
      "epoch": 0.6813253012048193,
      "grad_norm": 0.6925395727157593,
      "learning_rate": 4.148343373493976e-06,
      "loss": 0.4133,
      "step": 1131
    },
    {
      "epoch": 0.6819277108433734,
      "grad_norm": 0.8419461250305176,
      "learning_rate": 4.147590361445783e-06,
      "loss": 0.401,
      "step": 1132
    },
    {
      "epoch": 0.6825301204819277,
      "grad_norm": 0.6888376474380493,
      "learning_rate": 4.14683734939759e-06,
      "loss": 0.3593,
      "step": 1133
    },
    {
      "epoch": 0.6831325301204819,
      "grad_norm": 0.6958553791046143,
      "learning_rate": 4.146084337349398e-06,
      "loss": 0.3499,
      "step": 1134
    },
    {
      "epoch": 0.6837349397590361,
      "grad_norm": 0.7096388936042786,
      "learning_rate": 4.145331325301205e-06,
      "loss": 0.3975,
      "step": 1135
    },
    {
      "epoch": 0.6843373493975904,
      "grad_norm": 0.671700119972229,
      "learning_rate": 4.144578313253013e-06,
      "loss": 0.3915,
      "step": 1136
    },
    {
      "epoch": 0.6849397590361446,
      "grad_norm": 0.608258843421936,
      "learning_rate": 4.1438253012048196e-06,
      "loss": 0.3532,
      "step": 1137
    },
    {
      "epoch": 0.6855421686746987,
      "grad_norm": 0.6755176186561584,
      "learning_rate": 4.1430722891566265e-06,
      "loss": 0.3569,
      "step": 1138
    },
    {
      "epoch": 0.686144578313253,
      "grad_norm": 0.6804134249687195,
      "learning_rate": 4.142319277108434e-06,
      "loss": 0.3863,
      "step": 1139
    },
    {
      "epoch": 0.6867469879518072,
      "grad_norm": 0.6967179179191589,
      "learning_rate": 4.141566265060241e-06,
      "loss": 0.3446,
      "step": 1140
    },
    {
      "epoch": 0.6873493975903614,
      "grad_norm": 0.629173219203949,
      "learning_rate": 4.140813253012049e-06,
      "loss": 0.3351,
      "step": 1141
    },
    {
      "epoch": 0.6879518072289157,
      "grad_norm": 0.6653124094009399,
      "learning_rate": 4.140060240963856e-06,
      "loss": 0.3068,
      "step": 1142
    },
    {
      "epoch": 0.6885542168674699,
      "grad_norm": 0.6619611978530884,
      "learning_rate": 4.139307228915663e-06,
      "loss": 0.4037,
      "step": 1143
    },
    {
      "epoch": 0.689156626506024,
      "grad_norm": 0.6772018074989319,
      "learning_rate": 4.138554216867471e-06,
      "loss": 0.315,
      "step": 1144
    },
    {
      "epoch": 0.6897590361445783,
      "grad_norm": 0.6348771452903748,
      "learning_rate": 4.1378012048192775e-06,
      "loss": 0.3271,
      "step": 1145
    },
    {
      "epoch": 0.6903614457831325,
      "grad_norm": 0.9463487863540649,
      "learning_rate": 4.1370481927710844e-06,
      "loss": 0.3813,
      "step": 1146
    },
    {
      "epoch": 0.6909638554216867,
      "grad_norm": 0.6739287972450256,
      "learning_rate": 4.136295180722892e-06,
      "loss": 0.3224,
      "step": 1147
    },
    {
      "epoch": 0.691566265060241,
      "grad_norm": 0.6428196430206299,
      "learning_rate": 4.135542168674699e-06,
      "loss": 0.3492,
      "step": 1148
    },
    {
      "epoch": 0.6921686746987952,
      "grad_norm": 0.7027080655097961,
      "learning_rate": 4.134789156626506e-06,
      "loss": 0.3553,
      "step": 1149
    },
    {
      "epoch": 0.6927710843373494,
      "grad_norm": 0.7287865281105042,
      "learning_rate": 4.134036144578313e-06,
      "loss": 0.3958,
      "step": 1150
    },
    {
      "epoch": 0.6933734939759036,
      "grad_norm": 0.6444294452667236,
      "learning_rate": 4.133283132530121e-06,
      "loss": 0.3106,
      "step": 1151
    },
    {
      "epoch": 0.6939759036144578,
      "grad_norm": 0.6877959370613098,
      "learning_rate": 4.132530120481928e-06,
      "loss": 0.3432,
      "step": 1152
    },
    {
      "epoch": 0.694578313253012,
      "grad_norm": 0.6385447978973389,
      "learning_rate": 4.1317771084337355e-06,
      "loss": 0.3661,
      "step": 1153
    },
    {
      "epoch": 0.6951807228915663,
      "grad_norm": 0.6323879361152649,
      "learning_rate": 4.131024096385542e-06,
      "loss": 0.3646,
      "step": 1154
    },
    {
      "epoch": 0.6957831325301205,
      "grad_norm": 0.7787267565727234,
      "learning_rate": 4.130271084337349e-06,
      "loss": 0.3707,
      "step": 1155
    },
    {
      "epoch": 0.6963855421686747,
      "grad_norm": 0.7040953040122986,
      "learning_rate": 4.129518072289157e-06,
      "loss": 0.3742,
      "step": 1156
    },
    {
      "epoch": 0.696987951807229,
      "grad_norm": 0.6508787274360657,
      "learning_rate": 4.128765060240964e-06,
      "loss": 0.4157,
      "step": 1157
    },
    {
      "epoch": 0.6975903614457831,
      "grad_norm": 0.7312546968460083,
      "learning_rate": 4.128012048192772e-06,
      "loss": 0.3633,
      "step": 1158
    },
    {
      "epoch": 0.6981927710843373,
      "grad_norm": 0.7287075519561768,
      "learning_rate": 4.127259036144579e-06,
      "loss": 0.3206,
      "step": 1159
    },
    {
      "epoch": 0.6987951807228916,
      "grad_norm": 0.7207337617874146,
      "learning_rate": 4.1265060240963865e-06,
      "loss": 0.3907,
      "step": 1160
    },
    {
      "epoch": 0.6993975903614458,
      "grad_norm": 0.7196043729782104,
      "learning_rate": 4.125753012048193e-06,
      "loss": 0.3425,
      "step": 1161
    },
    {
      "epoch": 0.7,
      "grad_norm": 0.593317985534668,
      "learning_rate": 4.125e-06,
      "loss": 0.3379,
      "step": 1162
    },
    {
      "epoch": 0.7006024096385542,
      "grad_norm": 0.6804400086402893,
      "learning_rate": 4.124246987951808e-06,
      "loss": 0.3544,
      "step": 1163
    },
    {
      "epoch": 0.7012048192771084,
      "grad_norm": 0.7690721750259399,
      "learning_rate": 4.123493975903615e-06,
      "loss": 0.3344,
      "step": 1164
    },
    {
      "epoch": 0.7018072289156626,
      "grad_norm": 0.6648558378219604,
      "learning_rate": 4.122740963855422e-06,
      "loss": 0.331,
      "step": 1165
    },
    {
      "epoch": 0.7024096385542169,
      "grad_norm": 0.7409929037094116,
      "learning_rate": 4.121987951807229e-06,
      "loss": 0.4349,
      "step": 1166
    },
    {
      "epoch": 0.7030120481927711,
      "grad_norm": 0.6553030014038086,
      "learning_rate": 4.121234939759037e-06,
      "loss": 0.3511,
      "step": 1167
    },
    {
      "epoch": 0.7036144578313253,
      "grad_norm": 0.6518680453300476,
      "learning_rate": 4.1204819277108436e-06,
      "loss": 0.352,
      "step": 1168
    },
    {
      "epoch": 0.7042168674698795,
      "grad_norm": 0.6553515791893005,
      "learning_rate": 4.1197289156626505e-06,
      "loss": 0.3014,
      "step": 1169
    },
    {
      "epoch": 0.7048192771084337,
      "grad_norm": 0.5842414498329163,
      "learning_rate": 4.118975903614458e-06,
      "loss": 0.3487,
      "step": 1170
    },
    {
      "epoch": 0.7054216867469879,
      "grad_norm": 0.742221474647522,
      "learning_rate": 4.118222891566265e-06,
      "loss": 0.3354,
      "step": 1171
    },
    {
      "epoch": 0.7060240963855422,
      "grad_norm": 0.6439841389656067,
      "learning_rate": 4.117469879518073e-06,
      "loss": 0.359,
      "step": 1172
    },
    {
      "epoch": 0.7066265060240964,
      "grad_norm": 0.654100775718689,
      "learning_rate": 4.11671686746988e-06,
      "loss": 0.3285,
      "step": 1173
    },
    {
      "epoch": 0.7072289156626506,
      "grad_norm": 0.6148664951324463,
      "learning_rate": 4.115963855421687e-06,
      "loss": 0.3119,
      "step": 1174
    },
    {
      "epoch": 0.7078313253012049,
      "grad_norm": 0.6943126916885376,
      "learning_rate": 4.1152108433734946e-06,
      "loss": 0.3078,
      "step": 1175
    },
    {
      "epoch": 0.708433734939759,
      "grad_norm": 0.6641731262207031,
      "learning_rate": 4.1144578313253015e-06,
      "loss": 0.4124,
      "step": 1176
    },
    {
      "epoch": 0.7090361445783132,
      "grad_norm": 0.961254358291626,
      "learning_rate": 4.113704819277109e-06,
      "loss": 0.3503,
      "step": 1177
    },
    {
      "epoch": 0.7096385542168675,
      "grad_norm": 0.6832992434501648,
      "learning_rate": 4.112951807228916e-06,
      "loss": 0.4023,
      "step": 1178
    },
    {
      "epoch": 0.7102409638554217,
      "grad_norm": 0.6628142595291138,
      "learning_rate": 4.112198795180723e-06,
      "loss": 0.3421,
      "step": 1179
    },
    {
      "epoch": 0.7108433734939759,
      "grad_norm": 0.6357985734939575,
      "learning_rate": 4.111445783132531e-06,
      "loss": 0.2994,
      "step": 1180
    },
    {
      "epoch": 0.7114457831325302,
      "grad_norm": 0.666464626789093,
      "learning_rate": 4.110692771084338e-06,
      "loss": 0.327,
      "step": 1181
    },
    {
      "epoch": 0.7120481927710843,
      "grad_norm": 0.6557676196098328,
      "learning_rate": 4.109939759036145e-06,
      "loss": 0.389,
      "step": 1182
    },
    {
      "epoch": 0.7126506024096385,
      "grad_norm": 0.6301653385162354,
      "learning_rate": 4.109186746987952e-06,
      "loss": 0.3329,
      "step": 1183
    },
    {
      "epoch": 0.7132530120481928,
      "grad_norm": 0.6648207306861877,
      "learning_rate": 4.1084337349397594e-06,
      "loss": 0.3278,
      "step": 1184
    },
    {
      "epoch": 0.713855421686747,
      "grad_norm": 0.639979362487793,
      "learning_rate": 4.107680722891566e-06,
      "loss": 0.3505,
      "step": 1185
    },
    {
      "epoch": 0.7144578313253012,
      "grad_norm": 0.6536990404129028,
      "learning_rate": 4.106927710843373e-06,
      "loss": 0.3565,
      "step": 1186
    },
    {
      "epoch": 0.7150602409638555,
      "grad_norm": 0.6373607516288757,
      "learning_rate": 4.106174698795181e-06,
      "loss": 0.3316,
      "step": 1187
    },
    {
      "epoch": 0.7156626506024096,
      "grad_norm": 0.6662040948867798,
      "learning_rate": 4.105421686746988e-06,
      "loss": 0.3513,
      "step": 1188
    },
    {
      "epoch": 0.7162650602409638,
      "grad_norm": 0.6822841167449951,
      "learning_rate": 4.104668674698796e-06,
      "loss": 0.3729,
      "step": 1189
    },
    {
      "epoch": 0.7168674698795181,
      "grad_norm": 0.6177816987037659,
      "learning_rate": 4.103915662650603e-06,
      "loss": 0.3982,
      "step": 1190
    },
    {
      "epoch": 0.7174698795180723,
      "grad_norm": 0.6869747638702393,
      "learning_rate": 4.10316265060241e-06,
      "loss": 0.3379,
      "step": 1191
    },
    {
      "epoch": 0.7180722891566265,
      "grad_norm": 0.671220064163208,
      "learning_rate": 4.102409638554217e-06,
      "loss": 0.3585,
      "step": 1192
    },
    {
      "epoch": 0.7186746987951808,
      "grad_norm": 0.6088057160377502,
      "learning_rate": 4.101656626506024e-06,
      "loss": 0.3555,
      "step": 1193
    },
    {
      "epoch": 0.7192771084337349,
      "grad_norm": 0.6308735609054565,
      "learning_rate": 4.100903614457832e-06,
      "loss": 0.39,
      "step": 1194
    },
    {
      "epoch": 0.7198795180722891,
      "grad_norm": 0.5946885943412781,
      "learning_rate": 4.100150602409639e-06,
      "loss": 0.3507,
      "step": 1195
    },
    {
      "epoch": 0.7204819277108434,
      "grad_norm": 0.7320796251296997,
      "learning_rate": 4.099397590361447e-06,
      "loss": 0.3452,
      "step": 1196
    },
    {
      "epoch": 0.7210843373493976,
      "grad_norm": 0.638329029083252,
      "learning_rate": 4.098644578313254e-06,
      "loss": 0.3617,
      "step": 1197
    },
    {
      "epoch": 0.7216867469879518,
      "grad_norm": 0.7614736557006836,
      "learning_rate": 4.097891566265061e-06,
      "loss": 0.3781,
      "step": 1198
    },
    {
      "epoch": 0.7222891566265061,
      "grad_norm": 0.7191480398178101,
      "learning_rate": 4.0971385542168675e-06,
      "loss": 0.3977,
      "step": 1199
    },
    {
      "epoch": 0.7228915662650602,
      "grad_norm": 0.666515052318573,
      "learning_rate": 4.096385542168675e-06,
      "loss": 0.32,
      "step": 1200
    },
    {
      "epoch": 0.7234939759036144,
      "grad_norm": 0.6642076373100281,
      "learning_rate": 4.095632530120482e-06,
      "loss": 0.2996,
      "step": 1201
    },
    {
      "epoch": 0.7240963855421687,
      "grad_norm": 0.6532989144325256,
      "learning_rate": 4.094879518072289e-06,
      "loss": 0.3628,
      "step": 1202
    },
    {
      "epoch": 0.7246987951807229,
      "grad_norm": 0.7288198471069336,
      "learning_rate": 4.094126506024096e-06,
      "loss": 0.3533,
      "step": 1203
    },
    {
      "epoch": 0.7253012048192771,
      "grad_norm": 0.6485936641693115,
      "learning_rate": 4.093373493975904e-06,
      "loss": 0.3066,
      "step": 1204
    },
    {
      "epoch": 0.7259036144578314,
      "grad_norm": 0.5943530201911926,
      "learning_rate": 4.092620481927711e-06,
      "loss": 0.3251,
      "step": 1205
    },
    {
      "epoch": 0.7265060240963855,
      "grad_norm": 0.6991034746170044,
      "learning_rate": 4.0918674698795186e-06,
      "loss": 0.3552,
      "step": 1206
    },
    {
      "epoch": 0.7271084337349397,
      "grad_norm": 0.6467645764350891,
      "learning_rate": 4.0911144578313255e-06,
      "loss": 0.3124,
      "step": 1207
    },
    {
      "epoch": 0.727710843373494,
      "grad_norm": 0.6772527098655701,
      "learning_rate": 4.090361445783133e-06,
      "loss": 0.3699,
      "step": 1208
    },
    {
      "epoch": 0.7283132530120482,
      "grad_norm": 0.6998881101608276,
      "learning_rate": 4.08960843373494e-06,
      "loss": 0.321,
      "step": 1209
    },
    {
      "epoch": 0.7289156626506024,
      "grad_norm": 0.6877980828285217,
      "learning_rate": 4.088855421686747e-06,
      "loss": 0.3452,
      "step": 1210
    },
    {
      "epoch": 0.7295180722891567,
      "grad_norm": 0.6169600486755371,
      "learning_rate": 4.088102409638555e-06,
      "loss": 0.3507,
      "step": 1211
    },
    {
      "epoch": 0.7301204819277108,
      "grad_norm": 0.6485261917114258,
      "learning_rate": 4.087349397590362e-06,
      "loss": 0.303,
      "step": 1212
    },
    {
      "epoch": 0.730722891566265,
      "grad_norm": 0.6637840867042542,
      "learning_rate": 4.08659638554217e-06,
      "loss": 0.3289,
      "step": 1213
    },
    {
      "epoch": 0.7313253012048193,
      "grad_norm": 0.6247849464416504,
      "learning_rate": 4.0858433734939765e-06,
      "loss": 0.3286,
      "step": 1214
    },
    {
      "epoch": 0.7319277108433735,
      "grad_norm": 0.7294449210166931,
      "learning_rate": 4.0850903614457834e-06,
      "loss": 0.3817,
      "step": 1215
    },
    {
      "epoch": 0.7325301204819277,
      "grad_norm": 0.5837371945381165,
      "learning_rate": 4.08433734939759e-06,
      "loss": 0.3103,
      "step": 1216
    },
    {
      "epoch": 0.733132530120482,
      "grad_norm": 0.6328020095825195,
      "learning_rate": 4.083584337349398e-06,
      "loss": 0.3183,
      "step": 1217
    },
    {
      "epoch": 0.7337349397590361,
      "grad_norm": 0.6704870462417603,
      "learning_rate": 4.082831325301205e-06,
      "loss": 0.2924,
      "step": 1218
    },
    {
      "epoch": 0.7343373493975903,
      "grad_norm": 0.6246723532676697,
      "learning_rate": 4.082078313253012e-06,
      "loss": 0.3235,
      "step": 1219
    },
    {
      "epoch": 0.7349397590361446,
      "grad_norm": 0.6596233248710632,
      "learning_rate": 4.08132530120482e-06,
      "loss": 0.2911,
      "step": 1220
    },
    {
      "epoch": 0.7355421686746988,
      "grad_norm": 0.671612024307251,
      "learning_rate": 4.080572289156627e-06,
      "loss": 0.3453,
      "step": 1221
    },
    {
      "epoch": 0.736144578313253,
      "grad_norm": 0.6249350905418396,
      "learning_rate": 4.079819277108434e-06,
      "loss": 0.3385,
      "step": 1222
    },
    {
      "epoch": 0.7367469879518073,
      "grad_norm": 0.6206238865852356,
      "learning_rate": 4.079066265060241e-06,
      "loss": 0.348,
      "step": 1223
    },
    {
      "epoch": 0.7373493975903614,
      "grad_norm": 0.6484470367431641,
      "learning_rate": 4.078313253012048e-06,
      "loss": 0.3135,
      "step": 1224
    },
    {
      "epoch": 0.7379518072289156,
      "grad_norm": 0.6704936623573303,
      "learning_rate": 4.077560240963856e-06,
      "loss": 0.3013,
      "step": 1225
    },
    {
      "epoch": 0.7385542168674699,
      "grad_norm": 0.6527370810508728,
      "learning_rate": 4.076807228915663e-06,
      "loss": 0.3391,
      "step": 1226
    },
    {
      "epoch": 0.7391566265060241,
      "grad_norm": 0.6315814852714539,
      "learning_rate": 4.07605421686747e-06,
      "loss": 0.3805,
      "step": 1227
    },
    {
      "epoch": 0.7397590361445783,
      "grad_norm": 0.6264241337776184,
      "learning_rate": 4.075301204819278e-06,
      "loss": 0.3294,
      "step": 1228
    },
    {
      "epoch": 0.7403614457831326,
      "grad_norm": 0.6601309180259705,
      "learning_rate": 4.074548192771085e-06,
      "loss": 0.3583,
      "step": 1229
    },
    {
      "epoch": 0.7409638554216867,
      "grad_norm": 0.6084858179092407,
      "learning_rate": 4.073795180722892e-06,
      "loss": 0.3032,
      "step": 1230
    },
    {
      "epoch": 0.7415662650602409,
      "grad_norm": 0.6504090428352356,
      "learning_rate": 4.073042168674699e-06,
      "loss": 0.2876,
      "step": 1231
    },
    {
      "epoch": 0.7421686746987952,
      "grad_norm": 0.6300227046012878,
      "learning_rate": 4.072289156626506e-06,
      "loss": 0.3629,
      "step": 1232
    },
    {
      "epoch": 0.7427710843373494,
      "grad_norm": 0.7447614669799805,
      "learning_rate": 4.071536144578314e-06,
      "loss": 0.3205,
      "step": 1233
    },
    {
      "epoch": 0.7433734939759036,
      "grad_norm": 0.6265785694122314,
      "learning_rate": 4.070783132530121e-06,
      "loss": 0.3491,
      "step": 1234
    },
    {
      "epoch": 0.7439759036144579,
      "grad_norm": 0.6851110458374023,
      "learning_rate": 4.070030120481928e-06,
      "loss": 0.3355,
      "step": 1235
    },
    {
      "epoch": 0.744578313253012,
      "grad_norm": 0.6181727647781372,
      "learning_rate": 4.069277108433735e-06,
      "loss": 0.3662,
      "step": 1236
    },
    {
      "epoch": 0.7451807228915662,
      "grad_norm": 0.6513015031814575,
      "learning_rate": 4.0685240963855426e-06,
      "loss": 0.3811,
      "step": 1237
    },
    {
      "epoch": 0.7457831325301205,
      "grad_norm": 0.7065624594688416,
      "learning_rate": 4.0677710843373495e-06,
      "loss": 0.3611,
      "step": 1238
    },
    {
      "epoch": 0.7463855421686747,
      "grad_norm": 0.6146761178970337,
      "learning_rate": 4.067018072289156e-06,
      "loss": 0.3155,
      "step": 1239
    },
    {
      "epoch": 0.7469879518072289,
      "grad_norm": 0.6259605288505554,
      "learning_rate": 4.066265060240964e-06,
      "loss": 0.3623,
      "step": 1240
    },
    {
      "epoch": 0.7475903614457832,
      "grad_norm": 0.714974582195282,
      "learning_rate": 4.065512048192771e-06,
      "loss": 0.3675,
      "step": 1241
    },
    {
      "epoch": 0.7481927710843373,
      "grad_norm": 0.6834539175033569,
      "learning_rate": 4.064759036144579e-06,
      "loss": 0.2981,
      "step": 1242
    },
    {
      "epoch": 0.7487951807228915,
      "grad_norm": 0.6284765005111694,
      "learning_rate": 4.064006024096386e-06,
      "loss": 0.3061,
      "step": 1243
    },
    {
      "epoch": 0.7493975903614458,
      "grad_norm": 0.6228946447372437,
      "learning_rate": 4.0632530120481936e-06,
      "loss": 0.3615,
      "step": 1244
    },
    {
      "epoch": 0.75,
      "grad_norm": 0.6452662348747253,
      "learning_rate": 4.0625000000000005e-06,
      "loss": 0.3569,
      "step": 1245
    },
    {
      "epoch": 0.7506024096385542,
      "grad_norm": 0.6177148222923279,
      "learning_rate": 4.061746987951807e-06,
      "loss": 0.28,
      "step": 1246
    },
    {
      "epoch": 0.7512048192771085,
      "grad_norm": 0.63768470287323,
      "learning_rate": 4.060993975903615e-06,
      "loss": 0.3381,
      "step": 1247
    },
    {
      "epoch": 0.7518072289156627,
      "grad_norm": 0.6947692036628723,
      "learning_rate": 4.060240963855422e-06,
      "loss": 0.3603,
      "step": 1248
    },
    {
      "epoch": 0.7524096385542168,
      "grad_norm": 0.746010959148407,
      "learning_rate": 4.059487951807229e-06,
      "loss": 0.361,
      "step": 1249
    },
    {
      "epoch": 0.7530120481927711,
      "grad_norm": 0.6463040113449097,
      "learning_rate": 4.058734939759037e-06,
      "loss": 0.3274,
      "step": 1250
    },
    {
      "epoch": 0.7536144578313253,
      "grad_norm": 0.5757336020469666,
      "learning_rate": 4.057981927710844e-06,
      "loss": 0.3295,
      "step": 1251
    },
    {
      "epoch": 0.7542168674698795,
      "grad_norm": 0.6231273412704468,
      "learning_rate": 4.057228915662651e-06,
      "loss": 0.2704,
      "step": 1252
    },
    {
      "epoch": 0.7548192771084338,
      "grad_norm": 1.8718147277832031,
      "learning_rate": 4.056475903614458e-06,
      "loss": 0.3967,
      "step": 1253
    },
    {
      "epoch": 0.755421686746988,
      "grad_norm": 0.6424660682678223,
      "learning_rate": 4.055722891566265e-06,
      "loss": 0.3369,
      "step": 1254
    },
    {
      "epoch": 0.7560240963855421,
      "grad_norm": 0.6496632695198059,
      "learning_rate": 4.054969879518072e-06,
      "loss": 0.2821,
      "step": 1255
    },
    {
      "epoch": 0.7566265060240964,
      "grad_norm": 0.6833006143569946,
      "learning_rate": 4.05421686746988e-06,
      "loss": 0.311,
      "step": 1256
    },
    {
      "epoch": 0.7572289156626506,
      "grad_norm": 0.6339020729064941,
      "learning_rate": 4.053463855421687e-06,
      "loss": 0.3827,
      "step": 1257
    },
    {
      "epoch": 0.7578313253012048,
      "grad_norm": 0.6548845767974854,
      "learning_rate": 4.052710843373494e-06,
      "loss": 0.3441,
      "step": 1258
    },
    {
      "epoch": 0.7584337349397591,
      "grad_norm": 0.6124601364135742,
      "learning_rate": 4.051957831325302e-06,
      "loss": 0.33,
      "step": 1259
    },
    {
      "epoch": 0.7590361445783133,
      "grad_norm": 0.6618496775627136,
      "learning_rate": 4.051204819277109e-06,
      "loss": 0.3595,
      "step": 1260
    },
    {
      "epoch": 0.7596385542168674,
      "grad_norm": 0.600714385509491,
      "learning_rate": 4.050451807228916e-06,
      "loss": 0.286,
      "step": 1261
    },
    {
      "epoch": 0.7602409638554217,
      "grad_norm": 0.742878258228302,
      "learning_rate": 4.049698795180723e-06,
      "loss": 0.2679,
      "step": 1262
    },
    {
      "epoch": 0.7608433734939759,
      "grad_norm": 0.628395676612854,
      "learning_rate": 4.048945783132531e-06,
      "loss": 0.3269,
      "step": 1263
    },
    {
      "epoch": 0.7614457831325301,
      "grad_norm": 0.616290807723999,
      "learning_rate": 4.048192771084338e-06,
      "loss": 0.3184,
      "step": 1264
    },
    {
      "epoch": 0.7620481927710844,
      "grad_norm": 0.6116945147514343,
      "learning_rate": 4.047439759036145e-06,
      "loss": 0.3635,
      "step": 1265
    },
    {
      "epoch": 0.7626506024096386,
      "grad_norm": 0.6263760924339294,
      "learning_rate": 4.046686746987953e-06,
      "loss": 0.3486,
      "step": 1266
    },
    {
      "epoch": 0.7632530120481927,
      "grad_norm": 0.6438300013542175,
      "learning_rate": 4.04593373493976e-06,
      "loss": 0.3348,
      "step": 1267
    },
    {
      "epoch": 0.763855421686747,
      "grad_norm": 0.7289503216743469,
      "learning_rate": 4.0451807228915665e-06,
      "loss": 0.3722,
      "step": 1268
    },
    {
      "epoch": 0.7644578313253012,
      "grad_norm": 0.6300590634346008,
      "learning_rate": 4.0444277108433735e-06,
      "loss": 0.3841,
      "step": 1269
    },
    {
      "epoch": 0.7650602409638554,
      "grad_norm": 0.735176682472229,
      "learning_rate": 4.043674698795181e-06,
      "loss": 0.4026,
      "step": 1270
    },
    {
      "epoch": 0.7656626506024097,
      "grad_norm": 0.7484143972396851,
      "learning_rate": 4.042921686746988e-06,
      "loss": 0.3229,
      "step": 1271
    },
    {
      "epoch": 0.7662650602409639,
      "grad_norm": 0.6194080710411072,
      "learning_rate": 4.042168674698795e-06,
      "loss": 0.3011,
      "step": 1272
    },
    {
      "epoch": 0.766867469879518,
      "grad_norm": 0.617606520652771,
      "learning_rate": 4.041415662650603e-06,
      "loss": 0.3146,
      "step": 1273
    },
    {
      "epoch": 0.7674698795180723,
      "grad_norm": 0.5469546318054199,
      "learning_rate": 4.04066265060241e-06,
      "loss": 0.2769,
      "step": 1274
    },
    {
      "epoch": 0.7680722891566265,
      "grad_norm": 0.629283607006073,
      "learning_rate": 4.0399096385542176e-06,
      "loss": 0.3367,
      "step": 1275
    },
    {
      "epoch": 0.7686746987951807,
      "grad_norm": 0.5972431898117065,
      "learning_rate": 4.0391566265060245e-06,
      "loss": 0.4031,
      "step": 1276
    },
    {
      "epoch": 0.769277108433735,
      "grad_norm": 0.7306755185127258,
      "learning_rate": 4.038403614457831e-06,
      "loss": 0.2618,
      "step": 1277
    },
    {
      "epoch": 0.7698795180722892,
      "grad_norm": 0.5673789978027344,
      "learning_rate": 4.037650602409639e-06,
      "loss": 0.3324,
      "step": 1278
    },
    {
      "epoch": 0.7704819277108433,
      "grad_norm": 0.6718401312828064,
      "learning_rate": 4.036897590361446e-06,
      "loss": 0.2965,
      "step": 1279
    },
    {
      "epoch": 0.7710843373493976,
      "grad_norm": 0.6196247339248657,
      "learning_rate": 4.036144578313254e-06,
      "loss": 0.3534,
      "step": 1280
    },
    {
      "epoch": 0.7716867469879518,
      "grad_norm": 0.6686843633651733,
      "learning_rate": 4.035391566265061e-06,
      "loss": 0.3362,
      "step": 1281
    },
    {
      "epoch": 0.772289156626506,
      "grad_norm": 0.6558105945587158,
      "learning_rate": 4.034638554216868e-06,
      "loss": 0.2995,
      "step": 1282
    },
    {
      "epoch": 0.7728915662650603,
      "grad_norm": 0.6008678078651428,
      "learning_rate": 4.0338855421686755e-06,
      "loss": 0.3346,
      "step": 1283
    },
    {
      "epoch": 0.7734939759036145,
      "grad_norm": 0.6263175010681152,
      "learning_rate": 4.033132530120482e-06,
      "loss": 0.3823,
      "step": 1284
    },
    {
      "epoch": 0.7740963855421686,
      "grad_norm": 0.5866049528121948,
      "learning_rate": 4.032379518072289e-06,
      "loss": 0.3332,
      "step": 1285
    },
    {
      "epoch": 0.7746987951807229,
      "grad_norm": 0.6222193837165833,
      "learning_rate": 4.031626506024096e-06,
      "loss": 0.3067,
      "step": 1286
    },
    {
      "epoch": 0.7753012048192771,
      "grad_norm": 0.6535369753837585,
      "learning_rate": 4.030873493975904e-06,
      "loss": 0.3413,
      "step": 1287
    },
    {
      "epoch": 0.7759036144578313,
      "grad_norm": 0.6354822516441345,
      "learning_rate": 4.030120481927711e-06,
      "loss": 0.3496,
      "step": 1288
    },
    {
      "epoch": 0.7765060240963856,
      "grad_norm": 0.609175443649292,
      "learning_rate": 4.029367469879518e-06,
      "loss": 0.3198,
      "step": 1289
    },
    {
      "epoch": 0.7771084337349398,
      "grad_norm": 0.6117268800735474,
      "learning_rate": 4.028614457831326e-06,
      "loss": 0.3285,
      "step": 1290
    },
    {
      "epoch": 0.7777108433734939,
      "grad_norm": 0.68714839220047,
      "learning_rate": 4.027861445783133e-06,
      "loss": 0.4261,
      "step": 1291
    },
    {
      "epoch": 0.7783132530120482,
      "grad_norm": 0.6184390187263489,
      "learning_rate": 4.02710843373494e-06,
      "loss": 0.3672,
      "step": 1292
    },
    {
      "epoch": 0.7789156626506024,
      "grad_norm": 0.7787360548973083,
      "learning_rate": 4.026355421686747e-06,
      "loss": 0.3112,
      "step": 1293
    },
    {
      "epoch": 0.7795180722891566,
      "grad_norm": 0.6089714169502258,
      "learning_rate": 4.025602409638554e-06,
      "loss": 0.3525,
      "step": 1294
    },
    {
      "epoch": 0.7801204819277109,
      "grad_norm": 0.6705126762390137,
      "learning_rate": 4.024849397590362e-06,
      "loss": 0.3722,
      "step": 1295
    },
    {
      "epoch": 0.7807228915662651,
      "grad_norm": 0.6621392369270325,
      "learning_rate": 4.024096385542169e-06,
      "loss": 0.3642,
      "step": 1296
    },
    {
      "epoch": 0.7813253012048192,
      "grad_norm": 0.6657876372337341,
      "learning_rate": 4.023343373493977e-06,
      "loss": 0.3666,
      "step": 1297
    },
    {
      "epoch": 0.7819277108433735,
      "grad_norm": 0.5804451107978821,
      "learning_rate": 4.022590361445784e-06,
      "loss": 0.3286,
      "step": 1298
    },
    {
      "epoch": 0.7825301204819277,
      "grad_norm": 0.7140730619430542,
      "learning_rate": 4.021837349397591e-06,
      "loss": 0.3473,
      "step": 1299
    },
    {
      "epoch": 0.7831325301204819,
      "grad_norm": 0.6216347217559814,
      "learning_rate": 4.021084337349398e-06,
      "loss": 0.3006,
      "step": 1300
    },
    {
      "epoch": 0.7837349397590362,
      "grad_norm": 0.6258114576339722,
      "learning_rate": 4.020331325301205e-06,
      "loss": 0.3695,
      "step": 1301
    },
    {
      "epoch": 0.7843373493975904,
      "grad_norm": 0.7005812525749207,
      "learning_rate": 4.019578313253012e-06,
      "loss": 0.3635,
      "step": 1302
    },
    {
      "epoch": 0.7849397590361445,
      "grad_norm": 0.6109564900398254,
      "learning_rate": 4.01882530120482e-06,
      "loss": 0.3657,
      "step": 1303
    },
    {
      "epoch": 0.7855421686746988,
      "grad_norm": 0.5871607065200806,
      "learning_rate": 4.018072289156627e-06,
      "loss": 0.3705,
      "step": 1304
    },
    {
      "epoch": 0.786144578313253,
      "grad_norm": 0.6436138153076172,
      "learning_rate": 4.017319277108434e-06,
      "loss": 0.3035,
      "step": 1305
    },
    {
      "epoch": 0.7867469879518072,
      "grad_norm": 0.6891603469848633,
      "learning_rate": 4.016566265060241e-06,
      "loss": 0.3347,
      "step": 1306
    },
    {
      "epoch": 0.7873493975903615,
      "grad_norm": 0.6281223297119141,
      "learning_rate": 4.0158132530120485e-06,
      "loss": 0.3562,
      "step": 1307
    },
    {
      "epoch": 0.7879518072289157,
      "grad_norm": 0.6842108368873596,
      "learning_rate": 4.015060240963855e-06,
      "loss": 0.3495,
      "step": 1308
    },
    {
      "epoch": 0.7885542168674698,
      "grad_norm": 0.6588818430900574,
      "learning_rate": 4.014307228915663e-06,
      "loss": 0.2838,
      "step": 1309
    },
    {
      "epoch": 0.7891566265060241,
      "grad_norm": 0.6640658378601074,
      "learning_rate": 4.01355421686747e-06,
      "loss": 0.3586,
      "step": 1310
    },
    {
      "epoch": 0.7897590361445783,
      "grad_norm": 0.653046727180481,
      "learning_rate": 4.012801204819278e-06,
      "loss": 0.3005,
      "step": 1311
    },
    {
      "epoch": 0.7903614457831325,
      "grad_norm": 0.6317229866981506,
      "learning_rate": 4.012048192771085e-06,
      "loss": 0.336,
      "step": 1312
    },
    {
      "epoch": 0.7909638554216868,
      "grad_norm": 0.6044146418571472,
      "learning_rate": 4.011295180722892e-06,
      "loss": 0.2921,
      "step": 1313
    },
    {
      "epoch": 0.791566265060241,
      "grad_norm": 0.5884524583816528,
      "learning_rate": 4.0105421686746995e-06,
      "loss": 0.2934,
      "step": 1314
    },
    {
      "epoch": 0.7921686746987951,
      "grad_norm": 0.6843963265419006,
      "learning_rate": 4.009789156626506e-06,
      "loss": 0.3122,
      "step": 1315
    },
    {
      "epoch": 0.7927710843373494,
      "grad_norm": 0.5799911022186279,
      "learning_rate": 4.009036144578314e-06,
      "loss": 0.308,
      "step": 1316
    },
    {
      "epoch": 0.7933734939759036,
      "grad_norm": 0.5991789102554321,
      "learning_rate": 4.008283132530121e-06,
      "loss": 0.3228,
      "step": 1317
    },
    {
      "epoch": 0.7939759036144578,
      "grad_norm": 0.6013009548187256,
      "learning_rate": 4.007530120481928e-06,
      "loss": 0.2828,
      "step": 1318
    },
    {
      "epoch": 0.7945783132530121,
      "grad_norm": 0.697762131690979,
      "learning_rate": 4.006777108433735e-06,
      "loss": 0.3349,
      "step": 1319
    },
    {
      "epoch": 0.7951807228915663,
      "grad_norm": 0.6307864189147949,
      "learning_rate": 4.006024096385543e-06,
      "loss": 0.2806,
      "step": 1320
    },
    {
      "epoch": 0.7957831325301205,
      "grad_norm": 0.650434136390686,
      "learning_rate": 4.00527108433735e-06,
      "loss": 0.4076,
      "step": 1321
    },
    {
      "epoch": 0.7963855421686747,
      "grad_norm": 0.6774481534957886,
      "learning_rate": 4.0045180722891566e-06,
      "loss": 0.2994,
      "step": 1322
    },
    {
      "epoch": 0.7969879518072289,
      "grad_norm": 0.5776358842849731,
      "learning_rate": 4.003765060240964e-06,
      "loss": 0.3466,
      "step": 1323
    },
    {
      "epoch": 0.7975903614457831,
      "grad_norm": 0.6331484317779541,
      "learning_rate": 4.003012048192771e-06,
      "loss": 0.3188,
      "step": 1324
    },
    {
      "epoch": 0.7981927710843374,
      "grad_norm": 0.6793795824050903,
      "learning_rate": 4.002259036144578e-06,
      "loss": 0.3435,
      "step": 1325
    },
    {
      "epoch": 0.7987951807228916,
      "grad_norm": 0.6380743980407715,
      "learning_rate": 4.001506024096386e-06,
      "loss": 0.2983,
      "step": 1326
    },
    {
      "epoch": 0.7993975903614458,
      "grad_norm": 0.5929045677185059,
      "learning_rate": 4.000753012048193e-06,
      "loss": 0.3009,
      "step": 1327
    },
    {
      "epoch": 0.8,
      "grad_norm": 0.6801179051399231,
      "learning_rate": 4.000000000000001e-06,
      "loss": 0.3067,
      "step": 1328
    },
    {
      "epoch": 0.8006024096385542,
      "grad_norm": 0.6419205665588379,
      "learning_rate": 3.999246987951808e-06,
      "loss": 0.3449,
      "step": 1329
    },
    {
      "epoch": 0.8012048192771084,
      "grad_norm": 0.6122211813926697,
      "learning_rate": 3.9984939759036145e-06,
      "loss": 0.2983,
      "step": 1330
    },
    {
      "epoch": 0.8018072289156627,
      "grad_norm": 0.5620651841163635,
      "learning_rate": 3.997740963855422e-06,
      "loss": 0.3013,
      "step": 1331
    },
    {
      "epoch": 0.8024096385542169,
      "grad_norm": 0.6554595232009888,
      "learning_rate": 3.996987951807229e-06,
      "loss": 0.3088,
      "step": 1332
    },
    {
      "epoch": 0.803012048192771,
      "grad_norm": 0.627943217754364,
      "learning_rate": 3.996234939759037e-06,
      "loss": 0.3918,
      "step": 1333
    },
    {
      "epoch": 0.8036144578313253,
      "grad_norm": 0.5611220598220825,
      "learning_rate": 3.995481927710844e-06,
      "loss": 0.3659,
      "step": 1334
    },
    {
      "epoch": 0.8042168674698795,
      "grad_norm": 0.6513849496841431,
      "learning_rate": 3.994728915662651e-06,
      "loss": 0.3188,
      "step": 1335
    },
    {
      "epoch": 0.8048192771084337,
      "grad_norm": 0.6782734990119934,
      "learning_rate": 3.993975903614459e-06,
      "loss": 0.3716,
      "step": 1336
    },
    {
      "epoch": 0.805421686746988,
      "grad_norm": 0.7453643083572388,
      "learning_rate": 3.9932228915662655e-06,
      "loss": 0.3924,
      "step": 1337
    },
    {
      "epoch": 0.8060240963855422,
      "grad_norm": 0.7016344666481018,
      "learning_rate": 3.9924698795180725e-06,
      "loss": 0.3376,
      "step": 1338
    },
    {
      "epoch": 0.8066265060240964,
      "grad_norm": 0.7014093995094299,
      "learning_rate": 3.991716867469879e-06,
      "loss": 0.3615,
      "step": 1339
    },
    {
      "epoch": 0.8072289156626506,
      "grad_norm": 0.5761497020721436,
      "learning_rate": 3.990963855421687e-06,
      "loss": 0.3461,
      "step": 1340
    },
    {
      "epoch": 0.8078313253012048,
      "grad_norm": 0.5656259059906006,
      "learning_rate": 3.990210843373494e-06,
      "loss": 0.3092,
      "step": 1341
    },
    {
      "epoch": 0.808433734939759,
      "grad_norm": 0.6396241188049316,
      "learning_rate": 3.989457831325301e-06,
      "loss": 0.3576,
      "step": 1342
    },
    {
      "epoch": 0.8090361445783133,
      "grad_norm": 0.59798663854599,
      "learning_rate": 3.988704819277109e-06,
      "loss": 0.3484,
      "step": 1343
    },
    {
      "epoch": 0.8096385542168675,
      "grad_norm": 0.6356911659240723,
      "learning_rate": 3.987951807228916e-06,
      "loss": 0.3498,
      "step": 1344
    },
    {
      "epoch": 0.8102409638554217,
      "grad_norm": 0.6067638397216797,
      "learning_rate": 3.9871987951807235e-06,
      "loss": 0.32,
      "step": 1345
    },
    {
      "epoch": 0.810843373493976,
      "grad_norm": 0.6191250085830688,
      "learning_rate": 3.98644578313253e-06,
      "loss": 0.3617,
      "step": 1346
    },
    {
      "epoch": 0.8114457831325301,
      "grad_norm": 0.6212612390518188,
      "learning_rate": 3.985692771084338e-06,
      "loss": 0.3361,
      "step": 1347
    },
    {
      "epoch": 0.8120481927710843,
      "grad_norm": 0.6909214854240417,
      "learning_rate": 3.984939759036145e-06,
      "loss": 0.3234,
      "step": 1348
    },
    {
      "epoch": 0.8126506024096386,
      "grad_norm": 0.5728858709335327,
      "learning_rate": 3.984186746987952e-06,
      "loss": 0.3245,
      "step": 1349
    },
    {
      "epoch": 0.8132530120481928,
      "grad_norm": 0.6594992876052856,
      "learning_rate": 3.98343373493976e-06,
      "loss": 0.2854,
      "step": 1350
    },
    {
      "epoch": 0.813855421686747,
      "grad_norm": 0.601481020450592,
      "learning_rate": 3.982680722891567e-06,
      "loss": 0.3422,
      "step": 1351
    },
    {
      "epoch": 0.8144578313253013,
      "grad_norm": 0.6119340658187866,
      "learning_rate": 3.981927710843374e-06,
      "loss": 0.2734,
      "step": 1352
    },
    {
      "epoch": 0.8150602409638554,
      "grad_norm": 0.5223624110221863,
      "learning_rate": 3.981174698795181e-06,
      "loss": 0.3019,
      "step": 1353
    },
    {
      "epoch": 0.8156626506024096,
      "grad_norm": 0.6615728735923767,
      "learning_rate": 3.980421686746988e-06,
      "loss": 0.3133,
      "step": 1354
    },
    {
      "epoch": 0.8162650602409639,
      "grad_norm": 0.6171455383300781,
      "learning_rate": 3.979668674698795e-06,
      "loss": 0.3284,
      "step": 1355
    },
    {
      "epoch": 0.8168674698795181,
      "grad_norm": 0.6426794528961182,
      "learning_rate": 3.978915662650602e-06,
      "loss": 0.3445,
      "step": 1356
    },
    {
      "epoch": 0.8174698795180723,
      "grad_norm": 0.6206945776939392,
      "learning_rate": 3.97816265060241e-06,
      "loss": 0.3066,
      "step": 1357
    },
    {
      "epoch": 0.8180722891566266,
      "grad_norm": 0.58650141954422,
      "learning_rate": 3.977409638554217e-06,
      "loss": 0.3303,
      "step": 1358
    },
    {
      "epoch": 0.8186746987951807,
      "grad_norm": 0.6745992302894592,
      "learning_rate": 3.976656626506025e-06,
      "loss": 0.3286,
      "step": 1359
    },
    {
      "epoch": 0.8192771084337349,
      "grad_norm": 0.5994076728820801,
      "learning_rate": 3.975903614457832e-06,
      "loss": 0.3284,
      "step": 1360
    },
    {
      "epoch": 0.8198795180722892,
      "grad_norm": 0.5821515917778015,
      "learning_rate": 3.9751506024096385e-06,
      "loss": 0.3381,
      "step": 1361
    },
    {
      "epoch": 0.8204819277108434,
      "grad_norm": 0.5986096858978271,
      "learning_rate": 3.974397590361446e-06,
      "loss": 0.3506,
      "step": 1362
    },
    {
      "epoch": 0.8210843373493976,
      "grad_norm": 0.6910016536712646,
      "learning_rate": 3.973644578313253e-06,
      "loss": 0.3024,
      "step": 1363
    },
    {
      "epoch": 0.8216867469879519,
      "grad_norm": 0.6776958703994751,
      "learning_rate": 3.972891566265061e-06,
      "loss": 0.3428,
      "step": 1364
    },
    {
      "epoch": 0.822289156626506,
      "grad_norm": 0.6989503502845764,
      "learning_rate": 3.972138554216868e-06,
      "loss": 0.397,
      "step": 1365
    },
    {
      "epoch": 0.8228915662650602,
      "grad_norm": 0.6126896142959595,
      "learning_rate": 3.971385542168675e-06,
      "loss": 0.3414,
      "step": 1366
    },
    {
      "epoch": 0.8234939759036145,
      "grad_norm": 3.1984481811523438,
      "learning_rate": 3.970632530120483e-06,
      "loss": 0.2973,
      "step": 1367
    },
    {
      "epoch": 0.8240963855421687,
      "grad_norm": 0.658194899559021,
      "learning_rate": 3.9698795180722895e-06,
      "loss": 0.3223,
      "step": 1368
    },
    {
      "epoch": 0.8246987951807229,
      "grad_norm": 0.564806342124939,
      "learning_rate": 3.969126506024097e-06,
      "loss": 0.339,
      "step": 1369
    },
    {
      "epoch": 0.8253012048192772,
      "grad_norm": 0.6079427003860474,
      "learning_rate": 3.968373493975904e-06,
      "loss": 0.3528,
      "step": 1370
    },
    {
      "epoch": 0.8259036144578313,
      "grad_norm": 0.6791492700576782,
      "learning_rate": 3.967620481927711e-06,
      "loss": 0.2996,
      "step": 1371
    },
    {
      "epoch": 0.8265060240963855,
      "grad_norm": 0.6476836800575256,
      "learning_rate": 3.966867469879518e-06,
      "loss": 0.304,
      "step": 1372
    },
    {
      "epoch": 0.8271084337349398,
      "grad_norm": 0.7100253701210022,
      "learning_rate": 3.966114457831326e-06,
      "loss": 0.3392,
      "step": 1373
    },
    {
      "epoch": 0.827710843373494,
      "grad_norm": 0.6485374569892883,
      "learning_rate": 3.965361445783133e-06,
      "loss": 0.3437,
      "step": 1374
    },
    {
      "epoch": 0.8283132530120482,
      "grad_norm": 0.593036949634552,
      "learning_rate": 3.96460843373494e-06,
      "loss": 0.3227,
      "step": 1375
    },
    {
      "epoch": 0.8289156626506025,
      "grad_norm": 0.6757646799087524,
      "learning_rate": 3.9638554216867475e-06,
      "loss": 0.2972,
      "step": 1376
    },
    {
      "epoch": 0.8295180722891566,
      "grad_norm": 0.6048094630241394,
      "learning_rate": 3.963102409638554e-06,
      "loss": 0.3352,
      "step": 1377
    },
    {
      "epoch": 0.8301204819277108,
      "grad_norm": 0.6721474528312683,
      "learning_rate": 3.962349397590361e-06,
      "loss": 0.3457,
      "step": 1378
    },
    {
      "epoch": 0.8307228915662651,
      "grad_norm": 0.5574052333831787,
      "learning_rate": 3.961596385542169e-06,
      "loss": 0.3529,
      "step": 1379
    },
    {
      "epoch": 0.8313253012048193,
      "grad_norm": 0.6294012069702148,
      "learning_rate": 3.960843373493976e-06,
      "loss": 0.3105,
      "step": 1380
    },
    {
      "epoch": 0.8319277108433735,
      "grad_norm": 0.6508021950721741,
      "learning_rate": 3.960090361445784e-06,
      "loss": 0.3345,
      "step": 1381
    },
    {
      "epoch": 0.8325301204819278,
      "grad_norm": 0.5635744333267212,
      "learning_rate": 3.959337349397591e-06,
      "loss": 0.335,
      "step": 1382
    },
    {
      "epoch": 0.8331325301204819,
      "grad_norm": 0.6417914628982544,
      "learning_rate": 3.9585843373493985e-06,
      "loss": 0.3127,
      "step": 1383
    },
    {
      "epoch": 0.8337349397590361,
      "grad_norm": 0.5799146890640259,
      "learning_rate": 3.957831325301205e-06,
      "loss": 0.2681,
      "step": 1384
    },
    {
      "epoch": 0.8343373493975904,
      "grad_norm": 0.6010491847991943,
      "learning_rate": 3.957078313253012e-06,
      "loss": 0.3124,
      "step": 1385
    },
    {
      "epoch": 0.8349397590361446,
      "grad_norm": 0.5587651133537292,
      "learning_rate": 3.95632530120482e-06,
      "loss": 0.336,
      "step": 1386
    },
    {
      "epoch": 0.8355421686746988,
      "grad_norm": 0.7652880549430847,
      "learning_rate": 3.955572289156627e-06,
      "loss": 0.375,
      "step": 1387
    },
    {
      "epoch": 0.8361445783132531,
      "grad_norm": 0.6400353312492371,
      "learning_rate": 3.954819277108434e-06,
      "loss": 0.3008,
      "step": 1388
    },
    {
      "epoch": 0.8367469879518072,
      "grad_norm": 0.6172617077827454,
      "learning_rate": 3.954066265060241e-06,
      "loss": 0.3703,
      "step": 1389
    },
    {
      "epoch": 0.8373493975903614,
      "grad_norm": 0.6033502221107483,
      "learning_rate": 3.953313253012049e-06,
      "loss": 0.2828,
      "step": 1390
    },
    {
      "epoch": 0.8379518072289157,
      "grad_norm": 0.6023856401443481,
      "learning_rate": 3.9525602409638556e-06,
      "loss": 0.2734,
      "step": 1391
    },
    {
      "epoch": 0.8385542168674699,
      "grad_norm": 0.5573145747184753,
      "learning_rate": 3.9518072289156625e-06,
      "loss": 0.3011,
      "step": 1392
    },
    {
      "epoch": 0.8391566265060241,
      "grad_norm": 0.7295176982879639,
      "learning_rate": 3.95105421686747e-06,
      "loss": 0.3492,
      "step": 1393
    },
    {
      "epoch": 0.8397590361445784,
      "grad_norm": 0.7031347751617432,
      "learning_rate": 3.950301204819277e-06,
      "loss": 0.3572,
      "step": 1394
    },
    {
      "epoch": 0.8403614457831325,
      "grad_norm": 0.6086476445198059,
      "learning_rate": 3.949548192771085e-06,
      "loss": 0.3741,
      "step": 1395
    },
    {
      "epoch": 0.8409638554216867,
      "grad_norm": 0.6262593269348145,
      "learning_rate": 3.948795180722892e-06,
      "loss": 0.2867,
      "step": 1396
    },
    {
      "epoch": 0.841566265060241,
      "grad_norm": 0.6361790299415588,
      "learning_rate": 3.948042168674699e-06,
      "loss": 0.3343,
      "step": 1397
    },
    {
      "epoch": 0.8421686746987952,
      "grad_norm": 0.6084529757499695,
      "learning_rate": 3.947289156626507e-06,
      "loss": 0.2878,
      "step": 1398
    },
    {
      "epoch": 0.8427710843373494,
      "grad_norm": 0.601015567779541,
      "learning_rate": 3.9465361445783135e-06,
      "loss": 0.3253,
      "step": 1399
    },
    {
      "epoch": 0.8433734939759037,
      "grad_norm": 0.7950971126556396,
      "learning_rate": 3.945783132530121e-06,
      "loss": 0.3476,
      "step": 1400
    },
    {
      "epoch": 0.8439759036144578,
      "grad_norm": 0.6769210696220398,
      "learning_rate": 3.945030120481928e-06,
      "loss": 0.4046,
      "step": 1401
    },
    {
      "epoch": 0.844578313253012,
      "grad_norm": 0.643587052822113,
      "learning_rate": 3.944277108433735e-06,
      "loss": 0.3337,
      "step": 1402
    },
    {
      "epoch": 0.8451807228915663,
      "grad_norm": 0.6032992005348206,
      "learning_rate": 3.943524096385543e-06,
      "loss": 0.3017,
      "step": 1403
    },
    {
      "epoch": 0.8457831325301205,
      "grad_norm": 0.6370447278022766,
      "learning_rate": 3.94277108433735e-06,
      "loss": 0.3545,
      "step": 1404
    },
    {
      "epoch": 0.8463855421686747,
      "grad_norm": 0.5494651794433594,
      "learning_rate": 3.942018072289157e-06,
      "loss": 0.3322,
      "step": 1405
    },
    {
      "epoch": 0.846987951807229,
      "grad_norm": 0.598192036151886,
      "learning_rate": 3.9412650602409645e-06,
      "loss": 0.32,
      "step": 1406
    },
    {
      "epoch": 0.8475903614457831,
      "grad_norm": 0.6058151721954346,
      "learning_rate": 3.9405120481927714e-06,
      "loss": 0.3486,
      "step": 1407
    },
    {
      "epoch": 0.8481927710843373,
      "grad_norm": 0.606070339679718,
      "learning_rate": 3.939759036144578e-06,
      "loss": 0.2991,
      "step": 1408
    },
    {
      "epoch": 0.8487951807228916,
      "grad_norm": 0.5870070457458496,
      "learning_rate": 3.939006024096385e-06,
      "loss": 0.3477,
      "step": 1409
    },
    {
      "epoch": 0.8493975903614458,
      "grad_norm": 0.6793394684791565,
      "learning_rate": 3.938253012048193e-06,
      "loss": 0.356,
      "step": 1410
    },
    {
      "epoch": 0.85,
      "grad_norm": 0.5940564274787903,
      "learning_rate": 3.9375e-06,
      "loss": 0.2847,
      "step": 1411
    },
    {
      "epoch": 0.8506024096385543,
      "grad_norm": 0.6172290444374084,
      "learning_rate": 3.936746987951808e-06,
      "loss": 0.329,
      "step": 1412
    },
    {
      "epoch": 0.8512048192771084,
      "grad_norm": 0.5754877328872681,
      "learning_rate": 3.935993975903615e-06,
      "loss": 0.2943,
      "step": 1413
    },
    {
      "epoch": 0.8518072289156626,
      "grad_norm": 0.7081038355827332,
      "learning_rate": 3.935240963855422e-06,
      "loss": 0.3582,
      "step": 1414
    },
    {
      "epoch": 0.8524096385542169,
      "grad_norm": 0.5963576436042786,
      "learning_rate": 3.934487951807229e-06,
      "loss": 0.2735,
      "step": 1415
    },
    {
      "epoch": 0.8530120481927711,
      "grad_norm": 0.618776798248291,
      "learning_rate": 3.933734939759036e-06,
      "loss": 0.3506,
      "step": 1416
    },
    {
      "epoch": 0.8536144578313253,
      "grad_norm": 0.5732441544532776,
      "learning_rate": 3.932981927710844e-06,
      "loss": 0.2883,
      "step": 1417
    },
    {
      "epoch": 0.8542168674698796,
      "grad_norm": 0.6197009682655334,
      "learning_rate": 3.932228915662651e-06,
      "loss": 0.3203,
      "step": 1418
    },
    {
      "epoch": 0.8548192771084338,
      "grad_norm": 0.59293133020401,
      "learning_rate": 3.931475903614459e-06,
      "loss": 0.3045,
      "step": 1419
    },
    {
      "epoch": 0.8554216867469879,
      "grad_norm": 0.6446619629859924,
      "learning_rate": 3.930722891566266e-06,
      "loss": 0.3564,
      "step": 1420
    },
    {
      "epoch": 0.8560240963855422,
      "grad_norm": 0.5994415283203125,
      "learning_rate": 3.929969879518073e-06,
      "loss": 0.2931,
      "step": 1421
    },
    {
      "epoch": 0.8566265060240964,
      "grad_norm": 0.5201547741889954,
      "learning_rate": 3.9292168674698796e-06,
      "loss": 0.2881,
      "step": 1422
    },
    {
      "epoch": 0.8572289156626506,
      "grad_norm": 0.5957947969436646,
      "learning_rate": 3.928463855421687e-06,
      "loss": 0.3024,
      "step": 1423
    },
    {
      "epoch": 0.8578313253012049,
      "grad_norm": 0.6031786203384399,
      "learning_rate": 3.927710843373494e-06,
      "loss": 0.3187,
      "step": 1424
    },
    {
      "epoch": 0.858433734939759,
      "grad_norm": 0.6698057651519775,
      "learning_rate": 3.926957831325301e-06,
      "loss": 0.3154,
      "step": 1425
    },
    {
      "epoch": 0.8590361445783132,
      "grad_norm": 0.6066098213195801,
      "learning_rate": 3.926204819277108e-06,
      "loss": 0.3214,
      "step": 1426
    },
    {
      "epoch": 0.8596385542168675,
      "grad_norm": 0.6022853255271912,
      "learning_rate": 3.925451807228916e-06,
      "loss": 0.3263,
      "step": 1427
    },
    {
      "epoch": 0.8602409638554217,
      "grad_norm": 0.6293557286262512,
      "learning_rate": 3.924698795180723e-06,
      "loss": 0.3148,
      "step": 1428
    },
    {
      "epoch": 0.8608433734939759,
      "grad_norm": 0.6071876287460327,
      "learning_rate": 3.9239457831325306e-06,
      "loss": 0.3513,
      "step": 1429
    },
    {
      "epoch": 0.8614457831325302,
      "grad_norm": 0.6272757053375244,
      "learning_rate": 3.9231927710843375e-06,
      "loss": 0.3207,
      "step": 1430
    },
    {
      "epoch": 0.8620481927710844,
      "grad_norm": 0.6760497093200684,
      "learning_rate": 3.922439759036145e-06,
      "loss": 0.3616,
      "step": 1431
    },
    {
      "epoch": 0.8626506024096385,
      "grad_norm": 0.6228219866752625,
      "learning_rate": 3.921686746987952e-06,
      "loss": 0.2975,
      "step": 1432
    },
    {
      "epoch": 0.8632530120481928,
      "grad_norm": 0.6470205187797546,
      "learning_rate": 3.920933734939759e-06,
      "loss": 0.2946,
      "step": 1433
    },
    {
      "epoch": 0.863855421686747,
      "grad_norm": 0.6262308955192566,
      "learning_rate": 3.920180722891567e-06,
      "loss": 0.2979,
      "step": 1434
    },
    {
      "epoch": 0.8644578313253012,
      "grad_norm": 0.6120555996894836,
      "learning_rate": 3.919427710843374e-06,
      "loss": 0.3601,
      "step": 1435
    },
    {
      "epoch": 0.8650602409638555,
      "grad_norm": 0.6915979385375977,
      "learning_rate": 3.918674698795182e-06,
      "loss": 0.3669,
      "step": 1436
    },
    {
      "epoch": 0.8656626506024097,
      "grad_norm": 0.5589541792869568,
      "learning_rate": 3.9179216867469885e-06,
      "loss": 0.3317,
      "step": 1437
    },
    {
      "epoch": 0.8662650602409638,
      "grad_norm": 0.607118546962738,
      "learning_rate": 3.9171686746987954e-06,
      "loss": 0.3518,
      "step": 1438
    },
    {
      "epoch": 0.8668674698795181,
      "grad_norm": 0.6227332353591919,
      "learning_rate": 3.916415662650603e-06,
      "loss": 0.3165,
      "step": 1439
    },
    {
      "epoch": 0.8674698795180723,
      "grad_norm": 0.6581466794013977,
      "learning_rate": 3.91566265060241e-06,
      "loss": 0.3679,
      "step": 1440
    },
    {
      "epoch": 0.8680722891566265,
      "grad_norm": 0.5740444660186768,
      "learning_rate": 3.914909638554217e-06,
      "loss": 0.2723,
      "step": 1441
    },
    {
      "epoch": 0.8686746987951808,
      "grad_norm": 0.5948367714881897,
      "learning_rate": 3.914156626506024e-06,
      "loss": 0.3806,
      "step": 1442
    },
    {
      "epoch": 0.869277108433735,
      "grad_norm": 0.6018082499504089,
      "learning_rate": 3.913403614457832e-06,
      "loss": 0.2825,
      "step": 1443
    },
    {
      "epoch": 0.8698795180722891,
      "grad_norm": 0.6195386052131653,
      "learning_rate": 3.912650602409639e-06,
      "loss": 0.2801,
      "step": 1444
    },
    {
      "epoch": 0.8704819277108434,
      "grad_norm": 0.5687142014503479,
      "learning_rate": 3.911897590361446e-06,
      "loss": 0.2927,
      "step": 1445
    },
    {
      "epoch": 0.8710843373493976,
      "grad_norm": 0.6203567385673523,
      "learning_rate": 3.911144578313253e-06,
      "loss": 0.295,
      "step": 1446
    },
    {
      "epoch": 0.8716867469879518,
      "grad_norm": 0.6336008906364441,
      "learning_rate": 3.91039156626506e-06,
      "loss": 0.3563,
      "step": 1447
    },
    {
      "epoch": 0.8722891566265061,
      "grad_norm": 0.7858012914657593,
      "learning_rate": 3.909638554216868e-06,
      "loss": 0.3331,
      "step": 1448
    },
    {
      "epoch": 0.8728915662650603,
      "grad_norm": 1.0155388116836548,
      "learning_rate": 3.908885542168675e-06,
      "loss": 0.2971,
      "step": 1449
    },
    {
      "epoch": 0.8734939759036144,
      "grad_norm": 0.6691078543663025,
      "learning_rate": 3.908132530120482e-06,
      "loss": 0.3953,
      "step": 1450
    },
    {
      "epoch": 0.8740963855421687,
      "grad_norm": 0.645781397819519,
      "learning_rate": 3.90737951807229e-06,
      "loss": 0.3143,
      "step": 1451
    },
    {
      "epoch": 0.8746987951807229,
      "grad_norm": 0.5550936460494995,
      "learning_rate": 3.906626506024097e-06,
      "loss": 0.3296,
      "step": 1452
    },
    {
      "epoch": 0.8753012048192771,
      "grad_norm": 0.6181761622428894,
      "learning_rate": 3.905873493975904e-06,
      "loss": 0.2925,
      "step": 1453
    },
    {
      "epoch": 0.8759036144578313,
      "grad_norm": 0.5916808843612671,
      "learning_rate": 3.905120481927711e-06,
      "loss": 0.3083,
      "step": 1454
    },
    {
      "epoch": 0.8765060240963856,
      "grad_norm": 0.7072286605834961,
      "learning_rate": 3.904367469879518e-06,
      "loss": 0.3621,
      "step": 1455
    },
    {
      "epoch": 0.8771084337349397,
      "grad_norm": 0.5987376570701599,
      "learning_rate": 3.903614457831326e-06,
      "loss": 0.2925,
      "step": 1456
    },
    {
      "epoch": 0.8777108433734939,
      "grad_norm": 0.5414977073669434,
      "learning_rate": 3.902861445783133e-06,
      "loss": 0.3129,
      "step": 1457
    },
    {
      "epoch": 0.8783132530120482,
      "grad_norm": 0.59441077709198,
      "learning_rate": 3.90210843373494e-06,
      "loss": 0.2697,
      "step": 1458
    },
    {
      "epoch": 0.8789156626506024,
      "grad_norm": 0.5789410471916199,
      "learning_rate": 3.901355421686747e-06,
      "loss": 0.2639,
      "step": 1459
    },
    {
      "epoch": 0.8795180722891566,
      "grad_norm": 0.5992302894592285,
      "learning_rate": 3.9006024096385546e-06,
      "loss": 0.3702,
      "step": 1460
    },
    {
      "epoch": 0.8801204819277109,
      "grad_norm": 0.5708692669868469,
      "learning_rate": 3.8998493975903615e-06,
      "loss": 0.3283,
      "step": 1461
    },
    {
      "epoch": 0.880722891566265,
      "grad_norm": 0.6060417294502258,
      "learning_rate": 3.899096385542168e-06,
      "loss": 0.3247,
      "step": 1462
    },
    {
      "epoch": 0.8813253012048192,
      "grad_norm": 0.7509950399398804,
      "learning_rate": 3.898343373493976e-06,
      "loss": 0.3571,
      "step": 1463
    },
    {
      "epoch": 0.8819277108433735,
      "grad_norm": 0.6196795105934143,
      "learning_rate": 3.897590361445783e-06,
      "loss": 0.3246,
      "step": 1464
    },
    {
      "epoch": 0.8825301204819277,
      "grad_norm": 0.6399722695350647,
      "learning_rate": 3.896837349397591e-06,
      "loss": 0.3773,
      "step": 1465
    },
    {
      "epoch": 0.8831325301204819,
      "grad_norm": 0.5539848208427429,
      "learning_rate": 3.896084337349398e-06,
      "loss": 0.3357,
      "step": 1466
    },
    {
      "epoch": 0.8837349397590362,
      "grad_norm": 0.6491116285324097,
      "learning_rate": 3.8953313253012056e-06,
      "loss": 0.3044,
      "step": 1467
    },
    {
      "epoch": 0.8843373493975903,
      "grad_norm": 0.5303478837013245,
      "learning_rate": 3.8945783132530125e-06,
      "loss": 0.3006,
      "step": 1468
    },
    {
      "epoch": 0.8849397590361445,
      "grad_norm": 0.5889904499053955,
      "learning_rate": 3.8938253012048194e-06,
      "loss": 0.2905,
      "step": 1469
    },
    {
      "epoch": 0.8855421686746988,
      "grad_norm": 0.64664626121521,
      "learning_rate": 3.893072289156627e-06,
      "loss": 0.3835,
      "step": 1470
    },
    {
      "epoch": 0.886144578313253,
      "grad_norm": 0.6025084257125854,
      "learning_rate": 3.892319277108434e-06,
      "loss": 0.2976,
      "step": 1471
    },
    {
      "epoch": 0.8867469879518072,
      "grad_norm": 0.5852597951889038,
      "learning_rate": 3.891566265060242e-06,
      "loss": 0.3392,
      "step": 1472
    },
    {
      "epoch": 0.8873493975903615,
      "grad_norm": 0.6272315979003906,
      "learning_rate": 3.890813253012049e-06,
      "loss": 0.3396,
      "step": 1473
    },
    {
      "epoch": 0.8879518072289156,
      "grad_norm": 0.5656100511550903,
      "learning_rate": 3.890060240963856e-06,
      "loss": 0.329,
      "step": 1474
    },
    {
      "epoch": 0.8885542168674698,
      "grad_norm": 0.6999944448471069,
      "learning_rate": 3.889307228915663e-06,
      "loss": 0.3437,
      "step": 1475
    },
    {
      "epoch": 0.8891566265060241,
      "grad_norm": 0.5989434123039246,
      "learning_rate": 3.8885542168674704e-06,
      "loss": 0.3393,
      "step": 1476
    },
    {
      "epoch": 0.8897590361445783,
      "grad_norm": 0.6465456485748291,
      "learning_rate": 3.887801204819277e-06,
      "loss": 0.3374,
      "step": 1477
    },
    {
      "epoch": 0.8903614457831325,
      "grad_norm": 0.570784866809845,
      "learning_rate": 3.887048192771084e-06,
      "loss": 0.305,
      "step": 1478
    },
    {
      "epoch": 0.8909638554216868,
      "grad_norm": 0.5999892354011536,
      "learning_rate": 3.886295180722892e-06,
      "loss": 0.2749,
      "step": 1479
    },
    {
      "epoch": 0.891566265060241,
      "grad_norm": 0.6736495494842529,
      "learning_rate": 3.885542168674699e-06,
      "loss": 0.3785,
      "step": 1480
    },
    {
      "epoch": 0.8921686746987951,
      "grad_norm": 0.6472864747047424,
      "learning_rate": 3.884789156626506e-06,
      "loss": 0.3159,
      "step": 1481
    },
    {
      "epoch": 0.8927710843373494,
      "grad_norm": 0.5738742351531982,
      "learning_rate": 3.884036144578314e-06,
      "loss": 0.3009,
      "step": 1482
    },
    {
      "epoch": 0.8933734939759036,
      "grad_norm": 0.6121320128440857,
      "learning_rate": 3.883283132530121e-06,
      "loss": 0.3095,
      "step": 1483
    },
    {
      "epoch": 0.8939759036144578,
      "grad_norm": 0.7645326852798462,
      "learning_rate": 3.882530120481928e-06,
      "loss": 0.2861,
      "step": 1484
    },
    {
      "epoch": 0.8945783132530121,
      "grad_norm": 0.6446071863174438,
      "learning_rate": 3.881777108433735e-06,
      "loss": 0.35,
      "step": 1485
    },
    {
      "epoch": 0.8951807228915662,
      "grad_norm": 0.5727246999740601,
      "learning_rate": 3.881024096385542e-06,
      "loss": 0.3056,
      "step": 1486
    },
    {
      "epoch": 0.8957831325301204,
      "grad_norm": 0.7704877853393555,
      "learning_rate": 3.88027108433735e-06,
      "loss": 0.2741,
      "step": 1487
    },
    {
      "epoch": 0.8963855421686747,
      "grad_norm": 0.6276649832725525,
      "learning_rate": 3.879518072289157e-06,
      "loss": 0.295,
      "step": 1488
    },
    {
      "epoch": 0.8969879518072289,
      "grad_norm": 0.6408743262290955,
      "learning_rate": 3.878765060240965e-06,
      "loss": 0.3964,
      "step": 1489
    },
    {
      "epoch": 0.8975903614457831,
      "grad_norm": 0.5696626901626587,
      "learning_rate": 3.878012048192772e-06,
      "loss": 0.3198,
      "step": 1490
    },
    {
      "epoch": 0.8981927710843374,
      "grad_norm": 0.6622857451438904,
      "learning_rate": 3.8772590361445785e-06,
      "loss": 0.2533,
      "step": 1491
    },
    {
      "epoch": 0.8987951807228916,
      "grad_norm": 0.5418422222137451,
      "learning_rate": 3.8765060240963855e-06,
      "loss": 0.3183,
      "step": 1492
    },
    {
      "epoch": 0.8993975903614457,
      "grad_norm": 0.5857611894607544,
      "learning_rate": 3.875753012048193e-06,
      "loss": 0.339,
      "step": 1493
    },
    {
      "epoch": 0.9,
      "grad_norm": 0.5630123615264893,
      "learning_rate": 3.875e-06,
      "loss": 0.3233,
      "step": 1494
    },
    {
      "epoch": 0.9006024096385542,
      "grad_norm": 0.649299681186676,
      "learning_rate": 3.874246987951807e-06,
      "loss": 0.3322,
      "step": 1495
    },
    {
      "epoch": 0.9012048192771084,
      "grad_norm": 0.6714291572570801,
      "learning_rate": 3.873493975903615e-06,
      "loss": 0.2996,
      "step": 1496
    },
    {
      "epoch": 0.9018072289156627,
      "grad_norm": 0.591999888420105,
      "learning_rate": 3.872740963855422e-06,
      "loss": 0.3304,
      "step": 1497
    },
    {
      "epoch": 0.9024096385542169,
      "grad_norm": 0.6075760126113892,
      "learning_rate": 3.871987951807229e-06,
      "loss": 0.3617,
      "step": 1498
    },
    {
      "epoch": 0.903012048192771,
      "grad_norm": 0.614326000213623,
      "learning_rate": 3.8712349397590365e-06,
      "loss": 0.33,
      "step": 1499
    },
    {
      "epoch": 0.9036144578313253,
      "grad_norm": 0.5926133394241333,
      "learning_rate": 3.870481927710843e-06,
      "loss": 0.3811,
      "step": 1500
    },
    {
      "epoch": 0.9042168674698795,
      "grad_norm": 0.6255756616592407,
      "learning_rate": 3.869728915662651e-06,
      "loss": 0.3269,
      "step": 1501
    },
    {
      "epoch": 0.9048192771084337,
      "grad_norm": 0.5971084237098694,
      "learning_rate": 3.868975903614458e-06,
      "loss": 0.3187,
      "step": 1502
    },
    {
      "epoch": 0.905421686746988,
      "grad_norm": 0.5394378900527954,
      "learning_rate": 3.868222891566266e-06,
      "loss": 0.3163,
      "step": 1503
    },
    {
      "epoch": 0.9060240963855422,
      "grad_norm": 0.716162383556366,
      "learning_rate": 3.867469879518073e-06,
      "loss": 0.3216,
      "step": 1504
    },
    {
      "epoch": 0.9066265060240963,
      "grad_norm": 0.5666521787643433,
      "learning_rate": 3.86671686746988e-06,
      "loss": 0.293,
      "step": 1505
    },
    {
      "epoch": 0.9072289156626506,
      "grad_norm": 0.6327642202377319,
      "learning_rate": 3.8659638554216875e-06,
      "loss": 0.3957,
      "step": 1506
    },
    {
      "epoch": 0.9078313253012048,
      "grad_norm": 0.526078999042511,
      "learning_rate": 3.8652108433734944e-06,
      "loss": 0.3224,
      "step": 1507
    },
    {
      "epoch": 0.908433734939759,
      "grad_norm": 0.6290504336357117,
      "learning_rate": 3.864457831325301e-06,
      "loss": 0.3343,
      "step": 1508
    },
    {
      "epoch": 0.9090361445783133,
      "grad_norm": 0.5466744303703308,
      "learning_rate": 3.863704819277109e-06,
      "loss": 0.2822,
      "step": 1509
    },
    {
      "epoch": 0.9096385542168675,
      "grad_norm": 0.6429550051689148,
      "learning_rate": 3.862951807228916e-06,
      "loss": 0.2783,
      "step": 1510
    },
    {
      "epoch": 0.9102409638554216,
      "grad_norm": 0.5421547293663025,
      "learning_rate": 3.862198795180723e-06,
      "loss": 0.3369,
      "step": 1511
    },
    {
      "epoch": 0.9108433734939759,
      "grad_norm": 0.582439124584198,
      "learning_rate": 3.86144578313253e-06,
      "loss": 0.2719,
      "step": 1512
    },
    {
      "epoch": 0.9114457831325301,
      "grad_norm": 0.6102426052093506,
      "learning_rate": 3.860692771084338e-06,
      "loss": 0.2925,
      "step": 1513
    },
    {
      "epoch": 0.9120481927710843,
      "grad_norm": 0.6288671493530273,
      "learning_rate": 3.859939759036145e-06,
      "loss": 0.3106,
      "step": 1514
    },
    {
      "epoch": 0.9126506024096386,
      "grad_norm": 0.5865093469619751,
      "learning_rate": 3.859186746987952e-06,
      "loss": 0.2989,
      "step": 1515
    },
    {
      "epoch": 0.9132530120481928,
      "grad_norm": 0.554728090763092,
      "learning_rate": 3.858433734939759e-06,
      "loss": 0.2968,
      "step": 1516
    },
    {
      "epoch": 0.9138554216867469,
      "grad_norm": 0.5875564813613892,
      "learning_rate": 3.857680722891566e-06,
      "loss": 0.2932,
      "step": 1517
    },
    {
      "epoch": 0.9144578313253012,
      "grad_norm": 0.6277847290039062,
      "learning_rate": 3.856927710843374e-06,
      "loss": 0.3357,
      "step": 1518
    },
    {
      "epoch": 0.9150602409638554,
      "grad_norm": 0.5755590200424194,
      "learning_rate": 3.856174698795181e-06,
      "loss": 0.3288,
      "step": 1519
    },
    {
      "epoch": 0.9156626506024096,
      "grad_norm": 0.5947562456130981,
      "learning_rate": 3.855421686746989e-06,
      "loss": 0.319,
      "step": 1520
    },
    {
      "epoch": 0.9162650602409639,
      "grad_norm": 0.5838817358016968,
      "learning_rate": 3.854668674698796e-06,
      "loss": 0.3181,
      "step": 1521
    },
    {
      "epoch": 0.9168674698795181,
      "grad_norm": 0.5901022553443909,
      "learning_rate": 3.8539156626506025e-06,
      "loss": 0.3013,
      "step": 1522
    },
    {
      "epoch": 0.9174698795180722,
      "grad_norm": 0.618681788444519,
      "learning_rate": 3.85316265060241e-06,
      "loss": 0.296,
      "step": 1523
    },
    {
      "epoch": 0.9180722891566265,
      "grad_norm": 0.6470926403999329,
      "learning_rate": 3.852409638554217e-06,
      "loss": 0.3179,
      "step": 1524
    },
    {
      "epoch": 0.9186746987951807,
      "grad_norm": 0.5935212969779968,
      "learning_rate": 3.851656626506024e-06,
      "loss": 0.3237,
      "step": 1525
    },
    {
      "epoch": 0.9192771084337349,
      "grad_norm": 0.6585147976875305,
      "learning_rate": 3.850903614457832e-06,
      "loss": 0.2967,
      "step": 1526
    },
    {
      "epoch": 0.9198795180722892,
      "grad_norm": 0.626268208026886,
      "learning_rate": 3.850150602409639e-06,
      "loss": 0.3084,
      "step": 1527
    },
    {
      "epoch": 0.9204819277108434,
      "grad_norm": 0.639605700969696,
      "learning_rate": 3.849397590361446e-06,
      "loss": 0.3125,
      "step": 1528
    },
    {
      "epoch": 0.9210843373493975,
      "grad_norm": 0.6202170848846436,
      "learning_rate": 3.848644578313253e-06,
      "loss": 0.2713,
      "step": 1529
    },
    {
      "epoch": 0.9216867469879518,
      "grad_norm": 0.6557871103286743,
      "learning_rate": 3.8478915662650605e-06,
      "loss": 0.318,
      "step": 1530
    },
    {
      "epoch": 0.922289156626506,
      "grad_norm": 0.6643877625465393,
      "learning_rate": 3.847138554216867e-06,
      "loss": 0.3513,
      "step": 1531
    },
    {
      "epoch": 0.9228915662650602,
      "grad_norm": 0.5781038403511047,
      "learning_rate": 3.846385542168675e-06,
      "loss": 0.2787,
      "step": 1532
    },
    {
      "epoch": 0.9234939759036145,
      "grad_norm": 0.5741694569587708,
      "learning_rate": 3.845632530120482e-06,
      "loss": 0.2715,
      "step": 1533
    },
    {
      "epoch": 0.9240963855421687,
      "grad_norm": 0.6335145235061646,
      "learning_rate": 3.844879518072289e-06,
      "loss": 0.2534,
      "step": 1534
    },
    {
      "epoch": 0.9246987951807228,
      "grad_norm": 0.5724528431892395,
      "learning_rate": 3.844126506024097e-06,
      "loss": 0.3068,
      "step": 1535
    },
    {
      "epoch": 0.9253012048192771,
      "grad_norm": 0.5950543284416199,
      "learning_rate": 3.843373493975904e-06,
      "loss": 0.3407,
      "step": 1536
    },
    {
      "epoch": 0.9259036144578313,
      "grad_norm": 0.9487320184707642,
      "learning_rate": 3.8426204819277115e-06,
      "loss": 0.2562,
      "step": 1537
    },
    {
      "epoch": 0.9265060240963855,
      "grad_norm": 0.5676928758621216,
      "learning_rate": 3.841867469879518e-06,
      "loss": 0.2698,
      "step": 1538
    },
    {
      "epoch": 0.9271084337349398,
      "grad_norm": 0.6626879572868347,
      "learning_rate": 3.841114457831326e-06,
      "loss": 0.3401,
      "step": 1539
    },
    {
      "epoch": 0.927710843373494,
      "grad_norm": 0.5781557559967041,
      "learning_rate": 3.840361445783133e-06,
      "loss": 0.2572,
      "step": 1540
    },
    {
      "epoch": 0.9283132530120481,
      "grad_norm": 0.6139811873435974,
      "learning_rate": 3.83960843373494e-06,
      "loss": 0.3131,
      "step": 1541
    },
    {
      "epoch": 0.9289156626506024,
      "grad_norm": 0.5954063534736633,
      "learning_rate": 3.838855421686748e-06,
      "loss": 0.2562,
      "step": 1542
    },
    {
      "epoch": 0.9295180722891566,
      "grad_norm": 0.6485462784767151,
      "learning_rate": 3.838102409638555e-06,
      "loss": 0.3291,
      "step": 1543
    },
    {
      "epoch": 0.9301204819277108,
      "grad_norm": 0.7400915622711182,
      "learning_rate": 3.837349397590362e-06,
      "loss": 0.3305,
      "step": 1544
    },
    {
      "epoch": 0.9307228915662651,
      "grad_norm": 0.561465859413147,
      "learning_rate": 3.836596385542169e-06,
      "loss": 0.2524,
      "step": 1545
    },
    {
      "epoch": 0.9313253012048193,
      "grad_norm": 0.5430424213409424,
      "learning_rate": 3.835843373493976e-06,
      "loss": 0.3056,
      "step": 1546
    },
    {
      "epoch": 0.9319277108433734,
      "grad_norm": 0.6006090641021729,
      "learning_rate": 3.835090361445783e-06,
      "loss": 0.3203,
      "step": 1547
    },
    {
      "epoch": 0.9325301204819277,
      "grad_norm": 0.5962184071540833,
      "learning_rate": 3.83433734939759e-06,
      "loss": 0.3006,
      "step": 1548
    },
    {
      "epoch": 0.9331325301204819,
      "grad_norm": 0.5970362424850464,
      "learning_rate": 3.833584337349398e-06,
      "loss": 0.2986,
      "step": 1549
    },
    {
      "epoch": 0.9337349397590361,
      "grad_norm": 0.5440064072608948,
      "learning_rate": 3.832831325301205e-06,
      "loss": 0.2467,
      "step": 1550
    },
    {
      "epoch": 0.9343373493975904,
      "grad_norm": 0.6309421062469482,
      "learning_rate": 3.832078313253013e-06,
      "loss": 0.2497,
      "step": 1551
    },
    {
      "epoch": 0.9349397590361446,
      "grad_norm": 0.5724343657493591,
      "learning_rate": 3.83132530120482e-06,
      "loss": 0.3361,
      "step": 1552
    },
    {
      "epoch": 0.9355421686746987,
      "grad_norm": 0.5872223377227783,
      "learning_rate": 3.8305722891566265e-06,
      "loss": 0.3177,
      "step": 1553
    },
    {
      "epoch": 0.936144578313253,
      "grad_norm": 0.6251752376556396,
      "learning_rate": 3.829819277108434e-06,
      "loss": 0.2958,
      "step": 1554
    },
    {
      "epoch": 0.9367469879518072,
      "grad_norm": 0.6492981314659119,
      "learning_rate": 3.829066265060241e-06,
      "loss": 0.2692,
      "step": 1555
    },
    {
      "epoch": 0.9373493975903614,
      "grad_norm": 0.5034916996955872,
      "learning_rate": 3.828313253012049e-06,
      "loss": 0.2528,
      "step": 1556
    },
    {
      "epoch": 0.9379518072289157,
      "grad_norm": 0.599292516708374,
      "learning_rate": 3.827560240963856e-06,
      "loss": 0.2986,
      "step": 1557
    },
    {
      "epoch": 0.9385542168674699,
      "grad_norm": 0.561740517616272,
      "learning_rate": 3.826807228915663e-06,
      "loss": 0.2547,
      "step": 1558
    },
    {
      "epoch": 0.939156626506024,
      "grad_norm": 0.6577340960502625,
      "learning_rate": 3.826054216867471e-06,
      "loss": 0.2608,
      "step": 1559
    },
    {
      "epoch": 0.9397590361445783,
      "grad_norm": 0.5688811540603638,
      "learning_rate": 3.8253012048192775e-06,
      "loss": 0.3671,
      "step": 1560
    },
    {
      "epoch": 0.9403614457831325,
      "grad_norm": 0.6027348041534424,
      "learning_rate": 3.8245481927710845e-06,
      "loss": 0.3593,
      "step": 1561
    },
    {
      "epoch": 0.9409638554216867,
      "grad_norm": 0.6132913827896118,
      "learning_rate": 3.823795180722891e-06,
      "loss": 0.3107,
      "step": 1562
    },
    {
      "epoch": 0.941566265060241,
      "grad_norm": 0.6206803321838379,
      "learning_rate": 3.823042168674699e-06,
      "loss": 0.3009,
      "step": 1563
    },
    {
      "epoch": 0.9421686746987952,
      "grad_norm": 0.5531899929046631,
      "learning_rate": 3.822289156626506e-06,
      "loss": 0.3287,
      "step": 1564
    },
    {
      "epoch": 0.9427710843373494,
      "grad_norm": 0.6350348591804504,
      "learning_rate": 3.821536144578313e-06,
      "loss": 0.2639,
      "step": 1565
    },
    {
      "epoch": 0.9433734939759036,
      "grad_norm": 0.5605906248092651,
      "learning_rate": 3.820783132530121e-06,
      "loss": 0.2377,
      "step": 1566
    },
    {
      "epoch": 0.9439759036144578,
      "grad_norm": 0.6127449870109558,
      "learning_rate": 3.820030120481928e-06,
      "loss": 0.3423,
      "step": 1567
    },
    {
      "epoch": 0.944578313253012,
      "grad_norm": 0.5576363205909729,
      "learning_rate": 3.8192771084337355e-06,
      "loss": 0.2984,
      "step": 1568
    },
    {
      "epoch": 0.9451807228915663,
      "grad_norm": 0.61335688829422,
      "learning_rate": 3.818524096385542e-06,
      "loss": 0.2541,
      "step": 1569
    },
    {
      "epoch": 0.9457831325301205,
      "grad_norm": 0.5711690187454224,
      "learning_rate": 3.817771084337349e-06,
      "loss": 0.2893,
      "step": 1570
    },
    {
      "epoch": 0.9463855421686747,
      "grad_norm": 0.5990526080131531,
      "learning_rate": 3.817018072289157e-06,
      "loss": 0.3185,
      "step": 1571
    },
    {
      "epoch": 0.946987951807229,
      "grad_norm": 0.6177470088005066,
      "learning_rate": 3.816265060240964e-06,
      "loss": 0.3066,
      "step": 1572
    },
    {
      "epoch": 0.9475903614457831,
      "grad_norm": 0.5910263061523438,
      "learning_rate": 3.815512048192772e-06,
      "loss": 0.2574,
      "step": 1573
    },
    {
      "epoch": 0.9481927710843373,
      "grad_norm": 0.5925722718238831,
      "learning_rate": 3.814759036144579e-06,
      "loss": 0.2514,
      "step": 1574
    },
    {
      "epoch": 0.9487951807228916,
      "grad_norm": 0.5664945244789124,
      "learning_rate": 3.814006024096386e-06,
      "loss": 0.3284,
      "step": 1575
    },
    {
      "epoch": 0.9493975903614458,
      "grad_norm": 0.5281934142112732,
      "learning_rate": 3.813253012048193e-06,
      "loss": 0.2311,
      "step": 1576
    },
    {
      "epoch": 0.95,
      "grad_norm": 0.5318150520324707,
      "learning_rate": 3.8125e-06,
      "loss": 0.2847,
      "step": 1577
    },
    {
      "epoch": 0.9506024096385542,
      "grad_norm": 0.606515645980835,
      "learning_rate": 3.8117469879518077e-06,
      "loss": 0.3454,
      "step": 1578
    },
    {
      "epoch": 0.9512048192771084,
      "grad_norm": 0.6228699684143066,
      "learning_rate": 3.8109939759036146e-06,
      "loss": 0.314,
      "step": 1579
    },
    {
      "epoch": 0.9518072289156626,
      "grad_norm": 0.5946112275123596,
      "learning_rate": 3.8102409638554224e-06,
      "loss": 0.3461,
      "step": 1580
    },
    {
      "epoch": 0.9524096385542169,
      "grad_norm": 0.5903294682502747,
      "learning_rate": 3.8094879518072293e-06,
      "loss": 0.308,
      "step": 1581
    },
    {
      "epoch": 0.9530120481927711,
      "grad_norm": 0.7175417542457581,
      "learning_rate": 3.8087349397590362e-06,
      "loss": 0.3476,
      "step": 1582
    },
    {
      "epoch": 0.9536144578313253,
      "grad_norm": 0.6598929166793823,
      "learning_rate": 3.8079819277108436e-06,
      "loss": 0.2652,
      "step": 1583
    },
    {
      "epoch": 0.9542168674698795,
      "grad_norm": 0.588752031326294,
      "learning_rate": 3.807228915662651e-06,
      "loss": 0.303,
      "step": 1584
    },
    {
      "epoch": 0.9548192771084337,
      "grad_norm": 0.6789286136627197,
      "learning_rate": 3.8064759036144583e-06,
      "loss": 0.3153,
      "step": 1585
    },
    {
      "epoch": 0.9554216867469879,
      "grad_norm": 0.7106896042823792,
      "learning_rate": 3.805722891566265e-06,
      "loss": 0.3404,
      "step": 1586
    },
    {
      "epoch": 0.9560240963855422,
      "grad_norm": 0.5584235191345215,
      "learning_rate": 3.804969879518073e-06,
      "loss": 0.2813,
      "step": 1587
    },
    {
      "epoch": 0.9566265060240964,
      "grad_norm": 0.6088837385177612,
      "learning_rate": 3.80421686746988e-06,
      "loss": 0.3071,
      "step": 1588
    },
    {
      "epoch": 0.9572289156626506,
      "grad_norm": 0.5539889931678772,
      "learning_rate": 3.803463855421687e-06,
      "loss": 0.3297,
      "step": 1589
    },
    {
      "epoch": 0.9578313253012049,
      "grad_norm": 0.6028401851654053,
      "learning_rate": 3.802710843373494e-06,
      "loss": 0.2911,
      "step": 1590
    },
    {
      "epoch": 0.958433734939759,
      "grad_norm": 0.6054452657699585,
      "learning_rate": 3.8019578313253015e-06,
      "loss": 0.3267,
      "step": 1591
    },
    {
      "epoch": 0.9590361445783132,
      "grad_norm": 0.6290599703788757,
      "learning_rate": 3.801204819277109e-06,
      "loss": 0.3064,
      "step": 1592
    },
    {
      "epoch": 0.9596385542168675,
      "grad_norm": 0.525177538394928,
      "learning_rate": 3.800451807228916e-06,
      "loss": 0.2745,
      "step": 1593
    },
    {
      "epoch": 0.9602409638554217,
      "grad_norm": 0.6488851308822632,
      "learning_rate": 3.7996987951807227e-06,
      "loss": 0.2691,
      "step": 1594
    },
    {
      "epoch": 0.9608433734939759,
      "grad_norm": 0.6827554702758789,
      "learning_rate": 3.7989457831325305e-06,
      "loss": 0.3019,
      "step": 1595
    },
    {
      "epoch": 0.9614457831325302,
      "grad_norm": 0.5068113207817078,
      "learning_rate": 3.7981927710843374e-06,
      "loss": 0.2957,
      "step": 1596
    },
    {
      "epoch": 0.9620481927710843,
      "grad_norm": 0.5285426378250122,
      "learning_rate": 3.797439759036145e-06,
      "loss": 0.3067,
      "step": 1597
    },
    {
      "epoch": 0.9626506024096385,
      "grad_norm": 0.6348109245300293,
      "learning_rate": 3.796686746987952e-06,
      "loss": 0.3091,
      "step": 1598
    },
    {
      "epoch": 0.9632530120481928,
      "grad_norm": 0.6026304364204407,
      "learning_rate": 3.7959337349397595e-06,
      "loss": 0.2903,
      "step": 1599
    },
    {
      "epoch": 0.963855421686747,
      "grad_norm": 0.6431549787521362,
      "learning_rate": 3.7951807228915664e-06,
      "loss": 0.3164,
      "step": 1600
    },
    {
      "epoch": 0.9644578313253012,
      "grad_norm": 0.6270492672920227,
      "learning_rate": 3.7944277108433737e-06,
      "loss": 0.2827,
      "step": 1601
    },
    {
      "epoch": 0.9650602409638555,
      "grad_norm": 0.6652151942253113,
      "learning_rate": 3.793674698795181e-06,
      "loss": 0.3305,
      "step": 1602
    },
    {
      "epoch": 0.9656626506024096,
      "grad_norm": 0.5550526976585388,
      "learning_rate": 3.792921686746988e-06,
      "loss": 0.2827,
      "step": 1603
    },
    {
      "epoch": 0.9662650602409638,
      "grad_norm": 1.448011875152588,
      "learning_rate": 3.7921686746987958e-06,
      "loss": 0.3626,
      "step": 1604
    },
    {
      "epoch": 0.9668674698795181,
      "grad_norm": 0.744584858417511,
      "learning_rate": 3.7914156626506027e-06,
      "loss": 0.344,
      "step": 1605
    },
    {
      "epoch": 0.9674698795180723,
      "grad_norm": 0.6405799388885498,
      "learning_rate": 3.7906626506024096e-06,
      "loss": 0.3126,
      "step": 1606
    },
    {
      "epoch": 0.9680722891566265,
      "grad_norm": 0.5995344519615173,
      "learning_rate": 3.7899096385542174e-06,
      "loss": 0.2943,
      "step": 1607
    },
    {
      "epoch": 0.9686746987951808,
      "grad_norm": 0.6218671202659607,
      "learning_rate": 3.7891566265060243e-06,
      "loss": 0.364,
      "step": 1608
    },
    {
      "epoch": 0.9692771084337349,
      "grad_norm": 0.6581233143806458,
      "learning_rate": 3.7884036144578317e-06,
      "loss": 0.3812,
      "step": 1609
    },
    {
      "epoch": 0.9698795180722891,
      "grad_norm": 0.5701721906661987,
      "learning_rate": 3.7876506024096386e-06,
      "loss": 0.2909,
      "step": 1610
    },
    {
      "epoch": 0.9704819277108434,
      "grad_norm": 0.617834210395813,
      "learning_rate": 3.7868975903614464e-06,
      "loss": 0.295,
      "step": 1611
    },
    {
      "epoch": 0.9710843373493976,
      "grad_norm": 0.6945515275001526,
      "learning_rate": 3.7861445783132533e-06,
      "loss": 0.3143,
      "step": 1612
    },
    {
      "epoch": 0.9716867469879518,
      "grad_norm": 0.6043614149093628,
      "learning_rate": 3.7853915662650602e-06,
      "loss": 0.3344,
      "step": 1613
    },
    {
      "epoch": 0.9722891566265061,
      "grad_norm": 0.5400189161300659,
      "learning_rate": 3.784638554216868e-06,
      "loss": 0.2595,
      "step": 1614
    },
    {
      "epoch": 0.9728915662650602,
      "grad_norm": 0.5582118630409241,
      "learning_rate": 3.783885542168675e-06,
      "loss": 0.2429,
      "step": 1615
    },
    {
      "epoch": 0.9734939759036144,
      "grad_norm": 0.6470367312431335,
      "learning_rate": 3.7831325301204823e-06,
      "loss": 0.3363,
      "step": 1616
    },
    {
      "epoch": 0.9740963855421687,
      "grad_norm": 0.5635009407997131,
      "learning_rate": 3.7823795180722896e-06,
      "loss": 0.3081,
      "step": 1617
    },
    {
      "epoch": 0.9746987951807229,
      "grad_norm": 0.5566416382789612,
      "learning_rate": 3.7816265060240965e-06,
      "loss": 0.3167,
      "step": 1618
    },
    {
      "epoch": 0.9753012048192771,
      "grad_norm": 0.5722944736480713,
      "learning_rate": 3.780873493975904e-06,
      "loss": 0.2986,
      "step": 1619
    },
    {
      "epoch": 0.9759036144578314,
      "grad_norm": 0.5442400574684143,
      "learning_rate": 3.780120481927711e-06,
      "loss": 0.2682,
      "step": 1620
    },
    {
      "epoch": 0.9765060240963855,
      "grad_norm": 0.5935124158859253,
      "learning_rate": 3.7793674698795186e-06,
      "loss": 0.2798,
      "step": 1621
    },
    {
      "epoch": 0.9771084337349397,
      "grad_norm": 0.5872688293457031,
      "learning_rate": 3.7786144578313255e-06,
      "loss": 0.2853,
      "step": 1622
    },
    {
      "epoch": 0.977710843373494,
      "grad_norm": 0.673268735408783,
      "learning_rate": 3.777861445783133e-06,
      "loss": 0.3473,
      "step": 1623
    },
    {
      "epoch": 0.9783132530120482,
      "grad_norm": 0.5627865791320801,
      "learning_rate": 3.7771084337349402e-06,
      "loss": 0.2812,
      "step": 1624
    },
    {
      "epoch": 0.9789156626506024,
      "grad_norm": 0.6330248713493347,
      "learning_rate": 3.776355421686747e-06,
      "loss": 0.3034,
      "step": 1625
    },
    {
      "epoch": 0.9795180722891567,
      "grad_norm": 0.5852194428443909,
      "learning_rate": 3.7756024096385545e-06,
      "loss": 0.3116,
      "step": 1626
    },
    {
      "epoch": 0.9801204819277108,
      "grad_norm": 0.5885996222496033,
      "learning_rate": 3.7748493975903614e-06,
      "loss": 0.3224,
      "step": 1627
    },
    {
      "epoch": 0.980722891566265,
      "grad_norm": 0.5470009446144104,
      "learning_rate": 3.774096385542169e-06,
      "loss": 0.3512,
      "step": 1628
    },
    {
      "epoch": 0.9813253012048193,
      "grad_norm": 0.5824840068817139,
      "learning_rate": 3.773343373493976e-06,
      "loss": 0.2745,
      "step": 1629
    },
    {
      "epoch": 0.9819277108433735,
      "grad_norm": 0.6259004473686218,
      "learning_rate": 3.772590361445783e-06,
      "loss": 0.3673,
      "step": 1630
    },
    {
      "epoch": 0.9825301204819277,
      "grad_norm": 0.5868666768074036,
      "learning_rate": 3.771837349397591e-06,
      "loss": 0.3173,
      "step": 1631
    },
    {
      "epoch": 0.983132530120482,
      "grad_norm": 0.5551733374595642,
      "learning_rate": 3.7710843373493977e-06,
      "loss": 0.2644,
      "step": 1632
    },
    {
      "epoch": 0.9837349397590361,
      "grad_norm": 0.5434892177581787,
      "learning_rate": 3.770331325301205e-06,
      "loss": 0.2597,
      "step": 1633
    },
    {
      "epoch": 0.9843373493975903,
      "grad_norm": 0.5098376274108887,
      "learning_rate": 3.7695783132530124e-06,
      "loss": 0.3263,
      "step": 1634
    },
    {
      "epoch": 0.9849397590361446,
      "grad_norm": 0.6250258684158325,
      "learning_rate": 3.7688253012048198e-06,
      "loss": 0.3276,
      "step": 1635
    },
    {
      "epoch": 0.9855421686746988,
      "grad_norm": 0.6468021273612976,
      "learning_rate": 3.7680722891566267e-06,
      "loss": 0.3647,
      "step": 1636
    },
    {
      "epoch": 0.986144578313253,
      "grad_norm": 0.5309330224990845,
      "learning_rate": 3.7673192771084336e-06,
      "loss": 0.3448,
      "step": 1637
    },
    {
      "epoch": 0.9867469879518073,
      "grad_norm": 0.6378686428070068,
      "learning_rate": 3.7665662650602414e-06,
      "loss": 0.3728,
      "step": 1638
    },
    {
      "epoch": 0.9873493975903614,
      "grad_norm": 0.5713489055633545,
      "learning_rate": 3.7658132530120483e-06,
      "loss": 0.3263,
      "step": 1639
    },
    {
      "epoch": 0.9879518072289156,
      "grad_norm": 0.5673258304595947,
      "learning_rate": 3.765060240963856e-06,
      "loss": 0.2825,
      "step": 1640
    },
    {
      "epoch": 0.9885542168674699,
      "grad_norm": 0.620331346988678,
      "learning_rate": 3.764307228915663e-06,
      "loss": 0.3248,
      "step": 1641
    },
    {
      "epoch": 0.9891566265060241,
      "grad_norm": 0.5759044885635376,
      "learning_rate": 3.76355421686747e-06,
      "loss": 0.2592,
      "step": 1642
    },
    {
      "epoch": 0.9897590361445783,
      "grad_norm": 0.6607570648193359,
      "learning_rate": 3.7628012048192773e-06,
      "loss": 0.3727,
      "step": 1643
    },
    {
      "epoch": 0.9903614457831326,
      "grad_norm": 0.6990567445755005,
      "learning_rate": 3.7620481927710846e-06,
      "loss": 0.2857,
      "step": 1644
    },
    {
      "epoch": 0.9909638554216867,
      "grad_norm": 0.6433923244476318,
      "learning_rate": 3.761295180722892e-06,
      "loss": 0.3371,
      "step": 1645
    },
    {
      "epoch": 0.9915662650602409,
      "grad_norm": 0.6068524718284607,
      "learning_rate": 3.760542168674699e-06,
      "loss": 0.3188,
      "step": 1646
    },
    {
      "epoch": 0.9921686746987952,
      "grad_norm": 0.5908817648887634,
      "learning_rate": 3.7597891566265067e-06,
      "loss": 0.3232,
      "step": 1647
    },
    {
      "epoch": 0.9927710843373494,
      "grad_norm": 0.5583392977714539,
      "learning_rate": 3.7590361445783136e-06,
      "loss": 0.297,
      "step": 1648
    },
    {
      "epoch": 0.9933734939759036,
      "grad_norm": 0.6273563504219055,
      "learning_rate": 3.7582831325301205e-06,
      "loss": 0.302,
      "step": 1649
    },
    {
      "epoch": 0.9939759036144579,
      "grad_norm": 0.6419253349304199,
      "learning_rate": 3.7575301204819283e-06,
      "loss": 0.3226,
      "step": 1650
    },
    {
      "epoch": 0.994578313253012,
      "grad_norm": 0.7257032990455627,
      "learning_rate": 3.7567771084337352e-06,
      "loss": 0.2541,
      "step": 1651
    },
    {
      "epoch": 0.9951807228915662,
      "grad_norm": 0.580523669719696,
      "learning_rate": 3.7560240963855426e-06,
      "loss": 0.2983,
      "step": 1652
    },
    {
      "epoch": 0.9957831325301205,
      "grad_norm": 0.6886411309242249,
      "learning_rate": 3.7552710843373495e-06,
      "loss": 0.3141,
      "step": 1653
    },
    {
      "epoch": 0.9963855421686747,
      "grad_norm": 0.5931892991065979,
      "learning_rate": 3.754518072289157e-06,
      "loss": 0.2696,
      "step": 1654
    },
    {
      "epoch": 0.9969879518072289,
      "grad_norm": 0.6552515029907227,
      "learning_rate": 3.753765060240964e-06,
      "loss": 0.3816,
      "step": 1655
    },
    {
      "epoch": 0.9975903614457832,
      "grad_norm": 0.6197381019592285,
      "learning_rate": 3.753012048192771e-06,
      "loss": 0.3093,
      "step": 1656
    },
    {
      "epoch": 0.9981927710843373,
      "grad_norm": 0.5520281195640564,
      "learning_rate": 3.752259036144579e-06,
      "loss": 0.2646,
      "step": 1657
    },
    {
      "epoch": 0.9987951807228915,
      "grad_norm": 0.5857341885566711,
      "learning_rate": 3.751506024096386e-06,
      "loss": 0.2953,
      "step": 1658
    },
    {
      "epoch": 0.9993975903614458,
      "grad_norm": 0.6078221201896667,
      "learning_rate": 3.750753012048193e-06,
      "loss": 0.2648,
      "step": 1659
    },
    {
      "epoch": 1.0,
      "grad_norm": 0.6428865790367126,
      "learning_rate": 3.7500000000000005e-06,
      "loss": 0.3587,
      "step": 1660
    },
    {
      "epoch": 1.0006024096385542,
      "grad_norm": 2.8902788162231445,
      "learning_rate": 3.7492469879518074e-06,
      "loss": 0.2326,
      "step": 1661
    },
    {
      "epoch": 1.0012048192771084,
      "grad_norm": 0.7525188326835632,
      "learning_rate": 3.748493975903615e-06,
      "loss": 0.2318,
      "step": 1662
    },
    {
      "epoch": 1.0018072289156625,
      "grad_norm": 0.6610426306724548,
      "learning_rate": 3.7477409638554217e-06,
      "loss": 0.2154,
      "step": 1663
    },
    {
      "epoch": 1.002409638554217,
      "grad_norm": 0.7295645475387573,
      "learning_rate": 3.7469879518072295e-06,
      "loss": 0.2643,
      "step": 1664
    },
    {
      "epoch": 1.0030120481927711,
      "grad_norm": 0.8388773798942566,
      "learning_rate": 3.7462349397590364e-06,
      "loss": 0.2632,
      "step": 1665
    },
    {
      "epoch": 1.0036144578313253,
      "grad_norm": 0.787441611289978,
      "learning_rate": 3.7454819277108438e-06,
      "loss": 0.2466,
      "step": 1666
    },
    {
      "epoch": 1.0042168674698795,
      "grad_norm": 0.587364137172699,
      "learning_rate": 3.744728915662651e-06,
      "loss": 0.2477,
      "step": 1667
    },
    {
      "epoch": 1.0048192771084337,
      "grad_norm": 0.8240907192230225,
      "learning_rate": 3.743975903614458e-06,
      "loss": 0.268,
      "step": 1668
    },
    {
      "epoch": 1.0054216867469878,
      "grad_norm": 0.6490128040313721,
      "learning_rate": 3.7432228915662654e-06,
      "loss": 0.2739,
      "step": 1669
    },
    {
      "epoch": 1.0060240963855422,
      "grad_norm": 0.6723286509513855,
      "learning_rate": 3.7424698795180723e-06,
      "loss": 0.2125,
      "step": 1670
    },
    {
      "epoch": 1.0066265060240964,
      "grad_norm": 0.6370532512664795,
      "learning_rate": 3.74171686746988e-06,
      "loss": 0.2387,
      "step": 1671
    },
    {
      "epoch": 1.0072289156626506,
      "grad_norm": 0.6729452610015869,
      "learning_rate": 3.740963855421687e-06,
      "loss": 0.2575,
      "step": 1672
    },
    {
      "epoch": 1.0078313253012048,
      "grad_norm": 0.6559692025184631,
      "learning_rate": 3.740210843373494e-06,
      "loss": 0.2657,
      "step": 1673
    },
    {
      "epoch": 1.008433734939759,
      "grad_norm": 0.6199513077735901,
      "learning_rate": 3.7394578313253017e-06,
      "loss": 0.203,
      "step": 1674
    },
    {
      "epoch": 1.0090361445783131,
      "grad_norm": 0.6236467361450195,
      "learning_rate": 3.7387048192771086e-06,
      "loss": 0.2499,
      "step": 1675
    },
    {
      "epoch": 1.0096385542168675,
      "grad_norm": 0.6549357175827026,
      "learning_rate": 3.737951807228916e-06,
      "loss": 0.2055,
      "step": 1676
    },
    {
      "epoch": 1.0102409638554217,
      "grad_norm": 0.6541482210159302,
      "learning_rate": 3.7371987951807233e-06,
      "loss": 0.2494,
      "step": 1677
    },
    {
      "epoch": 1.010843373493976,
      "grad_norm": 0.7108975648880005,
      "learning_rate": 3.7364457831325307e-06,
      "loss": 0.2582,
      "step": 1678
    },
    {
      "epoch": 1.01144578313253,
      "grad_norm": 0.6541627645492554,
      "learning_rate": 3.7356927710843376e-06,
      "loss": 0.2731,
      "step": 1679
    },
    {
      "epoch": 1.0120481927710843,
      "grad_norm": 0.5545852184295654,
      "learning_rate": 3.7349397590361445e-06,
      "loss": 0.223,
      "step": 1680
    },
    {
      "epoch": 1.0126506024096384,
      "grad_norm": 0.5922397375106812,
      "learning_rate": 3.7341867469879523e-06,
      "loss": 0.2293,
      "step": 1681
    },
    {
      "epoch": 1.0132530120481928,
      "grad_norm": 0.6514495611190796,
      "learning_rate": 3.7334337349397592e-06,
      "loss": 0.2457,
      "step": 1682
    },
    {
      "epoch": 1.013855421686747,
      "grad_norm": 0.6153815388679504,
      "learning_rate": 3.732680722891567e-06,
      "loss": 0.2713,
      "step": 1683
    },
    {
      "epoch": 1.0144578313253012,
      "grad_norm": 0.5708422064781189,
      "learning_rate": 3.731927710843374e-06,
      "loss": 0.2319,
      "step": 1684
    },
    {
      "epoch": 1.0150602409638554,
      "grad_norm": 0.6098160147666931,
      "learning_rate": 3.731174698795181e-06,
      "loss": 0.2418,
      "step": 1685
    },
    {
      "epoch": 1.0156626506024096,
      "grad_norm": 0.5499950051307678,
      "learning_rate": 3.730421686746988e-06,
      "loss": 0.2485,
      "step": 1686
    },
    {
      "epoch": 1.0162650602409637,
      "grad_norm": 0.5622352361679077,
      "learning_rate": 3.7296686746987955e-06,
      "loss": 0.2895,
      "step": 1687
    },
    {
      "epoch": 1.0168674698795181,
      "grad_norm": 0.5924009680747986,
      "learning_rate": 3.728915662650603e-06,
      "loss": 0.2112,
      "step": 1688
    },
    {
      "epoch": 1.0174698795180723,
      "grad_norm": 0.5401963591575623,
      "learning_rate": 3.72816265060241e-06,
      "loss": 0.2245,
      "step": 1689
    },
    {
      "epoch": 1.0180722891566265,
      "grad_norm": 0.5884876251220703,
      "learning_rate": 3.7274096385542176e-06,
      "loss": 0.2055,
      "step": 1690
    },
    {
      "epoch": 1.0186746987951807,
      "grad_norm": 0.5260162353515625,
      "learning_rate": 3.7266566265060245e-06,
      "loss": 0.211,
      "step": 1691
    },
    {
      "epoch": 1.0192771084337349,
      "grad_norm": 0.5222471356391907,
      "learning_rate": 3.7259036144578314e-06,
      "loss": 0.2101,
      "step": 1692
    },
    {
      "epoch": 1.019879518072289,
      "grad_norm": 0.5883461236953735,
      "learning_rate": 3.725150602409639e-06,
      "loss": 0.2277,
      "step": 1693
    },
    {
      "epoch": 1.0204819277108435,
      "grad_norm": 0.5145010948181152,
      "learning_rate": 3.724397590361446e-06,
      "loss": 0.2459,
      "step": 1694
    },
    {
      "epoch": 1.0210843373493976,
      "grad_norm": 0.5201234817504883,
      "learning_rate": 3.7236445783132535e-06,
      "loss": 0.2208,
      "step": 1695
    },
    {
      "epoch": 1.0216867469879518,
      "grad_norm": 0.6330022811889648,
      "learning_rate": 3.7228915662650604e-06,
      "loss": 0.2407,
      "step": 1696
    },
    {
      "epoch": 1.022289156626506,
      "grad_norm": 0.582943320274353,
      "learning_rate": 3.7221385542168677e-06,
      "loss": 0.2357,
      "step": 1697
    },
    {
      "epoch": 1.0228915662650602,
      "grad_norm": 0.5321422219276428,
      "learning_rate": 3.721385542168675e-06,
      "loss": 0.2905,
      "step": 1698
    },
    {
      "epoch": 1.0234939759036144,
      "grad_norm": 0.49290159344673157,
      "learning_rate": 3.720632530120482e-06,
      "loss": 0.229,
      "step": 1699
    },
    {
      "epoch": 1.0240963855421688,
      "grad_norm": 0.5894807577133179,
      "learning_rate": 3.71987951807229e-06,
      "loss": 0.2083,
      "step": 1700
    },
    {
      "epoch": 1.024698795180723,
      "grad_norm": 0.5766307711601257,
      "learning_rate": 3.7191265060240967e-06,
      "loss": 0.2116,
      "step": 1701
    },
    {
      "epoch": 1.0253012048192771,
      "grad_norm": 0.5286462903022766,
      "learning_rate": 3.718373493975904e-06,
      "loss": 0.2323,
      "step": 1702
    },
    {
      "epoch": 1.0259036144578313,
      "grad_norm": 0.5507131218910217,
      "learning_rate": 3.717620481927711e-06,
      "loss": 0.2081,
      "step": 1703
    },
    {
      "epoch": 1.0265060240963855,
      "grad_norm": 0.5315890312194824,
      "learning_rate": 3.7168674698795183e-06,
      "loss": 0.2693,
      "step": 1704
    },
    {
      "epoch": 1.0271084337349397,
      "grad_norm": 0.5089263319969177,
      "learning_rate": 3.7161144578313257e-06,
      "loss": 0.2262,
      "step": 1705
    },
    {
      "epoch": 1.027710843373494,
      "grad_norm": 0.5681853294372559,
      "learning_rate": 3.7153614457831326e-06,
      "loss": 0.2645,
      "step": 1706
    },
    {
      "epoch": 1.0283132530120482,
      "grad_norm": 0.6918096542358398,
      "learning_rate": 3.7146084337349404e-06,
      "loss": 0.2098,
      "step": 1707
    },
    {
      "epoch": 1.0289156626506024,
      "grad_norm": 0.5051201581954956,
      "learning_rate": 3.7138554216867473e-06,
      "loss": 0.2125,
      "step": 1708
    },
    {
      "epoch": 1.0295180722891566,
      "grad_norm": 0.6301979422569275,
      "learning_rate": 3.7131024096385542e-06,
      "loss": 0.2226,
      "step": 1709
    },
    {
      "epoch": 1.0301204819277108,
      "grad_norm": 0.5956462621688843,
      "learning_rate": 3.712349397590362e-06,
      "loss": 0.2396,
      "step": 1710
    },
    {
      "epoch": 1.030722891566265,
      "grad_norm": 0.622769832611084,
      "learning_rate": 3.711596385542169e-06,
      "loss": 0.2279,
      "step": 1711
    },
    {
      "epoch": 1.0313253012048194,
      "grad_norm": 0.5436831116676331,
      "learning_rate": 3.7108433734939763e-06,
      "loss": 0.2184,
      "step": 1712
    },
    {
      "epoch": 1.0319277108433735,
      "grad_norm": 0.4974893033504486,
      "learning_rate": 3.710090361445783e-06,
      "loss": 0.2349,
      "step": 1713
    },
    {
      "epoch": 1.0325301204819277,
      "grad_norm": 0.5307173728942871,
      "learning_rate": 3.709337349397591e-06,
      "loss": 0.2425,
      "step": 1714
    },
    {
      "epoch": 1.033132530120482,
      "grad_norm": 0.5027891397476196,
      "learning_rate": 3.708584337349398e-06,
      "loss": 0.1949,
      "step": 1715
    },
    {
      "epoch": 1.033734939759036,
      "grad_norm": 0.5866191983222961,
      "learning_rate": 3.707831325301205e-06,
      "loss": 0.2599,
      "step": 1716
    },
    {
      "epoch": 1.0343373493975903,
      "grad_norm": 0.5078677535057068,
      "learning_rate": 3.7070783132530126e-06,
      "loss": 0.1905,
      "step": 1717
    },
    {
      "epoch": 1.0349397590361447,
      "grad_norm": 0.6177307963371277,
      "learning_rate": 3.7063253012048195e-06,
      "loss": 0.2578,
      "step": 1718
    },
    {
      "epoch": 1.0355421686746988,
      "grad_norm": 0.5996371507644653,
      "learning_rate": 3.705572289156627e-06,
      "loss": 0.2004,
      "step": 1719
    },
    {
      "epoch": 1.036144578313253,
      "grad_norm": 0.5484060049057007,
      "learning_rate": 3.7048192771084342e-06,
      "loss": 0.2201,
      "step": 1720
    },
    {
      "epoch": 1.0367469879518072,
      "grad_norm": 0.6181533336639404,
      "learning_rate": 3.704066265060241e-06,
      "loss": 0.2161,
      "step": 1721
    },
    {
      "epoch": 1.0373493975903614,
      "grad_norm": 0.5066192150115967,
      "learning_rate": 3.7033132530120485e-06,
      "loss": 0.2157,
      "step": 1722
    },
    {
      "epoch": 1.0379518072289156,
      "grad_norm": 0.4953658878803253,
      "learning_rate": 3.7025602409638554e-06,
      "loss": 0.2146,
      "step": 1723
    },
    {
      "epoch": 1.03855421686747,
      "grad_norm": 0.5822072625160217,
      "learning_rate": 3.701807228915663e-06,
      "loss": 0.3057,
      "step": 1724
    },
    {
      "epoch": 1.0391566265060241,
      "grad_norm": 0.5741856098175049,
      "learning_rate": 3.70105421686747e-06,
      "loss": 0.2141,
      "step": 1725
    },
    {
      "epoch": 1.0397590361445783,
      "grad_norm": 0.581577718257904,
      "learning_rate": 3.700301204819278e-06,
      "loss": 0.2024,
      "step": 1726
    },
    {
      "epoch": 1.0403614457831325,
      "grad_norm": 0.5326331853866577,
      "learning_rate": 3.699548192771085e-06,
      "loss": 0.2401,
      "step": 1727
    },
    {
      "epoch": 1.0409638554216867,
      "grad_norm": 0.5333704948425293,
      "learning_rate": 3.6987951807228917e-06,
      "loss": 0.2076,
      "step": 1728
    },
    {
      "epoch": 1.0415662650602409,
      "grad_norm": 0.5713103413581848,
      "learning_rate": 3.698042168674699e-06,
      "loss": 0.2503,
      "step": 1729
    },
    {
      "epoch": 1.0421686746987953,
      "grad_norm": 0.5987716317176819,
      "learning_rate": 3.6972891566265064e-06,
      "loss": 0.1889,
      "step": 1730
    },
    {
      "epoch": 1.0427710843373494,
      "grad_norm": 0.5836336612701416,
      "learning_rate": 3.6965361445783138e-06,
      "loss": 0.2755,
      "step": 1731
    },
    {
      "epoch": 1.0433734939759036,
      "grad_norm": 0.5637199878692627,
      "learning_rate": 3.6957831325301207e-06,
      "loss": 0.2102,
      "step": 1732
    },
    {
      "epoch": 1.0439759036144578,
      "grad_norm": 0.5377330183982849,
      "learning_rate": 3.6950301204819276e-06,
      "loss": 0.2324,
      "step": 1733
    },
    {
      "epoch": 1.044578313253012,
      "grad_norm": 0.5644047856330872,
      "learning_rate": 3.6942771084337354e-06,
      "loss": 0.244,
      "step": 1734
    },
    {
      "epoch": 1.0451807228915662,
      "grad_norm": 0.5438499450683594,
      "learning_rate": 3.6935240963855423e-06,
      "loss": 0.2376,
      "step": 1735
    },
    {
      "epoch": 1.0457831325301206,
      "grad_norm": 0.5666180849075317,
      "learning_rate": 3.6927710843373497e-06,
      "loss": 0.2217,
      "step": 1736
    },
    {
      "epoch": 1.0463855421686747,
      "grad_norm": 0.54560786485672,
      "learning_rate": 3.692018072289157e-06,
      "loss": 0.2355,
      "step": 1737
    },
    {
      "epoch": 1.046987951807229,
      "grad_norm": 0.5111879706382751,
      "learning_rate": 3.6912650602409644e-06,
      "loss": 0.2243,
      "step": 1738
    },
    {
      "epoch": 1.047590361445783,
      "grad_norm": 0.571427583694458,
      "learning_rate": 3.6905120481927713e-06,
      "loss": 0.221,
      "step": 1739
    },
    {
      "epoch": 1.0481927710843373,
      "grad_norm": 0.5687968730926514,
      "learning_rate": 3.6897590361445782e-06,
      "loss": 0.2383,
      "step": 1740
    },
    {
      "epoch": 1.0487951807228915,
      "grad_norm": 0.5143910646438599,
      "learning_rate": 3.689006024096386e-06,
      "loss": 0.2016,
      "step": 1741
    },
    {
      "epoch": 1.0493975903614459,
      "grad_norm": 0.5122699737548828,
      "learning_rate": 3.688253012048193e-06,
      "loss": 0.2072,
      "step": 1742
    },
    {
      "epoch": 1.05,
      "grad_norm": 0.6492652893066406,
      "learning_rate": 3.6875000000000007e-06,
      "loss": 0.2107,
      "step": 1743
    },
    {
      "epoch": 1.0506024096385542,
      "grad_norm": 0.5572070479393005,
      "learning_rate": 3.6867469879518076e-06,
      "loss": 0.2553,
      "step": 1744
    },
    {
      "epoch": 1.0512048192771084,
      "grad_norm": 0.5319817662239075,
      "learning_rate": 3.6859939759036145e-06,
      "loss": 0.2431,
      "step": 1745
    },
    {
      "epoch": 1.0518072289156626,
      "grad_norm": 0.5428441166877747,
      "learning_rate": 3.685240963855422e-06,
      "loss": 0.2142,
      "step": 1746
    },
    {
      "epoch": 1.0524096385542168,
      "grad_norm": 0.5147220492362976,
      "learning_rate": 3.6844879518072292e-06,
      "loss": 0.2402,
      "step": 1747
    },
    {
      "epoch": 1.0530120481927712,
      "grad_norm": 0.5003815293312073,
      "learning_rate": 3.6837349397590366e-06,
      "loss": 0.1956,
      "step": 1748
    },
    {
      "epoch": 1.0536144578313253,
      "grad_norm": 0.5597472786903381,
      "learning_rate": 3.6829819277108435e-06,
      "loss": 0.2649,
      "step": 1749
    },
    {
      "epoch": 1.0542168674698795,
      "grad_norm": 0.664603054523468,
      "learning_rate": 3.6822289156626513e-06,
      "loss": 0.2058,
      "step": 1750
    },
    {
      "epoch": 1.0548192771084337,
      "grad_norm": 0.5159468650817871,
      "learning_rate": 3.681475903614458e-06,
      "loss": 0.2063,
      "step": 1751
    },
    {
      "epoch": 1.0554216867469879,
      "grad_norm": 0.5327771902084351,
      "learning_rate": 3.680722891566265e-06,
      "loss": 0.2449,
      "step": 1752
    },
    {
      "epoch": 1.056024096385542,
      "grad_norm": 0.6030926704406738,
      "learning_rate": 3.679969879518073e-06,
      "loss": 0.2219,
      "step": 1753
    },
    {
      "epoch": 1.0566265060240965,
      "grad_norm": 0.5450859069824219,
      "learning_rate": 3.67921686746988e-06,
      "loss": 0.251,
      "step": 1754
    },
    {
      "epoch": 1.0572289156626506,
      "grad_norm": 0.5292580127716064,
      "learning_rate": 3.678463855421687e-06,
      "loss": 0.2096,
      "step": 1755
    },
    {
      "epoch": 1.0578313253012048,
      "grad_norm": 0.5401519536972046,
      "learning_rate": 3.677710843373494e-06,
      "loss": 0.2186,
      "step": 1756
    },
    {
      "epoch": 1.058433734939759,
      "grad_norm": 0.576551616191864,
      "learning_rate": 3.6769578313253015e-06,
      "loss": 0.2281,
      "step": 1757
    },
    {
      "epoch": 1.0590361445783132,
      "grad_norm": 0.5316277742385864,
      "learning_rate": 3.676204819277109e-06,
      "loss": 0.2272,
      "step": 1758
    },
    {
      "epoch": 1.0596385542168674,
      "grad_norm": 0.4858055114746094,
      "learning_rate": 3.6754518072289157e-06,
      "loss": 0.2294,
      "step": 1759
    },
    {
      "epoch": 1.0602409638554218,
      "grad_norm": 0.5658179521560669,
      "learning_rate": 3.6746987951807235e-06,
      "loss": 0.2238,
      "step": 1760
    },
    {
      "epoch": 1.060843373493976,
      "grad_norm": 0.4977278411388397,
      "learning_rate": 3.6739457831325304e-06,
      "loss": 0.1949,
      "step": 1761
    },
    {
      "epoch": 1.0614457831325301,
      "grad_norm": 0.5870270133018494,
      "learning_rate": 3.6731927710843378e-06,
      "loss": 0.2649,
      "step": 1762
    },
    {
      "epoch": 1.0620481927710843,
      "grad_norm": 0.5851371884346008,
      "learning_rate": 3.672439759036145e-06,
      "loss": 0.2445,
      "step": 1763
    },
    {
      "epoch": 1.0626506024096385,
      "grad_norm": 0.515423595905304,
      "learning_rate": 3.671686746987952e-06,
      "loss": 0.2059,
      "step": 1764
    },
    {
      "epoch": 1.0632530120481927,
      "grad_norm": 0.5263842940330505,
      "learning_rate": 3.6709337349397594e-06,
      "loss": 0.1902,
      "step": 1765
    },
    {
      "epoch": 1.063855421686747,
      "grad_norm": 0.6661396026611328,
      "learning_rate": 3.6701807228915663e-06,
      "loss": 0.2621,
      "step": 1766
    },
    {
      "epoch": 1.0644578313253013,
      "grad_norm": 1.722571849822998,
      "learning_rate": 3.669427710843374e-06,
      "loss": 0.2027,
      "step": 1767
    },
    {
      "epoch": 1.0650602409638554,
      "grad_norm": 0.6620476841926575,
      "learning_rate": 3.668674698795181e-06,
      "loss": 0.2816,
      "step": 1768
    },
    {
      "epoch": 1.0656626506024096,
      "grad_norm": 0.621968686580658,
      "learning_rate": 3.667921686746988e-06,
      "loss": 0.2013,
      "step": 1769
    },
    {
      "epoch": 1.0662650602409638,
      "grad_norm": 0.4915632903575897,
      "learning_rate": 3.6671686746987957e-06,
      "loss": 0.201,
      "step": 1770
    },
    {
      "epoch": 1.066867469879518,
      "grad_norm": 0.51091068983078,
      "learning_rate": 3.6664156626506026e-06,
      "loss": 0.232,
      "step": 1771
    },
    {
      "epoch": 1.0674698795180724,
      "grad_norm": 0.5139888525009155,
      "learning_rate": 3.66566265060241e-06,
      "loss": 0.2209,
      "step": 1772
    },
    {
      "epoch": 1.0680722891566266,
      "grad_norm": 0.5320976376533508,
      "learning_rate": 3.664909638554217e-06,
      "loss": 0.2317,
      "step": 1773
    },
    {
      "epoch": 1.0686746987951807,
      "grad_norm": 0.538306713104248,
      "learning_rate": 3.6641566265060247e-06,
      "loss": 0.198,
      "step": 1774
    },
    {
      "epoch": 1.069277108433735,
      "grad_norm": 0.5456199049949646,
      "learning_rate": 3.6634036144578316e-06,
      "loss": 0.2018,
      "step": 1775
    },
    {
      "epoch": 1.069879518072289,
      "grad_norm": 0.5517899990081787,
      "learning_rate": 3.6626506024096385e-06,
      "loss": 0.2165,
      "step": 1776
    },
    {
      "epoch": 1.0704819277108433,
      "grad_norm": 0.517218291759491,
      "learning_rate": 3.6618975903614463e-06,
      "loss": 0.2,
      "step": 1777
    },
    {
      "epoch": 1.0710843373493977,
      "grad_norm": 0.6907402873039246,
      "learning_rate": 3.6611445783132532e-06,
      "loss": 0.2844,
      "step": 1778
    },
    {
      "epoch": 1.0716867469879519,
      "grad_norm": 0.5352781414985657,
      "learning_rate": 3.6603915662650606e-06,
      "loss": 0.2099,
      "step": 1779
    },
    {
      "epoch": 1.072289156626506,
      "grad_norm": 0.5808607935905457,
      "learning_rate": 3.659638554216868e-06,
      "loss": 0.2505,
      "step": 1780
    },
    {
      "epoch": 1.0728915662650602,
      "grad_norm": 1.544675350189209,
      "learning_rate": 3.658885542168675e-06,
      "loss": 0.2615,
      "step": 1781
    },
    {
      "epoch": 1.0734939759036144,
      "grad_norm": 0.5704716444015503,
      "learning_rate": 3.658132530120482e-06,
      "loss": 0.2119,
      "step": 1782
    },
    {
      "epoch": 1.0740963855421686,
      "grad_norm": 0.6376128196716309,
      "learning_rate": 3.657379518072289e-06,
      "loss": 0.2294,
      "step": 1783
    },
    {
      "epoch": 1.074698795180723,
      "grad_norm": 0.5213203430175781,
      "learning_rate": 3.656626506024097e-06,
      "loss": 0.1803,
      "step": 1784
    },
    {
      "epoch": 1.0753012048192772,
      "grad_norm": 0.48753389716148376,
      "learning_rate": 3.655873493975904e-06,
      "loss": 0.186,
      "step": 1785
    },
    {
      "epoch": 1.0759036144578313,
      "grad_norm": 0.5407127737998962,
      "learning_rate": 3.6551204819277116e-06,
      "loss": 0.2375,
      "step": 1786
    },
    {
      "epoch": 1.0765060240963855,
      "grad_norm": 0.5732458829879761,
      "learning_rate": 3.6543674698795185e-06,
      "loss": 0.2556,
      "step": 1787
    },
    {
      "epoch": 1.0771084337349397,
      "grad_norm": 0.5161295533180237,
      "learning_rate": 3.6536144578313254e-06,
      "loss": 0.1892,
      "step": 1788
    },
    {
      "epoch": 1.0777108433734939,
      "grad_norm": 0.5301356911659241,
      "learning_rate": 3.652861445783133e-06,
      "loss": 0.2562,
      "step": 1789
    },
    {
      "epoch": 1.0783132530120483,
      "grad_norm": 0.5471339821815491,
      "learning_rate": 3.65210843373494e-06,
      "loss": 0.2534,
      "step": 1790
    },
    {
      "epoch": 1.0789156626506025,
      "grad_norm": 0.6099619269371033,
      "learning_rate": 3.6513554216867475e-06,
      "loss": 0.2316,
      "step": 1791
    },
    {
      "epoch": 1.0795180722891566,
      "grad_norm": 0.5430505871772766,
      "learning_rate": 3.6506024096385544e-06,
      "loss": 0.2331,
      "step": 1792
    },
    {
      "epoch": 1.0801204819277108,
      "grad_norm": 0.5519763231277466,
      "learning_rate": 3.6498493975903613e-06,
      "loss": 0.2082,
      "step": 1793
    },
    {
      "epoch": 1.080722891566265,
      "grad_norm": 0.4993734657764435,
      "learning_rate": 3.649096385542169e-06,
      "loss": 0.2003,
      "step": 1794
    },
    {
      "epoch": 1.0813253012048192,
      "grad_norm": 0.5352278351783752,
      "learning_rate": 3.648343373493976e-06,
      "loss": 0.1888,
      "step": 1795
    },
    {
      "epoch": 1.0819277108433736,
      "grad_norm": 0.4976137578487396,
      "learning_rate": 3.647590361445784e-06,
      "loss": 0.2432,
      "step": 1796
    },
    {
      "epoch": 1.0825301204819278,
      "grad_norm": 0.5279603600502014,
      "learning_rate": 3.6468373493975907e-06,
      "loss": 0.2487,
      "step": 1797
    },
    {
      "epoch": 1.083132530120482,
      "grad_norm": 0.5191442966461182,
      "learning_rate": 3.646084337349398e-06,
      "loss": 0.1992,
      "step": 1798
    },
    {
      "epoch": 1.0837349397590361,
      "grad_norm": 0.6498234868049622,
      "learning_rate": 3.645331325301205e-06,
      "loss": 0.2454,
      "step": 1799
    },
    {
      "epoch": 1.0843373493975903,
      "grad_norm": 0.5209619998931885,
      "learning_rate": 3.6445783132530124e-06,
      "loss": 0.2191,
      "step": 1800
    },
    {
      "epoch": 1.0849397590361445,
      "grad_norm": 0.4767676889896393,
      "learning_rate": 3.6438253012048197e-06,
      "loss": 0.2054,
      "step": 1801
    },
    {
      "epoch": 1.0855421686746989,
      "grad_norm": 0.5059422850608826,
      "learning_rate": 3.6430722891566266e-06,
      "loss": 0.2208,
      "step": 1802
    },
    {
      "epoch": 1.086144578313253,
      "grad_norm": 0.4945264458656311,
      "learning_rate": 3.6423192771084344e-06,
      "loss": 0.2062,
      "step": 1803
    },
    {
      "epoch": 1.0867469879518072,
      "grad_norm": 0.6036528944969177,
      "learning_rate": 3.6415662650602413e-06,
      "loss": 0.2222,
      "step": 1804
    },
    {
      "epoch": 1.0873493975903614,
      "grad_norm": 0.9362481832504272,
      "learning_rate": 3.6408132530120482e-06,
      "loss": 0.2072,
      "step": 1805
    },
    {
      "epoch": 1.0879518072289156,
      "grad_norm": 0.5534032583236694,
      "learning_rate": 3.6400602409638556e-06,
      "loss": 0.2006,
      "step": 1806
    },
    {
      "epoch": 1.0885542168674698,
      "grad_norm": 0.5292927026748657,
      "learning_rate": 3.639307228915663e-06,
      "loss": 0.2177,
      "step": 1807
    },
    {
      "epoch": 1.0891566265060242,
      "grad_norm": 0.7009420990943909,
      "learning_rate": 3.6385542168674703e-06,
      "loss": 0.2189,
      "step": 1808
    },
    {
      "epoch": 1.0897590361445784,
      "grad_norm": 0.5236589908599854,
      "learning_rate": 3.6378012048192772e-06,
      "loss": 0.1975,
      "step": 1809
    },
    {
      "epoch": 1.0903614457831325,
      "grad_norm": 0.5168382525444031,
      "learning_rate": 3.637048192771085e-06,
      "loss": 0.2281,
      "step": 1810
    },
    {
      "epoch": 1.0909638554216867,
      "grad_norm": 0.5542349815368652,
      "learning_rate": 3.636295180722892e-06,
      "loss": 0.2292,
      "step": 1811
    },
    {
      "epoch": 1.091566265060241,
      "grad_norm": 0.5416032075881958,
      "learning_rate": 3.635542168674699e-06,
      "loss": 0.2355,
      "step": 1812
    },
    {
      "epoch": 1.092168674698795,
      "grad_norm": 0.49922293424606323,
      "learning_rate": 3.6347891566265066e-06,
      "loss": 0.192,
      "step": 1813
    },
    {
      "epoch": 1.0927710843373495,
      "grad_norm": 0.4727264642715454,
      "learning_rate": 3.6340361445783135e-06,
      "loss": 0.2005,
      "step": 1814
    },
    {
      "epoch": 1.0933734939759037,
      "grad_norm": 0.652241587638855,
      "learning_rate": 3.633283132530121e-06,
      "loss": 0.2777,
      "step": 1815
    },
    {
      "epoch": 1.0939759036144578,
      "grad_norm": 0.7309126257896423,
      "learning_rate": 3.632530120481928e-06,
      "loss": 0.2495,
      "step": 1816
    },
    {
      "epoch": 1.094578313253012,
      "grad_norm": 0.5440033674240112,
      "learning_rate": 3.631777108433735e-06,
      "loss": 0.2113,
      "step": 1817
    },
    {
      "epoch": 1.0951807228915662,
      "grad_norm": 0.5106068253517151,
      "learning_rate": 3.6310240963855425e-06,
      "loss": 0.191,
      "step": 1818
    },
    {
      "epoch": 1.0957831325301204,
      "grad_norm": 0.5251469612121582,
      "learning_rate": 3.6302710843373494e-06,
      "loss": 0.22,
      "step": 1819
    },
    {
      "epoch": 1.0963855421686748,
      "grad_norm": 0.5420975089073181,
      "learning_rate": 3.629518072289157e-06,
      "loss": 0.2092,
      "step": 1820
    },
    {
      "epoch": 1.096987951807229,
      "grad_norm": 0.575240969657898,
      "learning_rate": 3.628765060240964e-06,
      "loss": 0.1915,
      "step": 1821
    },
    {
      "epoch": 1.0975903614457831,
      "grad_norm": 0.6066436767578125,
      "learning_rate": 3.6280120481927715e-06,
      "loss": 0.2157,
      "step": 1822
    },
    {
      "epoch": 1.0981927710843373,
      "grad_norm": 0.5130349397659302,
      "learning_rate": 3.627259036144579e-06,
      "loss": 0.2231,
      "step": 1823
    },
    {
      "epoch": 1.0987951807228915,
      "grad_norm": 0.5202393531799316,
      "learning_rate": 3.6265060240963857e-06,
      "loss": 0.1991,
      "step": 1824
    },
    {
      "epoch": 1.0993975903614457,
      "grad_norm": 0.5576655268669128,
      "learning_rate": 3.625753012048193e-06,
      "loss": 0.2552,
      "step": 1825
    },
    {
      "epoch": 1.1,
      "grad_norm": 0.5397372245788574,
      "learning_rate": 3.625e-06,
      "loss": 0.2194,
      "step": 1826
    },
    {
      "epoch": 1.1006024096385543,
      "grad_norm": 0.6186792254447937,
      "learning_rate": 3.624246987951808e-06,
      "loss": 0.2429,
      "step": 1827
    },
    {
      "epoch": 1.1012048192771084,
      "grad_norm": 0.5064077377319336,
      "learning_rate": 3.6234939759036147e-06,
      "loss": 0.1912,
      "step": 1828
    },
    {
      "epoch": 1.1018072289156626,
      "grad_norm": 0.5650830268859863,
      "learning_rate": 3.6227409638554216e-06,
      "loss": 0.224,
      "step": 1829
    },
    {
      "epoch": 1.1024096385542168,
      "grad_norm": 0.5865598320960999,
      "learning_rate": 3.6219879518072294e-06,
      "loss": 0.2137,
      "step": 1830
    },
    {
      "epoch": 1.103012048192771,
      "grad_norm": 0.48744258284568787,
      "learning_rate": 3.6212349397590363e-06,
      "loss": 0.1912,
      "step": 1831
    },
    {
      "epoch": 1.1036144578313254,
      "grad_norm": 0.5158724188804626,
      "learning_rate": 3.6204819277108437e-06,
      "loss": 0.2043,
      "step": 1832
    },
    {
      "epoch": 1.1042168674698796,
      "grad_norm": 0.618457019329071,
      "learning_rate": 3.619728915662651e-06,
      "loss": 0.2165,
      "step": 1833
    },
    {
      "epoch": 1.1048192771084338,
      "grad_norm": 0.5326606035232544,
      "learning_rate": 3.6189759036144584e-06,
      "loss": 0.2268,
      "step": 1834
    },
    {
      "epoch": 1.105421686746988,
      "grad_norm": 0.5614398121833801,
      "learning_rate": 3.6182228915662653e-06,
      "loss": 0.2297,
      "step": 1835
    },
    {
      "epoch": 1.106024096385542,
      "grad_norm": 0.5366196632385254,
      "learning_rate": 3.6174698795180722e-06,
      "loss": 0.1827,
      "step": 1836
    },
    {
      "epoch": 1.1066265060240963,
      "grad_norm": 0.49557822942733765,
      "learning_rate": 3.61671686746988e-06,
      "loss": 0.1981,
      "step": 1837
    },
    {
      "epoch": 1.1072289156626507,
      "grad_norm": 0.5710806846618652,
      "learning_rate": 3.615963855421687e-06,
      "loss": 0.2408,
      "step": 1838
    },
    {
      "epoch": 1.1078313253012049,
      "grad_norm": 0.4855464994907379,
      "learning_rate": 3.6152108433734943e-06,
      "loss": 0.1588,
      "step": 1839
    },
    {
      "epoch": 1.108433734939759,
      "grad_norm": 0.5112894773483276,
      "learning_rate": 3.6144578313253016e-06,
      "loss": 0.2025,
      "step": 1840
    },
    {
      "epoch": 1.1090361445783132,
      "grad_norm": 0.5455805659294128,
      "learning_rate": 3.6137048192771086e-06,
      "loss": 0.2346,
      "step": 1841
    },
    {
      "epoch": 1.1096385542168674,
      "grad_norm": 0.48493048548698425,
      "learning_rate": 3.612951807228916e-06,
      "loss": 0.1986,
      "step": 1842
    },
    {
      "epoch": 1.1102409638554216,
      "grad_norm": 0.5333696603775024,
      "learning_rate": 3.612198795180723e-06,
      "loss": 0.2253,
      "step": 1843
    },
    {
      "epoch": 1.110843373493976,
      "grad_norm": 0.5468068718910217,
      "learning_rate": 3.6114457831325306e-06,
      "loss": 0.231,
      "step": 1844
    },
    {
      "epoch": 1.1114457831325302,
      "grad_norm": 0.5463106036186218,
      "learning_rate": 3.6106927710843375e-06,
      "loss": 0.2381,
      "step": 1845
    },
    {
      "epoch": 1.1120481927710844,
      "grad_norm": 0.4786742925643921,
      "learning_rate": 3.6099397590361453e-06,
      "loss": 0.2107,
      "step": 1846
    },
    {
      "epoch": 1.1126506024096385,
      "grad_norm": 0.48470285534858704,
      "learning_rate": 3.6091867469879522e-06,
      "loss": 0.1833,
      "step": 1847
    },
    {
      "epoch": 1.1132530120481927,
      "grad_norm": 0.5540372729301453,
      "learning_rate": 3.608433734939759e-06,
      "loss": 0.2379,
      "step": 1848
    },
    {
      "epoch": 1.113855421686747,
      "grad_norm": 0.5727939605712891,
      "learning_rate": 3.6076807228915665e-06,
      "loss": 0.2577,
      "step": 1849
    },
    {
      "epoch": 1.1144578313253013,
      "grad_norm": 0.530805766582489,
      "learning_rate": 3.606927710843374e-06,
      "loss": 0.222,
      "step": 1850
    },
    {
      "epoch": 1.1150602409638555,
      "grad_norm": 0.4967154860496521,
      "learning_rate": 3.606174698795181e-06,
      "loss": 0.1524,
      "step": 1851
    },
    {
      "epoch": 1.1156626506024097,
      "grad_norm": 0.5501148700714111,
      "learning_rate": 3.605421686746988e-06,
      "loss": 0.2333,
      "step": 1852
    },
    {
      "epoch": 1.1162650602409638,
      "grad_norm": 0.57914137840271,
      "learning_rate": 3.604668674698795e-06,
      "loss": 0.249,
      "step": 1853
    },
    {
      "epoch": 1.116867469879518,
      "grad_norm": 0.5137569904327393,
      "learning_rate": 3.603915662650603e-06,
      "loss": 0.2015,
      "step": 1854
    },
    {
      "epoch": 1.1174698795180722,
      "grad_norm": 0.5201687812805176,
      "learning_rate": 3.6031626506024097e-06,
      "loss": 0.2266,
      "step": 1855
    },
    {
      "epoch": 1.1180722891566266,
      "grad_norm": 0.5590726733207703,
      "learning_rate": 3.6024096385542175e-06,
      "loss": 0.2373,
      "step": 1856
    },
    {
      "epoch": 1.1186746987951808,
      "grad_norm": 0.5036510825157166,
      "learning_rate": 3.6016566265060244e-06,
      "loss": 0.2006,
      "step": 1857
    },
    {
      "epoch": 1.119277108433735,
      "grad_norm": 0.6969351172447205,
      "learning_rate": 3.6009036144578318e-06,
      "loss": 0.2426,
      "step": 1858
    },
    {
      "epoch": 1.1198795180722891,
      "grad_norm": 0.5396798253059387,
      "learning_rate": 3.6001506024096387e-06,
      "loss": 0.2108,
      "step": 1859
    },
    {
      "epoch": 1.1204819277108433,
      "grad_norm": 0.5681760907173157,
      "learning_rate": 3.599397590361446e-06,
      "loss": 0.1859,
      "step": 1860
    },
    {
      "epoch": 1.1210843373493975,
      "grad_norm": 0.5974310040473938,
      "learning_rate": 3.5986445783132534e-06,
      "loss": 0.2445,
      "step": 1861
    },
    {
      "epoch": 1.121686746987952,
      "grad_norm": 0.5168758034706116,
      "learning_rate": 3.5978915662650603e-06,
      "loss": 0.213,
      "step": 1862
    },
    {
      "epoch": 1.122289156626506,
      "grad_norm": 0.6454432010650635,
      "learning_rate": 3.597138554216868e-06,
      "loss": 0.2907,
      "step": 1863
    },
    {
      "epoch": 1.1228915662650603,
      "grad_norm": 0.4491730332374573,
      "learning_rate": 3.596385542168675e-06,
      "loss": 0.173,
      "step": 1864
    },
    {
      "epoch": 1.1234939759036144,
      "grad_norm": 0.523381233215332,
      "learning_rate": 3.595632530120482e-06,
      "loss": 0.2191,
      "step": 1865
    },
    {
      "epoch": 1.1240963855421686,
      "grad_norm": 0.480185866355896,
      "learning_rate": 3.5948795180722897e-06,
      "loss": 0.1946,
      "step": 1866
    },
    {
      "epoch": 1.1246987951807228,
      "grad_norm": 0.568064272403717,
      "learning_rate": 3.5941265060240966e-06,
      "loss": 0.2225,
      "step": 1867
    },
    {
      "epoch": 1.1253012048192772,
      "grad_norm": 0.5137066841125488,
      "learning_rate": 3.593373493975904e-06,
      "loss": 0.2183,
      "step": 1868
    },
    {
      "epoch": 1.1259036144578314,
      "grad_norm": 0.48073890805244446,
      "learning_rate": 3.592620481927711e-06,
      "loss": 0.1765,
      "step": 1869
    },
    {
      "epoch": 1.1265060240963856,
      "grad_norm": 0.5150208473205566,
      "learning_rate": 3.5918674698795187e-06,
      "loss": 0.2174,
      "step": 1870
    },
    {
      "epoch": 1.1271084337349397,
      "grad_norm": 0.4647635519504547,
      "learning_rate": 3.5911144578313256e-06,
      "loss": 0.1979,
      "step": 1871
    },
    {
      "epoch": 1.127710843373494,
      "grad_norm": 0.542641818523407,
      "learning_rate": 3.5903614457831325e-06,
      "loss": 0.2394,
      "step": 1872
    },
    {
      "epoch": 1.128313253012048,
      "grad_norm": 0.48791560530662537,
      "learning_rate": 3.5896084337349403e-06,
      "loss": 0.2246,
      "step": 1873
    },
    {
      "epoch": 1.1289156626506025,
      "grad_norm": 0.5232220888137817,
      "learning_rate": 3.5888554216867472e-06,
      "loss": 0.2041,
      "step": 1874
    },
    {
      "epoch": 1.1295180722891567,
      "grad_norm": 0.511705219745636,
      "learning_rate": 3.5881024096385546e-06,
      "loss": 0.1925,
      "step": 1875
    },
    {
      "epoch": 1.1301204819277109,
      "grad_norm": 0.5310438871383667,
      "learning_rate": 3.5873493975903615e-06,
      "loss": 0.1986,
      "step": 1876
    },
    {
      "epoch": 1.130722891566265,
      "grad_norm": 0.5201348662376404,
      "learning_rate": 3.586596385542169e-06,
      "loss": 0.2155,
      "step": 1877
    },
    {
      "epoch": 1.1313253012048192,
      "grad_norm": 0.6243007183074951,
      "learning_rate": 3.585843373493976e-06,
      "loss": 0.2109,
      "step": 1878
    },
    {
      "epoch": 1.1319277108433734,
      "grad_norm": 0.6189445853233337,
      "learning_rate": 3.585090361445783e-06,
      "loss": 0.2214,
      "step": 1879
    },
    {
      "epoch": 1.1325301204819278,
      "grad_norm": 0.5555151104927063,
      "learning_rate": 3.584337349397591e-06,
      "loss": 0.2178,
      "step": 1880
    },
    {
      "epoch": 1.133132530120482,
      "grad_norm": 0.5583275556564331,
      "learning_rate": 3.583584337349398e-06,
      "loss": 0.1964,
      "step": 1881
    },
    {
      "epoch": 1.1337349397590362,
      "grad_norm": 0.4533446431159973,
      "learning_rate": 3.582831325301205e-06,
      "loss": 0.2157,
      "step": 1882
    },
    {
      "epoch": 1.1343373493975903,
      "grad_norm": 0.48873162269592285,
      "learning_rate": 3.5820783132530125e-06,
      "loss": 0.2005,
      "step": 1883
    },
    {
      "epoch": 1.1349397590361445,
      "grad_norm": 0.6029200553894043,
      "learning_rate": 3.5813253012048195e-06,
      "loss": 0.2471,
      "step": 1884
    },
    {
      "epoch": 1.1355421686746987,
      "grad_norm": 0.5068983435630798,
      "learning_rate": 3.580572289156627e-06,
      "loss": 0.1893,
      "step": 1885
    },
    {
      "epoch": 1.136144578313253,
      "grad_norm": 0.5562282800674438,
      "learning_rate": 3.5798192771084337e-06,
      "loss": 0.2258,
      "step": 1886
    },
    {
      "epoch": 1.1367469879518073,
      "grad_norm": 0.5012851357460022,
      "learning_rate": 3.5790662650602415e-06,
      "loss": 0.1773,
      "step": 1887
    },
    {
      "epoch": 1.1373493975903615,
      "grad_norm": 0.5232363939285278,
      "learning_rate": 3.5783132530120484e-06,
      "loss": 0.2156,
      "step": 1888
    },
    {
      "epoch": 1.1379518072289156,
      "grad_norm": 0.6307539939880371,
      "learning_rate": 3.5775602409638553e-06,
      "loss": 0.2697,
      "step": 1889
    },
    {
      "epoch": 1.1385542168674698,
      "grad_norm": 0.552983283996582,
      "learning_rate": 3.576807228915663e-06,
      "loss": 0.2154,
      "step": 1890
    },
    {
      "epoch": 1.139156626506024,
      "grad_norm": 0.4872068464756012,
      "learning_rate": 3.57605421686747e-06,
      "loss": 0.1613,
      "step": 1891
    },
    {
      "epoch": 1.1397590361445784,
      "grad_norm": 0.47133690118789673,
      "learning_rate": 3.5753012048192774e-06,
      "loss": 0.1635,
      "step": 1892
    },
    {
      "epoch": 1.1403614457831326,
      "grad_norm": 0.6003945469856262,
      "learning_rate": 3.5745481927710847e-06,
      "loss": 0.2132,
      "step": 1893
    },
    {
      "epoch": 1.1409638554216868,
      "grad_norm": 0.5726304054260254,
      "learning_rate": 3.573795180722892e-06,
      "loss": 0.2552,
      "step": 1894
    },
    {
      "epoch": 1.141566265060241,
      "grad_norm": 0.4629165530204773,
      "learning_rate": 3.573042168674699e-06,
      "loss": 0.212,
      "step": 1895
    },
    {
      "epoch": 1.1421686746987951,
      "grad_norm": 0.5427557826042175,
      "learning_rate": 3.572289156626506e-06,
      "loss": 0.2231,
      "step": 1896
    },
    {
      "epoch": 1.1427710843373493,
      "grad_norm": 0.4522092938423157,
      "learning_rate": 3.5715361445783137e-06,
      "loss": 0.1813,
      "step": 1897
    },
    {
      "epoch": 1.1433734939759037,
      "grad_norm": 0.4991479516029358,
      "learning_rate": 3.5707831325301206e-06,
      "loss": 0.2278,
      "step": 1898
    },
    {
      "epoch": 1.143975903614458,
      "grad_norm": 0.6597758531570435,
      "learning_rate": 3.5700301204819284e-06,
      "loss": 0.2363,
      "step": 1899
    },
    {
      "epoch": 1.144578313253012,
      "grad_norm": 0.5336946249008179,
      "learning_rate": 3.5692771084337353e-06,
      "loss": 0.2082,
      "step": 1900
    },
    {
      "epoch": 1.1451807228915662,
      "grad_norm": 0.5268189907073975,
      "learning_rate": 3.5685240963855423e-06,
      "loss": 0.1843,
      "step": 1901
    },
    {
      "epoch": 1.1457831325301204,
      "grad_norm": 0.6086470484733582,
      "learning_rate": 3.5677710843373496e-06,
      "loss": 0.2068,
      "step": 1902
    },
    {
      "epoch": 1.1463855421686746,
      "grad_norm": 0.5443216562271118,
      "learning_rate": 3.567018072289157e-06,
      "loss": 0.2004,
      "step": 1903
    },
    {
      "epoch": 1.146987951807229,
      "grad_norm": 0.5304714441299438,
      "learning_rate": 3.5662650602409643e-06,
      "loss": 0.1669,
      "step": 1904
    },
    {
      "epoch": 1.1475903614457832,
      "grad_norm": 0.5763527154922485,
      "learning_rate": 3.5655120481927712e-06,
      "loss": 0.2263,
      "step": 1905
    },
    {
      "epoch": 1.1481927710843374,
      "grad_norm": 0.56394362449646,
      "learning_rate": 3.564759036144579e-06,
      "loss": 0.2231,
      "step": 1906
    },
    {
      "epoch": 1.1487951807228916,
      "grad_norm": 0.5180308818817139,
      "learning_rate": 3.564006024096386e-06,
      "loss": 0.185,
      "step": 1907
    },
    {
      "epoch": 1.1493975903614457,
      "grad_norm": 0.5114798545837402,
      "learning_rate": 3.563253012048193e-06,
      "loss": 0.1771,
      "step": 1908
    },
    {
      "epoch": 1.15,
      "grad_norm": 0.623798131942749,
      "learning_rate": 3.5625e-06,
      "loss": 0.2222,
      "step": 1909
    },
    {
      "epoch": 1.1506024096385543,
      "grad_norm": 0.5000555515289307,
      "learning_rate": 3.5617469879518075e-06,
      "loss": 0.1981,
      "step": 1910
    },
    {
      "epoch": 1.1512048192771085,
      "grad_norm": 0.46002933382987976,
      "learning_rate": 3.560993975903615e-06,
      "loss": 0.1932,
      "step": 1911
    },
    {
      "epoch": 1.1518072289156627,
      "grad_norm": 0.5338752269744873,
      "learning_rate": 3.560240963855422e-06,
      "loss": 0.1775,
      "step": 1912
    },
    {
      "epoch": 1.1524096385542169,
      "grad_norm": 0.5209441781044006,
      "learning_rate": 3.5594879518072287e-06,
      "loss": 0.2186,
      "step": 1913
    },
    {
      "epoch": 1.153012048192771,
      "grad_norm": 0.5502431988716125,
      "learning_rate": 3.5587349397590365e-06,
      "loss": 0.2241,
      "step": 1914
    },
    {
      "epoch": 1.1536144578313252,
      "grad_norm": 0.4694243371486664,
      "learning_rate": 3.5579819277108434e-06,
      "loss": 0.1839,
      "step": 1915
    },
    {
      "epoch": 1.1542168674698796,
      "grad_norm": 0.6045483946800232,
      "learning_rate": 3.557228915662651e-06,
      "loss": 0.2116,
      "step": 1916
    },
    {
      "epoch": 1.1548192771084338,
      "grad_norm": 0.6211910247802734,
      "learning_rate": 3.556475903614458e-06,
      "loss": 0.2728,
      "step": 1917
    },
    {
      "epoch": 1.155421686746988,
      "grad_norm": 0.5767918229103088,
      "learning_rate": 3.5557228915662655e-06,
      "loss": 0.2038,
      "step": 1918
    },
    {
      "epoch": 1.1560240963855422,
      "grad_norm": 0.5253927111625671,
      "learning_rate": 3.5549698795180724e-06,
      "loss": 0.2021,
      "step": 1919
    },
    {
      "epoch": 1.1566265060240963,
      "grad_norm": 0.6798669695854187,
      "learning_rate": 3.5542168674698798e-06,
      "loss": 0.2205,
      "step": 1920
    },
    {
      "epoch": 1.1572289156626505,
      "grad_norm": 0.9202501773834229,
      "learning_rate": 3.553463855421687e-06,
      "loss": 0.1863,
      "step": 1921
    },
    {
      "epoch": 1.157831325301205,
      "grad_norm": 0.5722305178642273,
      "learning_rate": 3.552710843373494e-06,
      "loss": 0.1764,
      "step": 1922
    },
    {
      "epoch": 1.158433734939759,
      "grad_norm": 0.4511795938014984,
      "learning_rate": 3.551957831325302e-06,
      "loss": 0.1796,
      "step": 1923
    },
    {
      "epoch": 1.1590361445783133,
      "grad_norm": 0.6181716322898865,
      "learning_rate": 3.5512048192771087e-06,
      "loss": 0.2333,
      "step": 1924
    },
    {
      "epoch": 1.1596385542168675,
      "grad_norm": 0.5256522297859192,
      "learning_rate": 3.5504518072289157e-06,
      "loss": 0.1985,
      "step": 1925
    },
    {
      "epoch": 1.1602409638554216,
      "grad_norm": 0.5418611168861389,
      "learning_rate": 3.5496987951807234e-06,
      "loss": 0.1794,
      "step": 1926
    },
    {
      "epoch": 1.1608433734939758,
      "grad_norm": 0.5807791352272034,
      "learning_rate": 3.5489457831325303e-06,
      "loss": 0.2207,
      "step": 1927
    },
    {
      "epoch": 1.16144578313253,
      "grad_norm": 0.5584355592727661,
      "learning_rate": 3.5481927710843377e-06,
      "loss": 0.1762,
      "step": 1928
    },
    {
      "epoch": 1.1620481927710844,
      "grad_norm": 0.5216977000236511,
      "learning_rate": 3.5474397590361446e-06,
      "loss": 0.2135,
      "step": 1929
    },
    {
      "epoch": 1.1626506024096386,
      "grad_norm": 0.5388471484184265,
      "learning_rate": 3.5466867469879524e-06,
      "loss": 0.2131,
      "step": 1930
    },
    {
      "epoch": 1.1632530120481928,
      "grad_norm": 0.5327441692352295,
      "learning_rate": 3.5459337349397593e-06,
      "loss": 0.1916,
      "step": 1931
    },
    {
      "epoch": 1.163855421686747,
      "grad_norm": 0.79390949010849,
      "learning_rate": 3.5451807228915662e-06,
      "loss": 0.18,
      "step": 1932
    },
    {
      "epoch": 1.1644578313253011,
      "grad_norm": 0.5625535249710083,
      "learning_rate": 3.544427710843374e-06,
      "loss": 0.1677,
      "step": 1933
    },
    {
      "epoch": 1.1650602409638555,
      "grad_norm": 0.5284898281097412,
      "learning_rate": 3.543674698795181e-06,
      "loss": 0.1884,
      "step": 1934
    },
    {
      "epoch": 1.1656626506024097,
      "grad_norm": 0.5934779644012451,
      "learning_rate": 3.5429216867469883e-06,
      "loss": 0.1975,
      "step": 1935
    },
    {
      "epoch": 1.1662650602409639,
      "grad_norm": 0.5528005957603455,
      "learning_rate": 3.5421686746987956e-06,
      "loss": 0.1973,
      "step": 1936
    },
    {
      "epoch": 1.166867469879518,
      "grad_norm": 0.5045902729034424,
      "learning_rate": 3.5414156626506026e-06,
      "loss": 0.2011,
      "step": 1937
    },
    {
      "epoch": 1.1674698795180722,
      "grad_norm": 0.5585579872131348,
      "learning_rate": 3.54066265060241e-06,
      "loss": 0.2541,
      "step": 1938
    },
    {
      "epoch": 1.1680722891566264,
      "grad_norm": 0.6925086379051208,
      "learning_rate": 3.539909638554217e-06,
      "loss": 0.2299,
      "step": 1939
    },
    {
      "epoch": 1.1686746987951806,
      "grad_norm": 0.5372573137283325,
      "learning_rate": 3.5391566265060246e-06,
      "loss": 0.2305,
      "step": 1940
    },
    {
      "epoch": 1.169277108433735,
      "grad_norm": 0.5340548753738403,
      "learning_rate": 3.5384036144578315e-06,
      "loss": 0.1806,
      "step": 1941
    },
    {
      "epoch": 1.1698795180722892,
      "grad_norm": 0.5587242245674133,
      "learning_rate": 3.537650602409639e-06,
      "loss": 0.2269,
      "step": 1942
    },
    {
      "epoch": 1.1704819277108434,
      "grad_norm": 0.5295665264129639,
      "learning_rate": 3.5368975903614462e-06,
      "loss": 0.1772,
      "step": 1943
    },
    {
      "epoch": 1.1710843373493975,
      "grad_norm": 0.5442972183227539,
      "learning_rate": 3.536144578313253e-06,
      "loss": 0.2328,
      "step": 1944
    },
    {
      "epoch": 1.1716867469879517,
      "grad_norm": 0.5333402156829834,
      "learning_rate": 3.5353915662650605e-06,
      "loss": 0.2031,
      "step": 1945
    },
    {
      "epoch": 1.1722891566265061,
      "grad_norm": 0.4847143590450287,
      "learning_rate": 3.5346385542168674e-06,
      "loss": 0.2041,
      "step": 1946
    },
    {
      "epoch": 1.1728915662650603,
      "grad_norm": 0.550190806388855,
      "learning_rate": 3.533885542168675e-06,
      "loss": 0.2213,
      "step": 1947
    },
    {
      "epoch": 1.1734939759036145,
      "grad_norm": 0.5722302198410034,
      "learning_rate": 3.533132530120482e-06,
      "loss": 0.1809,
      "step": 1948
    },
    {
      "epoch": 1.1740963855421687,
      "grad_norm": 0.5838688015937805,
      "learning_rate": 3.532379518072289e-06,
      "loss": 0.227,
      "step": 1949
    },
    {
      "epoch": 1.1746987951807228,
      "grad_norm": 0.5972089767456055,
      "learning_rate": 3.531626506024097e-06,
      "loss": 0.2446,
      "step": 1950
    },
    {
      "epoch": 1.175301204819277,
      "grad_norm": 0.4549812376499176,
      "learning_rate": 3.5308734939759037e-06,
      "loss": 0.1824,
      "step": 1951
    },
    {
      "epoch": 1.1759036144578312,
      "grad_norm": 0.5612959265708923,
      "learning_rate": 3.530120481927711e-06,
      "loss": 0.223,
      "step": 1952
    },
    {
      "epoch": 1.1765060240963856,
      "grad_norm": 0.5330514907836914,
      "learning_rate": 3.5293674698795184e-06,
      "loss": 0.208,
      "step": 1953
    },
    {
      "epoch": 1.1771084337349398,
      "grad_norm": 0.4878823161125183,
      "learning_rate": 3.528614457831326e-06,
      "loss": 0.2061,
      "step": 1954
    },
    {
      "epoch": 1.177710843373494,
      "grad_norm": 0.4871922731399536,
      "learning_rate": 3.5278614457831327e-06,
      "loss": 0.179,
      "step": 1955
    },
    {
      "epoch": 1.1783132530120481,
      "grad_norm": 0.4937908947467804,
      "learning_rate": 3.5271084337349396e-06,
      "loss": 0.1854,
      "step": 1956
    },
    {
      "epoch": 1.1789156626506023,
      "grad_norm": 0.5777179598808289,
      "learning_rate": 3.5263554216867474e-06,
      "loss": 0.1724,
      "step": 1957
    },
    {
      "epoch": 1.1795180722891567,
      "grad_norm": 0.558320939540863,
      "learning_rate": 3.5256024096385543e-06,
      "loss": 0.1979,
      "step": 1958
    },
    {
      "epoch": 1.180120481927711,
      "grad_norm": 0.646327555179596,
      "learning_rate": 3.524849397590362e-06,
      "loss": 0.2403,
      "step": 1959
    },
    {
      "epoch": 1.180722891566265,
      "grad_norm": 0.5412321090698242,
      "learning_rate": 3.524096385542169e-06,
      "loss": 0.2246,
      "step": 1960
    },
    {
      "epoch": 1.1813253012048193,
      "grad_norm": 0.7903767824172974,
      "learning_rate": 3.523343373493976e-06,
      "loss": 0.2455,
      "step": 1961
    },
    {
      "epoch": 1.1819277108433734,
      "grad_norm": 0.6417059898376465,
      "learning_rate": 3.5225903614457833e-06,
      "loss": 0.2294,
      "step": 1962
    },
    {
      "epoch": 1.1825301204819276,
      "grad_norm": 0.5513738989830017,
      "learning_rate": 3.5218373493975907e-06,
      "loss": 0.2071,
      "step": 1963
    },
    {
      "epoch": 1.1831325301204818,
      "grad_norm": 0.6380841135978699,
      "learning_rate": 3.521084337349398e-06,
      "loss": 0.232,
      "step": 1964
    },
    {
      "epoch": 1.1837349397590362,
      "grad_norm": 0.47366970777511597,
      "learning_rate": 3.520331325301205e-06,
      "loss": 0.1886,
      "step": 1965
    },
    {
      "epoch": 1.1843373493975904,
      "grad_norm": 0.46425992250442505,
      "learning_rate": 3.5195783132530127e-06,
      "loss": 0.1727,
      "step": 1966
    },
    {
      "epoch": 1.1849397590361446,
      "grad_norm": 0.5134811997413635,
      "learning_rate": 3.5188253012048196e-06,
      "loss": 0.2426,
      "step": 1967
    },
    {
      "epoch": 1.1855421686746987,
      "grad_norm": 0.5646978616714478,
      "learning_rate": 3.5180722891566266e-06,
      "loss": 0.1956,
      "step": 1968
    },
    {
      "epoch": 1.186144578313253,
      "grad_norm": 0.6262858510017395,
      "learning_rate": 3.5173192771084343e-06,
      "loss": 0.218,
      "step": 1969
    },
    {
      "epoch": 1.1867469879518073,
      "grad_norm": 0.7291490435600281,
      "learning_rate": 3.5165662650602412e-06,
      "loss": 0.2031,
      "step": 1970
    },
    {
      "epoch": 1.1873493975903615,
      "grad_norm": 0.5288464426994324,
      "learning_rate": 3.5158132530120486e-06,
      "loss": 0.1963,
      "step": 1971
    },
    {
      "epoch": 1.1879518072289157,
      "grad_norm": 0.6112202405929565,
      "learning_rate": 3.5150602409638555e-06,
      "loss": 0.2381,
      "step": 1972
    },
    {
      "epoch": 1.1885542168674699,
      "grad_norm": 0.4541468918323517,
      "learning_rate": 3.514307228915663e-06,
      "loss": 0.1872,
      "step": 1973
    },
    {
      "epoch": 1.189156626506024,
      "grad_norm": 0.6004835367202759,
      "learning_rate": 3.5135542168674702e-06,
      "loss": 0.209,
      "step": 1974
    },
    {
      "epoch": 1.1897590361445782,
      "grad_norm": 0.5897566080093384,
      "learning_rate": 3.512801204819277e-06,
      "loss": 0.2019,
      "step": 1975
    },
    {
      "epoch": 1.1903614457831324,
      "grad_norm": 0.5811851620674133,
      "learning_rate": 3.512048192771085e-06,
      "loss": 0.2119,
      "step": 1976
    },
    {
      "epoch": 1.1909638554216868,
      "grad_norm": 0.4994572103023529,
      "learning_rate": 3.511295180722892e-06,
      "loss": 0.1997,
      "step": 1977
    },
    {
      "epoch": 1.191566265060241,
      "grad_norm": 0.5362081527709961,
      "learning_rate": 3.510542168674699e-06,
      "loss": 0.2738,
      "step": 1978
    },
    {
      "epoch": 1.1921686746987952,
      "grad_norm": 0.4626055657863617,
      "learning_rate": 3.509789156626506e-06,
      "loss": 0.2029,
      "step": 1979
    },
    {
      "epoch": 1.1927710843373494,
      "grad_norm": 0.5270035862922668,
      "learning_rate": 3.5090361445783135e-06,
      "loss": 0.1972,
      "step": 1980
    },
    {
      "epoch": 1.1933734939759035,
      "grad_norm": 0.49472570419311523,
      "learning_rate": 3.508283132530121e-06,
      "loss": 0.1596,
      "step": 1981
    },
    {
      "epoch": 1.193975903614458,
      "grad_norm": 0.49748873710632324,
      "learning_rate": 3.5075301204819277e-06,
      "loss": 0.2002,
      "step": 1982
    },
    {
      "epoch": 1.1945783132530121,
      "grad_norm": 0.5168370008468628,
      "learning_rate": 3.5067771084337355e-06,
      "loss": 0.1897,
      "step": 1983
    },
    {
      "epoch": 1.1951807228915663,
      "grad_norm": 0.5509143471717834,
      "learning_rate": 3.5060240963855424e-06,
      "loss": 0.2078,
      "step": 1984
    },
    {
      "epoch": 1.1957831325301205,
      "grad_norm": 0.5664194822311401,
      "learning_rate": 3.5052710843373494e-06,
      "loss": 0.2133,
      "step": 1985
    },
    {
      "epoch": 1.1963855421686747,
      "grad_norm": 0.5495983958244324,
      "learning_rate": 3.504518072289157e-06,
      "loss": 0.2141,
      "step": 1986
    },
    {
      "epoch": 1.1969879518072288,
      "grad_norm": 0.5220193862915039,
      "learning_rate": 3.503765060240964e-06,
      "loss": 0.1854,
      "step": 1987
    },
    {
      "epoch": 1.197590361445783,
      "grad_norm": 0.5321598649024963,
      "learning_rate": 3.5030120481927714e-06,
      "loss": 0.1958,
      "step": 1988
    },
    {
      "epoch": 1.1981927710843374,
      "grad_norm": 0.49093544483184814,
      "learning_rate": 3.5022590361445783e-06,
      "loss": 0.1923,
      "step": 1989
    },
    {
      "epoch": 1.1987951807228916,
      "grad_norm": 0.4828150272369385,
      "learning_rate": 3.501506024096386e-06,
      "loss": 0.1716,
      "step": 1990
    },
    {
      "epoch": 1.1993975903614458,
      "grad_norm": 0.7337071299552917,
      "learning_rate": 3.500753012048193e-06,
      "loss": 0.2359,
      "step": 1991
    },
    {
      "epoch": 1.2,
      "grad_norm": 0.5813181400299072,
      "learning_rate": 3.5e-06,
      "loss": 0.1893,
      "step": 1992
    },
    {
      "epoch": 1.2006024096385541,
      "grad_norm": 0.5201652646064758,
      "learning_rate": 3.4992469879518077e-06,
      "loss": 0.179,
      "step": 1993
    },
    {
      "epoch": 1.2012048192771085,
      "grad_norm": 0.5151999592781067,
      "learning_rate": 3.4984939759036146e-06,
      "loss": 0.1588,
      "step": 1994
    },
    {
      "epoch": 1.2018072289156627,
      "grad_norm": 0.6725699305534363,
      "learning_rate": 3.497740963855422e-06,
      "loss": 0.2516,
      "step": 1995
    },
    {
      "epoch": 1.202409638554217,
      "grad_norm": 0.5523222088813782,
      "learning_rate": 3.4969879518072293e-06,
      "loss": 0.1881,
      "step": 1996
    },
    {
      "epoch": 1.203012048192771,
      "grad_norm": 0.5591747164726257,
      "learning_rate": 3.4962349397590363e-06,
      "loss": 0.1976,
      "step": 1997
    },
    {
      "epoch": 1.2036144578313253,
      "grad_norm": 0.476422518491745,
      "learning_rate": 3.4954819277108436e-06,
      "loss": 0.1619,
      "step": 1998
    },
    {
      "epoch": 1.2042168674698794,
      "grad_norm": 0.6791964769363403,
      "learning_rate": 3.4947289156626505e-06,
      "loss": 0.2365,
      "step": 1999
    },
    {
      "epoch": 1.2048192771084336,
      "grad_norm": 0.5697889924049377,
      "learning_rate": 3.4939759036144583e-06,
      "loss": 0.2344,
      "step": 2000
    },
    {
      "epoch": 1.205421686746988,
      "grad_norm": 0.556526243686676,
      "learning_rate": 3.4932228915662652e-06,
      "loss": 0.1715,
      "step": 2001
    },
    {
      "epoch": 1.2060240963855422,
      "grad_norm": 0.5852112174034119,
      "learning_rate": 3.492469879518073e-06,
      "loss": 0.1912,
      "step": 2002
    },
    {
      "epoch": 1.2066265060240964,
      "grad_norm": 0.5451976656913757,
      "learning_rate": 3.49171686746988e-06,
      "loss": 0.174,
      "step": 2003
    },
    {
      "epoch": 1.2072289156626506,
      "grad_norm": 0.5502060055732727,
      "learning_rate": 3.490963855421687e-06,
      "loss": 0.2135,
      "step": 2004
    },
    {
      "epoch": 1.2078313253012047,
      "grad_norm": 0.5501101613044739,
      "learning_rate": 3.490210843373494e-06,
      "loss": 0.2252,
      "step": 2005
    },
    {
      "epoch": 1.2084337349397591,
      "grad_norm": 0.5340811014175415,
      "learning_rate": 3.4894578313253016e-06,
      "loss": 0.2032,
      "step": 2006
    },
    {
      "epoch": 1.2090361445783133,
      "grad_norm": 0.5341264605522156,
      "learning_rate": 3.488704819277109e-06,
      "loss": 0.2226,
      "step": 2007
    },
    {
      "epoch": 1.2096385542168675,
      "grad_norm": 0.5882899165153503,
      "learning_rate": 3.487951807228916e-06,
      "loss": 0.2122,
      "step": 2008
    },
    {
      "epoch": 1.2102409638554217,
      "grad_norm": 0.5526759624481201,
      "learning_rate": 3.4871987951807228e-06,
      "loss": 0.2164,
      "step": 2009
    },
    {
      "epoch": 1.2108433734939759,
      "grad_norm": 0.47695979475975037,
      "learning_rate": 3.4864457831325305e-06,
      "loss": 0.1989,
      "step": 2010
    },
    {
      "epoch": 1.21144578313253,
      "grad_norm": 0.5537417531013489,
      "learning_rate": 3.4856927710843374e-06,
      "loss": 0.1778,
      "step": 2011
    },
    {
      "epoch": 1.2120481927710842,
      "grad_norm": 0.5143576264381409,
      "learning_rate": 3.484939759036145e-06,
      "loss": 0.1922,
      "step": 2012
    },
    {
      "epoch": 1.2126506024096386,
      "grad_norm": 0.6017286777496338,
      "learning_rate": 3.484186746987952e-06,
      "loss": 0.2424,
      "step": 2013
    },
    {
      "epoch": 1.2132530120481928,
      "grad_norm": 0.5137811899185181,
      "learning_rate": 3.4834337349397595e-06,
      "loss": 0.1861,
      "step": 2014
    },
    {
      "epoch": 1.213855421686747,
      "grad_norm": 0.5626114010810852,
      "learning_rate": 3.4826807228915664e-06,
      "loss": 0.191,
      "step": 2015
    },
    {
      "epoch": 1.2144578313253012,
      "grad_norm": 0.48768070340156555,
      "learning_rate": 3.4819277108433733e-06,
      "loss": 0.1921,
      "step": 2016
    },
    {
      "epoch": 1.2150602409638553,
      "grad_norm": 0.5285738110542297,
      "learning_rate": 3.481174698795181e-06,
      "loss": 0.2204,
      "step": 2017
    },
    {
      "epoch": 1.2156626506024097,
      "grad_norm": 0.49416759610176086,
      "learning_rate": 3.480421686746988e-06,
      "loss": 0.183,
      "step": 2018
    },
    {
      "epoch": 1.216265060240964,
      "grad_norm": 0.5409873127937317,
      "learning_rate": 3.479668674698796e-06,
      "loss": 0.1868,
      "step": 2019
    },
    {
      "epoch": 1.216867469879518,
      "grad_norm": 0.48021864891052246,
      "learning_rate": 3.4789156626506027e-06,
      "loss": 0.1891,
      "step": 2020
    },
    {
      "epoch": 1.2174698795180723,
      "grad_norm": 0.5852272510528564,
      "learning_rate": 3.4781626506024097e-06,
      "loss": 0.1865,
      "step": 2021
    },
    {
      "epoch": 1.2180722891566265,
      "grad_norm": 0.41270217299461365,
      "learning_rate": 3.477409638554217e-06,
      "loss": 0.1792,
      "step": 2022
    },
    {
      "epoch": 1.2186746987951806,
      "grad_norm": 0.5289608836174011,
      "learning_rate": 3.4766566265060244e-06,
      "loss": 0.1822,
      "step": 2023
    },
    {
      "epoch": 1.2192771084337348,
      "grad_norm": 0.5047442317008972,
      "learning_rate": 3.4759036144578317e-06,
      "loss": 0.2064,
      "step": 2024
    },
    {
      "epoch": 1.2198795180722892,
      "grad_norm": 0.507767915725708,
      "learning_rate": 3.4751506024096386e-06,
      "loss": 0.1976,
      "step": 2025
    },
    {
      "epoch": 1.2204819277108434,
      "grad_norm": 0.46567168831825256,
      "learning_rate": 3.4743975903614464e-06,
      "loss": 0.1982,
      "step": 2026
    },
    {
      "epoch": 1.2210843373493976,
      "grad_norm": 0.6519518494606018,
      "learning_rate": 3.4736445783132533e-06,
      "loss": 0.2014,
      "step": 2027
    },
    {
      "epoch": 1.2216867469879518,
      "grad_norm": 0.5133561491966248,
      "learning_rate": 3.4728915662650603e-06,
      "loss": 0.1805,
      "step": 2028
    },
    {
      "epoch": 1.222289156626506,
      "grad_norm": 0.548743724822998,
      "learning_rate": 3.472138554216868e-06,
      "loss": 0.204,
      "step": 2029
    },
    {
      "epoch": 1.2228915662650603,
      "grad_norm": 0.515352725982666,
      "learning_rate": 3.471385542168675e-06,
      "loss": 0.1477,
      "step": 2030
    },
    {
      "epoch": 1.2234939759036145,
      "grad_norm": 0.595231831073761,
      "learning_rate": 3.4706325301204823e-06,
      "loss": 0.2355,
      "step": 2031
    },
    {
      "epoch": 1.2240963855421687,
      "grad_norm": 0.701998233795166,
      "learning_rate": 3.4698795180722892e-06,
      "loss": 0.2324,
      "step": 2032
    },
    {
      "epoch": 1.2246987951807229,
      "grad_norm": 0.4802406132221222,
      "learning_rate": 3.4691265060240966e-06,
      "loss": 0.1677,
      "step": 2033
    },
    {
      "epoch": 1.225301204819277,
      "grad_norm": 0.5727881193161011,
      "learning_rate": 3.468373493975904e-06,
      "loss": 0.1844,
      "step": 2034
    },
    {
      "epoch": 1.2259036144578312,
      "grad_norm": 0.5080808401107788,
      "learning_rate": 3.467620481927711e-06,
      "loss": 0.1607,
      "step": 2035
    },
    {
      "epoch": 1.2265060240963854,
      "grad_norm": 0.5779033899307251,
      "learning_rate": 3.4668674698795186e-06,
      "loss": 0.1871,
      "step": 2036
    },
    {
      "epoch": 1.2271084337349398,
      "grad_norm": 0.5835126638412476,
      "learning_rate": 3.4661144578313255e-06,
      "loss": 0.1972,
      "step": 2037
    },
    {
      "epoch": 1.227710843373494,
      "grad_norm": 0.5590648651123047,
      "learning_rate": 3.465361445783133e-06,
      "loss": 0.2315,
      "step": 2038
    },
    {
      "epoch": 1.2283132530120482,
      "grad_norm": 0.5708262324333191,
      "learning_rate": 3.4646084337349402e-06,
      "loss": 0.2038,
      "step": 2039
    },
    {
      "epoch": 1.2289156626506024,
      "grad_norm": 0.5036938190460205,
      "learning_rate": 3.463855421686747e-06,
      "loss": 0.1966,
      "step": 2040
    },
    {
      "epoch": 1.2295180722891565,
      "grad_norm": 0.515728771686554,
      "learning_rate": 3.4631024096385545e-06,
      "loss": 0.1718,
      "step": 2041
    },
    {
      "epoch": 1.230120481927711,
      "grad_norm": 0.7596684694290161,
      "learning_rate": 3.4623493975903614e-06,
      "loss": 0.1674,
      "step": 2042
    },
    {
      "epoch": 1.2307228915662651,
      "grad_norm": 0.5838156342506409,
      "learning_rate": 3.461596385542169e-06,
      "loss": 0.202,
      "step": 2043
    },
    {
      "epoch": 1.2313253012048193,
      "grad_norm": 0.5366291999816895,
      "learning_rate": 3.460843373493976e-06,
      "loss": 0.1908,
      "step": 2044
    },
    {
      "epoch": 1.2319277108433735,
      "grad_norm": 0.7282143235206604,
      "learning_rate": 3.460090361445783e-06,
      "loss": 0.2653,
      "step": 2045
    },
    {
      "epoch": 1.2325301204819277,
      "grad_norm": 0.45459771156311035,
      "learning_rate": 3.459337349397591e-06,
      "loss": 0.1694,
      "step": 2046
    },
    {
      "epoch": 1.2331325301204819,
      "grad_norm": 0.4918019473552704,
      "learning_rate": 3.4585843373493978e-06,
      "loss": 0.1745,
      "step": 2047
    },
    {
      "epoch": 1.233734939759036,
      "grad_norm": 0.44909799098968506,
      "learning_rate": 3.457831325301205e-06,
      "loss": 0.1935,
      "step": 2048
    },
    {
      "epoch": 1.2343373493975904,
      "grad_norm": 0.4871605336666107,
      "learning_rate": 3.4570783132530125e-06,
      "loss": 0.2003,
      "step": 2049
    },
    {
      "epoch": 1.2349397590361446,
      "grad_norm": 0.4671669602394104,
      "learning_rate": 3.45632530120482e-06,
      "loss": 0.1604,
      "step": 2050
    },
    {
      "epoch": 1.2355421686746988,
      "grad_norm": 0.4369525909423828,
      "learning_rate": 3.4555722891566267e-06,
      "loss": 0.1579,
      "step": 2051
    },
    {
      "epoch": 1.236144578313253,
      "grad_norm": 0.45884737372398376,
      "learning_rate": 3.4548192771084337e-06,
      "loss": 0.1884,
      "step": 2052
    },
    {
      "epoch": 1.2367469879518072,
      "grad_norm": 0.5407612919807434,
      "learning_rate": 3.4540662650602414e-06,
      "loss": 0.1634,
      "step": 2053
    },
    {
      "epoch": 1.2373493975903616,
      "grad_norm": 0.62928706407547,
      "learning_rate": 3.4533132530120483e-06,
      "loss": 0.1826,
      "step": 2054
    },
    {
      "epoch": 1.2379518072289157,
      "grad_norm": 0.4680214524269104,
      "learning_rate": 3.4525602409638557e-06,
      "loss": 0.1365,
      "step": 2055
    },
    {
      "epoch": 1.23855421686747,
      "grad_norm": 0.6037473678588867,
      "learning_rate": 3.451807228915663e-06,
      "loss": 0.2393,
      "step": 2056
    },
    {
      "epoch": 1.239156626506024,
      "grad_norm": 0.6627287864685059,
      "learning_rate": 3.45105421686747e-06,
      "loss": 0.2181,
      "step": 2057
    },
    {
      "epoch": 1.2397590361445783,
      "grad_norm": 0.7126745581626892,
      "learning_rate": 3.4503012048192773e-06,
      "loss": 0.2247,
      "step": 2058
    },
    {
      "epoch": 1.2403614457831325,
      "grad_norm": 0.5735305547714233,
      "learning_rate": 3.4495481927710842e-06,
      "loss": 0.2062,
      "step": 2059
    },
    {
      "epoch": 1.2409638554216866,
      "grad_norm": 0.5015614032745361,
      "learning_rate": 3.448795180722892e-06,
      "loss": 0.1971,
      "step": 2060
    },
    {
      "epoch": 1.241566265060241,
      "grad_norm": 0.5502299070358276,
      "learning_rate": 3.448042168674699e-06,
      "loss": 0.1862,
      "step": 2061
    },
    {
      "epoch": 1.2421686746987952,
      "grad_norm": 0.5076557397842407,
      "learning_rate": 3.4472891566265067e-06,
      "loss": 0.2055,
      "step": 2062
    },
    {
      "epoch": 1.2427710843373494,
      "grad_norm": 0.5356013178825378,
      "learning_rate": 3.4465361445783136e-06,
      "loss": 0.2042,
      "step": 2063
    },
    {
      "epoch": 1.2433734939759036,
      "grad_norm": 0.5650935769081116,
      "learning_rate": 3.4457831325301206e-06,
      "loss": 0.1714,
      "step": 2064
    },
    {
      "epoch": 1.2439759036144578,
      "grad_norm": 0.5624931454658508,
      "learning_rate": 3.445030120481928e-06,
      "loss": 0.1996,
      "step": 2065
    },
    {
      "epoch": 1.2445783132530122,
      "grad_norm": 0.5377682447433472,
      "learning_rate": 3.4442771084337353e-06,
      "loss": 0.1817,
      "step": 2066
    },
    {
      "epoch": 1.2451807228915663,
      "grad_norm": 0.5248361825942993,
      "learning_rate": 3.4435240963855426e-06,
      "loss": 0.1895,
      "step": 2067
    },
    {
      "epoch": 1.2457831325301205,
      "grad_norm": 0.6273812055587769,
      "learning_rate": 3.4427710843373495e-06,
      "loss": 0.2259,
      "step": 2068
    },
    {
      "epoch": 1.2463855421686747,
      "grad_norm": 0.6276546120643616,
      "learning_rate": 3.4420180722891565e-06,
      "loss": 0.1681,
      "step": 2069
    },
    {
      "epoch": 1.2469879518072289,
      "grad_norm": 0.5217364430427551,
      "learning_rate": 3.4412650602409642e-06,
      "loss": 0.1572,
      "step": 2070
    },
    {
      "epoch": 1.247590361445783,
      "grad_norm": 0.4542401432991028,
      "learning_rate": 3.440512048192771e-06,
      "loss": 0.1777,
      "step": 2071
    },
    {
      "epoch": 1.2481927710843372,
      "grad_norm": 0.5016821622848511,
      "learning_rate": 3.439759036144579e-06,
      "loss": 0.1661,
      "step": 2072
    },
    {
      "epoch": 1.2487951807228916,
      "grad_norm": 0.5691844820976257,
      "learning_rate": 3.439006024096386e-06,
      "loss": 0.2083,
      "step": 2073
    },
    {
      "epoch": 1.2493975903614458,
      "grad_norm": 0.6089550256729126,
      "learning_rate": 3.438253012048193e-06,
      "loss": 0.2372,
      "step": 2074
    },
    {
      "epoch": 1.25,
      "grad_norm": 0.4923158884048462,
      "learning_rate": 3.4375e-06,
      "loss": 0.191,
      "step": 2075
    },
    {
      "epoch": 1.2506024096385542,
      "grad_norm": 0.5066738128662109,
      "learning_rate": 3.4367469879518075e-06,
      "loss": 0.2181,
      "step": 2076
    },
    {
      "epoch": 1.2512048192771084,
      "grad_norm": 0.6223948001861572,
      "learning_rate": 3.435993975903615e-06,
      "loss": 0.1818,
      "step": 2077
    },
    {
      "epoch": 1.2518072289156628,
      "grad_norm": 0.5101329684257507,
      "learning_rate": 3.4352409638554217e-06,
      "loss": 0.21,
      "step": 2078
    },
    {
      "epoch": 1.252409638554217,
      "grad_norm": 0.6743287444114685,
      "learning_rate": 3.4344879518072295e-06,
      "loss": 0.2199,
      "step": 2079
    },
    {
      "epoch": 1.2530120481927711,
      "grad_norm": 0.5732030868530273,
      "learning_rate": 3.4337349397590364e-06,
      "loss": 0.2164,
      "step": 2080
    },
    {
      "epoch": 1.2536144578313253,
      "grad_norm": 0.5262653827667236,
      "learning_rate": 3.432981927710844e-06,
      "loss": 0.19,
      "step": 2081
    },
    {
      "epoch": 1.2542168674698795,
      "grad_norm": 0.5195073485374451,
      "learning_rate": 3.432228915662651e-06,
      "loss": 0.1688,
      "step": 2082
    },
    {
      "epoch": 1.2548192771084337,
      "grad_norm": 0.6705267429351807,
      "learning_rate": 3.431475903614458e-06,
      "loss": 0.1797,
      "step": 2083
    },
    {
      "epoch": 1.2554216867469878,
      "grad_norm": 0.5905163288116455,
      "learning_rate": 3.4307228915662654e-06,
      "loss": 0.1926,
      "step": 2084
    },
    {
      "epoch": 1.2560240963855422,
      "grad_norm": 0.5444174408912659,
      "learning_rate": 3.4299698795180723e-06,
      "loss": 0.1642,
      "step": 2085
    },
    {
      "epoch": 1.2566265060240964,
      "grad_norm": 0.5432671308517456,
      "learning_rate": 3.42921686746988e-06,
      "loss": 0.1797,
      "step": 2086
    },
    {
      "epoch": 1.2572289156626506,
      "grad_norm": 0.5709699988365173,
      "learning_rate": 3.428463855421687e-06,
      "loss": 0.2247,
      "step": 2087
    },
    {
      "epoch": 1.2578313253012048,
      "grad_norm": 0.4787343144416809,
      "learning_rate": 3.427710843373494e-06,
      "loss": 0.1747,
      "step": 2088
    },
    {
      "epoch": 1.258433734939759,
      "grad_norm": 0.5001586675643921,
      "learning_rate": 3.4269578313253017e-06,
      "loss": 0.1916,
      "step": 2089
    },
    {
      "epoch": 1.2590361445783134,
      "grad_norm": 0.5246764421463013,
      "learning_rate": 3.4262048192771087e-06,
      "loss": 0.1922,
      "step": 2090
    },
    {
      "epoch": 1.2596385542168675,
      "grad_norm": 0.5463794469833374,
      "learning_rate": 3.425451807228916e-06,
      "loss": 0.2651,
      "step": 2091
    },
    {
      "epoch": 1.2602409638554217,
      "grad_norm": 0.6034669876098633,
      "learning_rate": 3.424698795180723e-06,
      "loss": 0.2707,
      "step": 2092
    },
    {
      "epoch": 1.260843373493976,
      "grad_norm": 0.5854209065437317,
      "learning_rate": 3.4239457831325307e-06,
      "loss": 0.2027,
      "step": 2093
    },
    {
      "epoch": 1.26144578313253,
      "grad_norm": 0.7347007393836975,
      "learning_rate": 3.4231927710843376e-06,
      "loss": 0.2374,
      "step": 2094
    },
    {
      "epoch": 1.2620481927710843,
      "grad_norm": 0.5338838696479797,
      "learning_rate": 3.4224397590361445e-06,
      "loss": 0.1953,
      "step": 2095
    },
    {
      "epoch": 1.2626506024096384,
      "grad_norm": 0.5715125203132629,
      "learning_rate": 3.4216867469879523e-06,
      "loss": 0.2116,
      "step": 2096
    },
    {
      "epoch": 1.2632530120481928,
      "grad_norm": 0.6828548312187195,
      "learning_rate": 3.4209337349397592e-06,
      "loss": 0.2216,
      "step": 2097
    },
    {
      "epoch": 1.263855421686747,
      "grad_norm": 0.6024839878082275,
      "learning_rate": 3.4201807228915666e-06,
      "loss": 0.1536,
      "step": 2098
    },
    {
      "epoch": 1.2644578313253012,
      "grad_norm": 0.5981391072273254,
      "learning_rate": 3.419427710843374e-06,
      "loss": 0.1974,
      "step": 2099
    },
    {
      "epoch": 1.2650602409638554,
      "grad_norm": 0.5444223880767822,
      "learning_rate": 3.418674698795181e-06,
      "loss": 0.1626,
      "step": 2100
    },
    {
      "epoch": 1.2656626506024096,
      "grad_norm": 0.5210844874382019,
      "learning_rate": 3.4179216867469882e-06,
      "loss": 0.1891,
      "step": 2101
    },
    {
      "epoch": 1.266265060240964,
      "grad_norm": 0.5636170506477356,
      "learning_rate": 3.417168674698795e-06,
      "loss": 0.1708,
      "step": 2102
    },
    {
      "epoch": 1.2668674698795181,
      "grad_norm": 0.4624468684196472,
      "learning_rate": 3.416415662650603e-06,
      "loss": 0.1767,
      "step": 2103
    },
    {
      "epoch": 1.2674698795180723,
      "grad_norm": 0.5492368936538696,
      "learning_rate": 3.41566265060241e-06,
      "loss": 0.203,
      "step": 2104
    },
    {
      "epoch": 1.2680722891566265,
      "grad_norm": 0.41532665491104126,
      "learning_rate": 3.4149096385542176e-06,
      "loss": 0.1712,
      "step": 2105
    },
    {
      "epoch": 1.2686746987951807,
      "grad_norm": 0.5400065779685974,
      "learning_rate": 3.4141566265060245e-06,
      "loss": 0.1751,
      "step": 2106
    },
    {
      "epoch": 1.2692771084337349,
      "grad_norm": 0.548352837562561,
      "learning_rate": 3.4134036144578315e-06,
      "loss": 0.1934,
      "step": 2107
    },
    {
      "epoch": 1.269879518072289,
      "grad_norm": 0.4711238741874695,
      "learning_rate": 3.412650602409639e-06,
      "loss": 0.1749,
      "step": 2108
    },
    {
      "epoch": 1.2704819277108435,
      "grad_norm": 0.5385871529579163,
      "learning_rate": 3.411897590361446e-06,
      "loss": 0.2091,
      "step": 2109
    },
    {
      "epoch": 1.2710843373493976,
      "grad_norm": 0.6068189740180969,
      "learning_rate": 3.4111445783132535e-06,
      "loss": 0.1901,
      "step": 2110
    },
    {
      "epoch": 1.2716867469879518,
      "grad_norm": 0.7278315424919128,
      "learning_rate": 3.4103915662650604e-06,
      "loss": 0.2174,
      "step": 2111
    },
    {
      "epoch": 1.272289156626506,
      "grad_norm": 0.47695615887641907,
      "learning_rate": 3.4096385542168674e-06,
      "loss": 0.1498,
      "step": 2112
    },
    {
      "epoch": 1.2728915662650602,
      "grad_norm": 0.5401319861412048,
      "learning_rate": 3.408885542168675e-06,
      "loss": 0.156,
      "step": 2113
    },
    {
      "epoch": 1.2734939759036146,
      "grad_norm": 0.5709061026573181,
      "learning_rate": 3.408132530120482e-06,
      "loss": 0.1753,
      "step": 2114
    },
    {
      "epoch": 1.2740963855421688,
      "grad_norm": 0.5433210134506226,
      "learning_rate": 3.40737951807229e-06,
      "loss": 0.22,
      "step": 2115
    },
    {
      "epoch": 1.274698795180723,
      "grad_norm": 0.5271232724189758,
      "learning_rate": 3.4066265060240967e-06,
      "loss": 0.1425,
      "step": 2116
    },
    {
      "epoch": 1.2753012048192771,
      "grad_norm": 0.5194512009620667,
      "learning_rate": 3.405873493975904e-06,
      "loss": 0.1878,
      "step": 2117
    },
    {
      "epoch": 1.2759036144578313,
      "grad_norm": 0.5045605897903442,
      "learning_rate": 3.405120481927711e-06,
      "loss": 0.1804,
      "step": 2118
    },
    {
      "epoch": 1.2765060240963855,
      "grad_norm": 0.567807137966156,
      "learning_rate": 3.4043674698795184e-06,
      "loss": 0.2384,
      "step": 2119
    },
    {
      "epoch": 1.2771084337349397,
      "grad_norm": 0.5818949937820435,
      "learning_rate": 3.4036144578313257e-06,
      "loss": 0.2083,
      "step": 2120
    },
    {
      "epoch": 1.277710843373494,
      "grad_norm": 0.543378472328186,
      "learning_rate": 3.4028614457831326e-06,
      "loss": 0.2006,
      "step": 2121
    },
    {
      "epoch": 1.2783132530120482,
      "grad_norm": 0.6878830790519714,
      "learning_rate": 3.4021084337349404e-06,
      "loss": 0.2808,
      "step": 2122
    },
    {
      "epoch": 1.2789156626506024,
      "grad_norm": 0.4643586575984955,
      "learning_rate": 3.4013554216867473e-06,
      "loss": 0.1813,
      "step": 2123
    },
    {
      "epoch": 1.2795180722891566,
      "grad_norm": 1.9668904542922974,
      "learning_rate": 3.4006024096385543e-06,
      "loss": 0.2555,
      "step": 2124
    },
    {
      "epoch": 1.2801204819277108,
      "grad_norm": 0.539911687374115,
      "learning_rate": 3.3998493975903616e-06,
      "loss": 0.1956,
      "step": 2125
    },
    {
      "epoch": 1.2807228915662652,
      "grad_norm": 0.5893529057502747,
      "learning_rate": 3.399096385542169e-06,
      "loss": 0.165,
      "step": 2126
    },
    {
      "epoch": 1.2813253012048194,
      "grad_norm": 0.6351974606513977,
      "learning_rate": 3.3983433734939763e-06,
      "loss": 0.1803,
      "step": 2127
    },
    {
      "epoch": 1.2819277108433735,
      "grad_norm": 0.5328117609024048,
      "learning_rate": 3.3975903614457832e-06,
      "loss": 0.2369,
      "step": 2128
    },
    {
      "epoch": 1.2825301204819277,
      "grad_norm": 0.6335029006004333,
      "learning_rate": 3.396837349397591e-06,
      "loss": 0.1947,
      "step": 2129
    },
    {
      "epoch": 1.283132530120482,
      "grad_norm": 0.536750316619873,
      "learning_rate": 3.396084337349398e-06,
      "loss": 0.2025,
      "step": 2130
    },
    {
      "epoch": 1.283734939759036,
      "grad_norm": 0.608988344669342,
      "learning_rate": 3.395331325301205e-06,
      "loss": 0.2607,
      "step": 2131
    },
    {
      "epoch": 1.2843373493975903,
      "grad_norm": 0.6423946022987366,
      "learning_rate": 3.3945783132530126e-06,
      "loss": 0.1931,
      "step": 2132
    },
    {
      "epoch": 1.2849397590361447,
      "grad_norm": 0.6052485108375549,
      "learning_rate": 3.3938253012048196e-06,
      "loss": 0.1572,
      "step": 2133
    },
    {
      "epoch": 1.2855421686746988,
      "grad_norm": 0.5970794558525085,
      "learning_rate": 3.393072289156627e-06,
      "loss": 0.1901,
      "step": 2134
    },
    {
      "epoch": 1.286144578313253,
      "grad_norm": 0.5168659090995789,
      "learning_rate": 3.392319277108434e-06,
      "loss": 0.1897,
      "step": 2135
    },
    {
      "epoch": 1.2867469879518072,
      "grad_norm": 0.7272449135780334,
      "learning_rate": 3.391566265060241e-06,
      "loss": 0.2143,
      "step": 2136
    },
    {
      "epoch": 1.2873493975903614,
      "grad_norm": 0.5246810913085938,
      "learning_rate": 3.3908132530120485e-06,
      "loss": 0.1582,
      "step": 2137
    },
    {
      "epoch": 1.2879518072289158,
      "grad_norm": 0.5548911690711975,
      "learning_rate": 3.3900602409638554e-06,
      "loss": 0.1742,
      "step": 2138
    },
    {
      "epoch": 1.28855421686747,
      "grad_norm": 0.5539312362670898,
      "learning_rate": 3.3893072289156632e-06,
      "loss": 0.224,
      "step": 2139
    },
    {
      "epoch": 1.2891566265060241,
      "grad_norm": 0.4958588778972626,
      "learning_rate": 3.38855421686747e-06,
      "loss": 0.1684,
      "step": 2140
    },
    {
      "epoch": 1.2897590361445783,
      "grad_norm": 0.5502337217330933,
      "learning_rate": 3.3878012048192775e-06,
      "loss": 0.1553,
      "step": 2141
    },
    {
      "epoch": 1.2903614457831325,
      "grad_norm": 0.506787896156311,
      "learning_rate": 3.387048192771085e-06,
      "loss": 0.1393,
      "step": 2142
    },
    {
      "epoch": 1.2909638554216867,
      "grad_norm": 0.520797073841095,
      "learning_rate": 3.3862951807228918e-06,
      "loss": 0.1739,
      "step": 2143
    },
    {
      "epoch": 1.2915662650602409,
      "grad_norm": 0.4911218583583832,
      "learning_rate": 3.385542168674699e-06,
      "loss": 0.184,
      "step": 2144
    },
    {
      "epoch": 1.2921686746987953,
      "grad_norm": 0.6304951310157776,
      "learning_rate": 3.384789156626506e-06,
      "loss": 0.2129,
      "step": 2145
    },
    {
      "epoch": 1.2927710843373494,
      "grad_norm": 0.5265110731124878,
      "learning_rate": 3.384036144578314e-06,
      "loss": 0.1517,
      "step": 2146
    },
    {
      "epoch": 1.2933734939759036,
      "grad_norm": 0.5989672541618347,
      "learning_rate": 3.3832831325301207e-06,
      "loss": 0.1948,
      "step": 2147
    },
    {
      "epoch": 1.2939759036144578,
      "grad_norm": 0.4860436022281647,
      "learning_rate": 3.3825301204819277e-06,
      "loss": 0.1487,
      "step": 2148
    },
    {
      "epoch": 1.294578313253012,
      "grad_norm": 0.4730358123779297,
      "learning_rate": 3.3817771084337354e-06,
      "loss": 0.1881,
      "step": 2149
    },
    {
      "epoch": 1.2951807228915664,
      "grad_norm": 0.5083059668540955,
      "learning_rate": 3.3810240963855424e-06,
      "loss": 0.1752,
      "step": 2150
    },
    {
      "epoch": 1.2957831325301206,
      "grad_norm": 0.5130840539932251,
      "learning_rate": 3.3802710843373497e-06,
      "loss": 0.1816,
      "step": 2151
    },
    {
      "epoch": 1.2963855421686747,
      "grad_norm": 0.5468241572380066,
      "learning_rate": 3.379518072289157e-06,
      "loss": 0.179,
      "step": 2152
    },
    {
      "epoch": 1.296987951807229,
      "grad_norm": 0.5741077065467834,
      "learning_rate": 3.3787650602409644e-06,
      "loss": 0.1969,
      "step": 2153
    },
    {
      "epoch": 1.297590361445783,
      "grad_norm": 0.5532721281051636,
      "learning_rate": 3.3780120481927713e-06,
      "loss": 0.1709,
      "step": 2154
    },
    {
      "epoch": 1.2981927710843373,
      "grad_norm": 0.5262527465820312,
      "learning_rate": 3.3772590361445783e-06,
      "loss": 0.1748,
      "step": 2155
    },
    {
      "epoch": 1.2987951807228915,
      "grad_norm": 0.521207869052887,
      "learning_rate": 3.376506024096386e-06,
      "loss": 0.153,
      "step": 2156
    },
    {
      "epoch": 1.2993975903614459,
      "grad_norm": 0.5010892748832703,
      "learning_rate": 3.375753012048193e-06,
      "loss": 0.1601,
      "step": 2157
    },
    {
      "epoch": 1.3,
      "grad_norm": 0.6392609477043152,
      "learning_rate": 3.3750000000000003e-06,
      "loss": 0.2225,
      "step": 2158
    },
    {
      "epoch": 1.3006024096385542,
      "grad_norm": 0.47818392515182495,
      "learning_rate": 3.3742469879518076e-06,
      "loss": 0.1853,
      "step": 2159
    },
    {
      "epoch": 1.3012048192771084,
      "grad_norm": 0.4857233166694641,
      "learning_rate": 3.3734939759036146e-06,
      "loss": 0.1626,
      "step": 2160
    },
    {
      "epoch": 1.3018072289156626,
      "grad_norm": 0.4885181784629822,
      "learning_rate": 3.372740963855422e-06,
      "loss": 0.194,
      "step": 2161
    },
    {
      "epoch": 1.302409638554217,
      "grad_norm": 0.4921138882637024,
      "learning_rate": 3.371987951807229e-06,
      "loss": 0.1672,
      "step": 2162
    },
    {
      "epoch": 1.3030120481927712,
      "grad_norm": 0.582262396812439,
      "learning_rate": 3.3712349397590366e-06,
      "loss": 0.1676,
      "step": 2163
    },
    {
      "epoch": 1.3036144578313253,
      "grad_norm": 0.5322909355163574,
      "learning_rate": 3.3704819277108435e-06,
      "loss": 0.164,
      "step": 2164
    },
    {
      "epoch": 1.3042168674698795,
      "grad_norm": 0.5784886479377747,
      "learning_rate": 3.3697289156626513e-06,
      "loss": 0.1981,
      "step": 2165
    },
    {
      "epoch": 1.3048192771084337,
      "grad_norm": 0.5750011801719666,
      "learning_rate": 3.3689759036144582e-06,
      "loss": 0.178,
      "step": 2166
    },
    {
      "epoch": 1.3054216867469879,
      "grad_norm": 0.5379712581634521,
      "learning_rate": 3.368222891566265e-06,
      "loss": 0.2208,
      "step": 2167
    },
    {
      "epoch": 1.306024096385542,
      "grad_norm": 0.5415909290313721,
      "learning_rate": 3.3674698795180725e-06,
      "loss": 0.1616,
      "step": 2168
    },
    {
      "epoch": 1.3066265060240965,
      "grad_norm": 0.5281622409820557,
      "learning_rate": 3.36671686746988e-06,
      "loss": 0.1717,
      "step": 2169
    },
    {
      "epoch": 1.3072289156626506,
      "grad_norm": 0.4840790927410126,
      "learning_rate": 3.365963855421687e-06,
      "loss": 0.1725,
      "step": 2170
    },
    {
      "epoch": 1.3078313253012048,
      "grad_norm": 0.603191614151001,
      "learning_rate": 3.365210843373494e-06,
      "loss": 0.1737,
      "step": 2171
    },
    {
      "epoch": 1.308433734939759,
      "grad_norm": 0.5124083161354065,
      "learning_rate": 3.364457831325301e-06,
      "loss": 0.1565,
      "step": 2172
    },
    {
      "epoch": 1.3090361445783132,
      "grad_norm": 0.5679370760917664,
      "learning_rate": 3.363704819277109e-06,
      "loss": 0.1874,
      "step": 2173
    },
    {
      "epoch": 1.3096385542168676,
      "grad_norm": 0.6179459691047668,
      "learning_rate": 3.3629518072289158e-06,
      "loss": 0.2116,
      "step": 2174
    },
    {
      "epoch": 1.3102409638554218,
      "grad_norm": 0.5342100858688354,
      "learning_rate": 3.3621987951807235e-06,
      "loss": 0.1415,
      "step": 2175
    },
    {
      "epoch": 1.310843373493976,
      "grad_norm": 0.5421295762062073,
      "learning_rate": 3.3614457831325305e-06,
      "loss": 0.1758,
      "step": 2176
    },
    {
      "epoch": 1.3114457831325301,
      "grad_norm": 0.5054522156715393,
      "learning_rate": 3.360692771084338e-06,
      "loss": 0.1714,
      "step": 2177
    },
    {
      "epoch": 1.3120481927710843,
      "grad_norm": 0.7176417112350464,
      "learning_rate": 3.3599397590361447e-06,
      "loss": 0.2486,
      "step": 2178
    },
    {
      "epoch": 1.3126506024096385,
      "grad_norm": 0.5656958818435669,
      "learning_rate": 3.359186746987952e-06,
      "loss": 0.1709,
      "step": 2179
    },
    {
      "epoch": 1.3132530120481927,
      "grad_norm": 0.5943360924720764,
      "learning_rate": 3.3584337349397594e-06,
      "loss": 0.1724,
      "step": 2180
    },
    {
      "epoch": 1.313855421686747,
      "grad_norm": 0.5438188910484314,
      "learning_rate": 3.3576807228915663e-06,
      "loss": 0.2361,
      "step": 2181
    },
    {
      "epoch": 1.3144578313253013,
      "grad_norm": 0.637691855430603,
      "learning_rate": 3.356927710843374e-06,
      "loss": 0.2843,
      "step": 2182
    },
    {
      "epoch": 1.3150602409638554,
      "grad_norm": 0.601238489151001,
      "learning_rate": 3.356174698795181e-06,
      "loss": 0.1867,
      "step": 2183
    },
    {
      "epoch": 1.3156626506024096,
      "grad_norm": 0.5090012550354004,
      "learning_rate": 3.355421686746988e-06,
      "loss": 0.1752,
      "step": 2184
    },
    {
      "epoch": 1.3162650602409638,
      "grad_norm": 0.5991654396057129,
      "learning_rate": 3.3546686746987957e-06,
      "loss": 0.1706,
      "step": 2185
    },
    {
      "epoch": 1.3168674698795182,
      "grad_norm": 0.5276944637298584,
      "learning_rate": 3.3539156626506027e-06,
      "loss": 0.1729,
      "step": 2186
    },
    {
      "epoch": 1.3174698795180722,
      "grad_norm": 0.603066086769104,
      "learning_rate": 3.35316265060241e-06,
      "loss": 0.1403,
      "step": 2187
    },
    {
      "epoch": 1.3180722891566266,
      "grad_norm": 0.6752890944480896,
      "learning_rate": 3.352409638554217e-06,
      "loss": 0.2352,
      "step": 2188
    },
    {
      "epoch": 1.3186746987951807,
      "grad_norm": 0.45915618538856506,
      "learning_rate": 3.3516566265060247e-06,
      "loss": 0.1728,
      "step": 2189
    },
    {
      "epoch": 1.319277108433735,
      "grad_norm": 0.5333177447319031,
      "learning_rate": 3.3509036144578316e-06,
      "loss": 0.1743,
      "step": 2190
    },
    {
      "epoch": 1.319879518072289,
      "grad_norm": 0.5331075191497803,
      "learning_rate": 3.3501506024096386e-06,
      "loss": 0.2029,
      "step": 2191
    },
    {
      "epoch": 1.3204819277108433,
      "grad_norm": 0.54094398021698,
      "learning_rate": 3.3493975903614463e-06,
      "loss": 0.193,
      "step": 2192
    },
    {
      "epoch": 1.3210843373493977,
      "grad_norm": 0.47652849555015564,
      "learning_rate": 3.3486445783132533e-06,
      "loss": 0.1459,
      "step": 2193
    },
    {
      "epoch": 1.3216867469879519,
      "grad_norm": 0.5614989995956421,
      "learning_rate": 3.3478915662650606e-06,
      "loss": 0.2525,
      "step": 2194
    },
    {
      "epoch": 1.322289156626506,
      "grad_norm": 0.8744429349899292,
      "learning_rate": 3.3471385542168675e-06,
      "loss": 0.2502,
      "step": 2195
    },
    {
      "epoch": 1.3228915662650602,
      "grad_norm": 0.4960770010948181,
      "learning_rate": 3.346385542168675e-06,
      "loss": 0.1849,
      "step": 2196
    },
    {
      "epoch": 1.3234939759036144,
      "grad_norm": 0.5452732443809509,
      "learning_rate": 3.3456325301204822e-06,
      "loss": 0.1994,
      "step": 2197
    },
    {
      "epoch": 1.3240963855421688,
      "grad_norm": 0.5978367328643799,
      "learning_rate": 3.344879518072289e-06,
      "loss": 0.1922,
      "step": 2198
    },
    {
      "epoch": 1.3246987951807228,
      "grad_norm": 0.5892844796180725,
      "learning_rate": 3.344126506024097e-06,
      "loss": 0.1934,
      "step": 2199
    },
    {
      "epoch": 1.3253012048192772,
      "grad_norm": 0.5403298735618591,
      "learning_rate": 3.343373493975904e-06,
      "loss": 0.2015,
      "step": 2200
    },
    {
      "epoch": 1.3259036144578313,
      "grad_norm": 0.6163607239723206,
      "learning_rate": 3.342620481927711e-06,
      "loss": 0.2267,
      "step": 2201
    },
    {
      "epoch": 1.3265060240963855,
      "grad_norm": 0.5459454655647278,
      "learning_rate": 3.3418674698795185e-06,
      "loss": 0.1568,
      "step": 2202
    },
    {
      "epoch": 1.3271084337349397,
      "grad_norm": 0.4858717620372772,
      "learning_rate": 3.3411144578313255e-06,
      "loss": 0.1633,
      "step": 2203
    },
    {
      "epoch": 1.3277108433734939,
      "grad_norm": 0.46691572666168213,
      "learning_rate": 3.340361445783133e-06,
      "loss": 0.1595,
      "step": 2204
    },
    {
      "epoch": 1.3283132530120483,
      "grad_norm": 0.639611542224884,
      "learning_rate": 3.3396084337349397e-06,
      "loss": 0.2017,
      "step": 2205
    },
    {
      "epoch": 1.3289156626506025,
      "grad_norm": 0.7025013566017151,
      "learning_rate": 3.3388554216867475e-06,
      "loss": 0.219,
      "step": 2206
    },
    {
      "epoch": 1.3295180722891566,
      "grad_norm": 0.6818082928657532,
      "learning_rate": 3.3381024096385544e-06,
      "loss": 0.2046,
      "step": 2207
    },
    {
      "epoch": 1.3301204819277108,
      "grad_norm": 0.5272484421730042,
      "learning_rate": 3.3373493975903614e-06,
      "loss": 0.1758,
      "step": 2208
    },
    {
      "epoch": 1.330722891566265,
      "grad_norm": 0.5677202939987183,
      "learning_rate": 3.336596385542169e-06,
      "loss": 0.2316,
      "step": 2209
    },
    {
      "epoch": 1.3313253012048194,
      "grad_norm": 0.7099974751472473,
      "learning_rate": 3.335843373493976e-06,
      "loss": 0.2549,
      "step": 2210
    },
    {
      "epoch": 1.3319277108433734,
      "grad_norm": 0.58151775598526,
      "learning_rate": 3.3350903614457834e-06,
      "loss": 0.2189,
      "step": 2211
    },
    {
      "epoch": 1.3325301204819278,
      "grad_norm": 0.5087286233901978,
      "learning_rate": 3.3343373493975908e-06,
      "loss": 0.1674,
      "step": 2212
    },
    {
      "epoch": 1.333132530120482,
      "grad_norm": 0.48320260643959045,
      "learning_rate": 3.333584337349398e-06,
      "loss": 0.161,
      "step": 2213
    },
    {
      "epoch": 1.3337349397590361,
      "grad_norm": 0.6247238516807556,
      "learning_rate": 3.332831325301205e-06,
      "loss": 0.2653,
      "step": 2214
    },
    {
      "epoch": 1.3343373493975903,
      "grad_norm": 0.6483696103096008,
      "learning_rate": 3.332078313253012e-06,
      "loss": 0.1627,
      "step": 2215
    },
    {
      "epoch": 1.3349397590361445,
      "grad_norm": 0.5987302660942078,
      "learning_rate": 3.3313253012048197e-06,
      "loss": 0.2091,
      "step": 2216
    },
    {
      "epoch": 1.3355421686746989,
      "grad_norm": 0.5652212500572205,
      "learning_rate": 3.3305722891566267e-06,
      "loss": 0.1869,
      "step": 2217
    },
    {
      "epoch": 1.336144578313253,
      "grad_norm": 0.4876735508441925,
      "learning_rate": 3.3298192771084344e-06,
      "loss": 0.1641,
      "step": 2218
    },
    {
      "epoch": 1.3367469879518072,
      "grad_norm": 0.5972146987915039,
      "learning_rate": 3.3290662650602413e-06,
      "loss": 0.1411,
      "step": 2219
    },
    {
      "epoch": 1.3373493975903614,
      "grad_norm": 0.49905091524124146,
      "learning_rate": 3.3283132530120483e-06,
      "loss": 0.1557,
      "step": 2220
    },
    {
      "epoch": 1.3379518072289156,
      "grad_norm": 0.5220765471458435,
      "learning_rate": 3.3275602409638556e-06,
      "loss": 0.1699,
      "step": 2221
    },
    {
      "epoch": 1.33855421686747,
      "grad_norm": 0.5261567831039429,
      "learning_rate": 3.326807228915663e-06,
      "loss": 0.1749,
      "step": 2222
    },
    {
      "epoch": 1.339156626506024,
      "grad_norm": 0.5456541180610657,
      "learning_rate": 3.3260542168674703e-06,
      "loss": 0.1762,
      "step": 2223
    },
    {
      "epoch": 1.3397590361445784,
      "grad_norm": 0.5568458437919617,
      "learning_rate": 3.3253012048192772e-06,
      "loss": 0.1524,
      "step": 2224
    },
    {
      "epoch": 1.3403614457831325,
      "grad_norm": 0.5402275323867798,
      "learning_rate": 3.324548192771085e-06,
      "loss": 0.1322,
      "step": 2225
    },
    {
      "epoch": 1.3409638554216867,
      "grad_norm": 0.5231860280036926,
      "learning_rate": 3.323795180722892e-06,
      "loss": 0.154,
      "step": 2226
    },
    {
      "epoch": 1.341566265060241,
      "grad_norm": 0.5490689277648926,
      "learning_rate": 3.323042168674699e-06,
      "loss": 0.1796,
      "step": 2227
    },
    {
      "epoch": 1.342168674698795,
      "grad_norm": 0.5327231884002686,
      "learning_rate": 3.3222891566265062e-06,
      "loss": 0.1808,
      "step": 2228
    },
    {
      "epoch": 1.3427710843373495,
      "grad_norm": 0.4799266457557678,
      "learning_rate": 3.3215361445783136e-06,
      "loss": 0.1668,
      "step": 2229
    },
    {
      "epoch": 1.3433734939759037,
      "grad_norm": 0.5585055351257324,
      "learning_rate": 3.320783132530121e-06,
      "loss": 0.2403,
      "step": 2230
    },
    {
      "epoch": 1.3439759036144578,
      "grad_norm": 0.5391466617584229,
      "learning_rate": 3.320030120481928e-06,
      "loss": 0.1595,
      "step": 2231
    },
    {
      "epoch": 1.344578313253012,
      "grad_norm": 0.4820175766944885,
      "learning_rate": 3.3192771084337348e-06,
      "loss": 0.177,
      "step": 2232
    },
    {
      "epoch": 1.3451807228915662,
      "grad_norm": 0.5084237456321716,
      "learning_rate": 3.3185240963855425e-06,
      "loss": 0.174,
      "step": 2233
    },
    {
      "epoch": 1.3457831325301206,
      "grad_norm": 0.5444133281707764,
      "learning_rate": 3.3177710843373495e-06,
      "loss": 0.2249,
      "step": 2234
    },
    {
      "epoch": 1.3463855421686746,
      "grad_norm": 0.5300859212875366,
      "learning_rate": 3.3170180722891572e-06,
      "loss": 0.1707,
      "step": 2235
    },
    {
      "epoch": 1.346987951807229,
      "grad_norm": 0.5411295890808105,
      "learning_rate": 3.316265060240964e-06,
      "loss": 0.2017,
      "step": 2236
    },
    {
      "epoch": 1.3475903614457831,
      "grad_norm": 0.5139811635017395,
      "learning_rate": 3.3155120481927715e-06,
      "loss": 0.1802,
      "step": 2237
    },
    {
      "epoch": 1.3481927710843373,
      "grad_norm": 0.475290983915329,
      "learning_rate": 3.3147590361445784e-06,
      "loss": 0.2014,
      "step": 2238
    },
    {
      "epoch": 1.3487951807228915,
      "grad_norm": 0.7844736576080322,
      "learning_rate": 3.3140060240963858e-06,
      "loss": 0.2559,
      "step": 2239
    },
    {
      "epoch": 1.3493975903614457,
      "grad_norm": 0.5309044718742371,
      "learning_rate": 3.313253012048193e-06,
      "loss": 0.2037,
      "step": 2240
    },
    {
      "epoch": 1.35,
      "grad_norm": 0.47695955634117126,
      "learning_rate": 3.3125e-06,
      "loss": 0.1641,
      "step": 2241
    },
    {
      "epoch": 1.3506024096385543,
      "grad_norm": 0.5480832457542419,
      "learning_rate": 3.311746987951808e-06,
      "loss": 0.2199,
      "step": 2242
    },
    {
      "epoch": 1.3512048192771084,
      "grad_norm": 0.5083246827125549,
      "learning_rate": 3.3109939759036147e-06,
      "loss": 0.1237,
      "step": 2243
    },
    {
      "epoch": 1.3518072289156626,
      "grad_norm": 0.5461105108261108,
      "learning_rate": 3.3102409638554217e-06,
      "loss": 0.1269,
      "step": 2244
    },
    {
      "epoch": 1.3524096385542168,
      "grad_norm": 0.5126503705978394,
      "learning_rate": 3.3094879518072294e-06,
      "loss": 0.196,
      "step": 2245
    },
    {
      "epoch": 1.3530120481927712,
      "grad_norm": 0.536460816860199,
      "learning_rate": 3.3087349397590364e-06,
      "loss": 0.1557,
      "step": 2246
    },
    {
      "epoch": 1.3536144578313252,
      "grad_norm": 0.6304298043251038,
      "learning_rate": 3.3079819277108437e-06,
      "loss": 0.1644,
      "step": 2247
    },
    {
      "epoch": 1.3542168674698796,
      "grad_norm": 0.6573516130447388,
      "learning_rate": 3.3072289156626506e-06,
      "loss": 0.2131,
      "step": 2248
    },
    {
      "epoch": 1.3548192771084338,
      "grad_norm": 0.6588073372840881,
      "learning_rate": 3.3064759036144584e-06,
      "loss": 0.2238,
      "step": 2249
    },
    {
      "epoch": 1.355421686746988,
      "grad_norm": 0.5317850708961487,
      "learning_rate": 3.3057228915662653e-06,
      "loss": 0.1704,
      "step": 2250
    },
    {
      "epoch": 1.356024096385542,
      "grad_norm": 0.5383726358413696,
      "learning_rate": 3.3049698795180723e-06,
      "loss": 0.2094,
      "step": 2251
    },
    {
      "epoch": 1.3566265060240963,
      "grad_norm": 0.553881049156189,
      "learning_rate": 3.30421686746988e-06,
      "loss": 0.1709,
      "step": 2252
    },
    {
      "epoch": 1.3572289156626507,
      "grad_norm": 0.5734332203865051,
      "learning_rate": 3.303463855421687e-06,
      "loss": 0.2243,
      "step": 2253
    },
    {
      "epoch": 1.3578313253012049,
      "grad_norm": 0.5260661244392395,
      "learning_rate": 3.3027108433734943e-06,
      "loss": 0.2187,
      "step": 2254
    },
    {
      "epoch": 1.358433734939759,
      "grad_norm": 0.4255843460559845,
      "learning_rate": 3.3019578313253017e-06,
      "loss": 0.123,
      "step": 2255
    },
    {
      "epoch": 1.3590361445783132,
      "grad_norm": 0.47441625595092773,
      "learning_rate": 3.3012048192771086e-06,
      "loss": 0.153,
      "step": 2256
    },
    {
      "epoch": 1.3596385542168674,
      "grad_norm": 0.6757397651672363,
      "learning_rate": 3.300451807228916e-06,
      "loss": 0.2209,
      "step": 2257
    },
    {
      "epoch": 1.3602409638554218,
      "grad_norm": 0.4838614761829376,
      "learning_rate": 3.299698795180723e-06,
      "loss": 0.1622,
      "step": 2258
    },
    {
      "epoch": 1.3608433734939758,
      "grad_norm": 0.5339489579200745,
      "learning_rate": 3.2989457831325306e-06,
      "loss": 0.1728,
      "step": 2259
    },
    {
      "epoch": 1.3614457831325302,
      "grad_norm": 0.4874097406864166,
      "learning_rate": 3.2981927710843376e-06,
      "loss": 0.1545,
      "step": 2260
    },
    {
      "epoch": 1.3620481927710844,
      "grad_norm": 0.5022059679031372,
      "learning_rate": 3.297439759036145e-06,
      "loss": 0.1817,
      "step": 2261
    },
    {
      "epoch": 1.3626506024096385,
      "grad_norm": 0.7170632481575012,
      "learning_rate": 3.2966867469879522e-06,
      "loss": 0.1996,
      "step": 2262
    },
    {
      "epoch": 1.3632530120481927,
      "grad_norm": 0.6365703344345093,
      "learning_rate": 3.295933734939759e-06,
      "loss": 0.1967,
      "step": 2263
    },
    {
      "epoch": 1.363855421686747,
      "grad_norm": 0.537943422794342,
      "learning_rate": 3.2951807228915665e-06,
      "loss": 0.195,
      "step": 2264
    },
    {
      "epoch": 1.3644578313253013,
      "grad_norm": 0.6089466214179993,
      "learning_rate": 3.2944277108433734e-06,
      "loss": 0.2626,
      "step": 2265
    },
    {
      "epoch": 1.3650602409638555,
      "grad_norm": 0.5185316801071167,
      "learning_rate": 3.2936746987951812e-06,
      "loss": 0.2245,
      "step": 2266
    },
    {
      "epoch": 1.3656626506024097,
      "grad_norm": 0.526167631149292,
      "learning_rate": 3.292921686746988e-06,
      "loss": 0.1837,
      "step": 2267
    },
    {
      "epoch": 1.3662650602409638,
      "grad_norm": 0.5005173087120056,
      "learning_rate": 3.292168674698795e-06,
      "loss": 0.1657,
      "step": 2268
    },
    {
      "epoch": 1.366867469879518,
      "grad_norm": 1.459147572517395,
      "learning_rate": 3.291415662650603e-06,
      "loss": 0.1841,
      "step": 2269
    },
    {
      "epoch": 1.3674698795180724,
      "grad_norm": 0.5903847813606262,
      "learning_rate": 3.2906626506024098e-06,
      "loss": 0.1649,
      "step": 2270
    },
    {
      "epoch": 1.3680722891566264,
      "grad_norm": 0.49489232897758484,
      "learning_rate": 3.289909638554217e-06,
      "loss": 0.1785,
      "step": 2271
    },
    {
      "epoch": 1.3686746987951808,
      "grad_norm": 0.5390990972518921,
      "learning_rate": 3.2891566265060245e-06,
      "loss": 0.1521,
      "step": 2272
    },
    {
      "epoch": 1.369277108433735,
      "grad_norm": 0.5757667422294617,
      "learning_rate": 3.288403614457832e-06,
      "loss": 0.1968,
      "step": 2273
    },
    {
      "epoch": 1.3698795180722891,
      "grad_norm": 0.5520087480545044,
      "learning_rate": 3.2876506024096387e-06,
      "loss": 0.2287,
      "step": 2274
    },
    {
      "epoch": 1.3704819277108433,
      "grad_norm": 0.47886836528778076,
      "learning_rate": 3.2868975903614457e-06,
      "loss": 0.1678,
      "step": 2275
    },
    {
      "epoch": 1.3710843373493975,
      "grad_norm": 0.5804421901702881,
      "learning_rate": 3.2861445783132534e-06,
      "loss": 0.2206,
      "step": 2276
    },
    {
      "epoch": 1.371686746987952,
      "grad_norm": 0.477165549993515,
      "learning_rate": 3.2853915662650604e-06,
      "loss": 0.1685,
      "step": 2277
    },
    {
      "epoch": 1.372289156626506,
      "grad_norm": 0.5127388834953308,
      "learning_rate": 3.284638554216868e-06,
      "loss": 0.1652,
      "step": 2278
    },
    {
      "epoch": 1.3728915662650603,
      "grad_norm": 0.6152040362358093,
      "learning_rate": 3.283885542168675e-06,
      "loss": 0.1466,
      "step": 2279
    },
    {
      "epoch": 1.3734939759036144,
      "grad_norm": 0.7649134993553162,
      "learning_rate": 3.283132530120482e-06,
      "loss": 0.1961,
      "step": 2280
    },
    {
      "epoch": 1.3740963855421686,
      "grad_norm": 0.564720630645752,
      "learning_rate": 3.2823795180722893e-06,
      "loss": 0.1792,
      "step": 2281
    },
    {
      "epoch": 1.374698795180723,
      "grad_norm": 0.5082259178161621,
      "learning_rate": 3.2816265060240967e-06,
      "loss": 0.1894,
      "step": 2282
    },
    {
      "epoch": 1.375301204819277,
      "grad_norm": 0.5042557120323181,
      "learning_rate": 3.280873493975904e-06,
      "loss": 0.1841,
      "step": 2283
    },
    {
      "epoch": 1.3759036144578314,
      "grad_norm": 0.5463283061981201,
      "learning_rate": 3.280120481927711e-06,
      "loss": 0.1718,
      "step": 2284
    },
    {
      "epoch": 1.3765060240963856,
      "grad_norm": 0.5135012269020081,
      "learning_rate": 3.2793674698795187e-06,
      "loss": 0.1666,
      "step": 2285
    },
    {
      "epoch": 1.3771084337349397,
      "grad_norm": 0.5522847771644592,
      "learning_rate": 3.2786144578313256e-06,
      "loss": 0.1739,
      "step": 2286
    },
    {
      "epoch": 1.377710843373494,
      "grad_norm": 0.585415244102478,
      "learning_rate": 3.2778614457831326e-06,
      "loss": 0.1953,
      "step": 2287
    },
    {
      "epoch": 1.378313253012048,
      "grad_norm": 0.6520205140113831,
      "learning_rate": 3.2771084337349403e-06,
      "loss": 0.2207,
      "step": 2288
    },
    {
      "epoch": 1.3789156626506025,
      "grad_norm": 0.6522010564804077,
      "learning_rate": 3.2763554216867473e-06,
      "loss": 0.2073,
      "step": 2289
    },
    {
      "epoch": 1.3795180722891567,
      "grad_norm": 0.4590504765510559,
      "learning_rate": 3.2756024096385546e-06,
      "loss": 0.1649,
      "step": 2290
    },
    {
      "epoch": 1.3801204819277109,
      "grad_norm": 0.5777042508125305,
      "learning_rate": 3.2748493975903615e-06,
      "loss": 0.2348,
      "step": 2291
    },
    {
      "epoch": 1.380722891566265,
      "grad_norm": 0.849089503288269,
      "learning_rate": 3.274096385542169e-06,
      "loss": 0.1495,
      "step": 2292
    },
    {
      "epoch": 1.3813253012048192,
      "grad_norm": 0.4641526937484741,
      "learning_rate": 3.2733433734939762e-06,
      "loss": 0.1643,
      "step": 2293
    },
    {
      "epoch": 1.3819277108433736,
      "grad_norm": 0.4951135218143463,
      "learning_rate": 3.272590361445783e-06,
      "loss": 0.1397,
      "step": 2294
    },
    {
      "epoch": 1.3825301204819276,
      "grad_norm": 0.5129128694534302,
      "learning_rate": 3.271837349397591e-06,
      "loss": 0.1671,
      "step": 2295
    },
    {
      "epoch": 1.383132530120482,
      "grad_norm": 0.5217187404632568,
      "learning_rate": 3.271084337349398e-06,
      "loss": 0.1807,
      "step": 2296
    },
    {
      "epoch": 1.3837349397590362,
      "grad_norm": 0.5070087909698486,
      "learning_rate": 3.270331325301205e-06,
      "loss": 0.1809,
      "step": 2297
    },
    {
      "epoch": 1.3843373493975903,
      "grad_norm": 0.7505948543548584,
      "learning_rate": 3.269578313253012e-06,
      "loss": 0.144,
      "step": 2298
    },
    {
      "epoch": 1.3849397590361445,
      "grad_norm": 0.5911058783531189,
      "learning_rate": 3.2688253012048195e-06,
      "loss": 0.1852,
      "step": 2299
    },
    {
      "epoch": 1.3855421686746987,
      "grad_norm": 0.5311010479927063,
      "learning_rate": 3.268072289156627e-06,
      "loss": 0.1775,
      "step": 2300
    },
    {
      "epoch": 1.386144578313253,
      "grad_norm": 0.6199509501457214,
      "learning_rate": 3.2673192771084338e-06,
      "loss": 0.1976,
      "step": 2301
    },
    {
      "epoch": 1.3867469879518073,
      "grad_norm": 0.5587260723114014,
      "learning_rate": 3.2665662650602415e-06,
      "loss": 0.2001,
      "step": 2302
    },
    {
      "epoch": 1.3873493975903615,
      "grad_norm": 0.5887894630432129,
      "learning_rate": 3.2658132530120484e-06,
      "loss": 0.1745,
      "step": 2303
    },
    {
      "epoch": 1.3879518072289156,
      "grad_norm": 0.5279020071029663,
      "learning_rate": 3.2650602409638554e-06,
      "loss": 0.1753,
      "step": 2304
    },
    {
      "epoch": 1.3885542168674698,
      "grad_norm": 0.6231406331062317,
      "learning_rate": 3.264307228915663e-06,
      "loss": 0.2584,
      "step": 2305
    },
    {
      "epoch": 1.3891566265060242,
      "grad_norm": 0.5635800361633301,
      "learning_rate": 3.26355421686747e-06,
      "loss": 0.1739,
      "step": 2306
    },
    {
      "epoch": 1.3897590361445782,
      "grad_norm": 0.5833488702774048,
      "learning_rate": 3.2628012048192774e-06,
      "loss": 0.178,
      "step": 2307
    },
    {
      "epoch": 1.3903614457831326,
      "grad_norm": 0.5185661315917969,
      "learning_rate": 3.2620481927710843e-06,
      "loss": 0.1829,
      "step": 2308
    },
    {
      "epoch": 1.3909638554216868,
      "grad_norm": 0.6639968156814575,
      "learning_rate": 3.261295180722892e-06,
      "loss": 0.1914,
      "step": 2309
    },
    {
      "epoch": 1.391566265060241,
      "grad_norm": 0.6355679035186768,
      "learning_rate": 3.260542168674699e-06,
      "loss": 0.255,
      "step": 2310
    },
    {
      "epoch": 1.3921686746987951,
      "grad_norm": 0.5712906122207642,
      "learning_rate": 3.259789156626506e-06,
      "loss": 0.181,
      "step": 2311
    },
    {
      "epoch": 1.3927710843373493,
      "grad_norm": 0.48274120688438416,
      "learning_rate": 3.2590361445783137e-06,
      "loss": 0.1421,
      "step": 2312
    },
    {
      "epoch": 1.3933734939759037,
      "grad_norm": 0.4986405372619629,
      "learning_rate": 3.2582831325301207e-06,
      "loss": 0.1918,
      "step": 2313
    },
    {
      "epoch": 1.393975903614458,
      "grad_norm": 0.5768399834632874,
      "learning_rate": 3.257530120481928e-06,
      "loss": 0.2247,
      "step": 2314
    },
    {
      "epoch": 1.394578313253012,
      "grad_norm": 0.5570464134216309,
      "learning_rate": 3.2567771084337354e-06,
      "loss": 0.2099,
      "step": 2315
    },
    {
      "epoch": 1.3951807228915662,
      "grad_norm": 0.5300554037094116,
      "learning_rate": 3.2560240963855423e-06,
      "loss": 0.1778,
      "step": 2316
    },
    {
      "epoch": 1.3957831325301204,
      "grad_norm": 0.5668994784355164,
      "learning_rate": 3.2552710843373496e-06,
      "loss": 0.1604,
      "step": 2317
    },
    {
      "epoch": 1.3963855421686748,
      "grad_norm": 0.6545187830924988,
      "learning_rate": 3.2545180722891566e-06,
      "loss": 0.2126,
      "step": 2318
    },
    {
      "epoch": 1.3969879518072288,
      "grad_norm": 0.5351520776748657,
      "learning_rate": 3.2537650602409643e-06,
      "loss": 0.1755,
      "step": 2319
    },
    {
      "epoch": 1.3975903614457832,
      "grad_norm": 1.0719043016433716,
      "learning_rate": 3.2530120481927713e-06,
      "loss": 0.2777,
      "step": 2320
    },
    {
      "epoch": 1.3981927710843374,
      "grad_norm": 1.0552167892456055,
      "learning_rate": 3.252259036144579e-06,
      "loss": 0.2522,
      "step": 2321
    },
    {
      "epoch": 1.3987951807228916,
      "grad_norm": 0.8427613377571106,
      "learning_rate": 3.251506024096386e-06,
      "loss": 0.3143,
      "step": 2322
    },
    {
      "epoch": 1.3993975903614457,
      "grad_norm": 0.6672219038009644,
      "learning_rate": 3.250753012048193e-06,
      "loss": 0.2708,
      "step": 2323
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.8004064559936523,
      "learning_rate": 3.2500000000000002e-06,
      "loss": 0.3085,
      "step": 2324
    },
    {
      "epoch": 1.4006024096385543,
      "grad_norm": 0.7584937810897827,
      "learning_rate": 3.2492469879518076e-06,
      "loss": 0.2949,
      "step": 2325
    },
    {
      "epoch": 1.4012048192771085,
      "grad_norm": 0.8175997734069824,
      "learning_rate": 3.248493975903615e-06,
      "loss": 0.3337,
      "step": 2326
    },
    {
      "epoch": 1.4018072289156627,
      "grad_norm": 0.7111529111862183,
      "learning_rate": 3.247740963855422e-06,
      "loss": 0.3096,
      "step": 2327
    },
    {
      "epoch": 1.4024096385542169,
      "grad_norm": 0.5972256064414978,
      "learning_rate": 3.2469879518072288e-06,
      "loss": 0.2988,
      "step": 2328
    },
    {
      "epoch": 1.403012048192771,
      "grad_norm": 0.6622523069381714,
      "learning_rate": 3.2462349397590365e-06,
      "loss": 0.2893,
      "step": 2329
    },
    {
      "epoch": 1.4036144578313254,
      "grad_norm": 0.7183555960655212,
      "learning_rate": 3.2454819277108435e-06,
      "loss": 0.3037,
      "step": 2330
    },
    {
      "epoch": 1.4042168674698794,
      "grad_norm": 0.5691891312599182,
      "learning_rate": 3.244728915662651e-06,
      "loss": 0.265,
      "step": 2331
    },
    {
      "epoch": 1.4048192771084338,
      "grad_norm": 0.6210376024246216,
      "learning_rate": 3.243975903614458e-06,
      "loss": 0.2332,
      "step": 2332
    },
    {
      "epoch": 1.405421686746988,
      "grad_norm": 0.5608975291252136,
      "learning_rate": 3.2432228915662655e-06,
      "loss": 0.2655,
      "step": 2333
    },
    {
      "epoch": 1.4060240963855422,
      "grad_norm": 0.5489559173583984,
      "learning_rate": 3.2424698795180724e-06,
      "loss": 0.2553,
      "step": 2334
    },
    {
      "epoch": 1.4066265060240963,
      "grad_norm": 0.6758730411529541,
      "learning_rate": 3.2417168674698794e-06,
      "loss": 0.234,
      "step": 2335
    },
    {
      "epoch": 1.4072289156626505,
      "grad_norm": 0.5850198268890381,
      "learning_rate": 3.240963855421687e-06,
      "loss": 0.2841,
      "step": 2336
    },
    {
      "epoch": 1.407831325301205,
      "grad_norm": 0.5686837434768677,
      "learning_rate": 3.240210843373494e-06,
      "loss": 0.2405,
      "step": 2337
    },
    {
      "epoch": 1.408433734939759,
      "grad_norm": 0.5956066250801086,
      "learning_rate": 3.239457831325302e-06,
      "loss": 0.264,
      "step": 2338
    },
    {
      "epoch": 1.4090361445783133,
      "grad_norm": 0.5541865229606628,
      "learning_rate": 3.2387048192771088e-06,
      "loss": 0.2527,
      "step": 2339
    },
    {
      "epoch": 1.4096385542168675,
      "grad_norm": 0.6709200739860535,
      "learning_rate": 3.2379518072289157e-06,
      "loss": 0.232,
      "step": 2340
    },
    {
      "epoch": 1.4102409638554216,
      "grad_norm": 0.5762766003608704,
      "learning_rate": 3.237198795180723e-06,
      "loss": 0.2403,
      "step": 2341
    },
    {
      "epoch": 1.410843373493976,
      "grad_norm": 0.6475654244422913,
      "learning_rate": 3.2364457831325304e-06,
      "loss": 0.2593,
      "step": 2342
    },
    {
      "epoch": 1.41144578313253,
      "grad_norm": 0.634614884853363,
      "learning_rate": 3.2356927710843377e-06,
      "loss": 0.2708,
      "step": 2343
    },
    {
      "epoch": 1.4120481927710844,
      "grad_norm": 0.6058546304702759,
      "learning_rate": 3.2349397590361447e-06,
      "loss": 0.2777,
      "step": 2344
    },
    {
      "epoch": 1.4126506024096386,
      "grad_norm": 0.7038960456848145,
      "learning_rate": 3.2341867469879524e-06,
      "loss": 0.2639,
      "step": 2345
    },
    {
      "epoch": 1.4132530120481928,
      "grad_norm": 0.6931425929069519,
      "learning_rate": 3.2334337349397593e-06,
      "loss": 0.2989,
      "step": 2346
    },
    {
      "epoch": 1.413855421686747,
      "grad_norm": 0.597335159778595,
      "learning_rate": 3.2326807228915663e-06,
      "loss": 0.2824,
      "step": 2347
    },
    {
      "epoch": 1.4144578313253011,
      "grad_norm": 0.6621190905570984,
      "learning_rate": 3.231927710843374e-06,
      "loss": 0.2714,
      "step": 2348
    },
    {
      "epoch": 1.4150602409638555,
      "grad_norm": 0.5678834319114685,
      "learning_rate": 3.231174698795181e-06,
      "loss": 0.2652,
      "step": 2349
    },
    {
      "epoch": 1.4156626506024097,
      "grad_norm": 0.7015737891197205,
      "learning_rate": 3.2304216867469883e-06,
      "loss": 0.3078,
      "step": 2350
    },
    {
      "epoch": 1.4162650602409639,
      "grad_norm": 0.581649661064148,
      "learning_rate": 3.2296686746987952e-06,
      "loss": 0.2545,
      "step": 2351
    },
    {
      "epoch": 1.416867469879518,
      "grad_norm": 0.5673131942749023,
      "learning_rate": 3.2289156626506026e-06,
      "loss": 0.2563,
      "step": 2352
    },
    {
      "epoch": 1.4174698795180722,
      "grad_norm": 0.5348991751670837,
      "learning_rate": 3.22816265060241e-06,
      "loss": 0.2407,
      "step": 2353
    },
    {
      "epoch": 1.4180722891566266,
      "grad_norm": 0.617276132106781,
      "learning_rate": 3.227409638554217e-06,
      "loss": 0.295,
      "step": 2354
    },
    {
      "epoch": 1.4186746987951806,
      "grad_norm": 0.6518856287002563,
      "learning_rate": 3.2266566265060246e-06,
      "loss": 0.2626,
      "step": 2355
    },
    {
      "epoch": 1.419277108433735,
      "grad_norm": 0.5132614970207214,
      "learning_rate": 3.2259036144578316e-06,
      "loss": 0.2282,
      "step": 2356
    },
    {
      "epoch": 1.4198795180722892,
      "grad_norm": 0.5693657994270325,
      "learning_rate": 3.225150602409639e-06,
      "loss": 0.29,
      "step": 2357
    },
    {
      "epoch": 1.4204819277108434,
      "grad_norm": 0.6154908537864685,
      "learning_rate": 3.2243975903614463e-06,
      "loss": 0.2635,
      "step": 2358
    },
    {
      "epoch": 1.4210843373493975,
      "grad_norm": Infinity,
      "learning_rate": 3.2243975903614463e-06,
      "loss": 0.2578,
      "step": 2359
    },
    {
      "epoch": 1.4216867469879517,
      "grad_norm": 0.5772690176963806,
      "learning_rate": 3.223644578313253e-06,
      "loss": 0.2742,
      "step": 2360
    },
    {
      "epoch": 1.4222891566265061,
      "grad_norm": 0.5746062994003296,
      "learning_rate": 3.2228915662650605e-06,
      "loss": 0.2966,
      "step": 2361
    },
    {
      "epoch": 1.4228915662650603,
      "grad_norm": 0.5773410201072693,
      "learning_rate": 3.2221385542168675e-06,
      "loss": 0.2602,
      "step": 2362
    },
    {
      "epoch": 1.4234939759036145,
      "grad_norm": 0.5220562815666199,
      "learning_rate": 3.2213855421686752e-06,
      "loss": 0.2906,
      "step": 2363
    },
    {
      "epoch": 1.4240963855421687,
      "grad_norm": 0.5639569163322449,
      "learning_rate": 3.220632530120482e-06,
      "loss": 0.281,
      "step": 2364
    },
    {
      "epoch": 1.4246987951807228,
      "grad_norm": 0.5661048889160156,
      "learning_rate": 3.219879518072289e-06,
      "loss": 0.2799,
      "step": 2365
    },
    {
      "epoch": 1.4253012048192772,
      "grad_norm": 0.5652806758880615,
      "learning_rate": 3.219126506024097e-06,
      "loss": 0.2597,
      "step": 2366
    },
    {
      "epoch": 1.4259036144578312,
      "grad_norm": 0.573578953742981,
      "learning_rate": 3.2183734939759038e-06,
      "loss": 0.2916,
      "step": 2367
    },
    {
      "epoch": 1.4265060240963856,
      "grad_norm": 0.5287148952484131,
      "learning_rate": 3.217620481927711e-06,
      "loss": 0.2517,
      "step": 2368
    },
    {
      "epoch": 1.4271084337349398,
      "grad_norm": 0.5396540760993958,
      "learning_rate": 3.216867469879518e-06,
      "loss": 0.2381,
      "step": 2369
    },
    {
      "epoch": 1.427710843373494,
      "grad_norm": 0.612398087978363,
      "learning_rate": 3.216114457831326e-06,
      "loss": 0.2808,
      "step": 2370
    },
    {
      "epoch": 1.4283132530120481,
      "grad_norm": 0.6178961992263794,
      "learning_rate": 3.2153614457831327e-06,
      "loss": 0.2897,
      "step": 2371
    },
    {
      "epoch": 1.4289156626506023,
      "grad_norm": 0.6121024489402771,
      "learning_rate": 3.2146084337349397e-06,
      "loss": 0.2966,
      "step": 2372
    },
    {
      "epoch": 1.4295180722891567,
      "grad_norm": 0.6138757467269897,
      "learning_rate": 3.2138554216867474e-06,
      "loss": 0.2577,
      "step": 2373
    },
    {
      "epoch": 1.430120481927711,
      "grad_norm": 0.6238710880279541,
      "learning_rate": 3.2131024096385544e-06,
      "loss": 0.2552,
      "step": 2374
    },
    {
      "epoch": 1.430722891566265,
      "grad_norm": 0.529388964176178,
      "learning_rate": 3.2123493975903617e-06,
      "loss": 0.2942,
      "step": 2375
    },
    {
      "epoch": 1.4313253012048193,
      "grad_norm": 0.545788586139679,
      "learning_rate": 3.211596385542169e-06,
      "loss": 0.2306,
      "step": 2376
    },
    {
      "epoch": 1.4319277108433734,
      "grad_norm": 0.624305248260498,
      "learning_rate": 3.210843373493976e-06,
      "loss": 0.2234,
      "step": 2377
    },
    {
      "epoch": 1.4325301204819278,
      "grad_norm": 0.5486408472061157,
      "learning_rate": 3.2100903614457833e-06,
      "loss": 0.2099,
      "step": 2378
    },
    {
      "epoch": 1.4331325301204818,
      "grad_norm": 0.565563440322876,
      "learning_rate": 3.2093373493975903e-06,
      "loss": 0.2468,
      "step": 2379
    },
    {
      "epoch": 1.4337349397590362,
      "grad_norm": 0.9065265655517578,
      "learning_rate": 3.208584337349398e-06,
      "loss": 0.338,
      "step": 2380
    },
    {
      "epoch": 1.4343373493975904,
      "grad_norm": 0.5555992722511292,
      "learning_rate": 3.207831325301205e-06,
      "loss": 0.2631,
      "step": 2381
    },
    {
      "epoch": 1.4349397590361446,
      "grad_norm": 0.6425156593322754,
      "learning_rate": 3.2070783132530127e-06,
      "loss": 0.3262,
      "step": 2382
    },
    {
      "epoch": 1.4355421686746987,
      "grad_norm": 0.5395535230636597,
      "learning_rate": 3.2063253012048197e-06,
      "loss": 0.2335,
      "step": 2383
    },
    {
      "epoch": 1.436144578313253,
      "grad_norm": 0.5675008296966553,
      "learning_rate": 3.2055722891566266e-06,
      "loss": 0.2857,
      "step": 2384
    },
    {
      "epoch": 1.4367469879518073,
      "grad_norm": 0.5432442426681519,
      "learning_rate": 3.204819277108434e-06,
      "loss": 0.2448,
      "step": 2385
    },
    {
      "epoch": 1.4373493975903615,
      "grad_norm": 0.5099388957023621,
      "learning_rate": 3.2040662650602413e-06,
      "loss": 0.2536,
      "step": 2386
    },
    {
      "epoch": 1.4379518072289157,
      "grad_norm": 0.5909395217895508,
      "learning_rate": 3.2033132530120486e-06,
      "loss": 0.3084,
      "step": 2387
    },
    {
      "epoch": 1.4385542168674699,
      "grad_norm": 0.5531519651412964,
      "learning_rate": 3.2025602409638555e-06,
      "loss": 0.2743,
      "step": 2388
    },
    {
      "epoch": 1.439156626506024,
      "grad_norm": 0.5024061799049377,
      "learning_rate": 3.2018072289156625e-06,
      "loss": 0.2132,
      "step": 2389
    },
    {
      "epoch": 1.4397590361445782,
      "grad_norm": 0.5030510425567627,
      "learning_rate": 3.2010542168674702e-06,
      "loss": 0.2512,
      "step": 2390
    },
    {
      "epoch": 1.4403614457831324,
      "grad_norm": 0.6565135717391968,
      "learning_rate": 3.200301204819277e-06,
      "loss": 0.2728,
      "step": 2391
    },
    {
      "epoch": 1.4409638554216868,
      "grad_norm": 0.5676202178001404,
      "learning_rate": 3.199548192771085e-06,
      "loss": 0.2582,
      "step": 2392
    },
    {
      "epoch": 1.441566265060241,
      "grad_norm": 0.5839382410049438,
      "learning_rate": 3.198795180722892e-06,
      "loss": 0.2872,
      "step": 2393
    },
    {
      "epoch": 1.4421686746987952,
      "grad_norm": 0.5263449549674988,
      "learning_rate": 3.1980421686746992e-06,
      "loss": 0.2453,
      "step": 2394
    },
    {
      "epoch": 1.4427710843373494,
      "grad_norm": 0.6195815801620483,
      "learning_rate": 3.197289156626506e-06,
      "loss": 0.2713,
      "step": 2395
    },
    {
      "epoch": 1.4433734939759035,
      "grad_norm": 0.5947285294532776,
      "learning_rate": 3.1965361445783135e-06,
      "loss": 0.2509,
      "step": 2396
    },
    {
      "epoch": 1.443975903614458,
      "grad_norm": 0.5279322266578674,
      "learning_rate": 3.195783132530121e-06,
      "loss": 0.3421,
      "step": 2397
    },
    {
      "epoch": 1.4445783132530121,
      "grad_norm": 0.6023709177970886,
      "learning_rate": 3.1950301204819278e-06,
      "loss": 0.2866,
      "step": 2398
    },
    {
      "epoch": 1.4451807228915663,
      "grad_norm": 0.593633770942688,
      "learning_rate": 3.1942771084337355e-06,
      "loss": 0.2854,
      "step": 2399
    },
    {
      "epoch": 1.4457831325301205,
      "grad_norm": 0.5953160524368286,
      "learning_rate": 3.1935240963855425e-06,
      "loss": 0.2639,
      "step": 2400
    },
    {
      "epoch": 1.4463855421686747,
      "grad_norm": 0.5716562867164612,
      "learning_rate": 3.1927710843373494e-06,
      "loss": 0.2121,
      "step": 2401
    },
    {
      "epoch": 1.4469879518072288,
      "grad_norm": 0.5679633021354675,
      "learning_rate": 3.192018072289157e-06,
      "loss": 0.231,
      "step": 2402
    },
    {
      "epoch": 1.447590361445783,
      "grad_norm": 0.598146915435791,
      "learning_rate": 3.191265060240964e-06,
      "loss": 0.2465,
      "step": 2403
    },
    {
      "epoch": 1.4481927710843374,
      "grad_norm": 0.5601876378059387,
      "learning_rate": 3.1905120481927714e-06,
      "loss": 0.283,
      "step": 2404
    },
    {
      "epoch": 1.4487951807228916,
      "grad_norm": 0.5509586930274963,
      "learning_rate": 3.1897590361445784e-06,
      "loss": 0.2671,
      "step": 2405
    },
    {
      "epoch": 1.4493975903614458,
      "grad_norm": 0.5335848927497864,
      "learning_rate": 3.189006024096386e-06,
      "loss": 0.2569,
      "step": 2406
    },
    {
      "epoch": 1.45,
      "grad_norm": 0.5996041297912598,
      "learning_rate": 3.188253012048193e-06,
      "loss": 0.3003,
      "step": 2407
    },
    {
      "epoch": 1.4506024096385541,
      "grad_norm": 0.5700638890266418,
      "learning_rate": 3.1875e-06,
      "loss": 0.2608,
      "step": 2408
    },
    {
      "epoch": 1.4512048192771085,
      "grad_norm": 0.5490135550498962,
      "learning_rate": 3.1867469879518077e-06,
      "loss": 0.2594,
      "step": 2409
    },
    {
      "epoch": 1.4518072289156627,
      "grad_norm": 0.5775073766708374,
      "learning_rate": 3.1859939759036147e-06,
      "loss": 0.2174,
      "step": 2410
    },
    {
      "epoch": 1.452409638554217,
      "grad_norm": 0.5575551390647888,
      "learning_rate": 3.185240963855422e-06,
      "loss": 0.2487,
      "step": 2411
    },
    {
      "epoch": 1.453012048192771,
      "grad_norm": 0.5637847185134888,
      "learning_rate": 3.184487951807229e-06,
      "loss": 0.272,
      "step": 2412
    },
    {
      "epoch": 1.4536144578313253,
      "grad_norm": 0.6016808152198792,
      "learning_rate": 3.1837349397590363e-06,
      "loss": 0.2932,
      "step": 2413
    },
    {
      "epoch": 1.4542168674698794,
      "grad_norm": 0.4603452980518341,
      "learning_rate": 3.1829819277108436e-06,
      "loss": 0.2123,
      "step": 2414
    },
    {
      "epoch": 1.4548192771084336,
      "grad_norm": 0.666916012763977,
      "learning_rate": 3.1822289156626506e-06,
      "loss": 0.3684,
      "step": 2415
    },
    {
      "epoch": 1.455421686746988,
      "grad_norm": 0.5915474891662598,
      "learning_rate": 3.1814759036144583e-06,
      "loss": 0.2665,
      "step": 2416
    },
    {
      "epoch": 1.4560240963855422,
      "grad_norm": 0.574113667011261,
      "learning_rate": 3.1807228915662653e-06,
      "loss": 0.2859,
      "step": 2417
    },
    {
      "epoch": 1.4566265060240964,
      "grad_norm": 0.5165848135948181,
      "learning_rate": 3.1799698795180726e-06,
      "loss": 0.2256,
      "step": 2418
    },
    {
      "epoch": 1.4572289156626506,
      "grad_norm": 0.517151951789856,
      "learning_rate": 3.17921686746988e-06,
      "loss": 0.2518,
      "step": 2419
    },
    {
      "epoch": 1.4578313253012047,
      "grad_norm": 0.6174744367599487,
      "learning_rate": 3.178463855421687e-06,
      "loss": 0.2955,
      "step": 2420
    },
    {
      "epoch": 1.4584337349397591,
      "grad_norm": 0.5546735525131226,
      "learning_rate": 3.1777108433734942e-06,
      "loss": 0.2811,
      "step": 2421
    },
    {
      "epoch": 1.4590361445783133,
      "grad_norm": 0.5179075598716736,
      "learning_rate": 3.176957831325301e-06,
      "loss": 0.2808,
      "step": 2422
    },
    {
      "epoch": 1.4596385542168675,
      "grad_norm": 0.6142668128013611,
      "learning_rate": 3.176204819277109e-06,
      "loss": 0.2375,
      "step": 2423
    },
    {
      "epoch": 1.4602409638554217,
      "grad_norm": 0.5313810110092163,
      "learning_rate": 3.175451807228916e-06,
      "loss": 0.286,
      "step": 2424
    },
    {
      "epoch": 1.4608433734939759,
      "grad_norm": 0.6679770350456238,
      "learning_rate": 3.1746987951807228e-06,
      "loss": 0.2127,
      "step": 2425
    },
    {
      "epoch": 1.46144578313253,
      "grad_norm": 0.574705958366394,
      "learning_rate": 3.1739457831325306e-06,
      "loss": 0.2772,
      "step": 2426
    },
    {
      "epoch": 1.4620481927710842,
      "grad_norm": 0.5392354130744934,
      "learning_rate": 3.1731927710843375e-06,
      "loss": 0.2525,
      "step": 2427
    },
    {
      "epoch": 1.4626506024096386,
      "grad_norm": 0.5514311194419861,
      "learning_rate": 3.172439759036145e-06,
      "loss": 0.2887,
      "step": 2428
    },
    {
      "epoch": 1.4632530120481928,
      "grad_norm": 0.5209975242614746,
      "learning_rate": 3.171686746987952e-06,
      "loss": 0.2638,
      "step": 2429
    },
    {
      "epoch": 1.463855421686747,
      "grad_norm": 0.561789870262146,
      "learning_rate": 3.1709337349397595e-06,
      "loss": 0.2743,
      "step": 2430
    },
    {
      "epoch": 1.4644578313253012,
      "grad_norm": 0.6305611729621887,
      "learning_rate": 3.1701807228915664e-06,
      "loss": 0.2637,
      "step": 2431
    },
    {
      "epoch": 1.4650602409638553,
      "grad_norm": 0.5304118394851685,
      "learning_rate": 3.1694277108433734e-06,
      "loss": 0.2681,
      "step": 2432
    },
    {
      "epoch": 1.4656626506024097,
      "grad_norm": 0.5800032615661621,
      "learning_rate": 3.168674698795181e-06,
      "loss": 0.2656,
      "step": 2433
    },
    {
      "epoch": 1.466265060240964,
      "grad_norm": 0.5706097483634949,
      "learning_rate": 3.167921686746988e-06,
      "loss": 0.2269,
      "step": 2434
    },
    {
      "epoch": 1.466867469879518,
      "grad_norm": 0.48678749799728394,
      "learning_rate": 3.167168674698796e-06,
      "loss": 0.2195,
      "step": 2435
    },
    {
      "epoch": 1.4674698795180723,
      "grad_norm": 0.5970247387886047,
      "learning_rate": 3.1664156626506028e-06,
      "loss": 0.2396,
      "step": 2436
    },
    {
      "epoch": 1.4680722891566265,
      "grad_norm": 0.5569585561752319,
      "learning_rate": 3.1656626506024097e-06,
      "loss": 0.2764,
      "step": 2437
    },
    {
      "epoch": 1.4686746987951806,
      "grad_norm": 0.5628398060798645,
      "learning_rate": 3.164909638554217e-06,
      "loss": 0.2573,
      "step": 2438
    },
    {
      "epoch": 1.4692771084337348,
      "grad_norm": 0.6256368160247803,
      "learning_rate": 3.1641566265060244e-06,
      "loss": 0.244,
      "step": 2439
    },
    {
      "epoch": 1.4698795180722892,
      "grad_norm": 0.5658199191093445,
      "learning_rate": 3.1634036144578317e-06,
      "loss": 0.3238,
      "step": 2440
    },
    {
      "epoch": 1.4704819277108434,
      "grad_norm": 0.523566722869873,
      "learning_rate": 3.1626506024096387e-06,
      "loss": 0.24,
      "step": 2441
    },
    {
      "epoch": 1.4710843373493976,
      "grad_norm": 0.48439866304397583,
      "learning_rate": 3.1618975903614464e-06,
      "loss": 0.2412,
      "step": 2442
    },
    {
      "epoch": 1.4716867469879518,
      "grad_norm": 0.5267154574394226,
      "learning_rate": 3.1611445783132534e-06,
      "loss": 0.2419,
      "step": 2443
    },
    {
      "epoch": 1.472289156626506,
      "grad_norm": 0.5395108461380005,
      "learning_rate": 3.1603915662650603e-06,
      "loss": 0.2623,
      "step": 2444
    },
    {
      "epoch": 1.4728915662650603,
      "grad_norm": 0.546143651008606,
      "learning_rate": 3.1596385542168676e-06,
      "loss": 0.2322,
      "step": 2445
    },
    {
      "epoch": 1.4734939759036145,
      "grad_norm": 0.6387378573417664,
      "learning_rate": 3.158885542168675e-06,
      "loss": 0.2702,
      "step": 2446
    },
    {
      "epoch": 1.4740963855421687,
      "grad_norm": 0.58820641040802,
      "learning_rate": 3.1581325301204823e-06,
      "loss": 0.2492,
      "step": 2447
    },
    {
      "epoch": 1.4746987951807229,
      "grad_norm": 0.5257061719894409,
      "learning_rate": 3.1573795180722893e-06,
      "loss": 0.2689,
      "step": 2448
    },
    {
      "epoch": 1.475301204819277,
      "grad_norm": 0.5575844049453735,
      "learning_rate": 3.156626506024096e-06,
      "loss": 0.2545,
      "step": 2449
    },
    {
      "epoch": 1.4759036144578312,
      "grad_norm": 0.4715743362903595,
      "learning_rate": 3.155873493975904e-06,
      "loss": 0.2306,
      "step": 2450
    },
    {
      "epoch": 1.4765060240963854,
      "grad_norm": 0.6830964088439941,
      "learning_rate": 3.155120481927711e-06,
      "loss": 0.2961,
      "step": 2451
    },
    {
      "epoch": 1.4771084337349398,
      "grad_norm": 0.564764142036438,
      "learning_rate": 3.1543674698795186e-06,
      "loss": 0.2844,
      "step": 2452
    },
    {
      "epoch": 1.477710843373494,
      "grad_norm": 0.5079436898231506,
      "learning_rate": 3.1536144578313256e-06,
      "loss": 0.2386,
      "step": 2453
    },
    {
      "epoch": 1.4783132530120482,
      "grad_norm": 0.6696407794952393,
      "learning_rate": 3.152861445783133e-06,
      "loss": 0.2755,
      "step": 2454
    },
    {
      "epoch": 1.4789156626506024,
      "grad_norm": 0.4682590961456299,
      "learning_rate": 3.15210843373494e-06,
      "loss": 0.2189,
      "step": 2455
    },
    {
      "epoch": 1.4795180722891565,
      "grad_norm": 0.6286434531211853,
      "learning_rate": 3.151355421686747e-06,
      "loss": 0.3045,
      "step": 2456
    },
    {
      "epoch": 1.480120481927711,
      "grad_norm": 0.5291628241539001,
      "learning_rate": 3.1506024096385545e-06,
      "loss": 0.2195,
      "step": 2457
    },
    {
      "epoch": 1.4807228915662651,
      "grad_norm": 0.584175169467926,
      "learning_rate": 3.1498493975903615e-06,
      "loss": 0.297,
      "step": 2458
    },
    {
      "epoch": 1.4813253012048193,
      "grad_norm": 0.6882402896881104,
      "learning_rate": 3.1490963855421692e-06,
      "loss": 0.2808,
      "step": 2459
    },
    {
      "epoch": 1.4819277108433735,
      "grad_norm": 0.47927749156951904,
      "learning_rate": 3.148343373493976e-06,
      "loss": 0.2404,
      "step": 2460
    },
    {
      "epoch": 1.4825301204819277,
      "grad_norm": 0.5693801045417786,
      "learning_rate": 3.147590361445783e-06,
      "loss": 0.3197,
      "step": 2461
    },
    {
      "epoch": 1.4831325301204819,
      "grad_norm": 0.48282551765441895,
      "learning_rate": 3.146837349397591e-06,
      "loss": 0.216,
      "step": 2462
    },
    {
      "epoch": 1.483734939759036,
      "grad_norm": 0.4878125488758087,
      "learning_rate": 3.1460843373493978e-06,
      "loss": 0.2439,
      "step": 2463
    },
    {
      "epoch": 1.4843373493975904,
      "grad_norm": 0.6417106986045837,
      "learning_rate": 3.145331325301205e-06,
      "loss": 0.2709,
      "step": 2464
    },
    {
      "epoch": 1.4849397590361446,
      "grad_norm": 0.47354885935783386,
      "learning_rate": 3.144578313253012e-06,
      "loss": 0.2399,
      "step": 2465
    },
    {
      "epoch": 1.4855421686746988,
      "grad_norm": 0.6478527784347534,
      "learning_rate": 3.14382530120482e-06,
      "loss": 0.325,
      "step": 2466
    },
    {
      "epoch": 1.486144578313253,
      "grad_norm": 0.565790593624115,
      "learning_rate": 3.1430722891566268e-06,
      "loss": 0.2798,
      "step": 2467
    },
    {
      "epoch": 1.4867469879518072,
      "grad_norm": 0.5441462397575378,
      "learning_rate": 3.1423192771084337e-06,
      "loss": 0.2145,
      "step": 2468
    },
    {
      "epoch": 1.4873493975903616,
      "grad_norm": 0.5572789311408997,
      "learning_rate": 3.1415662650602414e-06,
      "loss": 0.3165,
      "step": 2469
    },
    {
      "epoch": 1.4879518072289157,
      "grad_norm": 0.5370597243309021,
      "learning_rate": 3.1408132530120484e-06,
      "loss": 0.2349,
      "step": 2470
    },
    {
      "epoch": 1.48855421686747,
      "grad_norm": 0.5295527577400208,
      "learning_rate": 3.1400602409638557e-06,
      "loss": 0.2459,
      "step": 2471
    },
    {
      "epoch": 1.489156626506024,
      "grad_norm": 0.5722746849060059,
      "learning_rate": 3.139307228915663e-06,
      "loss": 0.2634,
      "step": 2472
    },
    {
      "epoch": 1.4897590361445783,
      "grad_norm": 0.5980784296989441,
      "learning_rate": 3.13855421686747e-06,
      "loss": 0.2984,
      "step": 2473
    },
    {
      "epoch": 1.4903614457831325,
      "grad_norm": 0.46844300627708435,
      "learning_rate": 3.1378012048192773e-06,
      "loss": 0.2244,
      "step": 2474
    },
    {
      "epoch": 1.4909638554216866,
      "grad_norm": 0.5643948912620544,
      "learning_rate": 3.1370481927710843e-06,
      "loss": 0.251,
      "step": 2475
    },
    {
      "epoch": 1.491566265060241,
      "grad_norm": 0.592933177947998,
      "learning_rate": 3.136295180722892e-06,
      "loss": 0.2879,
      "step": 2476
    },
    {
      "epoch": 1.4921686746987952,
      "grad_norm": 0.5668283104896545,
      "learning_rate": 3.135542168674699e-06,
      "loss": 0.2489,
      "step": 2477
    },
    {
      "epoch": 1.4927710843373494,
      "grad_norm": 0.5441627502441406,
      "learning_rate": 3.1347891566265063e-06,
      "loss": 0.3085,
      "step": 2478
    },
    {
      "epoch": 1.4933734939759036,
      "grad_norm": 0.5321041941642761,
      "learning_rate": 3.1340361445783137e-06,
      "loss": 0.2686,
      "step": 2479
    },
    {
      "epoch": 1.4939759036144578,
      "grad_norm": 0.5317683815956116,
      "learning_rate": 3.1332831325301206e-06,
      "loss": 0.2532,
      "step": 2480
    },
    {
      "epoch": 1.4945783132530122,
      "grad_norm": 0.5642659068107605,
      "learning_rate": 3.132530120481928e-06,
      "loss": 0.2742,
      "step": 2481
    },
    {
      "epoch": 1.4951807228915663,
      "grad_norm": 0.6007651686668396,
      "learning_rate": 3.131777108433735e-06,
      "loss": 0.3235,
      "step": 2482
    },
    {
      "epoch": 1.4957831325301205,
      "grad_norm": 0.4871807098388672,
      "learning_rate": 3.1310240963855426e-06,
      "loss": 0.2455,
      "step": 2483
    },
    {
      "epoch": 1.4963855421686747,
      "grad_norm": 0.5476289391517639,
      "learning_rate": 3.1302710843373496e-06,
      "loss": 0.2457,
      "step": 2484
    },
    {
      "epoch": 1.4969879518072289,
      "grad_norm": 0.5624415278434753,
      "learning_rate": 3.1295180722891565e-06,
      "loss": 0.2947,
      "step": 2485
    },
    {
      "epoch": 1.497590361445783,
      "grad_norm": 0.5950581431388855,
      "learning_rate": 3.1287650602409643e-06,
      "loss": 0.3146,
      "step": 2486
    },
    {
      "epoch": 1.4981927710843372,
      "grad_norm": 0.539303719997406,
      "learning_rate": 3.128012048192771e-06,
      "loss": 0.246,
      "step": 2487
    },
    {
      "epoch": 1.4987951807228916,
      "grad_norm": 0.5244693160057068,
      "learning_rate": 3.1272590361445785e-06,
      "loss": 0.2177,
      "step": 2488
    },
    {
      "epoch": 1.4993975903614458,
      "grad_norm": 0.5054946541786194,
      "learning_rate": 3.126506024096386e-06,
      "loss": 0.2395,
      "step": 2489
    },
    {
      "epoch": 1.5,
      "grad_norm": 0.5142755508422852,
      "learning_rate": 3.1257530120481932e-06,
      "loss": 0.2361,
      "step": 2490
    },
    {
      "epoch": 1.5006024096385542,
      "grad_norm": 0.4867427349090576,
      "learning_rate": 3.125e-06,
      "loss": 0.2077,
      "step": 2491
    },
    {
      "epoch": 1.5012048192771084,
      "grad_norm": 0.5289206504821777,
      "learning_rate": 3.124246987951807e-06,
      "loss": 0.2266,
      "step": 2492
    },
    {
      "epoch": 1.5018072289156628,
      "grad_norm": 0.5216291546821594,
      "learning_rate": 3.123493975903615e-06,
      "loss": 0.2196,
      "step": 2493
    },
    {
      "epoch": 1.5024096385542167,
      "grad_norm": 0.49536922574043274,
      "learning_rate": 3.1227409638554218e-06,
      "loss": 0.2429,
      "step": 2494
    },
    {
      "epoch": 1.5030120481927711,
      "grad_norm": 0.5040246844291687,
      "learning_rate": 3.1219879518072295e-06,
      "loss": 0.2453,
      "step": 2495
    },
    {
      "epoch": 1.5036144578313253,
      "grad_norm": 0.5537317395210266,
      "learning_rate": 3.1212349397590365e-06,
      "loss": 0.2383,
      "step": 2496
    },
    {
      "epoch": 1.5042168674698795,
      "grad_norm": 0.5149937272071838,
      "learning_rate": 3.120481927710844e-06,
      "loss": 0.2201,
      "step": 2497
    },
    {
      "epoch": 1.5048192771084339,
      "grad_norm": 0.5255544185638428,
      "learning_rate": 3.1197289156626507e-06,
      "loss": 0.2895,
      "step": 2498
    },
    {
      "epoch": 1.5054216867469878,
      "grad_norm": 0.6312448978424072,
      "learning_rate": 3.118975903614458e-06,
      "loss": 0.2574,
      "step": 2499
    },
    {
      "epoch": 1.5060240963855422,
      "grad_norm": 0.44775667786598206,
      "learning_rate": 3.1182228915662654e-06,
      "loss": 0.2261,
      "step": 2500
    },
    {
      "epoch": 1.5066265060240964,
      "grad_norm": 0.55918288230896,
      "learning_rate": 3.1174698795180724e-06,
      "loss": 0.2333,
      "step": 2501
    },
    {
      "epoch": 1.5072289156626506,
      "grad_norm": 0.5472493767738342,
      "learning_rate": 3.11671686746988e-06,
      "loss": 0.2426,
      "step": 2502
    },
    {
      "epoch": 1.5078313253012048,
      "grad_norm": 0.5223514437675476,
      "learning_rate": 3.115963855421687e-06,
      "loss": 0.2176,
      "step": 2503
    },
    {
      "epoch": 1.508433734939759,
      "grad_norm": 0.5385407209396362,
      "learning_rate": 3.115210843373494e-06,
      "loss": 0.2248,
      "step": 2504
    },
    {
      "epoch": 1.5090361445783134,
      "grad_norm": 0.5481073260307312,
      "learning_rate": 3.1144578313253018e-06,
      "loss": 0.2576,
      "step": 2505
    },
    {
      "epoch": 1.5096385542168673,
      "grad_norm": 0.49026739597320557,
      "learning_rate": 3.1137048192771087e-06,
      "loss": 0.2339,
      "step": 2506
    },
    {
      "epoch": 1.5102409638554217,
      "grad_norm": 0.534420371055603,
      "learning_rate": 3.112951807228916e-06,
      "loss": 0.2488,
      "step": 2507
    },
    {
      "epoch": 1.510843373493976,
      "grad_norm": 0.5691958665847778,
      "learning_rate": 3.112198795180723e-06,
      "loss": 0.2887,
      "step": 2508
    },
    {
      "epoch": 1.51144578313253,
      "grad_norm": 1.030544638633728,
      "learning_rate": 3.1114457831325307e-06,
      "loss": 0.286,
      "step": 2509
    },
    {
      "epoch": 1.5120481927710845,
      "grad_norm": 0.5465506315231323,
      "learning_rate": 3.1106927710843377e-06,
      "loss": 0.2439,
      "step": 2510
    },
    {
      "epoch": 1.5126506024096384,
      "grad_norm": 0.5704508423805237,
      "learning_rate": 3.1099397590361446e-06,
      "loss": 0.2492,
      "step": 2511
    },
    {
      "epoch": 1.5132530120481928,
      "grad_norm": 0.5672659873962402,
      "learning_rate": 3.1091867469879523e-06,
      "loss": 0.2384,
      "step": 2512
    },
    {
      "epoch": 1.513855421686747,
      "grad_norm": 0.5329787135124207,
      "learning_rate": 3.1084337349397593e-06,
      "loss": 0.2356,
      "step": 2513
    },
    {
      "epoch": 1.5144578313253012,
      "grad_norm": 0.535917341709137,
      "learning_rate": 3.1076807228915666e-06,
      "loss": 0.2733,
      "step": 2514
    },
    {
      "epoch": 1.5150602409638554,
      "grad_norm": 0.5515421628952026,
      "learning_rate": 3.1069277108433735e-06,
      "loss": 0.2379,
      "step": 2515
    },
    {
      "epoch": 1.5156626506024096,
      "grad_norm": 0.5676942467689514,
      "learning_rate": 3.106174698795181e-06,
      "loss": 0.2555,
      "step": 2516
    },
    {
      "epoch": 1.516265060240964,
      "grad_norm": 0.5159069895744324,
      "learning_rate": 3.1054216867469882e-06,
      "loss": 0.226,
      "step": 2517
    },
    {
      "epoch": 1.516867469879518,
      "grad_norm": 0.5643845200538635,
      "learning_rate": 3.104668674698795e-06,
      "loss": 0.2686,
      "step": 2518
    },
    {
      "epoch": 1.5174698795180723,
      "grad_norm": 0.5720680952072144,
      "learning_rate": 3.103915662650603e-06,
      "loss": 0.287,
      "step": 2519
    },
    {
      "epoch": 1.5180722891566265,
      "grad_norm": 0.6037625670433044,
      "learning_rate": 3.10316265060241e-06,
      "loss": 0.2267,
      "step": 2520
    },
    {
      "epoch": 1.5186746987951807,
      "grad_norm": 0.4749074876308441,
      "learning_rate": 3.1024096385542172e-06,
      "loss": 0.2201,
      "step": 2521
    },
    {
      "epoch": 1.519277108433735,
      "grad_norm": 0.5045708417892456,
      "learning_rate": 3.1016566265060246e-06,
      "loss": 0.2275,
      "step": 2522
    },
    {
      "epoch": 1.519879518072289,
      "grad_norm": 0.5635451078414917,
      "learning_rate": 3.1009036144578315e-06,
      "loss": 0.2283,
      "step": 2523
    },
    {
      "epoch": 1.5204819277108435,
      "grad_norm": 0.5372699499130249,
      "learning_rate": 3.100150602409639e-06,
      "loss": 0.2659,
      "step": 2524
    },
    {
      "epoch": 1.5210843373493976,
      "grad_norm": 0.5382447838783264,
      "learning_rate": 3.0993975903614458e-06,
      "loss": 0.2201,
      "step": 2525
    },
    {
      "epoch": 1.5216867469879518,
      "grad_norm": 0.576557457447052,
      "learning_rate": 3.0986445783132535e-06,
      "loss": 0.2411,
      "step": 2526
    },
    {
      "epoch": 1.522289156626506,
      "grad_norm": 0.5384198427200317,
      "learning_rate": 3.0978915662650605e-06,
      "loss": 0.3056,
      "step": 2527
    },
    {
      "epoch": 1.5228915662650602,
      "grad_norm": 0.574475109577179,
      "learning_rate": 3.0971385542168674e-06,
      "loss": 0.2644,
      "step": 2528
    },
    {
      "epoch": 1.5234939759036146,
      "grad_norm": 0.6101995706558228,
      "learning_rate": 3.096385542168675e-06,
      "loss": 0.3186,
      "step": 2529
    },
    {
      "epoch": 1.5240963855421685,
      "grad_norm": 0.5367233157157898,
      "learning_rate": 3.095632530120482e-06,
      "loss": 0.1887,
      "step": 2530
    },
    {
      "epoch": 1.524698795180723,
      "grad_norm": 0.6147338151931763,
      "learning_rate": 3.0948795180722894e-06,
      "loss": 0.2564,
      "step": 2531
    },
    {
      "epoch": 1.5253012048192771,
      "grad_norm": 0.5615021586418152,
      "learning_rate": 3.0941265060240968e-06,
      "loss": 0.2793,
      "step": 2532
    },
    {
      "epoch": 1.5259036144578313,
      "grad_norm": 0.5827202200889587,
      "learning_rate": 3.093373493975904e-06,
      "loss": 0.2549,
      "step": 2533
    },
    {
      "epoch": 1.5265060240963857,
      "grad_norm": 0.5810577273368835,
      "learning_rate": 3.092620481927711e-06,
      "loss": 0.2438,
      "step": 2534
    },
    {
      "epoch": 1.5271084337349397,
      "grad_norm": 0.5646352767944336,
      "learning_rate": 3.091867469879518e-06,
      "loss": 0.3021,
      "step": 2535
    },
    {
      "epoch": 1.527710843373494,
      "grad_norm": 0.628230094909668,
      "learning_rate": 3.0911144578313257e-06,
      "loss": 0.2867,
      "step": 2536
    },
    {
      "epoch": 1.5283132530120482,
      "grad_norm": 0.45955947041511536,
      "learning_rate": 3.0903614457831327e-06,
      "loss": 0.1928,
      "step": 2537
    },
    {
      "epoch": 1.5289156626506024,
      "grad_norm": 0.5027443766593933,
      "learning_rate": 3.0896084337349404e-06,
      "loss": 0.2249,
      "step": 2538
    },
    {
      "epoch": 1.5295180722891566,
      "grad_norm": 0.5629249811172485,
      "learning_rate": 3.0888554216867474e-06,
      "loss": 0.2783,
      "step": 2539
    },
    {
      "epoch": 1.5301204819277108,
      "grad_norm": 0.5409953594207764,
      "learning_rate": 3.0881024096385543e-06,
      "loss": 0.2524,
      "step": 2540
    },
    {
      "epoch": 1.5307228915662652,
      "grad_norm": 0.7862994074821472,
      "learning_rate": 3.0873493975903616e-06,
      "loss": 0.2877,
      "step": 2541
    },
    {
      "epoch": 1.5313253012048191,
      "grad_norm": 0.5666959285736084,
      "learning_rate": 3.086596385542169e-06,
      "loss": 0.2399,
      "step": 2542
    },
    {
      "epoch": 1.5319277108433735,
      "grad_norm": 0.6537488698959351,
      "learning_rate": 3.0858433734939763e-06,
      "loss": 0.3071,
      "step": 2543
    },
    {
      "epoch": 1.5325301204819277,
      "grad_norm": 0.6330748200416565,
      "learning_rate": 3.0850903614457833e-06,
      "loss": 0.2996,
      "step": 2544
    },
    {
      "epoch": 1.533132530120482,
      "grad_norm": 0.5927461981773376,
      "learning_rate": 3.084337349397591e-06,
      "loss": 0.2107,
      "step": 2545
    },
    {
      "epoch": 1.5337349397590363,
      "grad_norm": 0.4810671806335449,
      "learning_rate": 3.083584337349398e-06,
      "loss": 0.259,
      "step": 2546
    },
    {
      "epoch": 1.5343373493975903,
      "grad_norm": 0.5326667428016663,
      "learning_rate": 3.082831325301205e-06,
      "loss": 0.2,
      "step": 2547
    },
    {
      "epoch": 1.5349397590361447,
      "grad_norm": 0.5969259142875671,
      "learning_rate": 3.0820783132530122e-06,
      "loss": 0.2653,
      "step": 2548
    },
    {
      "epoch": 1.5355421686746988,
      "grad_norm": 0.5031723380088806,
      "learning_rate": 3.0813253012048196e-06,
      "loss": 0.2474,
      "step": 2549
    },
    {
      "epoch": 1.536144578313253,
      "grad_norm": 0.492118239402771,
      "learning_rate": 3.080572289156627e-06,
      "loss": 0.2454,
      "step": 2550
    },
    {
      "epoch": 1.5367469879518072,
      "grad_norm": 0.7105907797813416,
      "learning_rate": 3.079819277108434e-06,
      "loss": 0.296,
      "step": 2551
    },
    {
      "epoch": 1.5373493975903614,
      "grad_norm": 0.5579463839530945,
      "learning_rate": 3.0790662650602408e-06,
      "loss": 0.2214,
      "step": 2552
    },
    {
      "epoch": 1.5379518072289158,
      "grad_norm": 1.475831389427185,
      "learning_rate": 3.0783132530120485e-06,
      "loss": 0.2735,
      "step": 2553
    },
    {
      "epoch": 1.5385542168674697,
      "grad_norm": 0.5560064911842346,
      "learning_rate": 3.0775602409638555e-06,
      "loss": 0.2624,
      "step": 2554
    },
    {
      "epoch": 1.5391566265060241,
      "grad_norm": 0.55191969871521,
      "learning_rate": 3.0768072289156632e-06,
      "loss": 0.2852,
      "step": 2555
    },
    {
      "epoch": 1.5397590361445783,
      "grad_norm": 0.48523420095443726,
      "learning_rate": 3.07605421686747e-06,
      "loss": 0.2506,
      "step": 2556
    },
    {
      "epoch": 1.5403614457831325,
      "grad_norm": 0.5365772843360901,
      "learning_rate": 3.0753012048192775e-06,
      "loss": 0.231,
      "step": 2557
    },
    {
      "epoch": 1.540963855421687,
      "grad_norm": 0.5400659441947937,
      "learning_rate": 3.0745481927710844e-06,
      "loss": 0.246,
      "step": 2558
    },
    {
      "epoch": 1.5415662650602409,
      "grad_norm": 0.4896804392337799,
      "learning_rate": 3.073795180722892e-06,
      "loss": 0.2765,
      "step": 2559
    },
    {
      "epoch": 1.5421686746987953,
      "grad_norm": 0.5855032801628113,
      "learning_rate": 3.073042168674699e-06,
      "loss": 0.2954,
      "step": 2560
    },
    {
      "epoch": 1.5427710843373494,
      "grad_norm": 0.5399377346038818,
      "learning_rate": 3.072289156626506e-06,
      "loss": 0.2693,
      "step": 2561
    },
    {
      "epoch": 1.5433734939759036,
      "grad_norm": 0.6110523343086243,
      "learning_rate": 3.071536144578314e-06,
      "loss": 0.2362,
      "step": 2562
    },
    {
      "epoch": 1.5439759036144578,
      "grad_norm": 0.5502533316612244,
      "learning_rate": 3.0707831325301208e-06,
      "loss": 0.2571,
      "step": 2563
    },
    {
      "epoch": 1.544578313253012,
      "grad_norm": 0.5784481167793274,
      "learning_rate": 3.0700301204819277e-06,
      "loss": 0.283,
      "step": 2564
    },
    {
      "epoch": 1.5451807228915664,
      "grad_norm": 0.5535722970962524,
      "learning_rate": 3.0692771084337355e-06,
      "loss": 0.2797,
      "step": 2565
    },
    {
      "epoch": 1.5457831325301203,
      "grad_norm": 0.5298920273780823,
      "learning_rate": 3.0685240963855424e-06,
      "loss": 0.2874,
      "step": 2566
    },
    {
      "epoch": 1.5463855421686747,
      "grad_norm": 0.5674065351486206,
      "learning_rate": 3.0677710843373497e-06,
      "loss": 0.2768,
      "step": 2567
    },
    {
      "epoch": 1.546987951807229,
      "grad_norm": 0.5006532669067383,
      "learning_rate": 3.0670180722891567e-06,
      "loss": 0.2133,
      "step": 2568
    },
    {
      "epoch": 1.547590361445783,
      "grad_norm": 0.6034864187240601,
      "learning_rate": 3.0662650602409644e-06,
      "loss": 0.2963,
      "step": 2569
    },
    {
      "epoch": 1.5481927710843375,
      "grad_norm": 0.5519295334815979,
      "learning_rate": 3.0655120481927714e-06,
      "loss": 0.237,
      "step": 2570
    },
    {
      "epoch": 1.5487951807228915,
      "grad_norm": 0.4943733811378479,
      "learning_rate": 3.0647590361445783e-06,
      "loss": 0.2364,
      "step": 2571
    },
    {
      "epoch": 1.5493975903614459,
      "grad_norm": 0.548042893409729,
      "learning_rate": 3.064006024096386e-06,
      "loss": 0.2633,
      "step": 2572
    },
    {
      "epoch": 1.55,
      "grad_norm": 0.5226701498031616,
      "learning_rate": 3.063253012048193e-06,
      "loss": 0.2568,
      "step": 2573
    },
    {
      "epoch": 1.5506024096385542,
      "grad_norm": 0.54787677526474,
      "learning_rate": 3.0625000000000003e-06,
      "loss": 0.3068,
      "step": 2574
    },
    {
      "epoch": 1.5512048192771084,
      "grad_norm": 0.5681536793708801,
      "learning_rate": 3.0617469879518077e-06,
      "loss": 0.296,
      "step": 2575
    },
    {
      "epoch": 1.5518072289156626,
      "grad_norm": 0.536812424659729,
      "learning_rate": 3.0609939759036146e-06,
      "loss": 0.2377,
      "step": 2576
    },
    {
      "epoch": 1.552409638554217,
      "grad_norm": 0.6544182896614075,
      "learning_rate": 3.060240963855422e-06,
      "loss": 0.3773,
      "step": 2577
    },
    {
      "epoch": 1.553012048192771,
      "grad_norm": 0.47237372398376465,
      "learning_rate": 3.059487951807229e-06,
      "loss": 0.2354,
      "step": 2578
    },
    {
      "epoch": 1.5536144578313253,
      "grad_norm": 0.5248885750770569,
      "learning_rate": 3.0587349397590366e-06,
      "loss": 0.2359,
      "step": 2579
    },
    {
      "epoch": 1.5542168674698795,
      "grad_norm": 0.6921848654747009,
      "learning_rate": 3.0579819277108436e-06,
      "loss": 0.2648,
      "step": 2580
    },
    {
      "epoch": 1.5548192771084337,
      "grad_norm": 0.5698782205581665,
      "learning_rate": 3.057228915662651e-06,
      "loss": 0.2744,
      "step": 2581
    },
    {
      "epoch": 1.555421686746988,
      "grad_norm": 0.5373696684837341,
      "learning_rate": 3.0564759036144583e-06,
      "loss": 0.2763,
      "step": 2582
    },
    {
      "epoch": 1.556024096385542,
      "grad_norm": 0.8308759927749634,
      "learning_rate": 3.055722891566265e-06,
      "loss": 0.2373,
      "step": 2583
    },
    {
      "epoch": 1.5566265060240965,
      "grad_norm": 0.5582278966903687,
      "learning_rate": 3.0549698795180725e-06,
      "loss": 0.2392,
      "step": 2584
    },
    {
      "epoch": 1.5572289156626506,
      "grad_norm": 0.5747614502906799,
      "learning_rate": 3.0542168674698795e-06,
      "loss": 0.2517,
      "step": 2585
    },
    {
      "epoch": 1.5578313253012048,
      "grad_norm": 0.5379107594490051,
      "learning_rate": 3.0534638554216872e-06,
      "loss": 0.2182,
      "step": 2586
    },
    {
      "epoch": 1.558433734939759,
      "grad_norm": 0.5256355404853821,
      "learning_rate": 3.052710843373494e-06,
      "loss": 0.218,
      "step": 2587
    },
    {
      "epoch": 1.5590361445783132,
      "grad_norm": 0.596487283706665,
      "learning_rate": 3.051957831325301e-06,
      "loss": 0.2404,
      "step": 2588
    },
    {
      "epoch": 1.5596385542168676,
      "grad_norm": 0.46271324157714844,
      "learning_rate": 3.051204819277109e-06,
      "loss": 0.2239,
      "step": 2589
    },
    {
      "epoch": 1.5602409638554215,
      "grad_norm": 0.5127665400505066,
      "learning_rate": 3.0504518072289158e-06,
      "loss": 0.2168,
      "step": 2590
    },
    {
      "epoch": 1.560843373493976,
      "grad_norm": 0.48466745018959045,
      "learning_rate": 3.049698795180723e-06,
      "loss": 0.2012,
      "step": 2591
    },
    {
      "epoch": 1.5614457831325301,
      "grad_norm": 0.5262506008148193,
      "learning_rate": 3.0489457831325305e-06,
      "loss": 0.2488,
      "step": 2592
    },
    {
      "epoch": 1.5620481927710843,
      "grad_norm": 0.5246886610984802,
      "learning_rate": 3.048192771084338e-06,
      "loss": 0.2559,
      "step": 2593
    },
    {
      "epoch": 1.5626506024096387,
      "grad_norm": 0.4975462555885315,
      "learning_rate": 3.0474397590361448e-06,
      "loss": 0.2209,
      "step": 2594
    },
    {
      "epoch": 1.5632530120481927,
      "grad_norm": 0.501866340637207,
      "learning_rate": 3.0466867469879517e-06,
      "loss": 0.2131,
      "step": 2595
    },
    {
      "epoch": 1.563855421686747,
      "grad_norm": 0.4529414176940918,
      "learning_rate": 3.0459337349397594e-06,
      "loss": 0.1907,
      "step": 2596
    },
    {
      "epoch": 1.5644578313253013,
      "grad_norm": 0.4771268963813782,
      "learning_rate": 3.0451807228915664e-06,
      "loss": 0.2009,
      "step": 2597
    },
    {
      "epoch": 1.5650602409638554,
      "grad_norm": 0.8983631134033203,
      "learning_rate": 3.044427710843374e-06,
      "loss": 0.2238,
      "step": 2598
    },
    {
      "epoch": 1.5656626506024096,
      "grad_norm": 0.5506731867790222,
      "learning_rate": 3.043674698795181e-06,
      "loss": 0.2207,
      "step": 2599
    },
    {
      "epoch": 1.5662650602409638,
      "grad_norm": 0.509965181350708,
      "learning_rate": 3.042921686746988e-06,
      "loss": 0.282,
      "step": 2600
    },
    {
      "epoch": 1.5668674698795182,
      "grad_norm": 0.5343419313430786,
      "learning_rate": 3.0421686746987953e-06,
      "loss": 0.2667,
      "step": 2601
    },
    {
      "epoch": 1.5674698795180722,
      "grad_norm": 11.108123779296875,
      "learning_rate": 3.0414156626506027e-06,
      "loss": 0.2478,
      "step": 2602
    },
    {
      "epoch": 1.5680722891566266,
      "grad_norm": 0.5531787872314453,
      "learning_rate": 3.04066265060241e-06,
      "loss": 0.254,
      "step": 2603
    },
    {
      "epoch": 1.5686746987951807,
      "grad_norm": 0.5218715667724609,
      "learning_rate": 3.039909638554217e-06,
      "loss": 0.242,
      "step": 2604
    },
    {
      "epoch": 1.569277108433735,
      "grad_norm": 0.48964858055114746,
      "learning_rate": 3.0391566265060247e-06,
      "loss": 0.2265,
      "step": 2605
    },
    {
      "epoch": 1.5698795180722893,
      "grad_norm": 0.6220632195472717,
      "learning_rate": 3.0384036144578317e-06,
      "loss": 0.2893,
      "step": 2606
    },
    {
      "epoch": 1.5704819277108433,
      "grad_norm": 0.5538098216056824,
      "learning_rate": 3.0376506024096386e-06,
      "loss": 0.2813,
      "step": 2607
    },
    {
      "epoch": 1.5710843373493977,
      "grad_norm": 0.5034011602401733,
      "learning_rate": 3.0368975903614464e-06,
      "loss": 0.2053,
      "step": 2608
    },
    {
      "epoch": 1.5716867469879519,
      "grad_norm": 0.5859427452087402,
      "learning_rate": 3.0361445783132533e-06,
      "loss": 0.3025,
      "step": 2609
    },
    {
      "epoch": 1.572289156626506,
      "grad_norm": 0.6144871115684509,
      "learning_rate": 3.0353915662650606e-06,
      "loss": 0.2399,
      "step": 2610
    },
    {
      "epoch": 1.5728915662650602,
      "grad_norm": 0.5147497653961182,
      "learning_rate": 3.0346385542168676e-06,
      "loss": 0.235,
      "step": 2611
    },
    {
      "epoch": 1.5734939759036144,
      "grad_norm": 0.5866078734397888,
      "learning_rate": 3.033885542168675e-06,
      "loss": 0.2175,
      "step": 2612
    },
    {
      "epoch": 1.5740963855421688,
      "grad_norm": 0.4724450707435608,
      "learning_rate": 3.0331325301204823e-06,
      "loss": 0.2146,
      "step": 2613
    },
    {
      "epoch": 1.5746987951807228,
      "grad_norm": 0.536747932434082,
      "learning_rate": 3.032379518072289e-06,
      "loss": 0.2475,
      "step": 2614
    },
    {
      "epoch": 1.5753012048192772,
      "grad_norm": 0.5386403799057007,
      "learning_rate": 3.031626506024097e-06,
      "loss": 0.2496,
      "step": 2615
    },
    {
      "epoch": 1.5759036144578313,
      "grad_norm": 0.6041068434715271,
      "learning_rate": 3.030873493975904e-06,
      "loss": 0.2116,
      "step": 2616
    },
    {
      "epoch": 1.5765060240963855,
      "grad_norm": 0.5804474949836731,
      "learning_rate": 3.0301204819277112e-06,
      "loss": 0.2106,
      "step": 2617
    },
    {
      "epoch": 1.57710843373494,
      "grad_norm": 0.5493632555007935,
      "learning_rate": 3.029367469879518e-06,
      "loss": 0.2532,
      "step": 2618
    },
    {
      "epoch": 1.5777108433734939,
      "grad_norm": 0.5007837414741516,
      "learning_rate": 3.0286144578313255e-06,
      "loss": 0.2139,
      "step": 2619
    },
    {
      "epoch": 1.5783132530120483,
      "grad_norm": 0.6335582137107849,
      "learning_rate": 3.027861445783133e-06,
      "loss": 0.2744,
      "step": 2620
    },
    {
      "epoch": 1.5789156626506025,
      "grad_norm": 0.6704020500183105,
      "learning_rate": 3.0271084337349398e-06,
      "loss": 0.2449,
      "step": 2621
    },
    {
      "epoch": 1.5795180722891566,
      "grad_norm": 0.5873422622680664,
      "learning_rate": 3.0263554216867475e-06,
      "loss": 0.262,
      "step": 2622
    },
    {
      "epoch": 1.5801204819277108,
      "grad_norm": 0.5135627388954163,
      "learning_rate": 3.0256024096385545e-06,
      "loss": 0.2253,
      "step": 2623
    },
    {
      "epoch": 1.580722891566265,
      "grad_norm": 0.6246292591094971,
      "learning_rate": 3.0248493975903614e-06,
      "loss": 0.243,
      "step": 2624
    },
    {
      "epoch": 1.5813253012048194,
      "grad_norm": 0.4798854887485504,
      "learning_rate": 3.024096385542169e-06,
      "loss": 0.2302,
      "step": 2625
    },
    {
      "epoch": 1.5819277108433734,
      "grad_norm": 0.4941321611404419,
      "learning_rate": 3.023343373493976e-06,
      "loss": 0.2435,
      "step": 2626
    },
    {
      "epoch": 1.5825301204819278,
      "grad_norm": 0.5474206805229187,
      "learning_rate": 3.0225903614457834e-06,
      "loss": 0.2515,
      "step": 2627
    },
    {
      "epoch": 1.583132530120482,
      "grad_norm": 0.6068997979164124,
      "learning_rate": 3.0218373493975904e-06,
      "loss": 0.2169,
      "step": 2628
    },
    {
      "epoch": 1.5837349397590361,
      "grad_norm": 0.5507051944732666,
      "learning_rate": 3.021084337349398e-06,
      "loss": 0.2753,
      "step": 2629
    },
    {
      "epoch": 1.5843373493975905,
      "grad_norm": 0.518954873085022,
      "learning_rate": 3.020331325301205e-06,
      "loss": 0.2591,
      "step": 2630
    },
    {
      "epoch": 1.5849397590361445,
      "grad_norm": 0.552155077457428,
      "learning_rate": 3.019578313253012e-06,
      "loss": 0.2665,
      "step": 2631
    },
    {
      "epoch": 1.5855421686746989,
      "grad_norm": 0.7217336297035217,
      "learning_rate": 3.0188253012048198e-06,
      "loss": 0.2847,
      "step": 2632
    },
    {
      "epoch": 1.586144578313253,
      "grad_norm": 0.539136528968811,
      "learning_rate": 3.0180722891566267e-06,
      "loss": 0.2255,
      "step": 2633
    },
    {
      "epoch": 1.5867469879518072,
      "grad_norm": 0.6507854461669922,
      "learning_rate": 3.017319277108434e-06,
      "loss": 0.2659,
      "step": 2634
    },
    {
      "epoch": 1.5873493975903614,
      "grad_norm": 0.5686783194541931,
      "learning_rate": 3.0165662650602414e-06,
      "loss": 0.2619,
      "step": 2635
    },
    {
      "epoch": 1.5879518072289156,
      "grad_norm": 0.6416877508163452,
      "learning_rate": 3.0158132530120483e-06,
      "loss": 0.2965,
      "step": 2636
    },
    {
      "epoch": 1.58855421686747,
      "grad_norm": 0.5027098655700684,
      "learning_rate": 3.0150602409638556e-06,
      "loss": 0.2374,
      "step": 2637
    },
    {
      "epoch": 1.589156626506024,
      "grad_norm": 0.5050172209739685,
      "learning_rate": 3.0143072289156626e-06,
      "loss": 0.2429,
      "step": 2638
    },
    {
      "epoch": 1.5897590361445784,
      "grad_norm": 0.45043107867240906,
      "learning_rate": 3.0135542168674703e-06,
      "loss": 0.2115,
      "step": 2639
    },
    {
      "epoch": 1.5903614457831325,
      "grad_norm": 0.5912532806396484,
      "learning_rate": 3.0128012048192773e-06,
      "loss": 0.2689,
      "step": 2640
    },
    {
      "epoch": 1.5909638554216867,
      "grad_norm": 1.477646827697754,
      "learning_rate": 3.012048192771085e-06,
      "loss": 0.2723,
      "step": 2641
    },
    {
      "epoch": 1.5915662650602411,
      "grad_norm": 0.5137320160865784,
      "learning_rate": 3.011295180722892e-06,
      "loss": 0.2474,
      "step": 2642
    },
    {
      "epoch": 1.592168674698795,
      "grad_norm": 0.5864467024803162,
      "learning_rate": 3.010542168674699e-06,
      "loss": 0.2172,
      "step": 2643
    },
    {
      "epoch": 1.5927710843373495,
      "grad_norm": 0.5647445321083069,
      "learning_rate": 3.0097891566265062e-06,
      "loss": 0.2624,
      "step": 2644
    },
    {
      "epoch": 1.5933734939759037,
      "grad_norm": 0.5746046304702759,
      "learning_rate": 3.0090361445783136e-06,
      "loss": 0.2497,
      "step": 2645
    },
    {
      "epoch": 1.5939759036144578,
      "grad_norm": 0.5180204510688782,
      "learning_rate": 3.008283132530121e-06,
      "loss": 0.2529,
      "step": 2646
    },
    {
      "epoch": 1.594578313253012,
      "grad_norm": 0.48598337173461914,
      "learning_rate": 3.007530120481928e-06,
      "loss": 0.2544,
      "step": 2647
    },
    {
      "epoch": 1.5951807228915662,
      "grad_norm": 0.5134677290916443,
      "learning_rate": 3.0067771084337348e-06,
      "loss": 0.2476,
      "step": 2648
    },
    {
      "epoch": 1.5957831325301206,
      "grad_norm": 0.5299552083015442,
      "learning_rate": 3.0060240963855426e-06,
      "loss": 0.2553,
      "step": 2649
    },
    {
      "epoch": 1.5963855421686746,
      "grad_norm": 0.5076191425323486,
      "learning_rate": 3.0052710843373495e-06,
      "loss": 0.2421,
      "step": 2650
    },
    {
      "epoch": 1.596987951807229,
      "grad_norm": 0.5155293941497803,
      "learning_rate": 3.004518072289157e-06,
      "loss": 0.2437,
      "step": 2651
    },
    {
      "epoch": 1.5975903614457831,
      "grad_norm": 0.5545744299888611,
      "learning_rate": 3.003765060240964e-06,
      "loss": 0.2314,
      "step": 2652
    },
    {
      "epoch": 1.5981927710843373,
      "grad_norm": 0.570732057094574,
      "learning_rate": 3.0030120481927715e-06,
      "loss": 0.2925,
      "step": 2653
    },
    {
      "epoch": 1.5987951807228917,
      "grad_norm": 0.49096575379371643,
      "learning_rate": 3.0022590361445785e-06,
      "loss": 0.2481,
      "step": 2654
    },
    {
      "epoch": 1.5993975903614457,
      "grad_norm": 0.4974973797798157,
      "learning_rate": 3.0015060240963854e-06,
      "loss": 0.2308,
      "step": 2655
    },
    {
      "epoch": 1.6,
      "grad_norm": 0.5524654388427734,
      "learning_rate": 3.000753012048193e-06,
      "loss": 0.2261,
      "step": 2656
    },
    {
      "epoch": 1.6006024096385543,
      "grad_norm": 0.5165151953697205,
      "learning_rate": 3e-06,
      "loss": 0.2716,
      "step": 2657
    },
    {
      "epoch": 1.6012048192771084,
      "grad_norm": 0.4927175045013428,
      "learning_rate": 2.999246987951808e-06,
      "loss": 0.2489,
      "step": 2658
    },
    {
      "epoch": 1.6018072289156626,
      "grad_norm": 0.5553125143051147,
      "learning_rate": 2.9984939759036148e-06,
      "loss": 0.2451,
      "step": 2659
    },
    {
      "epoch": 1.6024096385542168,
      "grad_norm": 0.5600733757019043,
      "learning_rate": 2.9977409638554217e-06,
      "loss": 0.2184,
      "step": 2660
    },
    {
      "epoch": 1.6030120481927712,
      "grad_norm": 0.5494466423988342,
      "learning_rate": 2.996987951807229e-06,
      "loss": 0.2411,
      "step": 2661
    },
    {
      "epoch": 1.6036144578313252,
      "grad_norm": 0.7241886854171753,
      "learning_rate": 2.9962349397590364e-06,
      "loss": 0.2945,
      "step": 2662
    },
    {
      "epoch": 1.6042168674698796,
      "grad_norm": 0.5933173894882202,
      "learning_rate": 2.9954819277108437e-06,
      "loss": 0.2784,
      "step": 2663
    },
    {
      "epoch": 1.6048192771084338,
      "grad_norm": 0.4615626037120819,
      "learning_rate": 2.9947289156626507e-06,
      "loss": 0.2051,
      "step": 2664
    },
    {
      "epoch": 1.605421686746988,
      "grad_norm": 0.5409082174301147,
      "learning_rate": 2.9939759036144584e-06,
      "loss": 0.2388,
      "step": 2665
    },
    {
      "epoch": 1.6060240963855423,
      "grad_norm": 0.5565555095672607,
      "learning_rate": 2.9932228915662654e-06,
      "loss": 0.2276,
      "step": 2666
    },
    {
      "epoch": 1.6066265060240963,
      "grad_norm": 0.5152169466018677,
      "learning_rate": 2.9924698795180723e-06,
      "loss": 0.2854,
      "step": 2667
    },
    {
      "epoch": 1.6072289156626507,
      "grad_norm": 0.6021714210510254,
      "learning_rate": 2.99171686746988e-06,
      "loss": 0.2706,
      "step": 2668
    },
    {
      "epoch": 1.6078313253012049,
      "grad_norm": 0.5449873805046082,
      "learning_rate": 2.990963855421687e-06,
      "loss": 0.2697,
      "step": 2669
    },
    {
      "epoch": 1.608433734939759,
      "grad_norm": 0.5586842894554138,
      "learning_rate": 2.9902108433734943e-06,
      "loss": 0.235,
      "step": 2670
    },
    {
      "epoch": 1.6090361445783132,
      "grad_norm": 0.4990924298763275,
      "learning_rate": 2.9894578313253013e-06,
      "loss": 0.2237,
      "step": 2671
    },
    {
      "epoch": 1.6096385542168674,
      "grad_norm": 0.5319259166717529,
      "learning_rate": 2.9887048192771086e-06,
      "loss": 0.234,
      "step": 2672
    },
    {
      "epoch": 1.6102409638554218,
      "grad_norm": 0.646817684173584,
      "learning_rate": 2.987951807228916e-06,
      "loss": 0.2948,
      "step": 2673
    },
    {
      "epoch": 1.6108433734939758,
      "grad_norm": 0.4636136591434479,
      "learning_rate": 2.987198795180723e-06,
      "loss": 0.1779,
      "step": 2674
    },
    {
      "epoch": 1.6114457831325302,
      "grad_norm": 0.5504961013793945,
      "learning_rate": 2.9864457831325307e-06,
      "loss": 0.2052,
      "step": 2675
    },
    {
      "epoch": 1.6120481927710844,
      "grad_norm": 0.5355128645896912,
      "learning_rate": 2.9856927710843376e-06,
      "loss": 0.237,
      "step": 2676
    },
    {
      "epoch": 1.6126506024096385,
      "grad_norm": 0.5722009539604187,
      "learning_rate": 2.984939759036145e-06,
      "loss": 0.2626,
      "step": 2677
    },
    {
      "epoch": 1.613253012048193,
      "grad_norm": 0.5677975416183472,
      "learning_rate": 2.9841867469879523e-06,
      "loss": 0.2611,
      "step": 2678
    },
    {
      "epoch": 1.613855421686747,
      "grad_norm": 0.48657599091529846,
      "learning_rate": 2.983433734939759e-06,
      "loss": 0.2297,
      "step": 2679
    },
    {
      "epoch": 1.6144578313253013,
      "grad_norm": 0.5704182386398315,
      "learning_rate": 2.9826807228915665e-06,
      "loss": 0.2223,
      "step": 2680
    },
    {
      "epoch": 1.6150602409638555,
      "grad_norm": 0.5682469606399536,
      "learning_rate": 2.9819277108433735e-06,
      "loss": 0.2624,
      "step": 2681
    },
    {
      "epoch": 1.6156626506024097,
      "grad_norm": 0.46373701095581055,
      "learning_rate": 2.9811746987951812e-06,
      "loss": 0.1918,
      "step": 2682
    },
    {
      "epoch": 1.6162650602409638,
      "grad_norm": 0.6057069301605225,
      "learning_rate": 2.980421686746988e-06,
      "loss": 0.2931,
      "step": 2683
    },
    {
      "epoch": 1.616867469879518,
      "grad_norm": 0.5598815679550171,
      "learning_rate": 2.979668674698795e-06,
      "loss": 0.1999,
      "step": 2684
    },
    {
      "epoch": 1.6174698795180724,
      "grad_norm": 0.5011535882949829,
      "learning_rate": 2.978915662650603e-06,
      "loss": 0.2696,
      "step": 2685
    },
    {
      "epoch": 1.6180722891566264,
      "grad_norm": 0.5005029439926147,
      "learning_rate": 2.97816265060241e-06,
      "loss": 0.2321,
      "step": 2686
    },
    {
      "epoch": 1.6186746987951808,
      "grad_norm": 0.5218991637229919,
      "learning_rate": 2.977409638554217e-06,
      "loss": 0.3058,
      "step": 2687
    },
    {
      "epoch": 1.619277108433735,
      "grad_norm": 0.623736560344696,
      "learning_rate": 2.976656626506024e-06,
      "loss": 0.2741,
      "step": 2688
    },
    {
      "epoch": 1.6198795180722891,
      "grad_norm": 0.578578770160675,
      "learning_rate": 2.975903614457832e-06,
      "loss": 0.2708,
      "step": 2689
    },
    {
      "epoch": 1.6204819277108435,
      "grad_norm": 0.47594574093818665,
      "learning_rate": 2.9751506024096388e-06,
      "loss": 0.2326,
      "step": 2690
    },
    {
      "epoch": 1.6210843373493975,
      "grad_norm": 0.6375739574432373,
      "learning_rate": 2.9743975903614457e-06,
      "loss": 0.1913,
      "step": 2691
    },
    {
      "epoch": 1.621686746987952,
      "grad_norm": 0.5434343814849854,
      "learning_rate": 2.9736445783132535e-06,
      "loss": 0.2029,
      "step": 2692
    },
    {
      "epoch": 1.622289156626506,
      "grad_norm": 0.6006760001182556,
      "learning_rate": 2.9728915662650604e-06,
      "loss": 0.2504,
      "step": 2693
    },
    {
      "epoch": 1.6228915662650603,
      "grad_norm": 0.5036621689796448,
      "learning_rate": 2.9721385542168677e-06,
      "loss": 0.253,
      "step": 2694
    },
    {
      "epoch": 1.6234939759036144,
      "grad_norm": 0.5717242360115051,
      "learning_rate": 2.971385542168675e-06,
      "loss": 0.2888,
      "step": 2695
    },
    {
      "epoch": 1.6240963855421686,
      "grad_norm": 0.6302549242973328,
      "learning_rate": 2.970632530120482e-06,
      "loss": 0.221,
      "step": 2696
    },
    {
      "epoch": 1.624698795180723,
      "grad_norm": 0.48973971605300903,
      "learning_rate": 2.9698795180722894e-06,
      "loss": 0.2342,
      "step": 2697
    },
    {
      "epoch": 1.625301204819277,
      "grad_norm": 0.6426960825920105,
      "learning_rate": 2.9691265060240963e-06,
      "loss": 0.2666,
      "step": 2698
    },
    {
      "epoch": 1.6259036144578314,
      "grad_norm": 0.5693354606628418,
      "learning_rate": 2.968373493975904e-06,
      "loss": 0.2365,
      "step": 2699
    },
    {
      "epoch": 1.6265060240963856,
      "grad_norm": 0.49548542499542236,
      "learning_rate": 2.967620481927711e-06,
      "loss": 0.2204,
      "step": 2700
    },
    {
      "epoch": 1.6271084337349397,
      "grad_norm": 0.6235952973365784,
      "learning_rate": 2.9668674698795187e-06,
      "loss": 0.291,
      "step": 2701
    },
    {
      "epoch": 1.627710843373494,
      "grad_norm": 0.4807998836040497,
      "learning_rate": 2.9661144578313257e-06,
      "loss": 0.2142,
      "step": 2702
    },
    {
      "epoch": 1.628313253012048,
      "grad_norm": 0.5655873417854309,
      "learning_rate": 2.9653614457831326e-06,
      "loss": 0.2527,
      "step": 2703
    },
    {
      "epoch": 1.6289156626506025,
      "grad_norm": 0.5863222479820251,
      "learning_rate": 2.96460843373494e-06,
      "loss": 0.2678,
      "step": 2704
    },
    {
      "epoch": 1.6295180722891565,
      "grad_norm": 0.6112331748008728,
      "learning_rate": 2.9638554216867473e-06,
      "loss": 0.2979,
      "step": 2705
    },
    {
      "epoch": 1.6301204819277109,
      "grad_norm": 0.5404385328292847,
      "learning_rate": 2.9631024096385546e-06,
      "loss": 0.2283,
      "step": 2706
    },
    {
      "epoch": 1.630722891566265,
      "grad_norm": 0.5702577233314514,
      "learning_rate": 2.9623493975903616e-06,
      "loss": 0.2391,
      "step": 2707
    },
    {
      "epoch": 1.6313253012048192,
      "grad_norm": 0.4726087749004364,
      "learning_rate": 2.9615963855421685e-06,
      "loss": 0.1911,
      "step": 2708
    },
    {
      "epoch": 1.6319277108433736,
      "grad_norm": 0.6396379470825195,
      "learning_rate": 2.9608433734939763e-06,
      "loss": 0.249,
      "step": 2709
    },
    {
      "epoch": 1.6325301204819276,
      "grad_norm": 0.5250244736671448,
      "learning_rate": 2.960090361445783e-06,
      "loss": 0.2078,
      "step": 2710
    },
    {
      "epoch": 1.633132530120482,
      "grad_norm": 0.5330511331558228,
      "learning_rate": 2.959337349397591e-06,
      "loss": 0.2256,
      "step": 2711
    },
    {
      "epoch": 1.6337349397590362,
      "grad_norm": 0.4713612496852875,
      "learning_rate": 2.958584337349398e-06,
      "loss": 0.2017,
      "step": 2712
    },
    {
      "epoch": 1.6343373493975903,
      "grad_norm": 0.5576905608177185,
      "learning_rate": 2.9578313253012052e-06,
      "loss": 0.2123,
      "step": 2713
    },
    {
      "epoch": 1.6349397590361445,
      "grad_norm": 0.5298132300376892,
      "learning_rate": 2.957078313253012e-06,
      "loss": 0.2287,
      "step": 2714
    },
    {
      "epoch": 1.6355421686746987,
      "grad_norm": 0.4993821084499359,
      "learning_rate": 2.9563253012048195e-06,
      "loss": 0.2216,
      "step": 2715
    },
    {
      "epoch": 1.636144578313253,
      "grad_norm": 0.6039029955863953,
      "learning_rate": 2.955572289156627e-06,
      "loss": 0.2564,
      "step": 2716
    },
    {
      "epoch": 1.636746987951807,
      "grad_norm": 0.5275285243988037,
      "learning_rate": 2.9548192771084338e-06,
      "loss": 0.2118,
      "step": 2717
    },
    {
      "epoch": 1.6373493975903615,
      "grad_norm": 0.508613646030426,
      "learning_rate": 2.9540662650602416e-06,
      "loss": 0.2295,
      "step": 2718
    },
    {
      "epoch": 1.6379518072289156,
      "grad_norm": 0.5644060373306274,
      "learning_rate": 2.9533132530120485e-06,
      "loss": 0.2392,
      "step": 2719
    },
    {
      "epoch": 1.6385542168674698,
      "grad_norm": 0.49200761318206787,
      "learning_rate": 2.9525602409638554e-06,
      "loss": 0.2144,
      "step": 2720
    },
    {
      "epoch": 1.6391566265060242,
      "grad_norm": 0.655207097530365,
      "learning_rate": 2.9518072289156627e-06,
      "loss": 0.2774,
      "step": 2721
    },
    {
      "epoch": 1.6397590361445782,
      "grad_norm": 0.5701876878738403,
      "learning_rate": 2.95105421686747e-06,
      "loss": 0.2442,
      "step": 2722
    },
    {
      "epoch": 1.6403614457831326,
      "grad_norm": 0.48794129490852356,
      "learning_rate": 2.9503012048192774e-06,
      "loss": 0.2189,
      "step": 2723
    },
    {
      "epoch": 1.6409638554216868,
      "grad_norm": 0.5081095099449158,
      "learning_rate": 2.9495481927710844e-06,
      "loss": 0.2622,
      "step": 2724
    },
    {
      "epoch": 1.641566265060241,
      "grad_norm": 0.5296944379806519,
      "learning_rate": 2.948795180722892e-06,
      "loss": 0.218,
      "step": 2725
    },
    {
      "epoch": 1.6421686746987951,
      "grad_norm": 0.5112140774726868,
      "learning_rate": 2.948042168674699e-06,
      "loss": 0.2282,
      "step": 2726
    },
    {
      "epoch": 1.6427710843373493,
      "grad_norm": 0.5499070882797241,
      "learning_rate": 2.947289156626506e-06,
      "loss": 0.2373,
      "step": 2727
    },
    {
      "epoch": 1.6433734939759037,
      "grad_norm": 0.4767138957977295,
      "learning_rate": 2.9465361445783138e-06,
      "loss": 0.2557,
      "step": 2728
    },
    {
      "epoch": 1.6439759036144577,
      "grad_norm": 0.5351964235305786,
      "learning_rate": 2.9457831325301207e-06,
      "loss": 0.2226,
      "step": 2729
    },
    {
      "epoch": 1.644578313253012,
      "grad_norm": 0.5317491888999939,
      "learning_rate": 2.945030120481928e-06,
      "loss": 0.2202,
      "step": 2730
    },
    {
      "epoch": 1.6451807228915662,
      "grad_norm": 0.4937199354171753,
      "learning_rate": 2.944277108433735e-06,
      "loss": 0.1984,
      "step": 2731
    },
    {
      "epoch": 1.6457831325301204,
      "grad_norm": 0.6692872047424316,
      "learning_rate": 2.9435240963855423e-06,
      "loss": 0.2681,
      "step": 2732
    },
    {
      "epoch": 1.6463855421686748,
      "grad_norm": 0.5404306054115295,
      "learning_rate": 2.9427710843373497e-06,
      "loss": 0.2564,
      "step": 2733
    },
    {
      "epoch": 1.6469879518072288,
      "grad_norm": 0.4716021418571472,
      "learning_rate": 2.9420180722891566e-06,
      "loss": 0.2272,
      "step": 2734
    },
    {
      "epoch": 1.6475903614457832,
      "grad_norm": 0.46916237473487854,
      "learning_rate": 2.9412650602409644e-06,
      "loss": 0.2327,
      "step": 2735
    },
    {
      "epoch": 1.6481927710843374,
      "grad_norm": 0.4817621409893036,
      "learning_rate": 2.9405120481927713e-06,
      "loss": 0.2084,
      "step": 2736
    },
    {
      "epoch": 1.6487951807228916,
      "grad_norm": 0.46996378898620605,
      "learning_rate": 2.9397590361445786e-06,
      "loss": 0.1958,
      "step": 2737
    },
    {
      "epoch": 1.6493975903614457,
      "grad_norm": 0.5975180864334106,
      "learning_rate": 2.939006024096386e-06,
      "loss": 0.2451,
      "step": 2738
    },
    {
      "epoch": 1.65,
      "grad_norm": 0.5604681372642517,
      "learning_rate": 2.938253012048193e-06,
      "loss": 0.2492,
      "step": 2739
    },
    {
      "epoch": 1.6506024096385543,
      "grad_norm": 0.8458766341209412,
      "learning_rate": 2.9375000000000003e-06,
      "loss": 0.2726,
      "step": 2740
    },
    {
      "epoch": 1.6512048192771083,
      "grad_norm": 0.8014577627182007,
      "learning_rate": 2.936746987951807e-06,
      "loss": 0.2802,
      "step": 2741
    },
    {
      "epoch": 1.6518072289156627,
      "grad_norm": 0.7490376234054565,
      "learning_rate": 2.935993975903615e-06,
      "loss": 0.3181,
      "step": 2742
    },
    {
      "epoch": 1.6524096385542169,
      "grad_norm": 0.9273775815963745,
      "learning_rate": 2.935240963855422e-06,
      "loss": 0.2371,
      "step": 2743
    },
    {
      "epoch": 1.653012048192771,
      "grad_norm": 0.9020917415618896,
      "learning_rate": 2.934487951807229e-06,
      "loss": 0.2725,
      "step": 2744
    },
    {
      "epoch": 1.6536144578313254,
      "grad_norm": 0.7716365456581116,
      "learning_rate": 2.9337349397590366e-06,
      "loss": 0.2718,
      "step": 2745
    },
    {
      "epoch": 1.6542168674698794,
      "grad_norm": 0.7796707153320312,
      "learning_rate": 2.9329819277108435e-06,
      "loss": 0.332,
      "step": 2746
    },
    {
      "epoch": 1.6548192771084338,
      "grad_norm": 0.6890038847923279,
      "learning_rate": 2.932228915662651e-06,
      "loss": 0.3154,
      "step": 2747
    },
    {
      "epoch": 1.655421686746988,
      "grad_norm": 0.7215785980224609,
      "learning_rate": 2.931475903614458e-06,
      "loss": 0.3866,
      "step": 2748
    },
    {
      "epoch": 1.6560240963855422,
      "grad_norm": 0.7902901768684387,
      "learning_rate": 2.9307228915662655e-06,
      "loss": 0.2997,
      "step": 2749
    },
    {
      "epoch": 1.6566265060240963,
      "grad_norm": 0.805115282535553,
      "learning_rate": 2.9299698795180725e-06,
      "loss": 0.2231,
      "step": 2750
    },
    {
      "epoch": 1.6572289156626505,
      "grad_norm": 0.6031847596168518,
      "learning_rate": 2.9292168674698794e-06,
      "loss": 0.2666,
      "step": 2751
    },
    {
      "epoch": 1.657831325301205,
      "grad_norm": 0.7230938076972961,
      "learning_rate": 2.928463855421687e-06,
      "loss": 0.2818,
      "step": 2752
    },
    {
      "epoch": 1.6584337349397589,
      "grad_norm": 0.7201229929924011,
      "learning_rate": 2.927710843373494e-06,
      "loss": 0.322,
      "step": 2753
    },
    {
      "epoch": 1.6590361445783133,
      "grad_norm": 0.7190512418746948,
      "learning_rate": 2.926957831325302e-06,
      "loss": 0.301,
      "step": 2754
    },
    {
      "epoch": 1.6596385542168675,
      "grad_norm": 0.7300453186035156,
      "learning_rate": 2.9262048192771088e-06,
      "loss": 0.2754,
      "step": 2755
    },
    {
      "epoch": 1.6602409638554216,
      "grad_norm": 0.6617128252983093,
      "learning_rate": 2.9254518072289157e-06,
      "loss": 0.2538,
      "step": 2756
    },
    {
      "epoch": 1.660843373493976,
      "grad_norm": 0.5891188383102417,
      "learning_rate": 2.924698795180723e-06,
      "loss": 0.2492,
      "step": 2757
    },
    {
      "epoch": 1.66144578313253,
      "grad_norm": 0.7179758548736572,
      "learning_rate": 2.92394578313253e-06,
      "loss": 0.2912,
      "step": 2758
    },
    {
      "epoch": 1.6620481927710844,
      "grad_norm": 6.243352890014648,
      "learning_rate": 2.9231927710843378e-06,
      "loss": 0.2931,
      "step": 2759
    },
    {
      "epoch": 1.6626506024096386,
      "grad_norm": 0.6276156306266785,
      "learning_rate": 2.9224397590361447e-06,
      "loss": 0.2842,
      "step": 2760
    },
    {
      "epoch": 1.6632530120481928,
      "grad_norm": 0.6436669230461121,
      "learning_rate": 2.9216867469879524e-06,
      "loss": 0.2521,
      "step": 2761
    },
    {
      "epoch": 1.663855421686747,
      "grad_norm": 0.6628603339195251,
      "learning_rate": 2.9209337349397594e-06,
      "loss": 0.3181,
      "step": 2762
    },
    {
      "epoch": 1.6644578313253011,
      "grad_norm": 0.5784590244293213,
      "learning_rate": 2.9201807228915663e-06,
      "loss": 0.2601,
      "step": 2763
    },
    {
      "epoch": 1.6650602409638555,
      "grad_norm": 0.6141110062599182,
      "learning_rate": 2.9194277108433736e-06,
      "loss": 0.2861,
      "step": 2764
    },
    {
      "epoch": 1.6656626506024095,
      "grad_norm": 0.6181651949882507,
      "learning_rate": 2.918674698795181e-06,
      "loss": 0.2669,
      "step": 2765
    },
    {
      "epoch": 1.6662650602409639,
      "grad_norm": 0.573609471321106,
      "learning_rate": 2.9179216867469883e-06,
      "loss": 0.2624,
      "step": 2766
    },
    {
      "epoch": 1.666867469879518,
      "grad_norm": 0.6637190580368042,
      "learning_rate": 2.9171686746987953e-06,
      "loss": 0.2891,
      "step": 2767
    },
    {
      "epoch": 1.6674698795180722,
      "grad_norm": 0.574670672416687,
      "learning_rate": 2.916415662650602e-06,
      "loss": 0.3237,
      "step": 2768
    },
    {
      "epoch": 1.6680722891566266,
      "grad_norm": 0.5554093718528748,
      "learning_rate": 2.91566265060241e-06,
      "loss": 0.2225,
      "step": 2769
    },
    {
      "epoch": 1.6686746987951806,
      "grad_norm": 0.6108439564704895,
      "learning_rate": 2.914909638554217e-06,
      "loss": 0.3261,
      "step": 2770
    },
    {
      "epoch": 1.669277108433735,
      "grad_norm": 0.6407626867294312,
      "learning_rate": 2.9141566265060247e-06,
      "loss": 0.2605,
      "step": 2771
    },
    {
      "epoch": 1.6698795180722892,
      "grad_norm": 0.5712094902992249,
      "learning_rate": 2.9134036144578316e-06,
      "loss": 0.3057,
      "step": 2772
    },
    {
      "epoch": 1.6704819277108434,
      "grad_norm": 0.6281792521476746,
      "learning_rate": 2.912650602409639e-06,
      "loss": 0.296,
      "step": 2773
    },
    {
      "epoch": 1.6710843373493975,
      "grad_norm": 0.597744882106781,
      "learning_rate": 2.911897590361446e-06,
      "loss": 0.2289,
      "step": 2774
    },
    {
      "epoch": 1.6716867469879517,
      "grad_norm": 0.5713860988616943,
      "learning_rate": 2.911144578313253e-06,
      "loss": 0.3206,
      "step": 2775
    },
    {
      "epoch": 1.6722891566265061,
      "grad_norm": 1.845240592956543,
      "learning_rate": 2.9103915662650606e-06,
      "loss": 0.333,
      "step": 2776
    },
    {
      "epoch": 1.67289156626506,
      "grad_norm": 0.5738739967346191,
      "learning_rate": 2.9096385542168675e-06,
      "loss": 0.2664,
      "step": 2777
    },
    {
      "epoch": 1.6734939759036145,
      "grad_norm": 0.5533925890922546,
      "learning_rate": 2.9088855421686753e-06,
      "loss": 0.2824,
      "step": 2778
    },
    {
      "epoch": 1.6740963855421687,
      "grad_norm": 0.5684736371040344,
      "learning_rate": 2.908132530120482e-06,
      "loss": 0.2398,
      "step": 2779
    },
    {
      "epoch": 1.6746987951807228,
      "grad_norm": 0.6051166653633118,
      "learning_rate": 2.907379518072289e-06,
      "loss": 0.3325,
      "step": 2780
    },
    {
      "epoch": 1.6753012048192772,
      "grad_norm": 0.5634081959724426,
      "learning_rate": 2.906626506024097e-06,
      "loss": 0.2805,
      "step": 2781
    },
    {
      "epoch": 1.6759036144578312,
      "grad_norm": 0.5304374098777771,
      "learning_rate": 2.905873493975904e-06,
      "loss": 0.2764,
      "step": 2782
    },
    {
      "epoch": 1.6765060240963856,
      "grad_norm": 0.564426600933075,
      "learning_rate": 2.905120481927711e-06,
      "loss": 0.28,
      "step": 2783
    },
    {
      "epoch": 1.6771084337349398,
      "grad_norm": 0.5555336475372314,
      "learning_rate": 2.904367469879518e-06,
      "loss": 0.2743,
      "step": 2784
    },
    {
      "epoch": 1.677710843373494,
      "grad_norm": 0.5932860374450684,
      "learning_rate": 2.903614457831326e-06,
      "loss": 0.2959,
      "step": 2785
    },
    {
      "epoch": 1.6783132530120481,
      "grad_norm": 0.5630435943603516,
      "learning_rate": 2.9028614457831328e-06,
      "loss": 0.2467,
      "step": 2786
    },
    {
      "epoch": 1.6789156626506023,
      "grad_norm": 0.5669923424720764,
      "learning_rate": 2.9021084337349397e-06,
      "loss": 0.2651,
      "step": 2787
    },
    {
      "epoch": 1.6795180722891567,
      "grad_norm": 0.5880084037780762,
      "learning_rate": 2.9013554216867475e-06,
      "loss": 0.2813,
      "step": 2788
    },
    {
      "epoch": 1.6801204819277107,
      "grad_norm": 0.5619683861732483,
      "learning_rate": 2.9006024096385544e-06,
      "loss": 0.2345,
      "step": 2789
    },
    {
      "epoch": 1.680722891566265,
      "grad_norm": 0.5943960547447205,
      "learning_rate": 2.8998493975903617e-06,
      "loss": 0.2401,
      "step": 2790
    },
    {
      "epoch": 1.6813253012048193,
      "grad_norm": 0.6489970088005066,
      "learning_rate": 2.899096385542169e-06,
      "loss": 0.3121,
      "step": 2791
    },
    {
      "epoch": 1.6819277108433734,
      "grad_norm": 0.6829344630241394,
      "learning_rate": 2.898343373493976e-06,
      "loss": 0.3068,
      "step": 2792
    },
    {
      "epoch": 1.6825301204819278,
      "grad_norm": 0.5643536448478699,
      "learning_rate": 2.8975903614457834e-06,
      "loss": 0.2678,
      "step": 2793
    },
    {
      "epoch": 1.6831325301204818,
      "grad_norm": 0.6883153915405273,
      "learning_rate": 2.8968373493975903e-06,
      "loss": 0.2538,
      "step": 2794
    },
    {
      "epoch": 1.6837349397590362,
      "grad_norm": 0.6403830647468567,
      "learning_rate": 2.896084337349398e-06,
      "loss": 0.301,
      "step": 2795
    },
    {
      "epoch": 1.6843373493975904,
      "grad_norm": 0.6367747783660889,
      "learning_rate": 2.895331325301205e-06,
      "loss": 0.3125,
      "step": 2796
    },
    {
      "epoch": 1.6849397590361446,
      "grad_norm": 0.5713905692100525,
      "learning_rate": 2.8945783132530123e-06,
      "loss": 0.2665,
      "step": 2797
    },
    {
      "epoch": 1.6855421686746987,
      "grad_norm": 0.9270291924476624,
      "learning_rate": 2.8938253012048197e-06,
      "loss": 0.2612,
      "step": 2798
    },
    {
      "epoch": 1.686144578313253,
      "grad_norm": 0.584417998790741,
      "learning_rate": 2.8930722891566266e-06,
      "loss": 0.3083,
      "step": 2799
    },
    {
      "epoch": 1.6867469879518073,
      "grad_norm": 0.5493406653404236,
      "learning_rate": 2.892319277108434e-06,
      "loss": 0.2498,
      "step": 2800
    },
    {
      "epoch": 1.6873493975903613,
      "grad_norm": 0.8569199442863464,
      "learning_rate": 2.891566265060241e-06,
      "loss": 0.2397,
      "step": 2801
    },
    {
      "epoch": 1.6879518072289157,
      "grad_norm": 0.5049594640731812,
      "learning_rate": 2.8908132530120487e-06,
      "loss": 0.2199,
      "step": 2802
    },
    {
      "epoch": 1.6885542168674699,
      "grad_norm": 0.6087396740913391,
      "learning_rate": 2.8900602409638556e-06,
      "loss": 0.3301,
      "step": 2803
    },
    {
      "epoch": 1.689156626506024,
      "grad_norm": 0.5189349055290222,
      "learning_rate": 2.8893072289156625e-06,
      "loss": 0.2173,
      "step": 2804
    },
    {
      "epoch": 1.6897590361445785,
      "grad_norm": 0.5426576137542725,
      "learning_rate": 2.8885542168674703e-06,
      "loss": 0.2321,
      "step": 2805
    },
    {
      "epoch": 1.6903614457831324,
      "grad_norm": 0.539405882358551,
      "learning_rate": 2.887801204819277e-06,
      "loss": 0.2794,
      "step": 2806
    },
    {
      "epoch": 1.6909638554216868,
      "grad_norm": 0.5461833477020264,
      "learning_rate": 2.8870481927710845e-06,
      "loss": 0.213,
      "step": 2807
    },
    {
      "epoch": 1.691566265060241,
      "grad_norm": 0.5783712267875671,
      "learning_rate": 2.886295180722892e-06,
      "loss": 0.2606,
      "step": 2808
    },
    {
      "epoch": 1.6921686746987952,
      "grad_norm": 0.5772024393081665,
      "learning_rate": 2.8855421686746992e-06,
      "loss": 0.27,
      "step": 2809
    },
    {
      "epoch": 1.6927710843373494,
      "grad_norm": 0.6209965944290161,
      "learning_rate": 2.884789156626506e-06,
      "loss": 0.301,
      "step": 2810
    },
    {
      "epoch": 1.6933734939759035,
      "grad_norm": 0.631231427192688,
      "learning_rate": 2.884036144578313e-06,
      "loss": 0.2233,
      "step": 2811
    },
    {
      "epoch": 1.693975903614458,
      "grad_norm": 0.5374614596366882,
      "learning_rate": 2.883283132530121e-06,
      "loss": 0.2477,
      "step": 2812
    },
    {
      "epoch": 1.694578313253012,
      "grad_norm": 0.642322838306427,
      "learning_rate": 2.882530120481928e-06,
      "loss": 0.2889,
      "step": 2813
    },
    {
      "epoch": 1.6951807228915663,
      "grad_norm": 0.6935487985610962,
      "learning_rate": 2.8817771084337356e-06,
      "loss": 0.2923,
      "step": 2814
    },
    {
      "epoch": 1.6957831325301205,
      "grad_norm": 0.6161943674087524,
      "learning_rate": 2.8810240963855425e-06,
      "loss": 0.2641,
      "step": 2815
    },
    {
      "epoch": 1.6963855421686747,
      "grad_norm": 0.6596494913101196,
      "learning_rate": 2.8802710843373494e-06,
      "loss": 0.2857,
      "step": 2816
    },
    {
      "epoch": 1.696987951807229,
      "grad_norm": 0.621330738067627,
      "learning_rate": 2.8795180722891568e-06,
      "loss": 0.3354,
      "step": 2817
    },
    {
      "epoch": 1.697590361445783,
      "grad_norm": 0.5921681523323059,
      "learning_rate": 2.878765060240964e-06,
      "loss": 0.2687,
      "step": 2818
    },
    {
      "epoch": 1.6981927710843374,
      "grad_norm": 0.6186074614524841,
      "learning_rate": 2.8780120481927715e-06,
      "loss": 0.2272,
      "step": 2819
    },
    {
      "epoch": 1.6987951807228916,
      "grad_norm": 0.5532707571983337,
      "learning_rate": 2.8772590361445784e-06,
      "loss": 0.2953,
      "step": 2820
    },
    {
      "epoch": 1.6993975903614458,
      "grad_norm": 0.578423261642456,
      "learning_rate": 2.876506024096386e-06,
      "loss": 0.2561,
      "step": 2821
    },
    {
      "epoch": 1.7,
      "grad_norm": 0.527356743812561,
      "learning_rate": 2.875753012048193e-06,
      "loss": 0.2482,
      "step": 2822
    },
    {
      "epoch": 1.7006024096385541,
      "grad_norm": 0.6102071404457092,
      "learning_rate": 2.875e-06,
      "loss": 0.2776,
      "step": 2823
    },
    {
      "epoch": 1.7012048192771085,
      "grad_norm": 0.6379199028015137,
      "learning_rate": 2.8742469879518078e-06,
      "loss": 0.2531,
      "step": 2824
    },
    {
      "epoch": 1.7018072289156625,
      "grad_norm": 0.5729057192802429,
      "learning_rate": 2.8734939759036147e-06,
      "loss": 0.2444,
      "step": 2825
    },
    {
      "epoch": 1.702409638554217,
      "grad_norm": 0.6728864312171936,
      "learning_rate": 2.872740963855422e-06,
      "loss": 0.3267,
      "step": 2826
    },
    {
      "epoch": 1.703012048192771,
      "grad_norm": 0.5945563912391663,
      "learning_rate": 2.871987951807229e-06,
      "loss": 0.2575,
      "step": 2827
    },
    {
      "epoch": 1.7036144578313253,
      "grad_norm": 0.6389757394790649,
      "learning_rate": 2.8712349397590363e-06,
      "loss": 0.2609,
      "step": 2828
    },
    {
      "epoch": 1.7042168674698797,
      "grad_norm": 0.560566782951355,
      "learning_rate": 2.8704819277108437e-06,
      "loss": 0.2109,
      "step": 2829
    },
    {
      "epoch": 1.7048192771084336,
      "grad_norm": 0.5427950024604797,
      "learning_rate": 2.8697289156626506e-06,
      "loss": 0.2549,
      "step": 2830
    },
    {
      "epoch": 1.705421686746988,
      "grad_norm": 0.5946295857429504,
      "learning_rate": 2.8689759036144584e-06,
      "loss": 0.2451,
      "step": 2831
    },
    {
      "epoch": 1.7060240963855422,
      "grad_norm": 0.6067692041397095,
      "learning_rate": 2.8682228915662653e-06,
      "loss": 0.2808,
      "step": 2832
    },
    {
      "epoch": 1.7066265060240964,
      "grad_norm": 0.6540196537971497,
      "learning_rate": 2.8674698795180726e-06,
      "loss": 0.2546,
      "step": 2833
    },
    {
      "epoch": 1.7072289156626506,
      "grad_norm": 0.5361276268959045,
      "learning_rate": 2.8667168674698796e-06,
      "loss": 0.2233,
      "step": 2834
    },
    {
      "epoch": 1.7078313253012047,
      "grad_norm": 0.6827237010002136,
      "learning_rate": 2.865963855421687e-06,
      "loss": 0.2274,
      "step": 2835
    },
    {
      "epoch": 1.7084337349397591,
      "grad_norm": 0.5676450729370117,
      "learning_rate": 2.8652108433734943e-06,
      "loss": 0.3264,
      "step": 2836
    },
    {
      "epoch": 1.709036144578313,
      "grad_norm": 0.5825704336166382,
      "learning_rate": 2.864457831325301e-06,
      "loss": 0.2697,
      "step": 2837
    },
    {
      "epoch": 1.7096385542168675,
      "grad_norm": 0.6714023351669312,
      "learning_rate": 2.863704819277109e-06,
      "loss": 0.3374,
      "step": 2838
    },
    {
      "epoch": 1.7102409638554217,
      "grad_norm": 0.5909920930862427,
      "learning_rate": 2.862951807228916e-06,
      "loss": 0.2613,
      "step": 2839
    },
    {
      "epoch": 1.7108433734939759,
      "grad_norm": 0.5422746539115906,
      "learning_rate": 2.862198795180723e-06,
      "loss": 0.212,
      "step": 2840
    },
    {
      "epoch": 1.7114457831325303,
      "grad_norm": 0.5738189220428467,
      "learning_rate": 2.8614457831325306e-06,
      "loss": 0.2317,
      "step": 2841
    },
    {
      "epoch": 1.7120481927710842,
      "grad_norm": 0.5680642127990723,
      "learning_rate": 2.8606927710843375e-06,
      "loss": 0.3028,
      "step": 2842
    },
    {
      "epoch": 1.7126506024096386,
      "grad_norm": 0.5428779721260071,
      "learning_rate": 2.859939759036145e-06,
      "loss": 0.2497,
      "step": 2843
    },
    {
      "epoch": 1.7132530120481928,
      "grad_norm": 0.6067304611206055,
      "learning_rate": 2.8591867469879518e-06,
      "loss": 0.2354,
      "step": 2844
    },
    {
      "epoch": 1.713855421686747,
      "grad_norm": 0.8925507068634033,
      "learning_rate": 2.8584337349397595e-06,
      "loss": 0.2666,
      "step": 2845
    },
    {
      "epoch": 1.7144578313253012,
      "grad_norm": 0.6151738166809082,
      "learning_rate": 2.8576807228915665e-06,
      "loss": 0.271,
      "step": 2846
    },
    {
      "epoch": 1.7150602409638553,
      "grad_norm": 0.5703992247581482,
      "learning_rate": 2.8569277108433734e-06,
      "loss": 0.2536,
      "step": 2847
    },
    {
      "epoch": 1.7156626506024097,
      "grad_norm": 0.5687015056610107,
      "learning_rate": 2.856174698795181e-06,
      "loss": 0.2614,
      "step": 2848
    },
    {
      "epoch": 1.7162650602409637,
      "grad_norm": 0.5672257542610168,
      "learning_rate": 2.855421686746988e-06,
      "loss": 0.2846,
      "step": 2849
    },
    {
      "epoch": 1.716867469879518,
      "grad_norm": 0.56076580286026,
      "learning_rate": 2.8546686746987954e-06,
      "loss": 0.3193,
      "step": 2850
    },
    {
      "epoch": 1.7174698795180723,
      "grad_norm": 0.6399503946304321,
      "learning_rate": 2.853915662650603e-06,
      "loss": 0.2647,
      "step": 2851
    },
    {
      "epoch": 1.7180722891566265,
      "grad_norm": 0.580233633518219,
      "learning_rate": 2.8531626506024097e-06,
      "loss": 0.2696,
      "step": 2852
    },
    {
      "epoch": 1.7186746987951809,
      "grad_norm": 0.6166430711746216,
      "learning_rate": 2.852409638554217e-06,
      "loss": 0.2844,
      "step": 2853
    },
    {
      "epoch": 1.7192771084337348,
      "grad_norm": 0.5880785584449768,
      "learning_rate": 2.851656626506024e-06,
      "loss": 0.3103,
      "step": 2854
    },
    {
      "epoch": 1.7198795180722892,
      "grad_norm": 0.5677370429039001,
      "learning_rate": 2.8509036144578318e-06,
      "loss": 0.2696,
      "step": 2855
    },
    {
      "epoch": 1.7204819277108434,
      "grad_norm": 0.6023218631744385,
      "learning_rate": 2.8501506024096387e-06,
      "loss": 0.2634,
      "step": 2856
    },
    {
      "epoch": 1.7210843373493976,
      "grad_norm": 0.5681709051132202,
      "learning_rate": 2.8493975903614465e-06,
      "loss": 0.2743,
      "step": 2857
    },
    {
      "epoch": 1.7216867469879518,
      "grad_norm": 0.6576975584030151,
      "learning_rate": 2.8486445783132534e-06,
      "loss": 0.3018,
      "step": 2858
    },
    {
      "epoch": 1.722289156626506,
      "grad_norm": 0.5633780360221863,
      "learning_rate": 2.8478915662650603e-06,
      "loss": 0.312,
      "step": 2859
    },
    {
      "epoch": 1.7228915662650603,
      "grad_norm": 0.6030386686325073,
      "learning_rate": 2.8471385542168677e-06,
      "loss": 0.233,
      "step": 2860
    },
    {
      "epoch": 1.7234939759036143,
      "grad_norm": 0.6445188522338867,
      "learning_rate": 2.846385542168675e-06,
      "loss": 0.2185,
      "step": 2861
    },
    {
      "epoch": 1.7240963855421687,
      "grad_norm": 0.6050657629966736,
      "learning_rate": 2.8456325301204824e-06,
      "loss": 0.2758,
      "step": 2862
    },
    {
      "epoch": 1.7246987951807229,
      "grad_norm": 0.5840875506401062,
      "learning_rate": 2.8448795180722893e-06,
      "loss": 0.2761,
      "step": 2863
    },
    {
      "epoch": 1.725301204819277,
      "grad_norm": 0.5444936156272888,
      "learning_rate": 2.844126506024096e-06,
      "loss": 0.2228,
      "step": 2864
    },
    {
      "epoch": 1.7259036144578315,
      "grad_norm": 0.5615944862365723,
      "learning_rate": 2.843373493975904e-06,
      "loss": 0.2361,
      "step": 2865
    },
    {
      "epoch": 1.7265060240963854,
      "grad_norm": 0.5479246973991394,
      "learning_rate": 2.842620481927711e-06,
      "loss": 0.275,
      "step": 2866
    },
    {
      "epoch": 1.7271084337349398,
      "grad_norm": 0.5569829940795898,
      "learning_rate": 2.8418674698795182e-06,
      "loss": 0.2282,
      "step": 2867
    },
    {
      "epoch": 1.727710843373494,
      "grad_norm": 0.5491496920585632,
      "learning_rate": 2.8411144578313256e-06,
      "loss": 0.2839,
      "step": 2868
    },
    {
      "epoch": 1.7283132530120482,
      "grad_norm": 0.5579409599304199,
      "learning_rate": 2.840361445783133e-06,
      "loss": 0.2409,
      "step": 2869
    },
    {
      "epoch": 1.7289156626506024,
      "grad_norm": 0.5718051791191101,
      "learning_rate": 2.83960843373494e-06,
      "loss": 0.2692,
      "step": 2870
    },
    {
      "epoch": 1.7295180722891565,
      "grad_norm": 0.6493368148803711,
      "learning_rate": 2.838855421686747e-06,
      "loss": 0.2804,
      "step": 2871
    },
    {
      "epoch": 1.730120481927711,
      "grad_norm": 0.8682625889778137,
      "learning_rate": 2.8381024096385546e-06,
      "loss": 0.2224,
      "step": 2872
    },
    {
      "epoch": 1.730722891566265,
      "grad_norm": 0.7038090825080872,
      "learning_rate": 2.8373493975903615e-06,
      "loss": 0.2573,
      "step": 2873
    },
    {
      "epoch": 1.7313253012048193,
      "grad_norm": 0.5638414025306702,
      "learning_rate": 2.8365963855421693e-06,
      "loss": 0.2464,
      "step": 2874
    },
    {
      "epoch": 1.7319277108433735,
      "grad_norm": 0.5419296622276306,
      "learning_rate": 2.835843373493976e-06,
      "loss": 0.3023,
      "step": 2875
    },
    {
      "epoch": 1.7325301204819277,
      "grad_norm": 0.5691571235656738,
      "learning_rate": 2.835090361445783e-06,
      "loss": 0.2394,
      "step": 2876
    },
    {
      "epoch": 1.733132530120482,
      "grad_norm": 0.5417325496673584,
      "learning_rate": 2.8343373493975905e-06,
      "loss": 0.2339,
      "step": 2877
    },
    {
      "epoch": 1.733734939759036,
      "grad_norm": 0.594123125076294,
      "learning_rate": 2.833584337349398e-06,
      "loss": 0.2215,
      "step": 2878
    },
    {
      "epoch": 1.7343373493975904,
      "grad_norm": 0.5383523106575012,
      "learning_rate": 2.832831325301205e-06,
      "loss": 0.2491,
      "step": 2879
    },
    {
      "epoch": 1.7349397590361446,
      "grad_norm": 0.5813083648681641,
      "learning_rate": 2.832078313253012e-06,
      "loss": 0.2027,
      "step": 2880
    },
    {
      "epoch": 1.7355421686746988,
      "grad_norm": 0.5634416341781616,
      "learning_rate": 2.83132530120482e-06,
      "loss": 0.2571,
      "step": 2881
    },
    {
      "epoch": 1.736144578313253,
      "grad_norm": 0.6004036664962769,
      "learning_rate": 2.8305722891566268e-06,
      "loss": 0.2615,
      "step": 2882
    },
    {
      "epoch": 1.7367469879518072,
      "grad_norm": 0.5617333650588989,
      "learning_rate": 2.8298192771084337e-06,
      "loss": 0.2797,
      "step": 2883
    },
    {
      "epoch": 1.7373493975903616,
      "grad_norm": 0.5792317986488342,
      "learning_rate": 2.8290662650602415e-06,
      "loss": 0.2352,
      "step": 2884
    },
    {
      "epoch": 1.7379518072289155,
      "grad_norm": 0.6206154823303223,
      "learning_rate": 2.8283132530120484e-06,
      "loss": 0.2269,
      "step": 2885
    },
    {
      "epoch": 1.73855421686747,
      "grad_norm": 0.6476181149482727,
      "learning_rate": 2.8275602409638558e-06,
      "loss": 0.2561,
      "step": 2886
    },
    {
      "epoch": 1.739156626506024,
      "grad_norm": 0.6320972442626953,
      "learning_rate": 2.8268072289156627e-06,
      "loss": 0.3162,
      "step": 2887
    },
    {
      "epoch": 1.7397590361445783,
      "grad_norm": 0.5997978448867798,
      "learning_rate": 2.82605421686747e-06,
      "loss": 0.2614,
      "step": 2888
    },
    {
      "epoch": 1.7403614457831327,
      "grad_norm": 0.5521248579025269,
      "learning_rate": 2.8253012048192774e-06,
      "loss": 0.2772,
      "step": 2889
    },
    {
      "epoch": 1.7409638554216866,
      "grad_norm": 0.5493324995040894,
      "learning_rate": 2.8245481927710843e-06,
      "loss": 0.2315,
      "step": 2890
    },
    {
      "epoch": 1.741566265060241,
      "grad_norm": 0.6154329776763916,
      "learning_rate": 2.823795180722892e-06,
      "loss": 0.2054,
      "step": 2891
    },
    {
      "epoch": 1.7421686746987952,
      "grad_norm": 0.6386085152626038,
      "learning_rate": 2.823042168674699e-06,
      "loss": 0.2795,
      "step": 2892
    },
    {
      "epoch": 1.7427710843373494,
      "grad_norm": 0.6259672045707703,
      "learning_rate": 2.8222891566265063e-06,
      "loss": 0.2474,
      "step": 2893
    },
    {
      "epoch": 1.7433734939759036,
      "grad_norm": 0.6293674111366272,
      "learning_rate": 2.8215361445783137e-06,
      "loss": 0.2743,
      "step": 2894
    },
    {
      "epoch": 1.7439759036144578,
      "grad_norm": 0.5438123941421509,
      "learning_rate": 2.8207831325301206e-06,
      "loss": 0.261,
      "step": 2895
    },
    {
      "epoch": 1.7445783132530122,
      "grad_norm": 0.6116155982017517,
      "learning_rate": 2.820030120481928e-06,
      "loss": 0.2918,
      "step": 2896
    },
    {
      "epoch": 1.7451807228915661,
      "grad_norm": 0.616064190864563,
      "learning_rate": 2.819277108433735e-06,
      "loss": 0.3033,
      "step": 2897
    },
    {
      "epoch": 1.7457831325301205,
      "grad_norm": 0.5795650482177734,
      "learning_rate": 2.8185240963855427e-06,
      "loss": 0.2938,
      "step": 2898
    },
    {
      "epoch": 1.7463855421686747,
      "grad_norm": 0.6028896570205688,
      "learning_rate": 2.8177710843373496e-06,
      "loss": 0.2448,
      "step": 2899
    },
    {
      "epoch": 1.7469879518072289,
      "grad_norm": 0.5928851962089539,
      "learning_rate": 2.8170180722891565e-06,
      "loss": 0.2728,
      "step": 2900
    },
    {
      "epoch": 1.7475903614457833,
      "grad_norm": 0.6326186060905457,
      "learning_rate": 2.8162650602409643e-06,
      "loss": 0.291,
      "step": 2901
    },
    {
      "epoch": 1.7481927710843372,
      "grad_norm": 0.5596456527709961,
      "learning_rate": 2.815512048192771e-06,
      "loss": 0.2203,
      "step": 2902
    },
    {
      "epoch": 1.7487951807228916,
      "grad_norm": 0.5632768273353577,
      "learning_rate": 2.8147590361445786e-06,
      "loss": 0.2421,
      "step": 2903
    },
    {
      "epoch": 1.7493975903614458,
      "grad_norm": 0.5979451537132263,
      "learning_rate": 2.8140060240963855e-06,
      "loss": 0.2847,
      "step": 2904
    },
    {
      "epoch": 1.75,
      "grad_norm": 0.7859722375869751,
      "learning_rate": 2.8132530120481933e-06,
      "loss": 0.2939,
      "step": 2905
    },
    {
      "epoch": 1.7506024096385542,
      "grad_norm": 0.5322251319885254,
      "learning_rate": 2.8125e-06,
      "loss": 0.2109,
      "step": 2906
    },
    {
      "epoch": 1.7512048192771084,
      "grad_norm": 0.6113383769989014,
      "learning_rate": 2.811746987951807e-06,
      "loss": 0.2634,
      "step": 2907
    },
    {
      "epoch": 1.7518072289156628,
      "grad_norm": 0.6993430852890015,
      "learning_rate": 2.810993975903615e-06,
      "loss": 0.2758,
      "step": 2908
    },
    {
      "epoch": 1.7524096385542167,
      "grad_norm": 0.637210488319397,
      "learning_rate": 2.810240963855422e-06,
      "loss": 0.2896,
      "step": 2909
    },
    {
      "epoch": 1.7530120481927711,
      "grad_norm": 0.598037838935852,
      "learning_rate": 2.809487951807229e-06,
      "loss": 0.2633,
      "step": 2910
    },
    {
      "epoch": 1.7536144578313253,
      "grad_norm": 0.5310599207878113,
      "learning_rate": 2.8087349397590365e-06,
      "loss": 0.2608,
      "step": 2911
    },
    {
      "epoch": 1.7542168674698795,
      "grad_norm": 0.5639597177505493,
      "learning_rate": 2.807981927710844e-06,
      "loss": 0.1962,
      "step": 2912
    },
    {
      "epoch": 1.7548192771084339,
      "grad_norm": 0.7251783609390259,
      "learning_rate": 2.8072289156626508e-06,
      "loss": 0.3276,
      "step": 2913
    },
    {
      "epoch": 1.7554216867469878,
      "grad_norm": 0.554513156414032,
      "learning_rate": 2.8064759036144577e-06,
      "loss": 0.261,
      "step": 2914
    },
    {
      "epoch": 1.7560240963855422,
      "grad_norm": 0.5265331268310547,
      "learning_rate": 2.8057228915662655e-06,
      "loss": 0.2163,
      "step": 2915
    },
    {
      "epoch": 1.7566265060240964,
      "grad_norm": 0.5752587914466858,
      "learning_rate": 2.8049698795180724e-06,
      "loss": 0.2411,
      "step": 2916
    },
    {
      "epoch": 1.7572289156626506,
      "grad_norm": 0.5916367173194885,
      "learning_rate": 2.80421686746988e-06,
      "loss": 0.3138,
      "step": 2917
    },
    {
      "epoch": 1.7578313253012048,
      "grad_norm": 0.5640520453453064,
      "learning_rate": 2.803463855421687e-06,
      "loss": 0.2711,
      "step": 2918
    },
    {
      "epoch": 1.758433734939759,
      "grad_norm": 0.6166675686836243,
      "learning_rate": 2.802710843373494e-06,
      "loss": 0.2487,
      "step": 2919
    },
    {
      "epoch": 1.7590361445783134,
      "grad_norm": 0.635948896408081,
      "learning_rate": 2.8019578313253014e-06,
      "loss": 0.2943,
      "step": 2920
    },
    {
      "epoch": 1.7596385542168673,
      "grad_norm": 0.578754723072052,
      "learning_rate": 2.8012048192771087e-06,
      "loss": 0.2123,
      "step": 2921
    },
    {
      "epoch": 1.7602409638554217,
      "grad_norm": 0.5929449796676636,
      "learning_rate": 2.800451807228916e-06,
      "loss": 0.1857,
      "step": 2922
    },
    {
      "epoch": 1.760843373493976,
      "grad_norm": 0.5508859157562256,
      "learning_rate": 2.799698795180723e-06,
      "loss": 0.2543,
      "step": 2923
    },
    {
      "epoch": 1.76144578313253,
      "grad_norm": 0.625353217124939,
      "learning_rate": 2.7989457831325308e-06,
      "loss": 0.2499,
      "step": 2924
    },
    {
      "epoch": 1.7620481927710845,
      "grad_norm": 0.6161813139915466,
      "learning_rate": 2.7981927710843377e-06,
      "loss": 0.282,
      "step": 2925
    },
    {
      "epoch": 1.7626506024096384,
      "grad_norm": 0.5405360460281372,
      "learning_rate": 2.7974397590361446e-06,
      "loss": 0.279,
      "step": 2926
    },
    {
      "epoch": 1.7632530120481928,
      "grad_norm": 1.1825624704360962,
      "learning_rate": 2.7966867469879524e-06,
      "loss": 0.2623,
      "step": 2927
    },
    {
      "epoch": 1.763855421686747,
      "grad_norm": 0.6339597105979919,
      "learning_rate": 2.7959337349397593e-06,
      "loss": 0.315,
      "step": 2928
    },
    {
      "epoch": 1.7644578313253012,
      "grad_norm": 0.7074953317642212,
      "learning_rate": 2.7951807228915666e-06,
      "loss": 0.312,
      "step": 2929
    },
    {
      "epoch": 1.7650602409638554,
      "grad_norm": 0.6546735167503357,
      "learning_rate": 2.7944277108433736e-06,
      "loss": 0.3281,
      "step": 2930
    },
    {
      "epoch": 1.7656626506024096,
      "grad_norm": 0.6195193529129028,
      "learning_rate": 2.793674698795181e-06,
      "loss": 0.2591,
      "step": 2931
    },
    {
      "epoch": 1.766265060240964,
      "grad_norm": 0.5539537072181702,
      "learning_rate": 2.7929216867469883e-06,
      "loss": 0.2263,
      "step": 2932
    },
    {
      "epoch": 1.766867469879518,
      "grad_norm": 0.5763875246047974,
      "learning_rate": 2.792168674698795e-06,
      "loss": 0.2377,
      "step": 2933
    },
    {
      "epoch": 1.7674698795180723,
      "grad_norm": 0.5234881043434143,
      "learning_rate": 2.791415662650603e-06,
      "loss": 0.2098,
      "step": 2934
    },
    {
      "epoch": 1.7680722891566265,
      "grad_norm": 0.6138724088668823,
      "learning_rate": 2.79066265060241e-06,
      "loss": 0.2744,
      "step": 2935
    },
    {
      "epoch": 1.7686746987951807,
      "grad_norm": 0.6717120409011841,
      "learning_rate": 2.7899096385542172e-06,
      "loss": 0.3305,
      "step": 2936
    },
    {
      "epoch": 1.769277108433735,
      "grad_norm": 0.6707942485809326,
      "learning_rate": 2.789156626506024e-06,
      "loss": 0.1909,
      "step": 2937
    },
    {
      "epoch": 1.769879518072289,
      "grad_norm": 0.5799897909164429,
      "learning_rate": 2.7884036144578315e-06,
      "loss": 0.2775,
      "step": 2938
    },
    {
      "epoch": 1.7704819277108435,
      "grad_norm": 0.5278369784355164,
      "learning_rate": 2.787650602409639e-06,
      "loss": 0.2274,
      "step": 2939
    },
    {
      "epoch": 1.7710843373493976,
      "grad_norm": 0.6221970915794373,
      "learning_rate": 2.7868975903614458e-06,
      "loss": 0.286,
      "step": 2940
    },
    {
      "epoch": 1.7716867469879518,
      "grad_norm": 0.5887879729270935,
      "learning_rate": 2.7861445783132536e-06,
      "loss": 0.2688,
      "step": 2941
    },
    {
      "epoch": 1.772289156626506,
      "grad_norm": 0.5775963068008423,
      "learning_rate": 2.7853915662650605e-06,
      "loss": 0.2279,
      "step": 2942
    },
    {
      "epoch": 1.7728915662650602,
      "grad_norm": 0.571781575679779,
      "learning_rate": 2.7846385542168674e-06,
      "loss": 0.2778,
      "step": 2943
    },
    {
      "epoch": 1.7734939759036146,
      "grad_norm": 0.5893726348876953,
      "learning_rate": 2.783885542168675e-06,
      "loss": 0.3159,
      "step": 2944
    },
    {
      "epoch": 1.7740963855421685,
      "grad_norm": 0.5826438665390015,
      "learning_rate": 2.783132530120482e-06,
      "loss": 0.268,
      "step": 2945
    },
    {
      "epoch": 1.774698795180723,
      "grad_norm": 0.6163573861122131,
      "learning_rate": 2.7823795180722895e-06,
      "loss": 0.2342,
      "step": 2946
    },
    {
      "epoch": 1.7753012048192771,
      "grad_norm": 0.6662957072257996,
      "learning_rate": 2.7816265060240964e-06,
      "loss": 0.2755,
      "step": 2947
    },
    {
      "epoch": 1.7759036144578313,
      "grad_norm": 0.6467824578285217,
      "learning_rate": 2.780873493975904e-06,
      "loss": 0.298,
      "step": 2948
    },
    {
      "epoch": 1.7765060240963857,
      "grad_norm": 0.5442202687263489,
      "learning_rate": 2.780120481927711e-06,
      "loss": 0.2582,
      "step": 2949
    },
    {
      "epoch": 1.7771084337349397,
      "grad_norm": 0.5875389575958252,
      "learning_rate": 2.779367469879518e-06,
      "loss": 0.2638,
      "step": 2950
    },
    {
      "epoch": 1.777710843373494,
      "grad_norm": 0.7238200902938843,
      "learning_rate": 2.7786144578313258e-06,
      "loss": 0.3677,
      "step": 2951
    },
    {
      "epoch": 1.7783132530120482,
      "grad_norm": 0.6272393465042114,
      "learning_rate": 2.7778614457831327e-06,
      "loss": 0.315,
      "step": 2952
    },
    {
      "epoch": 1.7789156626506024,
      "grad_norm": 0.6310514211654663,
      "learning_rate": 2.77710843373494e-06,
      "loss": 0.2433,
      "step": 2953
    },
    {
      "epoch": 1.7795180722891566,
      "grad_norm": 0.5890146493911743,
      "learning_rate": 2.7763554216867474e-06,
      "loss": 0.3022,
      "step": 2954
    },
    {
      "epoch": 1.7801204819277108,
      "grad_norm": 0.6341933012008667,
      "learning_rate": 2.7756024096385543e-06,
      "loss": 0.2994,
      "step": 2955
    },
    {
      "epoch": 1.7807228915662652,
      "grad_norm": 0.6338129639625549,
      "learning_rate": 2.7748493975903617e-06,
      "loss": 0.2856,
      "step": 2956
    },
    {
      "epoch": 1.7813253012048191,
      "grad_norm": 0.643894612789154,
      "learning_rate": 2.7740963855421686e-06,
      "loss": 0.3122,
      "step": 2957
    },
    {
      "epoch": 1.7819277108433735,
      "grad_norm": 0.5467098355293274,
      "learning_rate": 2.7733433734939764e-06,
      "loss": 0.2621,
      "step": 2958
    },
    {
      "epoch": 1.7825301204819277,
      "grad_norm": 0.6453173160552979,
      "learning_rate": 2.7725903614457833e-06,
      "loss": 0.2875,
      "step": 2959
    },
    {
      "epoch": 1.783132530120482,
      "grad_norm": 0.5711750388145447,
      "learning_rate": 2.771837349397591e-06,
      "loss": 0.2238,
      "step": 2960
    },
    {
      "epoch": 1.7837349397590363,
      "grad_norm": 0.6248502731323242,
      "learning_rate": 2.771084337349398e-06,
      "loss": 0.3049,
      "step": 2961
    },
    {
      "epoch": 1.7843373493975903,
      "grad_norm": 0.5973455905914307,
      "learning_rate": 2.770331325301205e-06,
      "loss": 0.2952,
      "step": 2962
    },
    {
      "epoch": 1.7849397590361447,
      "grad_norm": 0.5515391230583191,
      "learning_rate": 2.7695783132530123e-06,
      "loss": 0.2922,
      "step": 2963
    },
    {
      "epoch": 1.7855421686746988,
      "grad_norm": 0.5980784296989441,
      "learning_rate": 2.7688253012048196e-06,
      "loss": 0.3087,
      "step": 2964
    },
    {
      "epoch": 1.786144578313253,
      "grad_norm": 0.5606144666671753,
      "learning_rate": 2.768072289156627e-06,
      "loss": 0.244,
      "step": 2965
    },
    {
      "epoch": 1.7867469879518072,
      "grad_norm": 0.5738018751144409,
      "learning_rate": 2.767319277108434e-06,
      "loss": 0.2612,
      "step": 2966
    },
    {
      "epoch": 1.7873493975903614,
      "grad_norm": 0.5775852799415588,
      "learning_rate": 2.766566265060241e-06,
      "loss": 0.2859,
      "step": 2967
    },
    {
      "epoch": 1.7879518072289158,
      "grad_norm": 0.6206601858139038,
      "learning_rate": 2.7658132530120486e-06,
      "loss": 0.2882,
      "step": 2968
    },
    {
      "epoch": 1.7885542168674697,
      "grad_norm": 0.5629733204841614,
      "learning_rate": 2.7650602409638555e-06,
      "loss": 0.2206,
      "step": 2969
    },
    {
      "epoch": 1.7891566265060241,
      "grad_norm": 0.6328372955322266,
      "learning_rate": 2.764307228915663e-06,
      "loss": 0.2855,
      "step": 2970
    },
    {
      "epoch": 1.7897590361445783,
      "grad_norm": 0.5634071826934814,
      "learning_rate": 2.76355421686747e-06,
      "loss": 0.2214,
      "step": 2971
    },
    {
      "epoch": 1.7903614457831325,
      "grad_norm": 0.6768593788146973,
      "learning_rate": 2.7628012048192775e-06,
      "loss": 0.2685,
      "step": 2972
    },
    {
      "epoch": 1.790963855421687,
      "grad_norm": 0.5404052138328552,
      "learning_rate": 2.7620481927710845e-06,
      "loss": 0.2257,
      "step": 2973
    },
    {
      "epoch": 1.7915662650602409,
      "grad_norm": 0.6081833839416504,
      "learning_rate": 2.7612951807228914e-06,
      "loss": 0.2418,
      "step": 2974
    },
    {
      "epoch": 1.7921686746987953,
      "grad_norm": 0.5854887366294861,
      "learning_rate": 2.760542168674699e-06,
      "loss": 0.2444,
      "step": 2975
    },
    {
      "epoch": 1.7927710843373494,
      "grad_norm": 0.5887286067008972,
      "learning_rate": 2.759789156626506e-06,
      "loss": 0.2492,
      "step": 2976
    },
    {
      "epoch": 1.7933734939759036,
      "grad_norm": 0.570676863193512,
      "learning_rate": 2.759036144578314e-06,
      "loss": 0.2671,
      "step": 2977
    },
    {
      "epoch": 1.7939759036144578,
      "grad_norm": 0.5714876055717468,
      "learning_rate": 2.758283132530121e-06,
      "loss": 0.2121,
      "step": 2978
    },
    {
      "epoch": 1.794578313253012,
      "grad_norm": 0.6975621581077576,
      "learning_rate": 2.7575301204819277e-06,
      "loss": 0.2779,
      "step": 2979
    },
    {
      "epoch": 1.7951807228915664,
      "grad_norm": 0.564218282699585,
      "learning_rate": 2.756777108433735e-06,
      "loss": 0.208,
      "step": 2980
    },
    {
      "epoch": 1.7957831325301203,
      "grad_norm": 0.6235710978507996,
      "learning_rate": 2.7560240963855424e-06,
      "loss": 0.352,
      "step": 2981
    },
    {
      "epoch": 1.7963855421686747,
      "grad_norm": 0.4935593008995056,
      "learning_rate": 2.7552710843373498e-06,
      "loss": 0.2266,
      "step": 2982
    },
    {
      "epoch": 1.796987951807229,
      "grad_norm": 0.5687627792358398,
      "learning_rate": 2.7545180722891567e-06,
      "loss": 0.2902,
      "step": 2983
    },
    {
      "epoch": 1.797590361445783,
      "grad_norm": 0.6054610013961792,
      "learning_rate": 2.7537650602409645e-06,
      "loss": 0.2524,
      "step": 2984
    },
    {
      "epoch": 1.7981927710843375,
      "grad_norm": 0.5716139674186707,
      "learning_rate": 2.7530120481927714e-06,
      "loss": 0.2668,
      "step": 2985
    },
    {
      "epoch": 1.7987951807228915,
      "grad_norm": 0.5467560291290283,
      "learning_rate": 2.7522590361445783e-06,
      "loss": 0.2317,
      "step": 2986
    },
    {
      "epoch": 1.7993975903614459,
      "grad_norm": 0.5378908514976501,
      "learning_rate": 2.751506024096386e-06,
      "loss": 0.2232,
      "step": 2987
    },
    {
      "epoch": 1.8,
      "grad_norm": 0.6013126969337463,
      "learning_rate": 2.750753012048193e-06,
      "loss": 0.2207,
      "step": 2988
    },
    {
      "epoch": 1.8006024096385542,
      "grad_norm": 0.5603404641151428,
      "learning_rate": 2.7500000000000004e-06,
      "loss": 0.2796,
      "step": 2989
    },
    {
      "epoch": 1.8012048192771084,
      "grad_norm": 0.539723813533783,
      "learning_rate": 2.7492469879518073e-06,
      "loss": 0.2409,
      "step": 2990
    },
    {
      "epoch": 1.8018072289156626,
      "grad_norm": 0.5187844038009644,
      "learning_rate": 2.7484939759036146e-06,
      "loss": 0.2323,
      "step": 2991
    },
    {
      "epoch": 1.802409638554217,
      "grad_norm": 0.6993266344070435,
      "learning_rate": 2.747740963855422e-06,
      "loss": 0.2465,
      "step": 2992
    },
    {
      "epoch": 1.803012048192771,
      "grad_norm": NaN,
      "learning_rate": 2.747740963855422e-06,
      "loss": 0.3348,
      "step": 2993
    },
    {
      "epoch": 1.8036144578313253,
      "grad_norm": 0.539157509803772,
      "learning_rate": 2.746987951807229e-06,
      "loss": 0.3075,
      "step": 2994
    },
    {
      "epoch": 1.8042168674698795,
      "grad_norm": 0.6320173144340515,
      "learning_rate": 2.7462349397590367e-06,
      "loss": 0.2644,
      "step": 2995
    },
    {
      "epoch": 1.8048192771084337,
      "grad_norm": 0.7263595461845398,
      "learning_rate": 2.7454819277108436e-06,
      "loss": 0.316,
      "step": 2996
    },
    {
      "epoch": 1.805421686746988,
      "grad_norm": 0.6975674629211426,
      "learning_rate": 2.744728915662651e-06,
      "loss": 0.3293,
      "step": 2997
    },
    {
      "epoch": 1.806024096385542,
      "grad_norm": 0.5265007615089417,
      "learning_rate": 2.7439759036144583e-06,
      "loss": 0.2746,
      "step": 2998
    },
    {
      "epoch": 1.8066265060240965,
      "grad_norm": 0.662276029586792,
      "learning_rate": 2.7432228915662652e-06,
      "loss": 0.3047,
      "step": 2999
    },
    {
      "epoch": 1.8072289156626506,
      "grad_norm": 0.5335251688957214,
      "learning_rate": 2.7424698795180726e-06,
      "loss": 0.2804,
      "step": 3000
    },
    {
      "epoch": 1.8078313253012048,
      "grad_norm": 0.6086839437484741,
      "learning_rate": 2.7417168674698795e-06,
      "loss": 0.2441,
      "step": 3001
    },
    {
      "epoch": 1.808433734939759,
      "grad_norm": 0.6174079179763794,
      "learning_rate": 2.7409638554216873e-06,
      "loss": 0.3003,
      "step": 3002
    },
    {
      "epoch": 1.8090361445783132,
      "grad_norm": 0.5336986184120178,
      "learning_rate": 2.740210843373494e-06,
      "loss": 0.2786,
      "step": 3003
    },
    {
      "epoch": 1.8096385542168676,
      "grad_norm": 0.8100552558898926,
      "learning_rate": 2.739457831325301e-06,
      "loss": 0.3048,
      "step": 3004
    },
    {
      "epoch": 1.8102409638554215,
      "grad_norm": 0.6125314831733704,
      "learning_rate": 2.738704819277109e-06,
      "loss": 0.2677,
      "step": 3005
    },
    {
      "epoch": 1.810843373493976,
      "grad_norm": 0.7147898077964783,
      "learning_rate": 2.737951807228916e-06,
      "loss": 0.3117,
      "step": 3006
    },
    {
      "epoch": 1.8114457831325301,
      "grad_norm": 0.6361804604530334,
      "learning_rate": 2.737198795180723e-06,
      "loss": 0.2781,
      "step": 3007
    },
    {
      "epoch": 1.8120481927710843,
      "grad_norm": 0.5985737442970276,
      "learning_rate": 2.73644578313253e-06,
      "loss": 0.2582,
      "step": 3008
    },
    {
      "epoch": 1.8126506024096387,
      "grad_norm": 0.5506425499916077,
      "learning_rate": 2.735692771084338e-06,
      "loss": 0.2658,
      "step": 3009
    },
    {
      "epoch": 1.8132530120481927,
      "grad_norm": 0.5958214998245239,
      "learning_rate": 2.7349397590361448e-06,
      "loss": 0.2169,
      "step": 3010
    },
    {
      "epoch": 1.813855421686747,
      "grad_norm": 0.5470455884933472,
      "learning_rate": 2.7341867469879517e-06,
      "loss": 0.2686,
      "step": 3011
    },
    {
      "epoch": 1.8144578313253013,
      "grad_norm": 0.5654826164245605,
      "learning_rate": 2.7334337349397595e-06,
      "loss": 0.2142,
      "step": 3012
    },
    {
      "epoch": 1.8150602409638554,
      "grad_norm": 0.5430563688278198,
      "learning_rate": 2.7326807228915664e-06,
      "loss": 0.2422,
      "step": 3013
    },
    {
      "epoch": 1.8156626506024096,
      "grad_norm": 1.8496254682540894,
      "learning_rate": 2.7319277108433737e-06,
      "loss": 0.2594,
      "step": 3014
    },
    {
      "epoch": 1.8162650602409638,
      "grad_norm": 0.575400173664093,
      "learning_rate": 2.731174698795181e-06,
      "loss": 0.2677,
      "step": 3015
    },
    {
      "epoch": 1.8168674698795182,
      "grad_norm": 0.6745866537094116,
      "learning_rate": 2.730421686746988e-06,
      "loss": 0.2925,
      "step": 3016
    },
    {
      "epoch": 1.8174698795180722,
      "grad_norm": 0.5166099071502686,
      "learning_rate": 2.7296686746987954e-06,
      "loss": 0.2467,
      "step": 3017
    },
    {
      "epoch": 1.8180722891566266,
      "grad_norm": 0.542449951171875,
      "learning_rate": 2.7289156626506023e-06,
      "loss": 0.271,
      "step": 3018
    },
    {
      "epoch": 1.8186746987951807,
      "grad_norm": 0.5726538300514221,
      "learning_rate": 2.72816265060241e-06,
      "loss": 0.2588,
      "step": 3019
    },
    {
      "epoch": 1.819277108433735,
      "grad_norm": 0.5988814234733582,
      "learning_rate": 2.727409638554217e-06,
      "loss": 0.2771,
      "step": 3020
    },
    {
      "epoch": 1.8198795180722893,
      "grad_norm": 0.5877054929733276,
      "learning_rate": 2.7266566265060248e-06,
      "loss": 0.2824,
      "step": 3021
    },
    {
      "epoch": 1.8204819277108433,
      "grad_norm": 0.6391502022743225,
      "learning_rate": 2.7259036144578317e-06,
      "loss": 0.2923,
      "step": 3022
    },
    {
      "epoch": 1.8210843373493977,
      "grad_norm": 0.5950971841812134,
      "learning_rate": 2.7251506024096386e-06,
      "loss": 0.2267,
      "step": 3023
    },
    {
      "epoch": 1.8216867469879519,
      "grad_norm": 0.5505557656288147,
      "learning_rate": 2.724397590361446e-06,
      "loss": 0.2796,
      "step": 3024
    },
    {
      "epoch": 1.822289156626506,
      "grad_norm": 0.7218191027641296,
      "learning_rate": 2.7236445783132533e-06,
      "loss": 0.3409,
      "step": 3025
    },
    {
      "epoch": 1.8228915662650602,
      "grad_norm": 0.6299192309379578,
      "learning_rate": 2.7228915662650607e-06,
      "loss": 0.2874,
      "step": 3026
    },
    {
      "epoch": 1.8234939759036144,
      "grad_norm": 0.6974181532859802,
      "learning_rate": 2.7221385542168676e-06,
      "loss": 0.2482,
      "step": 3027
    },
    {
      "epoch": 1.8240963855421688,
      "grad_norm": 0.5669901371002197,
      "learning_rate": 2.7213855421686745e-06,
      "loss": 0.2609,
      "step": 3028
    },
    {
      "epoch": 1.8246987951807228,
      "grad_norm": 0.5694848895072937,
      "learning_rate": 2.7206325301204823e-06,
      "loss": 0.2745,
      "step": 3029
    },
    {
      "epoch": 1.8253012048192772,
      "grad_norm": 0.6530871987342834,
      "learning_rate": 2.719879518072289e-06,
      "loss": 0.2952,
      "step": 3030
    },
    {
      "epoch": 1.8259036144578313,
      "grad_norm": 0.5770267844200134,
      "learning_rate": 2.719126506024097e-06,
      "loss": 0.2433,
      "step": 3031
    },
    {
      "epoch": 1.8265060240963855,
      "grad_norm": 0.6124784350395203,
      "learning_rate": 2.718373493975904e-06,
      "loss": 0.2386,
      "step": 3032
    },
    {
      "epoch": 1.82710843373494,
      "grad_norm": 0.6898939609527588,
      "learning_rate": 2.7176204819277113e-06,
      "loss": 0.2654,
      "step": 3033
    },
    {
      "epoch": 1.8277108433734939,
      "grad_norm": 0.5937497019767761,
      "learning_rate": 2.716867469879518e-06,
      "loss": 0.2917,
      "step": 3034
    },
    {
      "epoch": 1.8283132530120483,
      "grad_norm": 0.5621161460876465,
      "learning_rate": 2.7161144578313255e-06,
      "loss": 0.2529,
      "step": 3035
    },
    {
      "epoch": 1.8289156626506025,
      "grad_norm": 0.5916843414306641,
      "learning_rate": 2.715361445783133e-06,
      "loss": 0.248,
      "step": 3036
    },
    {
      "epoch": 1.8295180722891566,
      "grad_norm": 0.6092104911804199,
      "learning_rate": 2.71460843373494e-06,
      "loss": 0.2867,
      "step": 3037
    },
    {
      "epoch": 1.8301204819277108,
      "grad_norm": 0.6833736896514893,
      "learning_rate": 2.7138554216867476e-06,
      "loss": 0.2806,
      "step": 3038
    },
    {
      "epoch": 1.830722891566265,
      "grad_norm": 0.5583386421203613,
      "learning_rate": 2.7131024096385545e-06,
      "loss": 0.3087,
      "step": 3039
    },
    {
      "epoch": 1.8313253012048194,
      "grad_norm": 0.5411962866783142,
      "learning_rate": 2.7123493975903614e-06,
      "loss": 0.248,
      "step": 3040
    },
    {
      "epoch": 1.8319277108433734,
      "grad_norm": 0.7242968082427979,
      "learning_rate": 2.7115963855421688e-06,
      "loss": 0.2796,
      "step": 3041
    },
    {
      "epoch": 1.8325301204819278,
      "grad_norm": 0.6629630923271179,
      "learning_rate": 2.710843373493976e-06,
      "loss": 0.2803,
      "step": 3042
    },
    {
      "epoch": 1.833132530120482,
      "grad_norm": 0.5003069639205933,
      "learning_rate": 2.7100903614457835e-06,
      "loss": 0.2412,
      "step": 3043
    },
    {
      "epoch": 1.8337349397590361,
      "grad_norm": 0.6088835597038269,
      "learning_rate": 2.7093373493975904e-06,
      "loss": 0.2122,
      "step": 3044
    },
    {
      "epoch": 1.8343373493975905,
      "grad_norm": 0.5968723297119141,
      "learning_rate": 2.708584337349398e-06,
      "loss": 0.2478,
      "step": 3045
    },
    {
      "epoch": 1.8349397590361445,
      "grad_norm": 0.5876049995422363,
      "learning_rate": 2.707831325301205e-06,
      "loss": 0.2851,
      "step": 3046
    },
    {
      "epoch": 1.8355421686746989,
      "grad_norm": 0.7132875919342041,
      "learning_rate": 2.707078313253012e-06,
      "loss": 0.3245,
      "step": 3047
    },
    {
      "epoch": 1.836144578313253,
      "grad_norm": 0.5340571999549866,
      "learning_rate": 2.7063253012048198e-06,
      "loss": 0.2423,
      "step": 3048
    },
    {
      "epoch": 1.8367469879518072,
      "grad_norm": 0.6134470105171204,
      "learning_rate": 2.7055722891566267e-06,
      "loss": 0.3186,
      "step": 3049
    },
    {
      "epoch": 1.8373493975903614,
      "grad_norm": 0.48962995409965515,
      "learning_rate": 2.704819277108434e-06,
      "loss": 0.2184,
      "step": 3050
    },
    {
      "epoch": 1.8379518072289156,
      "grad_norm": 0.5165354609489441,
      "learning_rate": 2.704066265060241e-06,
      "loss": 0.21,
      "step": 3051
    },
    {
      "epoch": 1.83855421686747,
      "grad_norm": 0.6478949189186096,
      "learning_rate": 2.7033132530120483e-06,
      "loss": 0.2463,
      "step": 3052
    },
    {
      "epoch": 1.839156626506024,
      "grad_norm": 0.6089721918106079,
      "learning_rate": 2.7025602409638557e-06,
      "loss": 0.2858,
      "step": 3053
    },
    {
      "epoch": 1.8397590361445784,
      "grad_norm": 0.5804002285003662,
      "learning_rate": 2.7018072289156626e-06,
      "loss": 0.2968,
      "step": 3054
    },
    {
      "epoch": 1.8403614457831325,
      "grad_norm": 0.5921035408973694,
      "learning_rate": 2.7010542168674704e-06,
      "loss": 0.3149,
      "step": 3055
    },
    {
      "epoch": 1.8409638554216867,
      "grad_norm": 0.5241014957427979,
      "learning_rate": 2.7003012048192773e-06,
      "loss": 0.2176,
      "step": 3056
    },
    {
      "epoch": 1.8415662650602411,
      "grad_norm": 0.605356752872467,
      "learning_rate": 2.6995481927710846e-06,
      "loss": 0.2731,
      "step": 3057
    },
    {
      "epoch": 1.842168674698795,
      "grad_norm": 0.5796985626220703,
      "learning_rate": 2.698795180722892e-06,
      "loss": 0.223,
      "step": 3058
    },
    {
      "epoch": 1.8427710843373495,
      "grad_norm": 0.6425116062164307,
      "learning_rate": 2.698042168674699e-06,
      "loss": 0.2694,
      "step": 3059
    },
    {
      "epoch": 1.8433734939759037,
      "grad_norm": 0.6206061840057373,
      "learning_rate": 2.6972891566265063e-06,
      "loss": 0.2836,
      "step": 3060
    },
    {
      "epoch": 1.8439759036144578,
      "grad_norm": 0.6779822707176208,
      "learning_rate": 2.696536144578313e-06,
      "loss": 0.3348,
      "step": 3061
    },
    {
      "epoch": 1.844578313253012,
      "grad_norm": 0.6275926232337952,
      "learning_rate": 2.695783132530121e-06,
      "loss": 0.279,
      "step": 3062
    },
    {
      "epoch": 1.8451807228915662,
      "grad_norm": 0.531660258769989,
      "learning_rate": 2.695030120481928e-06,
      "loss": 0.2544,
      "step": 3063
    },
    {
      "epoch": 1.8457831325301206,
      "grad_norm": 0.6085386276245117,
      "learning_rate": 2.694277108433735e-06,
      "loss": 0.2913,
      "step": 3064
    },
    {
      "epoch": 1.8463855421686746,
      "grad_norm": 0.5050563216209412,
      "learning_rate": 2.6935240963855426e-06,
      "loss": 0.2766,
      "step": 3065
    },
    {
      "epoch": 1.846987951807229,
      "grad_norm": 0.5541330575942993,
      "learning_rate": 2.6927710843373495e-06,
      "loss": 0.2638,
      "step": 3066
    },
    {
      "epoch": 1.8475903614457831,
      "grad_norm": 0.5938383340835571,
      "learning_rate": 2.692018072289157e-06,
      "loss": 0.2849,
      "step": 3067
    },
    {
      "epoch": 1.8481927710843373,
      "grad_norm": 0.5773007273674011,
      "learning_rate": 2.691265060240964e-06,
      "loss": 0.2406,
      "step": 3068
    },
    {
      "epoch": 1.8487951807228917,
      "grad_norm": 0.5823017954826355,
      "learning_rate": 2.6905120481927716e-06,
      "loss": 0.28,
      "step": 3069
    },
    {
      "epoch": 1.8493975903614457,
      "grad_norm": 0.6181334257125854,
      "learning_rate": 2.6897590361445785e-06,
      "loss": 0.2966,
      "step": 3070
    },
    {
      "epoch": 1.85,
      "grad_norm": 0.6048548221588135,
      "learning_rate": 2.6890060240963854e-06,
      "loss": 0.2344,
      "step": 3071
    },
    {
      "epoch": 1.8506024096385543,
      "grad_norm": 0.6057931184768677,
      "learning_rate": 2.688253012048193e-06,
      "loss": 0.2724,
      "step": 3072
    },
    {
      "epoch": 1.8512048192771084,
      "grad_norm": 0.5120041966438293,
      "learning_rate": 2.6875e-06,
      "loss": 0.2321,
      "step": 3073
    },
    {
      "epoch": 1.8518072289156626,
      "grad_norm": 0.6132620573043823,
      "learning_rate": 2.6867469879518075e-06,
      "loss": 0.3087,
      "step": 3074
    },
    {
      "epoch": 1.8524096385542168,
      "grad_norm": 0.5583551526069641,
      "learning_rate": 2.685993975903615e-06,
      "loss": 0.2134,
      "step": 3075
    },
    {
      "epoch": 1.8530120481927712,
      "grad_norm": 0.7036951780319214,
      "learning_rate": 2.6852409638554217e-06,
      "loss": 0.2978,
      "step": 3076
    },
    {
      "epoch": 1.8536144578313252,
      "grad_norm": 0.49800872802734375,
      "learning_rate": 2.684487951807229e-06,
      "loss": 0.2436,
      "step": 3077
    },
    {
      "epoch": 1.8542168674698796,
      "grad_norm": 0.6591835618019104,
      "learning_rate": 2.683734939759036e-06,
      "loss": 0.2605,
      "step": 3078
    },
    {
      "epoch": 1.8548192771084338,
      "grad_norm": 0.5769891142845154,
      "learning_rate": 2.6829819277108438e-06,
      "loss": 0.2523,
      "step": 3079
    },
    {
      "epoch": 1.855421686746988,
      "grad_norm": 0.6199761033058167,
      "learning_rate": 2.6822289156626507e-06,
      "loss": 0.3058,
      "step": 3080
    },
    {
      "epoch": 1.8560240963855423,
      "grad_norm": 0.5622718930244446,
      "learning_rate": 2.6814759036144585e-06,
      "loss": 0.2319,
      "step": 3081
    },
    {
      "epoch": 1.8566265060240963,
      "grad_norm": 0.5377212166786194,
      "learning_rate": 2.6807228915662654e-06,
      "loss": 0.2456,
      "step": 3082
    },
    {
      "epoch": 1.8572289156626507,
      "grad_norm": 0.5643188953399658,
      "learning_rate": 2.6799698795180723e-06,
      "loss": 0.2433,
      "step": 3083
    },
    {
      "epoch": 1.8578313253012049,
      "grad_norm": 0.5845944881439209,
      "learning_rate": 2.6792168674698797e-06,
      "loss": 0.2646,
      "step": 3084
    },
    {
      "epoch": 1.858433734939759,
      "grad_norm": 0.5688101053237915,
      "learning_rate": 2.678463855421687e-06,
      "loss": 0.2615,
      "step": 3085
    },
    {
      "epoch": 1.8590361445783132,
      "grad_norm": 0.5586199164390564,
      "learning_rate": 2.6777108433734944e-06,
      "loss": 0.2673,
      "step": 3086
    },
    {
      "epoch": 1.8596385542168674,
      "grad_norm": 0.5428382158279419,
      "learning_rate": 2.6769578313253013e-06,
      "loss": 0.273,
      "step": 3087
    },
    {
      "epoch": 1.8602409638554218,
      "grad_norm": 0.5469577312469482,
      "learning_rate": 2.676204819277108e-06,
      "loss": 0.2504,
      "step": 3088
    },
    {
      "epoch": 1.8608433734939758,
      "grad_norm": 0.8732976913452148,
      "learning_rate": 2.675451807228916e-06,
      "loss": 0.2955,
      "step": 3089
    },
    {
      "epoch": 1.8614457831325302,
      "grad_norm": 0.5511825680732727,
      "learning_rate": 2.674698795180723e-06,
      "loss": 0.2714,
      "step": 3090
    },
    {
      "epoch": 1.8620481927710844,
      "grad_norm": 0.6740285158157349,
      "learning_rate": 2.6739457831325307e-06,
      "loss": 0.2962,
      "step": 3091
    },
    {
      "epoch": 1.8626506024096385,
      "grad_norm": 0.7473270297050476,
      "learning_rate": 2.6731927710843376e-06,
      "loss": 0.2449,
      "step": 3092
    },
    {
      "epoch": 1.863253012048193,
      "grad_norm": 0.674853503704071,
      "learning_rate": 2.672439759036145e-06,
      "loss": 0.2522,
      "step": 3093
    },
    {
      "epoch": 1.863855421686747,
      "grad_norm": 0.5537087321281433,
      "learning_rate": 2.671686746987952e-06,
      "loss": 0.2416,
      "step": 3094
    },
    {
      "epoch": 1.8644578313253013,
      "grad_norm": 0.6165897250175476,
      "learning_rate": 2.6709337349397592e-06,
      "loss": 0.2992,
      "step": 3095
    },
    {
      "epoch": 1.8650602409638555,
      "grad_norm": 0.6904845237731934,
      "learning_rate": 2.6701807228915666e-06,
      "loss": 0.3125,
      "step": 3096
    },
    {
      "epoch": 1.8656626506024097,
      "grad_norm": 0.5270583033561707,
      "learning_rate": 2.6694277108433735e-06,
      "loss": 0.2883,
      "step": 3097
    },
    {
      "epoch": 1.8662650602409638,
      "grad_norm": 0.6144618391990662,
      "learning_rate": 2.6686746987951813e-06,
      "loss": 0.293,
      "step": 3098
    },
    {
      "epoch": 1.866867469879518,
      "grad_norm": 0.5848511457443237,
      "learning_rate": 2.667921686746988e-06,
      "loss": 0.2627,
      "step": 3099
    },
    {
      "epoch": 1.8674698795180724,
      "grad_norm": 0.5827662348747253,
      "learning_rate": 2.667168674698795e-06,
      "loss": 0.3116,
      "step": 3100
    },
    {
      "epoch": 1.8680722891566264,
      "grad_norm": 0.5482858419418335,
      "learning_rate": 2.666415662650603e-06,
      "loss": 0.2114,
      "step": 3101
    },
    {
      "epoch": 1.8686746987951808,
      "grad_norm": 0.5860644578933716,
      "learning_rate": 2.66566265060241e-06,
      "loss": 0.3323,
      "step": 3102
    },
    {
      "epoch": 1.869277108433735,
      "grad_norm": 0.5590407848358154,
      "learning_rate": 2.664909638554217e-06,
      "loss": 0.2195,
      "step": 3103
    },
    {
      "epoch": 1.8698795180722891,
      "grad_norm": 0.5366846919059753,
      "learning_rate": 2.664156626506024e-06,
      "loss": 0.2222,
      "step": 3104
    },
    {
      "epoch": 1.8704819277108435,
      "grad_norm": 0.5557202100753784,
      "learning_rate": 2.663403614457832e-06,
      "loss": 0.2284,
      "step": 3105
    },
    {
      "epoch": 1.8710843373493975,
      "grad_norm": 0.5828529596328735,
      "learning_rate": 2.662650602409639e-06,
      "loss": 0.2483,
      "step": 3106
    },
    {
      "epoch": 1.871686746987952,
      "grad_norm": 0.6216326355934143,
      "learning_rate": 2.6618975903614457e-06,
      "loss": 0.3039,
      "step": 3107
    },
    {
      "epoch": 1.872289156626506,
      "grad_norm": 0.6162299513816833,
      "learning_rate": 2.6611445783132535e-06,
      "loss": 0.2824,
      "step": 3108
    },
    {
      "epoch": 1.8728915662650603,
      "grad_norm": 0.5471111536026001,
      "learning_rate": 2.6603915662650604e-06,
      "loss": 0.2407,
      "step": 3109
    },
    {
      "epoch": 1.8734939759036144,
      "grad_norm": 0.7025694847106934,
      "learning_rate": 2.6596385542168678e-06,
      "loss": 0.3445,
      "step": 3110
    },
    {
      "epoch": 1.8740963855421686,
      "grad_norm": 0.6653546690940857,
      "learning_rate": 2.6588855421686747e-06,
      "loss": 0.2478,
      "step": 3111
    },
    {
      "epoch": 1.874698795180723,
      "grad_norm": 0.5313456058502197,
      "learning_rate": 2.658132530120482e-06,
      "loss": 0.2799,
      "step": 3112
    },
    {
      "epoch": 1.875301204819277,
      "grad_norm": 0.625231146812439,
      "learning_rate": 2.6573795180722894e-06,
      "loss": 0.2347,
      "step": 3113
    },
    {
      "epoch": 1.8759036144578314,
      "grad_norm": 0.5495824217796326,
      "learning_rate": 2.6566265060240963e-06,
      "loss": 0.2661,
      "step": 3114
    },
    {
      "epoch": 1.8765060240963856,
      "grad_norm": 0.6789343953132629,
      "learning_rate": 2.655873493975904e-06,
      "loss": 0.3092,
      "step": 3115
    },
    {
      "epoch": 1.8771084337349397,
      "grad_norm": 0.5633417963981628,
      "learning_rate": 2.655120481927711e-06,
      "loss": 0.2336,
      "step": 3116
    },
    {
      "epoch": 1.877710843373494,
      "grad_norm": 0.5207986831665039,
      "learning_rate": 2.6543674698795184e-06,
      "loss": 0.2621,
      "step": 3117
    },
    {
      "epoch": 1.878313253012048,
      "grad_norm": 0.5891199111938477,
      "learning_rate": 2.6536144578313257e-06,
      "loss": 0.2182,
      "step": 3118
    },
    {
      "epoch": 1.8789156626506025,
      "grad_norm": 0.48434215784072876,
      "learning_rate": 2.6528614457831326e-06,
      "loss": 0.2172,
      "step": 3119
    },
    {
      "epoch": 1.8795180722891565,
      "grad_norm": 0.5944862365722656,
      "learning_rate": 2.65210843373494e-06,
      "loss": 0.3246,
      "step": 3120
    },
    {
      "epoch": 1.8801204819277109,
      "grad_norm": 0.683096170425415,
      "learning_rate": 2.651355421686747e-06,
      "loss": 0.2804,
      "step": 3121
    },
    {
      "epoch": 1.880722891566265,
      "grad_norm": 0.6016747951507568,
      "learning_rate": 2.6506024096385547e-06,
      "loss": 0.2805,
      "step": 3122
    },
    {
      "epoch": 1.8813253012048192,
      "grad_norm": 0.6488305926322937,
      "learning_rate": 2.6498493975903616e-06,
      "loss": 0.2974,
      "step": 3123
    },
    {
      "epoch": 1.8819277108433736,
      "grad_norm": 0.5746429562568665,
      "learning_rate": 2.6490963855421685e-06,
      "loss": 0.2684,
      "step": 3124
    },
    {
      "epoch": 1.8825301204819276,
      "grad_norm": 0.5878287553787231,
      "learning_rate": 2.6483433734939763e-06,
      "loss": 0.3309,
      "step": 3125
    },
    {
      "epoch": 1.883132530120482,
      "grad_norm": 0.6559327840805054,
      "learning_rate": 2.6475903614457832e-06,
      "loss": 0.2974,
      "step": 3126
    },
    {
      "epoch": 1.8837349397590362,
      "grad_norm": 0.6638343334197998,
      "learning_rate": 2.6468373493975906e-06,
      "loss": 0.2587,
      "step": 3127
    },
    {
      "epoch": 1.8843373493975903,
      "grad_norm": 0.5549041032791138,
      "learning_rate": 2.646084337349398e-06,
      "loss": 0.2496,
      "step": 3128
    },
    {
      "epoch": 1.8849397590361445,
      "grad_norm": 0.5651376247406006,
      "learning_rate": 2.6453313253012053e-06,
      "loss": 0.2429,
      "step": 3129
    },
    {
      "epoch": 1.8855421686746987,
      "grad_norm": 0.7016350030899048,
      "learning_rate": 2.644578313253012e-06,
      "loss": 0.3393,
      "step": 3130
    },
    {
      "epoch": 1.886144578313253,
      "grad_norm": 0.5901877284049988,
      "learning_rate": 2.643825301204819e-06,
      "loss": 0.2473,
      "step": 3131
    },
    {
      "epoch": 1.886746987951807,
      "grad_norm": 0.6576697826385498,
      "learning_rate": 2.643072289156627e-06,
      "loss": 0.2964,
      "step": 3132
    },
    {
      "epoch": 1.8873493975903615,
      "grad_norm": 0.6232914328575134,
      "learning_rate": 2.642319277108434e-06,
      "loss": 0.2913,
      "step": 3133
    },
    {
      "epoch": 1.8879518072289156,
      "grad_norm": 0.553104817867279,
      "learning_rate": 2.6415662650602416e-06,
      "loss": 0.2785,
      "step": 3134
    },
    {
      "epoch": 1.8885542168674698,
      "grad_norm": 0.6673808097839355,
      "learning_rate": 2.6408132530120485e-06,
      "loss": 0.2881,
      "step": 3135
    },
    {
      "epoch": 1.8891566265060242,
      "grad_norm": 0.5977755188941956,
      "learning_rate": 2.6400602409638554e-06,
      "loss": 0.2974,
      "step": 3136
    },
    {
      "epoch": 1.8897590361445782,
      "grad_norm": 0.6222184300422668,
      "learning_rate": 2.6393072289156628e-06,
      "loss": 0.29,
      "step": 3137
    },
    {
      "epoch": 1.8903614457831326,
      "grad_norm": 0.5484399199485779,
      "learning_rate": 2.63855421686747e-06,
      "loss": 0.253,
      "step": 3138
    },
    {
      "epoch": 1.8909638554216868,
      "grad_norm": 0.5397223234176636,
      "learning_rate": 2.6378012048192775e-06,
      "loss": 0.2212,
      "step": 3139
    },
    {
      "epoch": 1.891566265060241,
      "grad_norm": 0.6263642907142639,
      "learning_rate": 2.6370481927710844e-06,
      "loss": 0.3243,
      "step": 3140
    },
    {
      "epoch": 1.8921686746987951,
      "grad_norm": 0.5790056586265564,
      "learning_rate": 2.636295180722892e-06,
      "loss": 0.2716,
      "step": 3141
    },
    {
      "epoch": 1.8927710843373493,
      "grad_norm": 0.6141536235809326,
      "learning_rate": 2.635542168674699e-06,
      "loss": 0.2545,
      "step": 3142
    },
    {
      "epoch": 1.8933734939759037,
      "grad_norm": 0.6142562031745911,
      "learning_rate": 2.634789156626506e-06,
      "loss": 0.252,
      "step": 3143
    },
    {
      "epoch": 1.8939759036144577,
      "grad_norm": 0.6925948858261108,
      "learning_rate": 2.634036144578314e-06,
      "loss": 0.2258,
      "step": 3144
    },
    {
      "epoch": 1.894578313253012,
      "grad_norm": 0.5946621894836426,
      "learning_rate": 2.6332831325301207e-06,
      "loss": 0.3058,
      "step": 3145
    },
    {
      "epoch": 1.8951807228915662,
      "grad_norm": 0.5376235246658325,
      "learning_rate": 2.632530120481928e-06,
      "loss": 0.2438,
      "step": 3146
    },
    {
      "epoch": 1.8957831325301204,
      "grad_norm": 0.5418663620948792,
      "learning_rate": 2.631777108433735e-06,
      "loss": 0.2193,
      "step": 3147
    },
    {
      "epoch": 1.8963855421686748,
      "grad_norm": 0.6199110746383667,
      "learning_rate": 2.631024096385542e-06,
      "loss": 0.2515,
      "step": 3148
    },
    {
      "epoch": 1.8969879518072288,
      "grad_norm": 0.7373347282409668,
      "learning_rate": 2.6302710843373497e-06,
      "loss": 0.3553,
      "step": 3149
    },
    {
      "epoch": 1.8975903614457832,
      "grad_norm": 0.6347373127937317,
      "learning_rate": 2.6295180722891566e-06,
      "loss": 0.2764,
      "step": 3150
    },
    {
      "epoch": 1.8981927710843374,
      "grad_norm": 0.532427966594696,
      "learning_rate": 2.6287650602409644e-06,
      "loss": 0.1987,
      "step": 3151
    },
    {
      "epoch": 1.8987951807228916,
      "grad_norm": 0.5500121712684631,
      "learning_rate": 2.6280120481927713e-06,
      "loss": 0.2794,
      "step": 3152
    },
    {
      "epoch": 1.8993975903614457,
      "grad_norm": 0.5728650689125061,
      "learning_rate": 2.6272590361445787e-06,
      "loss": 0.2833,
      "step": 3153
    },
    {
      "epoch": 1.9,
      "grad_norm": 0.5659545660018921,
      "learning_rate": 2.6265060240963856e-06,
      "loss": 0.2853,
      "step": 3154
    },
    {
      "epoch": 1.9006024096385543,
      "grad_norm": 0.5873114466667175,
      "learning_rate": 2.625753012048193e-06,
      "loss": 0.2878,
      "step": 3155
    },
    {
      "epoch": 1.9012048192771083,
      "grad_norm": 0.5761933922767639,
      "learning_rate": 2.6250000000000003e-06,
      "loss": 0.2467,
      "step": 3156
    },
    {
      "epoch": 1.9018072289156627,
      "grad_norm": 0.5829206109046936,
      "learning_rate": 2.624246987951807e-06,
      "loss": 0.2791,
      "step": 3157
    },
    {
      "epoch": 1.9024096385542169,
      "grad_norm": 0.5500309467315674,
      "learning_rate": 2.623493975903615e-06,
      "loss": 0.3109,
      "step": 3158
    },
    {
      "epoch": 1.903012048192771,
      "grad_norm": 0.6796573400497437,
      "learning_rate": 2.622740963855422e-06,
      "loss": 0.2898,
      "step": 3159
    },
    {
      "epoch": 1.9036144578313254,
      "grad_norm": 0.5815838575363159,
      "learning_rate": 2.621987951807229e-06,
      "loss": 0.3306,
      "step": 3160
    },
    {
      "epoch": 1.9042168674698794,
      "grad_norm": 0.6034603118896484,
      "learning_rate": 2.6212349397590366e-06,
      "loss": 0.2702,
      "step": 3161
    },
    {
      "epoch": 1.9048192771084338,
      "grad_norm": 0.6720820069313049,
      "learning_rate": 2.6204819277108435e-06,
      "loss": 0.2707,
      "step": 3162
    },
    {
      "epoch": 1.905421686746988,
      "grad_norm": 0.55243980884552,
      "learning_rate": 2.619728915662651e-06,
      "loss": 0.2658,
      "step": 3163
    },
    {
      "epoch": 1.9060240963855422,
      "grad_norm": 0.5835483074188232,
      "learning_rate": 2.618975903614458e-06,
      "loss": 0.2704,
      "step": 3164
    },
    {
      "epoch": 1.9066265060240963,
      "grad_norm": 0.5145631432533264,
      "learning_rate": 2.6182228915662656e-06,
      "loss": 0.2388,
      "step": 3165
    },
    {
      "epoch": 1.9072289156626505,
      "grad_norm": 0.6097027063369751,
      "learning_rate": 2.6174698795180725e-06,
      "loss": 0.3503,
      "step": 3166
    },
    {
      "epoch": 1.907831325301205,
      "grad_norm": 0.5193833112716675,
      "learning_rate": 2.6167168674698794e-06,
      "loss": 0.2709,
      "step": 3167
    },
    {
      "epoch": 1.9084337349397589,
      "grad_norm": 0.6143947839736938,
      "learning_rate": 2.615963855421687e-06,
      "loss": 0.2804,
      "step": 3168
    },
    {
      "epoch": 1.9090361445783133,
      "grad_norm": 0.5674359202384949,
      "learning_rate": 2.615210843373494e-06,
      "loss": 0.2384,
      "step": 3169
    },
    {
      "epoch": 1.9096385542168675,
      "grad_norm": 0.632753312587738,
      "learning_rate": 2.6144578313253015e-06,
      "loss": 0.2269,
      "step": 3170
    },
    {
      "epoch": 1.9102409638554216,
      "grad_norm": 0.564799427986145,
      "learning_rate": 2.613704819277109e-06,
      "loss": 0.2886,
      "step": 3171
    },
    {
      "epoch": 1.910843373493976,
      "grad_norm": 0.5812406539916992,
      "learning_rate": 2.6129518072289157e-06,
      "loss": 0.2231,
      "step": 3172
    },
    {
      "epoch": 1.91144578313253,
      "grad_norm": 0.5785353183746338,
      "learning_rate": 2.612198795180723e-06,
      "loss": 0.2445,
      "step": 3173
    },
    {
      "epoch": 1.9120481927710844,
      "grad_norm": 0.5296031832695007,
      "learning_rate": 2.61144578313253e-06,
      "loss": 0.2494,
      "step": 3174
    },
    {
      "epoch": 1.9126506024096386,
      "grad_norm": 0.5870848894119263,
      "learning_rate": 2.6106927710843378e-06,
      "loss": 0.2583,
      "step": 3175
    },
    {
      "epoch": 1.9132530120481928,
      "grad_norm": 0.5155567526817322,
      "learning_rate": 2.6099397590361447e-06,
      "loss": 0.2466,
      "step": 3176
    },
    {
      "epoch": 1.913855421686747,
      "grad_norm": 0.5532148480415344,
      "learning_rate": 2.6091867469879525e-06,
      "loss": 0.2487,
      "step": 3177
    },
    {
      "epoch": 1.9144578313253011,
      "grad_norm": 0.5567554831504822,
      "learning_rate": 2.6084337349397594e-06,
      "loss": 0.288,
      "step": 3178
    },
    {
      "epoch": 1.9150602409638555,
      "grad_norm": 0.5499016642570496,
      "learning_rate": 2.6076807228915663e-06,
      "loss": 0.2873,
      "step": 3179
    },
    {
      "epoch": 1.9156626506024095,
      "grad_norm": 0.5642952919006348,
      "learning_rate": 2.6069277108433737e-06,
      "loss": 0.2766,
      "step": 3180
    },
    {
      "epoch": 1.9162650602409639,
      "grad_norm": 0.5757083296775818,
      "learning_rate": 2.606174698795181e-06,
      "loss": 0.2828,
      "step": 3181
    },
    {
      "epoch": 1.916867469879518,
      "grad_norm": 0.6048982739448547,
      "learning_rate": 2.6054216867469884e-06,
      "loss": 0.2571,
      "step": 3182
    },
    {
      "epoch": 1.9174698795180722,
      "grad_norm": 0.5676209926605225,
      "learning_rate": 2.6046686746987953e-06,
      "loss": 0.239,
      "step": 3183
    },
    {
      "epoch": 1.9180722891566266,
      "grad_norm": 0.7002446055412292,
      "learning_rate": 2.6039156626506022e-06,
      "loss": 0.2757,
      "step": 3184
    },
    {
      "epoch": 1.9186746987951806,
      "grad_norm": 0.7297356128692627,
      "learning_rate": 2.60316265060241e-06,
      "loss": 0.2869,
      "step": 3185
    },
    {
      "epoch": 1.919277108433735,
      "grad_norm": 0.6202640533447266,
      "learning_rate": 2.602409638554217e-06,
      "loss": 0.2439,
      "step": 3186
    },
    {
      "epoch": 1.9198795180722892,
      "grad_norm": 0.5692622065544128,
      "learning_rate": 2.6016566265060243e-06,
      "loss": 0.2557,
      "step": 3187
    },
    {
      "epoch": 1.9204819277108434,
      "grad_norm": 0.6984268426895142,
      "learning_rate": 2.6009036144578316e-06,
      "loss": 0.2725,
      "step": 3188
    },
    {
      "epoch": 1.9210843373493975,
      "grad_norm": 0.5600194334983826,
      "learning_rate": 2.600150602409639e-06,
      "loss": 0.2283,
      "step": 3189
    },
    {
      "epoch": 1.9216867469879517,
      "grad_norm": 0.609812319278717,
      "learning_rate": 2.599397590361446e-06,
      "loss": 0.2714,
      "step": 3190
    },
    {
      "epoch": 1.9222891566265061,
      "grad_norm": 0.6593748331069946,
      "learning_rate": 2.598644578313253e-06,
      "loss": 0.2957,
      "step": 3191
    },
    {
      "epoch": 1.92289156626506,
      "grad_norm": 0.5825187563896179,
      "learning_rate": 2.5978915662650606e-06,
      "loss": 0.2382,
      "step": 3192
    },
    {
      "epoch": 1.9234939759036145,
      "grad_norm": 0.5991600155830383,
      "learning_rate": 2.5971385542168675e-06,
      "loss": 0.2194,
      "step": 3193
    },
    {
      "epoch": 1.9240963855421687,
      "grad_norm": 0.5637121200561523,
      "learning_rate": 2.5963855421686753e-06,
      "loss": 0.1987,
      "step": 3194
    },
    {
      "epoch": 1.9246987951807228,
      "grad_norm": 0.60831618309021,
      "learning_rate": 2.595632530120482e-06,
      "loss": 0.259,
      "step": 3195
    },
    {
      "epoch": 1.9253012048192772,
      "grad_norm": 0.6125224828720093,
      "learning_rate": 2.594879518072289e-06,
      "loss": 0.2842,
      "step": 3196
    },
    {
      "epoch": 1.9259036144578312,
      "grad_norm": 0.5291866064071655,
      "learning_rate": 2.5941265060240965e-06,
      "loss": 0.1959,
      "step": 3197
    },
    {
      "epoch": 1.9265060240963856,
      "grad_norm": 0.6010977625846863,
      "learning_rate": 2.593373493975904e-06,
      "loss": 0.2136,
      "step": 3198
    },
    {
      "epoch": 1.9271084337349398,
      "grad_norm": 0.623100757598877,
      "learning_rate": 2.592620481927711e-06,
      "loss": 0.2938,
      "step": 3199
    },
    {
      "epoch": 1.927710843373494,
      "grad_norm": 0.5680497884750366,
      "learning_rate": 2.591867469879518e-06,
      "loss": 0.2143,
      "step": 3200
    },
    {
      "epoch": 1.9283132530120481,
      "grad_norm": 0.6129957437515259,
      "learning_rate": 2.591114457831326e-06,
      "loss": 0.2536,
      "step": 3201
    },
    {
      "epoch": 1.9289156626506023,
      "grad_norm": 0.5353586077690125,
      "learning_rate": 2.590361445783133e-06,
      "loss": 0.2039,
      "step": 3202
    },
    {
      "epoch": 1.9295180722891567,
      "grad_norm": 0.5839246511459351,
      "learning_rate": 2.5896084337349397e-06,
      "loss": 0.2821,
      "step": 3203
    },
    {
      "epoch": 1.9301204819277107,
      "grad_norm": 0.7026335000991821,
      "learning_rate": 2.5888554216867475e-06,
      "loss": 0.2793,
      "step": 3204
    },
    {
      "epoch": 1.930722891566265,
      "grad_norm": 0.5311402678489685,
      "learning_rate": 2.5881024096385544e-06,
      "loss": 0.2066,
      "step": 3205
    },
    {
      "epoch": 1.9313253012048193,
      "grad_norm": 0.5120426416397095,
      "learning_rate": 2.5873493975903618e-06,
      "loss": 0.2554,
      "step": 3206
    },
    {
      "epoch": 1.9319277108433734,
      "grad_norm": 0.6645122766494751,
      "learning_rate": 2.5865963855421687e-06,
      "loss": 0.2743,
      "step": 3207
    },
    {
      "epoch": 1.9325301204819278,
      "grad_norm": 0.6125863194465637,
      "learning_rate": 2.585843373493976e-06,
      "loss": 0.2551,
      "step": 3208
    },
    {
      "epoch": 1.9331325301204818,
      "grad_norm": 0.5373601913452148,
      "learning_rate": 2.5850903614457834e-06,
      "loss": 0.252,
      "step": 3209
    },
    {
      "epoch": 1.9337349397590362,
      "grad_norm": 0.5325685739517212,
      "learning_rate": 2.5843373493975903e-06,
      "loss": 0.1997,
      "step": 3210
    },
    {
      "epoch": 1.9343373493975904,
      "grad_norm": 0.5757636427879333,
      "learning_rate": 2.583584337349398e-06,
      "loss": 0.2106,
      "step": 3211
    },
    {
      "epoch": 1.9349397590361446,
      "grad_norm": 0.5619849562644958,
      "learning_rate": 2.582831325301205e-06,
      "loss": 0.2919,
      "step": 3212
    },
    {
      "epoch": 1.9355421686746987,
      "grad_norm": 0.6038918495178223,
      "learning_rate": 2.5820783132530124e-06,
      "loss": 0.2733,
      "step": 3213
    },
    {
      "epoch": 1.936144578313253,
      "grad_norm": 0.5232537388801575,
      "learning_rate": 2.5813253012048197e-06,
      "loss": 0.249,
      "step": 3214
    },
    {
      "epoch": 1.9367469879518073,
      "grad_norm": 0.6620514392852783,
      "learning_rate": 2.5805722891566266e-06,
      "loss": 0.2352,
      "step": 3215
    },
    {
      "epoch": 1.9373493975903613,
      "grad_norm": 0.5507671236991882,
      "learning_rate": 2.579819277108434e-06,
      "loss": 0.2058,
      "step": 3216
    },
    {
      "epoch": 1.9379518072289157,
      "grad_norm": 0.5778091549873352,
      "learning_rate": 2.579066265060241e-06,
      "loss": 0.2467,
      "step": 3217
    },
    {
      "epoch": 1.9385542168674699,
      "grad_norm": 0.5221557021141052,
      "learning_rate": 2.5783132530120487e-06,
      "loss": 0.2099,
      "step": 3218
    },
    {
      "epoch": 1.939156626506024,
      "grad_norm": 0.6018508076667786,
      "learning_rate": 2.5775602409638556e-06,
      "loss": 0.2127,
      "step": 3219
    },
    {
      "epoch": 1.9397590361445785,
      "grad_norm": 0.5453314185142517,
      "learning_rate": 2.5768072289156625e-06,
      "loss": 0.3193,
      "step": 3220
    },
    {
      "epoch": 1.9403614457831324,
      "grad_norm": 0.611531674861908,
      "learning_rate": 2.5760542168674703e-06,
      "loss": 0.3013,
      "step": 3221
    },
    {
      "epoch": 1.9409638554216868,
      "grad_norm": 0.6595730185508728,
      "learning_rate": 2.5753012048192772e-06,
      "loss": 0.261,
      "step": 3222
    },
    {
      "epoch": 1.941566265060241,
      "grad_norm": 0.5862306356430054,
      "learning_rate": 2.5745481927710846e-06,
      "loss": 0.252,
      "step": 3223
    },
    {
      "epoch": 1.9421686746987952,
      "grad_norm": 0.5403996109962463,
      "learning_rate": 2.5737951807228915e-06,
      "loss": 0.2713,
      "step": 3224
    },
    {
      "epoch": 1.9427710843373494,
      "grad_norm": 0.5229787230491638,
      "learning_rate": 2.5730421686746993e-06,
      "loss": 0.219,
      "step": 3225
    },
    {
      "epoch": 1.9433734939759035,
      "grad_norm": 0.49990689754486084,
      "learning_rate": 2.572289156626506e-06,
      "loss": 0.192,
      "step": 3226
    },
    {
      "epoch": 1.943975903614458,
      "grad_norm": 0.6534057855606079,
      "learning_rate": 2.571536144578313e-06,
      "loss": 0.2916,
      "step": 3227
    },
    {
      "epoch": 1.944578313253012,
      "grad_norm": 0.5520704984664917,
      "learning_rate": 2.570783132530121e-06,
      "loss": 0.2526,
      "step": 3228
    },
    {
      "epoch": 1.9451807228915663,
      "grad_norm": 0.6259394288063049,
      "learning_rate": 2.570030120481928e-06,
      "loss": 0.218,
      "step": 3229
    },
    {
      "epoch": 1.9457831325301205,
      "grad_norm": 0.518794596195221,
      "learning_rate": 2.569277108433735e-06,
      "loss": 0.2349,
      "step": 3230
    },
    {
      "epoch": 1.9463855421686747,
      "grad_norm": 0.7024228572845459,
      "learning_rate": 2.5685240963855425e-06,
      "loss": 0.2834,
      "step": 3231
    },
    {
      "epoch": 1.946987951807229,
      "grad_norm": 0.6520490646362305,
      "learning_rate": 2.5677710843373494e-06,
      "loss": 0.2613,
      "step": 3232
    },
    {
      "epoch": 1.947590361445783,
      "grad_norm": 0.5704225301742554,
      "learning_rate": 2.5670180722891568e-06,
      "loss": 0.209,
      "step": 3233
    },
    {
      "epoch": 1.9481927710843374,
      "grad_norm": 0.6785972714424133,
      "learning_rate": 2.5662650602409637e-06,
      "loss": 0.2125,
      "step": 3234
    },
    {
      "epoch": 1.9487951807228916,
      "grad_norm": 0.6544299125671387,
      "learning_rate": 2.5655120481927715e-06,
      "loss": 0.2901,
      "step": 3235
    },
    {
      "epoch": 1.9493975903614458,
      "grad_norm": 0.6016119718551636,
      "learning_rate": 2.5647590361445784e-06,
      "loss": 0.1935,
      "step": 3236
    },
    {
      "epoch": 1.95,
      "grad_norm": 0.5362990498542786,
      "learning_rate": 2.564006024096386e-06,
      "loss": 0.2343,
      "step": 3237
    },
    {
      "epoch": 1.9506024096385541,
      "grad_norm": 0.5777273178100586,
      "learning_rate": 2.563253012048193e-06,
      "loss": 0.2984,
      "step": 3238
    },
    {
      "epoch": 1.9512048192771085,
      "grad_norm": 0.6908467411994934,
      "learning_rate": 2.5625e-06,
      "loss": 0.2817,
      "step": 3239
    },
    {
      "epoch": 1.9518072289156625,
      "grad_norm": 2.287578582763672,
      "learning_rate": 2.5617469879518074e-06,
      "loss": 0.3069,
      "step": 3240
    },
    {
      "epoch": 1.952409638554217,
      "grad_norm": 0.6256735324859619,
      "learning_rate": 2.5609939759036147e-06,
      "loss": 0.2745,
      "step": 3241
    },
    {
      "epoch": 1.953012048192771,
      "grad_norm": 0.6991748213768005,
      "learning_rate": 2.560240963855422e-06,
      "loss": 0.3129,
      "step": 3242
    },
    {
      "epoch": 1.9536144578313253,
      "grad_norm": 0.5823225975036621,
      "learning_rate": 2.559487951807229e-06,
      "loss": 0.22,
      "step": 3243
    },
    {
      "epoch": 1.9542168674698797,
      "grad_norm": 0.5778762698173523,
      "learning_rate": 2.558734939759036e-06,
      "loss": 0.2681,
      "step": 3244
    },
    {
      "epoch": 1.9548192771084336,
      "grad_norm": 0.6069991588592529,
      "learning_rate": 2.5579819277108437e-06,
      "loss": 0.2699,
      "step": 3245
    },
    {
      "epoch": 1.955421686746988,
      "grad_norm": 0.6051972508430481,
      "learning_rate": 2.5572289156626506e-06,
      "loss": 0.2858,
      "step": 3246
    },
    {
      "epoch": 1.9560240963855422,
      "grad_norm": 0.6526292562484741,
      "learning_rate": 2.5564759036144584e-06,
      "loss": 0.2306,
      "step": 3247
    },
    {
      "epoch": 1.9566265060240964,
      "grad_norm": 0.7393151521682739,
      "learning_rate": 2.5557228915662653e-06,
      "loss": 0.28,
      "step": 3248
    },
    {
      "epoch": 1.9572289156626506,
      "grad_norm": 0.5471425652503967,
      "learning_rate": 2.5549698795180727e-06,
      "loss": 0.2881,
      "step": 3249
    },
    {
      "epoch": 1.9578313253012047,
      "grad_norm": 0.5685131549835205,
      "learning_rate": 2.5542168674698796e-06,
      "loss": 0.248,
      "step": 3250
    },
    {
      "epoch": 1.9584337349397591,
      "grad_norm": 0.6585801243782043,
      "learning_rate": 2.553463855421687e-06,
      "loss": 0.2787,
      "step": 3251
    },
    {
      "epoch": 1.959036144578313,
      "grad_norm": 0.6008751392364502,
      "learning_rate": 2.5527108433734943e-06,
      "loss": 0.2591,
      "step": 3252
    },
    {
      "epoch": 1.9596385542168675,
      "grad_norm": 0.568803071975708,
      "learning_rate": 2.5519578313253012e-06,
      "loss": 0.2221,
      "step": 3253
    },
    {
      "epoch": 1.9602409638554217,
      "grad_norm": 0.5315886735916138,
      "learning_rate": 2.551204819277109e-06,
      "loss": 0.2096,
      "step": 3254
    },
    {
      "epoch": 1.9608433734939759,
      "grad_norm": 0.5863327980041504,
      "learning_rate": 2.550451807228916e-06,
      "loss": 0.2511,
      "step": 3255
    },
    {
      "epoch": 1.9614457831325303,
      "grad_norm": 0.5306770205497742,
      "learning_rate": 2.549698795180723e-06,
      "loss": 0.2558,
      "step": 3256
    },
    {
      "epoch": 1.9620481927710842,
      "grad_norm": 0.5310285091400146,
      "learning_rate": 2.54894578313253e-06,
      "loss": 0.2544,
      "step": 3257
    },
    {
      "epoch": 1.9626506024096386,
      "grad_norm": 0.6394982933998108,
      "learning_rate": 2.5481927710843375e-06,
      "loss": 0.2713,
      "step": 3258
    },
    {
      "epoch": 1.9632530120481928,
      "grad_norm": 0.6327621340751648,
      "learning_rate": 2.547439759036145e-06,
      "loss": 0.2556,
      "step": 3259
    },
    {
      "epoch": 1.963855421686747,
      "grad_norm": 0.58985835313797,
      "learning_rate": 2.546686746987952e-06,
      "loss": 0.2705,
      "step": 3260
    },
    {
      "epoch": 1.9644578313253012,
      "grad_norm": 0.5982980728149414,
      "learning_rate": 2.5459337349397596e-06,
      "loss": 0.2285,
      "step": 3261
    },
    {
      "epoch": 1.9650602409638553,
      "grad_norm": 0.5918188095092773,
      "learning_rate": 2.5451807228915665e-06,
      "loss": 0.2778,
      "step": 3262
    },
    {
      "epoch": 1.9656626506024097,
      "grad_norm": 0.5364345908164978,
      "learning_rate": 2.5444277108433734e-06,
      "loss": 0.2465,
      "step": 3263
    },
    {
      "epoch": 1.9662650602409637,
      "grad_norm": 0.8805769085884094,
      "learning_rate": 2.543674698795181e-06,
      "loss": 0.3346,
      "step": 3264
    },
    {
      "epoch": 1.966867469879518,
      "grad_norm": 0.615078866481781,
      "learning_rate": 2.542921686746988e-06,
      "loss": 0.2988,
      "step": 3265
    },
    {
      "epoch": 1.9674698795180723,
      "grad_norm": 0.5646905899047852,
      "learning_rate": 2.5421686746987955e-06,
      "loss": 0.2687,
      "step": 3266
    },
    {
      "epoch": 1.9680722891566265,
      "grad_norm": 0.608162522315979,
      "learning_rate": 2.5414156626506024e-06,
      "loss": 0.2534,
      "step": 3267
    },
    {
      "epoch": 1.9686746987951809,
      "grad_norm": 0.6372812986373901,
      "learning_rate": 2.5406626506024097e-06,
      "loss": 0.3364,
      "step": 3268
    },
    {
      "epoch": 1.9692771084337348,
      "grad_norm": 0.705766499042511,
      "learning_rate": 2.539909638554217e-06,
      "loss": 0.3499,
      "step": 3269
    },
    {
      "epoch": 1.9698795180722892,
      "grad_norm": 0.5531877279281616,
      "learning_rate": 2.539156626506024e-06,
      "loss": 0.2437,
      "step": 3270
    },
    {
      "epoch": 1.9704819277108434,
      "grad_norm": 0.5836827158927917,
      "learning_rate": 2.538403614457832e-06,
      "loss": 0.2464,
      "step": 3271
    },
    {
      "epoch": 1.9710843373493976,
      "grad_norm": 0.6258847117424011,
      "learning_rate": 2.5376506024096387e-06,
      "loss": 0.2695,
      "step": 3272
    },
    {
      "epoch": 1.9716867469879518,
      "grad_norm": 0.60298091173172,
      "learning_rate": 2.536897590361446e-06,
      "loss": 0.2931,
      "step": 3273
    },
    {
      "epoch": 1.972289156626506,
      "grad_norm": 0.5883190035820007,
      "learning_rate": 2.5361445783132534e-06,
      "loss": 0.2188,
      "step": 3274
    },
    {
      "epoch": 1.9728915662650603,
      "grad_norm": 0.5499547123908997,
      "learning_rate": 2.5353915662650603e-06,
      "loss": 0.1972,
      "step": 3275
    },
    {
      "epoch": 1.9734939759036143,
      "grad_norm": 0.6605150699615479,
      "learning_rate": 2.5346385542168677e-06,
      "loss": 0.2945,
      "step": 3276
    },
    {
      "epoch": 1.9740963855421687,
      "grad_norm": 0.571970522403717,
      "learning_rate": 2.5338855421686746e-06,
      "loss": 0.2648,
      "step": 3277
    },
    {
      "epoch": 1.9746987951807229,
      "grad_norm": 0.6766816973686218,
      "learning_rate": 2.5331325301204824e-06,
      "loss": 0.273,
      "step": 3278
    },
    {
      "epoch": 1.975301204819277,
      "grad_norm": 0.6056786775588989,
      "learning_rate": 2.5323795180722893e-06,
      "loss": 0.252,
      "step": 3279
    },
    {
      "epoch": 1.9759036144578315,
      "grad_norm": 0.5534700751304626,
      "learning_rate": 2.5316265060240962e-06,
      "loss": 0.2202,
      "step": 3280
    },
    {
      "epoch": 1.9765060240963854,
      "grad_norm": 0.5898459553718567,
      "learning_rate": 2.530873493975904e-06,
      "loss": 0.2364,
      "step": 3281
    },
    {
      "epoch": 1.9771084337349398,
      "grad_norm": 0.5776882171630859,
      "learning_rate": 2.530120481927711e-06,
      "loss": 0.2424,
      "step": 3282
    },
    {
      "epoch": 1.977710843373494,
      "grad_norm": 0.6202924251556396,
      "learning_rate": 2.5293674698795183e-06,
      "loss": 0.2994,
      "step": 3283
    },
    {
      "epoch": 1.9783132530120482,
      "grad_norm": 0.5378469824790955,
      "learning_rate": 2.5286144578313256e-06,
      "loss": 0.2385,
      "step": 3284
    },
    {
      "epoch": 1.9789156626506024,
      "grad_norm": 0.6691017150878906,
      "learning_rate": 2.527861445783133e-06,
      "loss": 0.2606,
      "step": 3285
    },
    {
      "epoch": 1.9795180722891565,
      "grad_norm": 0.5856606364250183,
      "learning_rate": 2.52710843373494e-06,
      "loss": 0.2739,
      "step": 3286
    },
    {
      "epoch": 1.980120481927711,
      "grad_norm": 0.6834169626235962,
      "learning_rate": 2.526355421686747e-06,
      "loss": 0.3018,
      "step": 3287
    },
    {
      "epoch": 1.980722891566265,
      "grad_norm": 0.5810458064079285,
      "learning_rate": 2.5256024096385546e-06,
      "loss": 0.3145,
      "step": 3288
    },
    {
      "epoch": 1.9813253012048193,
      "grad_norm": 0.5828225016593933,
      "learning_rate": 2.5248493975903615e-06,
      "loss": 0.2267,
      "step": 3289
    },
    {
      "epoch": 1.9819277108433735,
      "grad_norm": 0.5950515866279602,
      "learning_rate": 2.524096385542169e-06,
      "loss": 0.328,
      "step": 3290
    },
    {
      "epoch": 1.9825301204819277,
      "grad_norm": 0.5911925435066223,
      "learning_rate": 2.5233433734939762e-06,
      "loss": 0.272,
      "step": 3291
    },
    {
      "epoch": 1.983132530120482,
      "grad_norm": 0.5455687642097473,
      "learning_rate": 2.522590361445783e-06,
      "loss": 0.217,
      "step": 3292
    },
    {
      "epoch": 1.983734939759036,
      "grad_norm": 0.5147219300270081,
      "learning_rate": 2.5218373493975905e-06,
      "loss": 0.2163,
      "step": 3293
    },
    {
      "epoch": 1.9843373493975904,
      "grad_norm": 0.5420126914978027,
      "learning_rate": 2.5210843373493974e-06,
      "loss": 0.2793,
      "step": 3294
    },
    {
      "epoch": 1.9849397590361446,
      "grad_norm": 0.6521531343460083,
      "learning_rate": 2.520331325301205e-06,
      "loss": 0.2837,
      "step": 3295
    },
    {
      "epoch": 1.9855421686746988,
      "grad_norm": 0.6777289509773254,
      "learning_rate": 2.519578313253012e-06,
      "loss": 0.3272,
      "step": 3296
    },
    {
      "epoch": 1.986144578313253,
      "grad_norm": 0.5847601890563965,
      "learning_rate": 2.51882530120482e-06,
      "loss": 0.3038,
      "step": 3297
    },
    {
      "epoch": 1.9867469879518072,
      "grad_norm": 0.6033922433853149,
      "learning_rate": 2.518072289156627e-06,
      "loss": 0.3327,
      "step": 3298
    },
    {
      "epoch": 1.9873493975903616,
      "grad_norm": 0.5854074954986572,
      "learning_rate": 2.5173192771084337e-06,
      "loss": 0.2828,
      "step": 3299
    },
    {
      "epoch": 1.9879518072289155,
      "grad_norm": 0.5799117684364319,
      "learning_rate": 2.516566265060241e-06,
      "loss": 0.2455,
      "step": 3300
    },
    {
      "epoch": 1.98855421686747,
      "grad_norm": 0.7000740170478821,
      "learning_rate": 2.5158132530120484e-06,
      "loss": 0.2948,
      "step": 3301
    },
    {
      "epoch": 1.989156626506024,
      "grad_norm": 0.6725067496299744,
      "learning_rate": 2.5150602409638558e-06,
      "loss": 0.2215,
      "step": 3302
    },
    {
      "epoch": 1.9897590361445783,
      "grad_norm": 0.6904001832008362,
      "learning_rate": 2.5143072289156627e-06,
      "loss": 0.3382,
      "step": 3303
    },
    {
      "epoch": 1.9903614457831327,
      "grad_norm": 0.6044745445251465,
      "learning_rate": 2.5135542168674696e-06,
      "loss": 0.2498,
      "step": 3304
    },
    {
      "epoch": 1.9909638554216866,
      "grad_norm": 0.6308416724205017,
      "learning_rate": 2.5128012048192774e-06,
      "loss": 0.2998,
      "step": 3305
    },
    {
      "epoch": 1.991566265060241,
      "grad_norm": 0.6642490029335022,
      "learning_rate": 2.5120481927710843e-06,
      "loss": 0.2865,
      "step": 3306
    },
    {
      "epoch": 1.9921686746987952,
      "grad_norm": 0.6209582686424255,
      "learning_rate": 2.511295180722892e-06,
      "loss": 0.2799,
      "step": 3307
    },
    {
      "epoch": 1.9927710843373494,
      "grad_norm": 0.5417104363441467,
      "learning_rate": 2.510542168674699e-06,
      "loss": 0.259,
      "step": 3308
    },
    {
      "epoch": 1.9933734939759036,
      "grad_norm": 0.6291229724884033,
      "learning_rate": 2.5097891566265064e-06,
      "loss": 0.2629,
      "step": 3309
    },
    {
      "epoch": 1.9939759036144578,
      "grad_norm": 0.5701476335525513,
      "learning_rate": 2.5090361445783133e-06,
      "loss": 0.2791,
      "step": 3310
    },
    {
      "epoch": 1.9945783132530122,
      "grad_norm": 0.6157622933387756,
      "learning_rate": 2.5082831325301206e-06,
      "loss": 0.2112,
      "step": 3311
    },
    {
      "epoch": 1.9951807228915661,
      "grad_norm": 0.6462115049362183,
      "learning_rate": 2.507530120481928e-06,
      "loss": 0.2669,
      "step": 3312
    },
    {
      "epoch": 1.9957831325301205,
      "grad_norm": 0.6768850684165955,
      "learning_rate": 2.506777108433735e-06,
      "loss": 0.2799,
      "step": 3313
    },
    {
      "epoch": 1.9963855421686747,
      "grad_norm": 0.5379418730735779,
      "learning_rate": 2.5060240963855427e-06,
      "loss": 0.2331,
      "step": 3314
    },
    {
      "epoch": 1.9969879518072289,
      "grad_norm": 0.6042695045471191,
      "learning_rate": 2.5052710843373496e-06,
      "loss": 0.3347,
      "step": 3315
    },
    {
      "epoch": 1.9975903614457833,
      "grad_norm": 0.6583542227745056,
      "learning_rate": 2.5045180722891565e-06,
      "loss": 0.2707,
      "step": 3316
    },
    {
      "epoch": 1.9981927710843372,
      "grad_norm": 0.5764530897140503,
      "learning_rate": 2.5037650602409643e-06,
      "loss": 0.214,
      "step": 3317
    },
    {
      "epoch": 1.9987951807228916,
      "grad_norm": 0.524838924407959,
      "learning_rate": 2.5030120481927712e-06,
      "loss": 0.2521,
      "step": 3318
    },
    {
      "epoch": 1.9993975903614458,
      "grad_norm": 0.5427148938179016,
      "learning_rate": 2.5022590361445786e-06,
      "loss": 0.226,
      "step": 3319
    },
    {
      "epoch": 2.0,
      "grad_norm": 0.6248267889022827,
      "learning_rate": 2.5015060240963855e-06,
      "loss": 0.3192,
      "step": 3320
    },
    {
      "epoch": 2.0006024096385544,
      "grad_norm": 0.8601822257041931,
      "learning_rate": 2.5007530120481933e-06,
      "loss": 0.173,
      "step": 3321
    },
    {
      "epoch": 2.0012048192771084,
      "grad_norm": 0.8677046895027161,
      "learning_rate": 2.5e-06,
      "loss": 0.1886,
      "step": 3322
    },
    {
      "epoch": 2.0018072289156628,
      "grad_norm": 0.7618901133537292,
      "learning_rate": 2.4992469879518076e-06,
      "loss": 0.177,
      "step": 3323
    },
    {
      "epoch": 2.0024096385542167,
      "grad_norm": 0.7392041683197021,
      "learning_rate": 2.498493975903615e-06,
      "loss": 0.2169,
      "step": 3324
    },
    {
      "epoch": 2.003012048192771,
      "grad_norm": 0.8884011507034302,
      "learning_rate": 2.497740963855422e-06,
      "loss": 0.2146,
      "step": 3325
    },
    {
      "epoch": 2.003614457831325,
      "grad_norm": 0.7522888779640198,
      "learning_rate": 2.496987951807229e-06,
      "loss": 0.1995,
      "step": 3326
    },
    {
      "epoch": 2.0042168674698795,
      "grad_norm": 0.663469135761261,
      "learning_rate": 2.496234939759036e-06,
      "loss": 0.2049,
      "step": 3327
    },
    {
      "epoch": 2.004819277108434,
      "grad_norm": 0.7288620471954346,
      "learning_rate": 2.4954819277108434e-06,
      "loss": 0.2306,
      "step": 3328
    },
    {
      "epoch": 2.005421686746988,
      "grad_norm": 0.6589181423187256,
      "learning_rate": 2.494728915662651e-06,
      "loss": 0.2348,
      "step": 3329
    },
    {
      "epoch": 2.0060240963855422,
      "grad_norm": 0.6520573496818542,
      "learning_rate": 2.493975903614458e-06,
      "loss": 0.1696,
      "step": 3330
    },
    {
      "epoch": 2.006626506024096,
      "grad_norm": 0.615570604801178,
      "learning_rate": 2.4932228915662655e-06,
      "loss": 0.1912,
      "step": 3331
    },
    {
      "epoch": 2.0072289156626506,
      "grad_norm": 0.8109323382377625,
      "learning_rate": 2.4924698795180724e-06,
      "loss": 0.2193,
      "step": 3332
    },
    {
      "epoch": 2.007831325301205,
      "grad_norm": 0.6551888585090637,
      "learning_rate": 2.4917168674698798e-06,
      "loss": 0.2244,
      "step": 3333
    },
    {
      "epoch": 2.008433734939759,
      "grad_norm": 0.6341142058372498,
      "learning_rate": 2.490963855421687e-06,
      "loss": 0.1547,
      "step": 3334
    },
    {
      "epoch": 2.0090361445783134,
      "grad_norm": 0.6936740279197693,
      "learning_rate": 2.490210843373494e-06,
      "loss": 0.2161,
      "step": 3335
    },
    {
      "epoch": 2.0096385542168673,
      "grad_norm": 0.5769056677818298,
      "learning_rate": 2.4894578313253014e-06,
      "loss": 0.1561,
      "step": 3336
    },
    {
      "epoch": 2.0102409638554217,
      "grad_norm": 0.6995612382888794,
      "learning_rate": 2.4887048192771087e-06,
      "loss": 0.2088,
      "step": 3337
    },
    {
      "epoch": 2.0108433734939757,
      "grad_norm": 0.7121310234069824,
      "learning_rate": 2.4879518072289157e-06,
      "loss": 0.2188,
      "step": 3338
    },
    {
      "epoch": 2.01144578313253,
      "grad_norm": 0.6575042009353638,
      "learning_rate": 2.487198795180723e-06,
      "loss": 0.2214,
      "step": 3339
    },
    {
      "epoch": 2.0120481927710845,
      "grad_norm": 0.5318411588668823,
      "learning_rate": 2.4864457831325304e-06,
      "loss": 0.1774,
      "step": 3340
    },
    {
      "epoch": 2.0126506024096384,
      "grad_norm": 0.7161276936531067,
      "learning_rate": 2.4856927710843377e-06,
      "loss": 0.1785,
      "step": 3341
    },
    {
      "epoch": 2.013253012048193,
      "grad_norm": 0.632017970085144,
      "learning_rate": 2.484939759036145e-06,
      "loss": 0.1917,
      "step": 3342
    },
    {
      "epoch": 2.013855421686747,
      "grad_norm": 0.5873064994812012,
      "learning_rate": 2.484186746987952e-06,
      "loss": 0.2281,
      "step": 3343
    },
    {
      "epoch": 2.014457831325301,
      "grad_norm": 0.5983318090438843,
      "learning_rate": 2.4834337349397593e-06,
      "loss": 0.1841,
      "step": 3344
    },
    {
      "epoch": 2.0150602409638556,
      "grad_norm": 0.6745656132698059,
      "learning_rate": 2.4826807228915663e-06,
      "loss": 0.2019,
      "step": 3345
    },
    {
      "epoch": 2.0156626506024096,
      "grad_norm": 0.6250988245010376,
      "learning_rate": 2.4819277108433736e-06,
      "loss": 0.2007,
      "step": 3346
    },
    {
      "epoch": 2.016265060240964,
      "grad_norm": 0.5417555570602417,
      "learning_rate": 2.481174698795181e-06,
      "loss": 0.2534,
      "step": 3347
    },
    {
      "epoch": 2.016867469879518,
      "grad_norm": 0.5405175685882568,
      "learning_rate": 2.4804216867469883e-06,
      "loss": 0.159,
      "step": 3348
    },
    {
      "epoch": 2.0174698795180723,
      "grad_norm": 0.6178736686706543,
      "learning_rate": 2.4796686746987956e-06,
      "loss": 0.1737,
      "step": 3349
    },
    {
      "epoch": 2.0180722891566263,
      "grad_norm": 0.5475565195083618,
      "learning_rate": 2.4789156626506026e-06,
      "loss": 0.1572,
      "step": 3350
    },
    {
      "epoch": 2.0186746987951807,
      "grad_norm": 0.6239098906517029,
      "learning_rate": 2.47816265060241e-06,
      "loss": 0.1645,
      "step": 3351
    },
    {
      "epoch": 2.019277108433735,
      "grad_norm": 0.5354381799697876,
      "learning_rate": 2.4774096385542173e-06,
      "loss": 0.169,
      "step": 3352
    },
    {
      "epoch": 2.019879518072289,
      "grad_norm": 0.4841941297054291,
      "learning_rate": 2.476656626506024e-06,
      "loss": 0.1887,
      "step": 3353
    },
    {
      "epoch": 2.0204819277108435,
      "grad_norm": 0.5711162090301514,
      "learning_rate": 2.4759036144578315e-06,
      "loss": 0.1962,
      "step": 3354
    },
    {
      "epoch": 2.0210843373493974,
      "grad_norm": 0.6144154071807861,
      "learning_rate": 2.475150602409639e-06,
      "loss": 0.1719,
      "step": 3355
    },
    {
      "epoch": 2.021686746987952,
      "grad_norm": 0.5893869996070862,
      "learning_rate": 2.474397590361446e-06,
      "loss": 0.1953,
      "step": 3356
    },
    {
      "epoch": 2.022289156626506,
      "grad_norm": 0.5826955437660217,
      "learning_rate": 2.473644578313253e-06,
      "loss": 0.199,
      "step": 3357
    },
    {
      "epoch": 2.02289156626506,
      "grad_norm": 0.6246376633644104,
      "learning_rate": 2.4728915662650605e-06,
      "loss": 0.2513,
      "step": 3358
    },
    {
      "epoch": 2.0234939759036146,
      "grad_norm": 0.5113880038261414,
      "learning_rate": 2.472138554216868e-06,
      "loss": 0.1937,
      "step": 3359
    },
    {
      "epoch": 2.0240963855421685,
      "grad_norm": 0.5814321637153625,
      "learning_rate": 2.4713855421686748e-06,
      "loss": 0.1567,
      "step": 3360
    },
    {
      "epoch": 2.024698795180723,
      "grad_norm": NaN,
      "learning_rate": 2.4713855421686748e-06,
      "loss": 0.1702,
      "step": 3361
    },
    {
      "epoch": 2.025301204819277,
      "grad_norm": 0.5756857991218567,
      "learning_rate": 2.470632530120482e-06,
      "loss": 0.1847,
      "step": 3362
    },
    {
      "epoch": 2.0259036144578313,
      "grad_norm": 0.5648029446601868,
      "learning_rate": 2.469879518072289e-06,
      "loss": 0.1568,
      "step": 3363
    },
    {
      "epoch": 2.0265060240963857,
      "grad_norm": 0.5688080191612244,
      "learning_rate": 2.4691265060240964e-06,
      "loss": 0.2384,
      "step": 3364
    },
    {
      "epoch": 2.0271084337349397,
      "grad_norm": 0.47675180435180664,
      "learning_rate": 2.4683734939759038e-06,
      "loss": 0.188,
      "step": 3365
    },
    {
      "epoch": 2.027710843373494,
      "grad_norm": 0.48272019624710083,
      "learning_rate": 2.467620481927711e-06,
      "loss": 0.225,
      "step": 3366
    },
    {
      "epoch": 2.028313253012048,
      "grad_norm": 0.6055417656898499,
      "learning_rate": 2.4668674698795185e-06,
      "loss": 0.1573,
      "step": 3367
    },
    {
      "epoch": 2.0289156626506024,
      "grad_norm": 0.5379714369773865,
      "learning_rate": 2.466114457831326e-06,
      "loss": 0.1665,
      "step": 3368
    },
    {
      "epoch": 2.029518072289157,
      "grad_norm": 0.506131649017334,
      "learning_rate": 2.4653614457831327e-06,
      "loss": 0.1705,
      "step": 3369
    },
    {
      "epoch": 2.0301204819277108,
      "grad_norm": 0.6194770932197571,
      "learning_rate": 2.46460843373494e-06,
      "loss": 0.1833,
      "step": 3370
    },
    {
      "epoch": 2.030722891566265,
      "grad_norm": 0.5719035863876343,
      "learning_rate": 2.463855421686747e-06,
      "loss": 0.1797,
      "step": 3371
    },
    {
      "epoch": 2.031325301204819,
      "grad_norm": 0.5971821546554565,
      "learning_rate": 2.4631024096385543e-06,
      "loss": 0.1805,
      "step": 3372
    },
    {
      "epoch": 2.0319277108433735,
      "grad_norm": 0.6427832841873169,
      "learning_rate": 2.4623493975903617e-06,
      "loss": 0.2012,
      "step": 3373
    },
    {
      "epoch": 2.0325301204819275,
      "grad_norm": 0.5559017062187195,
      "learning_rate": 2.461596385542169e-06,
      "loss": 0.2031,
      "step": 3374
    },
    {
      "epoch": 2.033132530120482,
      "grad_norm": 0.5369560122489929,
      "learning_rate": 2.460843373493976e-06,
      "loss": 0.1631,
      "step": 3375
    },
    {
      "epoch": 2.0337349397590363,
      "grad_norm": 0.5958021283149719,
      "learning_rate": 2.4600903614457833e-06,
      "loss": 0.2218,
      "step": 3376
    },
    {
      "epoch": 2.0343373493975903,
      "grad_norm": 0.49128973484039307,
      "learning_rate": 2.4593373493975907e-06,
      "loss": 0.1426,
      "step": 3377
    },
    {
      "epoch": 2.0349397590361447,
      "grad_norm": 0.5327351689338684,
      "learning_rate": 2.458584337349398e-06,
      "loss": 0.2088,
      "step": 3378
    },
    {
      "epoch": 2.0355421686746986,
      "grad_norm": 0.4983801245689392,
      "learning_rate": 2.457831325301205e-06,
      "loss": 0.1593,
      "step": 3379
    },
    {
      "epoch": 2.036144578313253,
      "grad_norm": 0.5376930832862854,
      "learning_rate": 2.4570783132530123e-06,
      "loss": 0.1721,
      "step": 3380
    },
    {
      "epoch": 2.0367469879518074,
      "grad_norm": 0.5302660465240479,
      "learning_rate": 2.456325301204819e-06,
      "loss": 0.1745,
      "step": 3381
    },
    {
      "epoch": 2.0373493975903614,
      "grad_norm": 0.48032668232917786,
      "learning_rate": 2.4555722891566266e-06,
      "loss": 0.1748,
      "step": 3382
    },
    {
      "epoch": 2.037951807228916,
      "grad_norm": 0.47927775979042053,
      "learning_rate": 2.454819277108434e-06,
      "loss": 0.178,
      "step": 3383
    },
    {
      "epoch": 2.0385542168674697,
      "grad_norm": 0.5872754454612732,
      "learning_rate": 2.4540662650602413e-06,
      "loss": 0.2573,
      "step": 3384
    },
    {
      "epoch": 2.039156626506024,
      "grad_norm": 0.6919260025024414,
      "learning_rate": 2.4533132530120486e-06,
      "loss": 0.1697,
      "step": 3385
    },
    {
      "epoch": 2.039759036144578,
      "grad_norm": 0.5387522578239441,
      "learning_rate": 2.452560240963856e-06,
      "loss": 0.1535,
      "step": 3386
    },
    {
      "epoch": 2.0403614457831325,
      "grad_norm": 0.5200400948524475,
      "learning_rate": 2.451807228915663e-06,
      "loss": 0.2014,
      "step": 3387
    },
    {
      "epoch": 2.040963855421687,
      "grad_norm": 0.5424625873565674,
      "learning_rate": 2.4510542168674702e-06,
      "loss": 0.1592,
      "step": 3388
    },
    {
      "epoch": 2.041566265060241,
      "grad_norm": 1.212056279182434,
      "learning_rate": 2.450301204819277e-06,
      "loss": 0.2093,
      "step": 3389
    },
    {
      "epoch": 2.0421686746987953,
      "grad_norm": 0.5311685800552368,
      "learning_rate": 2.4495481927710845e-06,
      "loss": 0.1431,
      "step": 3390
    },
    {
      "epoch": 2.042771084337349,
      "grad_norm": 0.5868041515350342,
      "learning_rate": 2.448795180722892e-06,
      "loss": 0.2406,
      "step": 3391
    },
    {
      "epoch": 2.0433734939759036,
      "grad_norm": 0.5189146995544434,
      "learning_rate": 2.448042168674699e-06,
      "loss": 0.1574,
      "step": 3392
    },
    {
      "epoch": 2.043975903614458,
      "grad_norm": 0.5734142661094666,
      "learning_rate": 2.447289156626506e-06,
      "loss": 0.1914,
      "step": 3393
    },
    {
      "epoch": 2.044578313253012,
      "grad_norm": 0.5081375241279602,
      "learning_rate": 2.4465361445783135e-06,
      "loss": 0.1956,
      "step": 3394
    },
    {
      "epoch": 2.0451807228915664,
      "grad_norm": 0.4873962104320526,
      "learning_rate": 2.445783132530121e-06,
      "loss": 0.1962,
      "step": 3395
    },
    {
      "epoch": 2.0457831325301203,
      "grad_norm": 0.6000650525093079,
      "learning_rate": 2.4450301204819277e-06,
      "loss": 0.1827,
      "step": 3396
    },
    {
      "epoch": 2.0463855421686747,
      "grad_norm": 0.5698335766792297,
      "learning_rate": 2.444277108433735e-06,
      "loss": 0.1926,
      "step": 3397
    },
    {
      "epoch": 2.0469879518072287,
      "grad_norm": 0.5066388249397278,
      "learning_rate": 2.4435240963855424e-06,
      "loss": 0.1858,
      "step": 3398
    },
    {
      "epoch": 2.047590361445783,
      "grad_norm": 0.5456631779670715,
      "learning_rate": 2.4427710843373494e-06,
      "loss": 0.1723,
      "step": 3399
    },
    {
      "epoch": 2.0481927710843375,
      "grad_norm": 0.5428458452224731,
      "learning_rate": 2.4420180722891567e-06,
      "loss": 0.1953,
      "step": 3400
    },
    {
      "epoch": 2.0487951807228915,
      "grad_norm": 0.48055991530418396,
      "learning_rate": 2.441265060240964e-06,
      "loss": 0.1597,
      "step": 3401
    },
    {
      "epoch": 2.049397590361446,
      "grad_norm": 0.5114625692367554,
      "learning_rate": 2.4405120481927714e-06,
      "loss": 0.1588,
      "step": 3402
    },
    {
      "epoch": 2.05,
      "grad_norm": 0.4974266588687897,
      "learning_rate": 2.4397590361445788e-06,
      "loss": 0.1611,
      "step": 3403
    },
    {
      "epoch": 2.0506024096385542,
      "grad_norm": 0.6187301874160767,
      "learning_rate": 2.4390060240963857e-06,
      "loss": 0.2196,
      "step": 3404
    },
    {
      "epoch": 2.0512048192771086,
      "grad_norm": 0.5153840780258179,
      "learning_rate": 2.438253012048193e-06,
      "loss": 0.1946,
      "step": 3405
    },
    {
      "epoch": 2.0518072289156626,
      "grad_norm": 0.501403272151947,
      "learning_rate": 2.4375e-06,
      "loss": 0.1648,
      "step": 3406
    },
    {
      "epoch": 2.052409638554217,
      "grad_norm": 0.5273116230964661,
      "learning_rate": 2.4367469879518073e-06,
      "loss": 0.207,
      "step": 3407
    },
    {
      "epoch": 2.053012048192771,
      "grad_norm": 0.5246257781982422,
      "learning_rate": 2.4359939759036147e-06,
      "loss": 0.1502,
      "step": 3408
    },
    {
      "epoch": 2.0536144578313253,
      "grad_norm": 0.6000198721885681,
      "learning_rate": 2.435240963855422e-06,
      "loss": 0.2272,
      "step": 3409
    },
    {
      "epoch": 2.0542168674698793,
      "grad_norm": 0.5545559525489807,
      "learning_rate": 2.4344879518072293e-06,
      "loss": 0.1552,
      "step": 3410
    },
    {
      "epoch": 2.0548192771084337,
      "grad_norm": 0.5161374807357788,
      "learning_rate": 2.4337349397590363e-06,
      "loss": 0.1628,
      "step": 3411
    },
    {
      "epoch": 2.055421686746988,
      "grad_norm": 0.4992135167121887,
      "learning_rate": 2.4329819277108436e-06,
      "loss": 0.2036,
      "step": 3412
    },
    {
      "epoch": 2.056024096385542,
      "grad_norm": 0.5317087769508362,
      "learning_rate": 2.432228915662651e-06,
      "loss": 0.1742,
      "step": 3413
    },
    {
      "epoch": 2.0566265060240965,
      "grad_norm": 0.5971701145172119,
      "learning_rate": 2.431475903614458e-06,
      "loss": 0.2057,
      "step": 3414
    },
    {
      "epoch": 2.0572289156626504,
      "grad_norm": 0.5739705562591553,
      "learning_rate": 2.4307228915662652e-06,
      "loss": 0.1771,
      "step": 3415
    },
    {
      "epoch": 2.057831325301205,
      "grad_norm": 0.5304529070854187,
      "learning_rate": 2.4299698795180726e-06,
      "loss": 0.1775,
      "step": 3416
    },
    {
      "epoch": 2.0584337349397592,
      "grad_norm": 0.5103877186775208,
      "learning_rate": 2.4292168674698795e-06,
      "loss": 0.1761,
      "step": 3417
    },
    {
      "epoch": 2.059036144578313,
      "grad_norm": 0.5269716382026672,
      "learning_rate": 2.428463855421687e-06,
      "loss": 0.1834,
      "step": 3418
    },
    {
      "epoch": 2.0596385542168676,
      "grad_norm": 0.632989227771759,
      "learning_rate": 2.4277108433734942e-06,
      "loss": 0.1842,
      "step": 3419
    },
    {
      "epoch": 2.0602409638554215,
      "grad_norm": 0.6138862371444702,
      "learning_rate": 2.4269578313253016e-06,
      "loss": 0.1739,
      "step": 3420
    },
    {
      "epoch": 2.060843373493976,
      "grad_norm": 0.5062234997749329,
      "learning_rate": 2.426204819277109e-06,
      "loss": 0.1537,
      "step": 3421
    },
    {
      "epoch": 2.06144578313253,
      "grad_norm": 0.4954589009284973,
      "learning_rate": 2.425451807228916e-06,
      "loss": 0.2051,
      "step": 3422
    },
    {
      "epoch": 2.0620481927710843,
      "grad_norm": 0.5626078248023987,
      "learning_rate": 2.424698795180723e-06,
      "loss": 0.203,
      "step": 3423
    },
    {
      "epoch": 2.0626506024096387,
      "grad_norm": 0.5346068739891052,
      "learning_rate": 2.42394578313253e-06,
      "loss": 0.1648,
      "step": 3424
    },
    {
      "epoch": 2.0632530120481927,
      "grad_norm": 0.47459304332733154,
      "learning_rate": 2.4231927710843375e-06,
      "loss": 0.1442,
      "step": 3425
    },
    {
      "epoch": 2.063855421686747,
      "grad_norm": 0.6782777905464172,
      "learning_rate": 2.422439759036145e-06,
      "loss": 0.2138,
      "step": 3426
    },
    {
      "epoch": 2.064457831325301,
      "grad_norm": 0.5200983285903931,
      "learning_rate": 2.421686746987952e-06,
      "loss": 0.1516,
      "step": 3427
    },
    {
      "epoch": 2.0650602409638554,
      "grad_norm": 0.7096513509750366,
      "learning_rate": 2.4209337349397595e-06,
      "loss": 0.2503,
      "step": 3428
    },
    {
      "epoch": 2.06566265060241,
      "grad_norm": 0.5152601599693298,
      "learning_rate": 2.4201807228915664e-06,
      "loss": 0.1608,
      "step": 3429
    },
    {
      "epoch": 2.066265060240964,
      "grad_norm": 0.5250794887542725,
      "learning_rate": 2.4194277108433738e-06,
      "loss": 0.1519,
      "step": 3430
    },
    {
      "epoch": 2.066867469879518,
      "grad_norm": 0.5480452179908752,
      "learning_rate": 2.4186746987951807e-06,
      "loss": 0.1871,
      "step": 3431
    },
    {
      "epoch": 2.067469879518072,
      "grad_norm": 0.6419910192489624,
      "learning_rate": 2.417921686746988e-06,
      "loss": 0.1803,
      "step": 3432
    },
    {
      "epoch": 2.0680722891566266,
      "grad_norm": 0.5628624558448792,
      "learning_rate": 2.4171686746987954e-06,
      "loss": 0.1889,
      "step": 3433
    },
    {
      "epoch": 2.0686746987951805,
      "grad_norm": 0.6637483835220337,
      "learning_rate": 2.4164156626506027e-06,
      "loss": 0.1574,
      "step": 3434
    },
    {
      "epoch": 2.069277108433735,
      "grad_norm": 0.4763321280479431,
      "learning_rate": 2.4156626506024097e-06,
      "loss": 0.1619,
      "step": 3435
    },
    {
      "epoch": 2.0698795180722893,
      "grad_norm": 0.5139448046684265,
      "learning_rate": 2.414909638554217e-06,
      "loss": 0.1638,
      "step": 3436
    },
    {
      "epoch": 2.0704819277108433,
      "grad_norm": 0.49500060081481934,
      "learning_rate": 2.4141566265060244e-06,
      "loss": 0.151,
      "step": 3437
    },
    {
      "epoch": 2.0710843373493977,
      "grad_norm": 0.6065577864646912,
      "learning_rate": 2.4134036144578317e-06,
      "loss": 0.2366,
      "step": 3438
    },
    {
      "epoch": 2.0716867469879516,
      "grad_norm": 0.5632181167602539,
      "learning_rate": 2.4126506024096386e-06,
      "loss": 0.1685,
      "step": 3439
    },
    {
      "epoch": 2.072289156626506,
      "grad_norm": 0.5701243281364441,
      "learning_rate": 2.411897590361446e-06,
      "loss": 0.2056,
      "step": 3440
    },
    {
      "epoch": 2.0728915662650604,
      "grad_norm": 0.5383309721946716,
      "learning_rate": 2.411144578313253e-06,
      "loss": 0.2176,
      "step": 3441
    },
    {
      "epoch": 2.0734939759036144,
      "grad_norm": 0.6024153232574463,
      "learning_rate": 2.4103915662650603e-06,
      "loss": 0.1625,
      "step": 3442
    },
    {
      "epoch": 2.074096385542169,
      "grad_norm": 0.5884382128715515,
      "learning_rate": 2.4096385542168676e-06,
      "loss": 0.1858,
      "step": 3443
    },
    {
      "epoch": 2.0746987951807228,
      "grad_norm": 0.5172635912895203,
      "learning_rate": 2.408885542168675e-06,
      "loss": 0.1395,
      "step": 3444
    },
    {
      "epoch": 2.075301204819277,
      "grad_norm": 0.5240135788917542,
      "learning_rate": 2.4081325301204823e-06,
      "loss": 0.1494,
      "step": 3445
    },
    {
      "epoch": 2.075903614457831,
      "grad_norm": 0.5318594574928284,
      "learning_rate": 2.4073795180722897e-06,
      "loss": 0.191,
      "step": 3446
    },
    {
      "epoch": 2.0765060240963855,
      "grad_norm": 0.6280199289321899,
      "learning_rate": 2.4066265060240966e-06,
      "loss": 0.2206,
      "step": 3447
    },
    {
      "epoch": 2.07710843373494,
      "grad_norm": 0.463093101978302,
      "learning_rate": 2.405873493975904e-06,
      "loss": 0.149,
      "step": 3448
    },
    {
      "epoch": 2.077710843373494,
      "grad_norm": 0.5811804533004761,
      "learning_rate": 2.405120481927711e-06,
      "loss": 0.2259,
      "step": 3449
    },
    {
      "epoch": 2.0783132530120483,
      "grad_norm": 0.5632022619247437,
      "learning_rate": 2.404367469879518e-06,
      "loss": 0.2095,
      "step": 3450
    },
    {
      "epoch": 2.0789156626506022,
      "grad_norm": 0.5511020421981812,
      "learning_rate": 2.4036144578313256e-06,
      "loss": 0.1995,
      "step": 3451
    },
    {
      "epoch": 2.0795180722891566,
      "grad_norm": 0.7040441632270813,
      "learning_rate": 2.402861445783133e-06,
      "loss": 0.1995,
      "step": 3452
    },
    {
      "epoch": 2.080120481927711,
      "grad_norm": 0.5687726736068726,
      "learning_rate": 2.40210843373494e-06,
      "loss": 0.1532,
      "step": 3453
    },
    {
      "epoch": 2.080722891566265,
      "grad_norm": 0.4874556362628937,
      "learning_rate": 2.401355421686747e-06,
      "loss": 0.1568,
      "step": 3454
    },
    {
      "epoch": 2.0813253012048194,
      "grad_norm": 1.4247658252716064,
      "learning_rate": 2.4006024096385545e-06,
      "loss": 0.1667,
      "step": 3455
    },
    {
      "epoch": 2.0819277108433734,
      "grad_norm": 0.6375276446342468,
      "learning_rate": 2.399849397590362e-06,
      "loss": 0.2173,
      "step": 3456
    },
    {
      "epoch": 2.0825301204819278,
      "grad_norm": 0.547387957572937,
      "learning_rate": 2.399096385542169e-06,
      "loss": 0.202,
      "step": 3457
    },
    {
      "epoch": 2.0831325301204817,
      "grad_norm": 0.6502662301063538,
      "learning_rate": 2.398343373493976e-06,
      "loss": 0.164,
      "step": 3458
    },
    {
      "epoch": 2.083734939759036,
      "grad_norm": 0.49439501762390137,
      "learning_rate": 2.397590361445783e-06,
      "loss": 0.1959,
      "step": 3459
    },
    {
      "epoch": 2.0843373493975905,
      "grad_norm": 0.5731000304222107,
      "learning_rate": 2.3968373493975904e-06,
      "loss": 0.1781,
      "step": 3460
    },
    {
      "epoch": 2.0849397590361445,
      "grad_norm": 0.4755123257637024,
      "learning_rate": 2.3960843373493978e-06,
      "loss": 0.1603,
      "step": 3461
    },
    {
      "epoch": 2.085542168674699,
      "grad_norm": 0.5319614410400391,
      "learning_rate": 2.395331325301205e-06,
      "loss": 0.1723,
      "step": 3462
    },
    {
      "epoch": 2.086144578313253,
      "grad_norm": 0.5046893358230591,
      "learning_rate": 2.3945783132530125e-06,
      "loss": 0.1657,
      "step": 3463
    },
    {
      "epoch": 2.0867469879518072,
      "grad_norm": 0.4577949643135071,
      "learning_rate": 2.3938253012048194e-06,
      "loss": 0.1862,
      "step": 3464
    },
    {
      "epoch": 2.0873493975903616,
      "grad_norm": 0.5816761255264282,
      "learning_rate": 2.3930722891566267e-06,
      "loss": 0.151,
      "step": 3465
    },
    {
      "epoch": 2.0879518072289156,
      "grad_norm": 0.5426065325737,
      "learning_rate": 2.3923192771084337e-06,
      "loss": 0.167,
      "step": 3466
    },
    {
      "epoch": 2.08855421686747,
      "grad_norm": 0.5660575032234192,
      "learning_rate": 2.391566265060241e-06,
      "loss": 0.1792,
      "step": 3467
    },
    {
      "epoch": 2.089156626506024,
      "grad_norm": 0.664172351360321,
      "learning_rate": 2.3908132530120484e-06,
      "loss": 0.1676,
      "step": 3468
    },
    {
      "epoch": 2.0897590361445784,
      "grad_norm": 0.5827385187149048,
      "learning_rate": 2.3900602409638557e-06,
      "loss": 0.1622,
      "step": 3469
    },
    {
      "epoch": 2.0903614457831323,
      "grad_norm": 0.6237558126449585,
      "learning_rate": 2.389307228915663e-06,
      "loss": 0.1869,
      "step": 3470
    },
    {
      "epoch": 2.0909638554216867,
      "grad_norm": 0.5121387839317322,
      "learning_rate": 2.38855421686747e-06,
      "loss": 0.1817,
      "step": 3471
    },
    {
      "epoch": 2.091566265060241,
      "grad_norm": 0.5562722682952881,
      "learning_rate": 2.3878012048192773e-06,
      "loss": 0.1918,
      "step": 3472
    },
    {
      "epoch": 2.092168674698795,
      "grad_norm": 0.5990578532218933,
      "learning_rate": 2.3870481927710847e-06,
      "loss": 0.1558,
      "step": 3473
    },
    {
      "epoch": 2.0927710843373495,
      "grad_norm": 0.47869834303855896,
      "learning_rate": 2.3862951807228916e-06,
      "loss": 0.1643,
      "step": 3474
    },
    {
      "epoch": 2.0933734939759034,
      "grad_norm": 0.6854106187820435,
      "learning_rate": 2.385542168674699e-06,
      "loss": 0.243,
      "step": 3475
    },
    {
      "epoch": 2.093975903614458,
      "grad_norm": 0.6239080429077148,
      "learning_rate": 2.3847891566265063e-06,
      "loss": 0.2029,
      "step": 3476
    },
    {
      "epoch": 2.0945783132530122,
      "grad_norm": 0.6067444682121277,
      "learning_rate": 2.3840361445783132e-06,
      "loss": 0.1736,
      "step": 3477
    },
    {
      "epoch": 2.095180722891566,
      "grad_norm": 0.5586827397346497,
      "learning_rate": 2.3832831325301206e-06,
      "loss": 0.1479,
      "step": 3478
    },
    {
      "epoch": 2.0957831325301206,
      "grad_norm": 0.49711716175079346,
      "learning_rate": 2.382530120481928e-06,
      "loss": 0.1833,
      "step": 3479
    },
    {
      "epoch": 2.0963855421686746,
      "grad_norm": 0.655230700969696,
      "learning_rate": 2.3817771084337353e-06,
      "loss": 0.1732,
      "step": 3480
    },
    {
      "epoch": 2.096987951807229,
      "grad_norm": 0.6368761658668518,
      "learning_rate": 2.3810240963855426e-06,
      "loss": 0.1554,
      "step": 3481
    },
    {
      "epoch": 2.097590361445783,
      "grad_norm": 0.5533215403556824,
      "learning_rate": 2.3802710843373495e-06,
      "loss": 0.1722,
      "step": 3482
    },
    {
      "epoch": 2.0981927710843373,
      "grad_norm": 0.5581807494163513,
      "learning_rate": 2.379518072289157e-06,
      "loss": 0.182,
      "step": 3483
    },
    {
      "epoch": 2.0987951807228917,
      "grad_norm": 0.48845478892326355,
      "learning_rate": 2.378765060240964e-06,
      "loss": 0.1621,
      "step": 3484
    },
    {
      "epoch": 2.0993975903614457,
      "grad_norm": 0.7095978856086731,
      "learning_rate": 2.378012048192771e-06,
      "loss": 0.2272,
      "step": 3485
    },
    {
      "epoch": 2.1,
      "grad_norm": 0.4966297447681427,
      "learning_rate": 2.3772590361445785e-06,
      "loss": 0.1683,
      "step": 3486
    },
    {
      "epoch": 2.100602409638554,
      "grad_norm": 0.6383998394012451,
      "learning_rate": 2.376506024096386e-06,
      "loss": 0.2095,
      "step": 3487
    },
    {
      "epoch": 2.1012048192771084,
      "grad_norm": 0.5428155660629272,
      "learning_rate": 2.375753012048193e-06,
      "loss": 0.1524,
      "step": 3488
    },
    {
      "epoch": 2.101807228915663,
      "grad_norm": 0.5404128432273865,
      "learning_rate": 2.375e-06,
      "loss": 0.1776,
      "step": 3489
    },
    {
      "epoch": 2.102409638554217,
      "grad_norm": 0.6569461226463318,
      "learning_rate": 2.3742469879518075e-06,
      "loss": 0.1783,
      "step": 3490
    },
    {
      "epoch": 2.103012048192771,
      "grad_norm": 0.4959549009799957,
      "learning_rate": 2.373493975903615e-06,
      "loss": 0.1499,
      "step": 3491
    },
    {
      "epoch": 2.103614457831325,
      "grad_norm": 0.48382899165153503,
      "learning_rate": 2.3727409638554218e-06,
      "loss": 0.1653,
      "step": 3492
    },
    {
      "epoch": 2.1042168674698796,
      "grad_norm": 0.5869998931884766,
      "learning_rate": 2.371987951807229e-06,
      "loss": 0.1692,
      "step": 3493
    },
    {
      "epoch": 2.1048192771084335,
      "grad_norm": 0.6048973798751831,
      "learning_rate": 2.3712349397590364e-06,
      "loss": 0.1847,
      "step": 3494
    },
    {
      "epoch": 2.105421686746988,
      "grad_norm": 0.5470077991485596,
      "learning_rate": 2.3704819277108434e-06,
      "loss": 0.1877,
      "step": 3495
    },
    {
      "epoch": 2.1060240963855423,
      "grad_norm": 0.503587007522583,
      "learning_rate": 2.3697289156626507e-06,
      "loss": 0.1389,
      "step": 3496
    },
    {
      "epoch": 2.1066265060240963,
      "grad_norm": 0.46715301275253296,
      "learning_rate": 2.368975903614458e-06,
      "loss": 0.1579,
      "step": 3497
    },
    {
      "epoch": 2.1072289156626507,
      "grad_norm": 0.5601235032081604,
      "learning_rate": 2.3682228915662654e-06,
      "loss": 0.1972,
      "step": 3498
    },
    {
      "epoch": 2.1078313253012047,
      "grad_norm": 0.5676539540290833,
      "learning_rate": 2.3674698795180723e-06,
      "loss": 0.1191,
      "step": 3499
    },
    {
      "epoch": 2.108433734939759,
      "grad_norm": 0.5360918045043945,
      "learning_rate": 2.3667168674698797e-06,
      "loss": 0.1608,
      "step": 3500
    },
    {
      "epoch": 2.1090361445783135,
      "grad_norm": 0.5535004138946533,
      "learning_rate": 2.3659638554216866e-06,
      "loss": 0.1951,
      "step": 3501
    },
    {
      "epoch": 2.1096385542168674,
      "grad_norm": 0.5310267806053162,
      "learning_rate": 2.365210843373494e-06,
      "loss": 0.1512,
      "step": 3502
    },
    {
      "epoch": 2.110240963855422,
      "grad_norm": 0.5406293869018555,
      "learning_rate": 2.3644578313253013e-06,
      "loss": 0.1864,
      "step": 3503
    },
    {
      "epoch": 2.1108433734939758,
      "grad_norm": 0.6057215332984924,
      "learning_rate": 2.3637048192771087e-06,
      "loss": 0.1963,
      "step": 3504
    },
    {
      "epoch": 2.11144578313253,
      "grad_norm": 0.7236614227294922,
      "learning_rate": 2.362951807228916e-06,
      "loss": 0.197,
      "step": 3505
    },
    {
      "epoch": 2.112048192771084,
      "grad_norm": 0.5220010876655579,
      "learning_rate": 2.3621987951807234e-06,
      "loss": 0.1716,
      "step": 3506
    },
    {
      "epoch": 2.1126506024096385,
      "grad_norm": 0.49033471941947937,
      "learning_rate": 2.3614457831325303e-06,
      "loss": 0.1487,
      "step": 3507
    },
    {
      "epoch": 2.113253012048193,
      "grad_norm": 0.66576087474823,
      "learning_rate": 2.3606927710843376e-06,
      "loss": 0.2023,
      "step": 3508
    },
    {
      "epoch": 2.113855421686747,
      "grad_norm": 0.5598342418670654,
      "learning_rate": 2.3599397590361446e-06,
      "loss": 0.2163,
      "step": 3509
    },
    {
      "epoch": 2.1144578313253013,
      "grad_norm": 0.6270653009414673,
      "learning_rate": 2.359186746987952e-06,
      "loss": 0.1776,
      "step": 3510
    },
    {
      "epoch": 2.1150602409638553,
      "grad_norm": 0.6548855900764465,
      "learning_rate": 2.3584337349397593e-06,
      "loss": 0.1136,
      "step": 3511
    },
    {
      "epoch": 2.1156626506024097,
      "grad_norm": 0.7157778739929199,
      "learning_rate": 2.3576807228915666e-06,
      "loss": 0.198,
      "step": 3512
    },
    {
      "epoch": 2.116265060240964,
      "grad_norm": 0.7166957259178162,
      "learning_rate": 2.3569277108433735e-06,
      "loss": 0.2133,
      "step": 3513
    },
    {
      "epoch": 2.116867469879518,
      "grad_norm": 0.5349072813987732,
      "learning_rate": 2.356174698795181e-06,
      "loss": 0.1607,
      "step": 3514
    },
    {
      "epoch": 2.1174698795180724,
      "grad_norm": 0.5410184264183044,
      "learning_rate": 2.3554216867469882e-06,
      "loss": 0.1882,
      "step": 3515
    },
    {
      "epoch": 2.1180722891566264,
      "grad_norm": 0.5990451574325562,
      "learning_rate": 2.3546686746987956e-06,
      "loss": 0.2011,
      "step": 3516
    },
    {
      "epoch": 2.1186746987951808,
      "grad_norm": 0.48308420181274414,
      "learning_rate": 2.3539156626506025e-06,
      "loss": 0.1573,
      "step": 3517
    },
    {
      "epoch": 2.1192771084337347,
      "grad_norm": 0.6299652457237244,
      "learning_rate": 2.35316265060241e-06,
      "loss": 0.2125,
      "step": 3518
    },
    {
      "epoch": 2.119879518072289,
      "grad_norm": 0.49395307898521423,
      "learning_rate": 2.3524096385542168e-06,
      "loss": 0.1687,
      "step": 3519
    },
    {
      "epoch": 2.1204819277108435,
      "grad_norm": 0.6449525356292725,
      "learning_rate": 2.351656626506024e-06,
      "loss": 0.1497,
      "step": 3520
    },
    {
      "epoch": 2.1210843373493975,
      "grad_norm": 0.6737229228019714,
      "learning_rate": 2.3509036144578315e-06,
      "loss": 0.2148,
      "step": 3521
    },
    {
      "epoch": 2.121686746987952,
      "grad_norm": 0.5979295372962952,
      "learning_rate": 2.350150602409639e-06,
      "loss": 0.172,
      "step": 3522
    },
    {
      "epoch": 2.122289156626506,
      "grad_norm": 0.6449459791183472,
      "learning_rate": 2.349397590361446e-06,
      "loss": 0.266,
      "step": 3523
    },
    {
      "epoch": 2.1228915662650603,
      "grad_norm": 0.4009864330291748,
      "learning_rate": 2.3486445783132535e-06,
      "loss": 0.1376,
      "step": 3524
    },
    {
      "epoch": 2.1234939759036147,
      "grad_norm": 0.5749833583831787,
      "learning_rate": 2.3478915662650604e-06,
      "loss": 0.1866,
      "step": 3525
    },
    {
      "epoch": 2.1240963855421686,
      "grad_norm": 0.4612143635749817,
      "learning_rate": 2.3471385542168678e-06,
      "loss": 0.1571,
      "step": 3526
    },
    {
      "epoch": 2.124698795180723,
      "grad_norm": 0.6197301149368286,
      "learning_rate": 2.3463855421686747e-06,
      "loss": 0.1865,
      "step": 3527
    },
    {
      "epoch": 2.125301204819277,
      "grad_norm": 0.5219976902008057,
      "learning_rate": 2.345632530120482e-06,
      "loss": 0.1835,
      "step": 3528
    },
    {
      "epoch": 2.1259036144578314,
      "grad_norm": 0.5138671398162842,
      "learning_rate": 2.3448795180722894e-06,
      "loss": 0.1366,
      "step": 3529
    },
    {
      "epoch": 2.1265060240963853,
      "grad_norm": 0.510458767414093,
      "learning_rate": 2.3441265060240968e-06,
      "loss": 0.182,
      "step": 3530
    },
    {
      "epoch": 2.1271084337349397,
      "grad_norm": 0.4939744174480438,
      "learning_rate": 2.3433734939759037e-06,
      "loss": 0.156,
      "step": 3531
    },
    {
      "epoch": 2.127710843373494,
      "grad_norm": 0.53229159116745,
      "learning_rate": 2.342620481927711e-06,
      "loss": 0.2086,
      "step": 3532
    },
    {
      "epoch": 2.128313253012048,
      "grad_norm": 0.5224921107292175,
      "learning_rate": 2.3418674698795184e-06,
      "loss": 0.1913,
      "step": 3533
    },
    {
      "epoch": 2.1289156626506025,
      "grad_norm": 0.4937300384044647,
      "learning_rate": 2.3411144578313257e-06,
      "loss": 0.1632,
      "step": 3534
    },
    {
      "epoch": 2.1295180722891565,
      "grad_norm": 0.4979749023914337,
      "learning_rate": 2.3403614457831327e-06,
      "loss": 0.1473,
      "step": 3535
    },
    {
      "epoch": 2.130120481927711,
      "grad_norm": 0.4827873408794403,
      "learning_rate": 2.33960843373494e-06,
      "loss": 0.1646,
      "step": 3536
    },
    {
      "epoch": 2.1307228915662653,
      "grad_norm": 0.5143129825592041,
      "learning_rate": 2.338855421686747e-06,
      "loss": 0.1727,
      "step": 3537
    },
    {
      "epoch": 2.1313253012048192,
      "grad_norm": 0.5243656635284424,
      "learning_rate": 2.3381024096385543e-06,
      "loss": 0.1677,
      "step": 3538
    },
    {
      "epoch": 2.1319277108433736,
      "grad_norm": 0.5855850577354431,
      "learning_rate": 2.3373493975903616e-06,
      "loss": 0.1863,
      "step": 3539
    },
    {
      "epoch": 2.1325301204819276,
      "grad_norm": 0.6830323934555054,
      "learning_rate": 2.336596385542169e-06,
      "loss": 0.1799,
      "step": 3540
    },
    {
      "epoch": 2.133132530120482,
      "grad_norm": 0.6049726605415344,
      "learning_rate": 2.3358433734939763e-06,
      "loss": 0.1602,
      "step": 3541
    },
    {
      "epoch": 2.133734939759036,
      "grad_norm": 0.5096325874328613,
      "learning_rate": 2.3350903614457832e-06,
      "loss": 0.1834,
      "step": 3542
    },
    {
      "epoch": 2.1343373493975903,
      "grad_norm": 0.5364909768104553,
      "learning_rate": 2.3343373493975906e-06,
      "loss": 0.1598,
      "step": 3543
    },
    {
      "epoch": 2.1349397590361447,
      "grad_norm": 0.6329699754714966,
      "learning_rate": 2.3335843373493975e-06,
      "loss": 0.2128,
      "step": 3544
    },
    {
      "epoch": 2.1355421686746987,
      "grad_norm": 0.48746585845947266,
      "learning_rate": 2.332831325301205e-06,
      "loss": 0.1528,
      "step": 3545
    },
    {
      "epoch": 2.136144578313253,
      "grad_norm": 0.6619240045547485,
      "learning_rate": 2.3320783132530122e-06,
      "loss": 0.1829,
      "step": 3546
    },
    {
      "epoch": 2.136746987951807,
      "grad_norm": 0.49120229482650757,
      "learning_rate": 2.3313253012048196e-06,
      "loss": 0.1483,
      "step": 3547
    },
    {
      "epoch": 2.1373493975903615,
      "grad_norm": 0.4730915427207947,
      "learning_rate": 2.330572289156627e-06,
      "loss": 0.1891,
      "step": 3548
    },
    {
      "epoch": 2.137951807228916,
      "grad_norm": 0.6151455640792847,
      "learning_rate": 2.329819277108434e-06,
      "loss": 0.2379,
      "step": 3549
    },
    {
      "epoch": 2.13855421686747,
      "grad_norm": 0.5044475197792053,
      "learning_rate": 2.329066265060241e-06,
      "loss": 0.1701,
      "step": 3550
    },
    {
      "epoch": 2.1391566265060242,
      "grad_norm": 0.5926870703697205,
      "learning_rate": 2.3283132530120485e-06,
      "loss": 0.126,
      "step": 3551
    },
    {
      "epoch": 2.139759036144578,
      "grad_norm": 0.4703878164291382,
      "learning_rate": 2.3275602409638555e-06,
      "loss": 0.1305,
      "step": 3552
    },
    {
      "epoch": 2.1403614457831326,
      "grad_norm": 1.3887834548950195,
      "learning_rate": 2.326807228915663e-06,
      "loss": 0.1847,
      "step": 3553
    },
    {
      "epoch": 2.1409638554216865,
      "grad_norm": 0.6166972517967224,
      "learning_rate": 2.32605421686747e-06,
      "loss": 0.2211,
      "step": 3554
    },
    {
      "epoch": 2.141566265060241,
      "grad_norm": 0.5280343294143677,
      "learning_rate": 2.325301204819277e-06,
      "loss": 0.1768,
      "step": 3555
    },
    {
      "epoch": 2.1421686746987953,
      "grad_norm": 0.606187641620636,
      "learning_rate": 2.3245481927710844e-06,
      "loss": 0.1859,
      "step": 3556
    },
    {
      "epoch": 2.1427710843373493,
      "grad_norm": 0.5437409281730652,
      "learning_rate": 2.3237951807228918e-06,
      "loss": 0.1483,
      "step": 3557
    },
    {
      "epoch": 2.1433734939759037,
      "grad_norm": 0.5502442121505737,
      "learning_rate": 2.323042168674699e-06,
      "loss": 0.1896,
      "step": 3558
    },
    {
      "epoch": 2.1439759036144577,
      "grad_norm": 0.5913944840431213,
      "learning_rate": 2.3222891566265065e-06,
      "loss": 0.2005,
      "step": 3559
    },
    {
      "epoch": 2.144578313253012,
      "grad_norm": 0.5569299459457397,
      "learning_rate": 2.3215361445783134e-06,
      "loss": 0.1779,
      "step": 3560
    },
    {
      "epoch": 2.1451807228915665,
      "grad_norm": 0.4895709455013275,
      "learning_rate": 2.3207831325301207e-06,
      "loss": 0.149,
      "step": 3561
    },
    {
      "epoch": 2.1457831325301204,
      "grad_norm": 0.9451467394828796,
      "learning_rate": 2.3200301204819277e-06,
      "loss": 0.1644,
      "step": 3562
    },
    {
      "epoch": 2.146385542168675,
      "grad_norm": 0.501609742641449,
      "learning_rate": 2.319277108433735e-06,
      "loss": 0.1627,
      "step": 3563
    },
    {
      "epoch": 2.146987951807229,
      "grad_norm": 0.5167017579078674,
      "learning_rate": 2.3185240963855424e-06,
      "loss": 0.1266,
      "step": 3564
    },
    {
      "epoch": 2.147590361445783,
      "grad_norm": 0.5777844786643982,
      "learning_rate": 2.3177710843373497e-06,
      "loss": 0.1926,
      "step": 3565
    },
    {
      "epoch": 2.148192771084337,
      "grad_norm": 0.6201580166816711,
      "learning_rate": 2.317018072289157e-06,
      "loss": 0.1869,
      "step": 3566
    },
    {
      "epoch": 2.1487951807228916,
      "grad_norm": 0.6073698401451111,
      "learning_rate": 2.316265060240964e-06,
      "loss": 0.1601,
      "step": 3567
    },
    {
      "epoch": 2.149397590361446,
      "grad_norm": 0.5093387961387634,
      "learning_rate": 2.3155120481927713e-06,
      "loss": 0.1495,
      "step": 3568
    },
    {
      "epoch": 2.15,
      "grad_norm": 0.5213432312011719,
      "learning_rate": 2.3147590361445787e-06,
      "loss": 0.179,
      "step": 3569
    },
    {
      "epoch": 2.1506024096385543,
      "grad_norm": 0.5774011015892029,
      "learning_rate": 2.3140060240963856e-06,
      "loss": 0.1674,
      "step": 3570
    },
    {
      "epoch": 2.1512048192771083,
      "grad_norm": 0.48480725288391113,
      "learning_rate": 2.313253012048193e-06,
      "loss": 0.1651,
      "step": 3571
    },
    {
      "epoch": 2.1518072289156627,
      "grad_norm": 0.5396303534507751,
      "learning_rate": 2.3125000000000003e-06,
      "loss": 0.1364,
      "step": 3572
    },
    {
      "epoch": 2.152409638554217,
      "grad_norm": 0.4807904064655304,
      "learning_rate": 2.3117469879518072e-06,
      "loss": 0.1805,
      "step": 3573
    },
    {
      "epoch": 2.153012048192771,
      "grad_norm": 0.5381886959075928,
      "learning_rate": 2.3109939759036146e-06,
      "loss": 0.1894,
      "step": 3574
    },
    {
      "epoch": 2.1536144578313254,
      "grad_norm": 0.48124992847442627,
      "learning_rate": 2.310240963855422e-06,
      "loss": 0.1536,
      "step": 3575
    },
    {
      "epoch": 2.1542168674698794,
      "grad_norm": 0.5635653734207153,
      "learning_rate": 2.3094879518072293e-06,
      "loss": 0.1662,
      "step": 3576
    },
    {
      "epoch": 2.154819277108434,
      "grad_norm": 0.6474276781082153,
      "learning_rate": 2.308734939759036e-06,
      "loss": 0.2452,
      "step": 3577
    },
    {
      "epoch": 2.1554216867469878,
      "grad_norm": 0.5255497097969055,
      "learning_rate": 2.3079819277108435e-06,
      "loss": 0.1669,
      "step": 3578
    },
    {
      "epoch": 2.156024096385542,
      "grad_norm": 0.5250255465507507,
      "learning_rate": 2.3072289156626505e-06,
      "loss": 0.1746,
      "step": 3579
    },
    {
      "epoch": 2.1566265060240966,
      "grad_norm": 0.5627350211143494,
      "learning_rate": 2.306475903614458e-06,
      "loss": 0.1719,
      "step": 3580
    },
    {
      "epoch": 2.1572289156626505,
      "grad_norm": 1.8900805711746216,
      "learning_rate": 2.305722891566265e-06,
      "loss": 0.1618,
      "step": 3581
    },
    {
      "epoch": 2.157831325301205,
      "grad_norm": 0.5221740007400513,
      "learning_rate": 2.3049698795180725e-06,
      "loss": 0.1423,
      "step": 3582
    },
    {
      "epoch": 2.158433734939759,
      "grad_norm": 0.5426338315010071,
      "learning_rate": 2.30421686746988e-06,
      "loss": 0.1426,
      "step": 3583
    },
    {
      "epoch": 2.1590361445783133,
      "grad_norm": 0.6196458339691162,
      "learning_rate": 2.3034638554216872e-06,
      "loss": 0.2058,
      "step": 3584
    },
    {
      "epoch": 2.1596385542168672,
      "grad_norm": 0.43881186842918396,
      "learning_rate": 2.302710843373494e-06,
      "loss": 0.1584,
      "step": 3585
    },
    {
      "epoch": 2.1602409638554216,
      "grad_norm": 0.47708213329315186,
      "learning_rate": 2.3019578313253015e-06,
      "loss": 0.1442,
      "step": 3586
    },
    {
      "epoch": 2.160843373493976,
      "grad_norm": 0.5402153730392456,
      "learning_rate": 2.3012048192771084e-06,
      "loss": 0.1814,
      "step": 3587
    },
    {
      "epoch": 2.16144578313253,
      "grad_norm": 0.5369868278503418,
      "learning_rate": 2.3004518072289158e-06,
      "loss": 0.1451,
      "step": 3588
    },
    {
      "epoch": 2.1620481927710844,
      "grad_norm": 0.5417331457138062,
      "learning_rate": 2.299698795180723e-06,
      "loss": 0.1763,
      "step": 3589
    },
    {
      "epoch": 2.1626506024096384,
      "grad_norm": 0.5142738819122314,
      "learning_rate": 2.2989457831325305e-06,
      "loss": 0.1758,
      "step": 3590
    },
    {
      "epoch": 2.1632530120481928,
      "grad_norm": 0.5879736542701721,
      "learning_rate": 2.2981927710843374e-06,
      "loss": 0.163,
      "step": 3591
    },
    {
      "epoch": 2.163855421686747,
      "grad_norm": 0.4205372631549835,
      "learning_rate": 2.2974397590361447e-06,
      "loss": 0.1446,
      "step": 3592
    },
    {
      "epoch": 2.164457831325301,
      "grad_norm": 0.5825233459472656,
      "learning_rate": 2.296686746987952e-06,
      "loss": 0.1351,
      "step": 3593
    },
    {
      "epoch": 2.1650602409638555,
      "grad_norm": 0.48456528782844543,
      "learning_rate": 2.2959337349397594e-06,
      "loss": 0.1546,
      "step": 3594
    },
    {
      "epoch": 2.1656626506024095,
      "grad_norm": 0.7163540124893188,
      "learning_rate": 2.2951807228915664e-06,
      "loss": 0.1572,
      "step": 3595
    },
    {
      "epoch": 2.166265060240964,
      "grad_norm": 0.6129399538040161,
      "learning_rate": 2.2944277108433737e-06,
      "loss": 0.1721,
      "step": 3596
    },
    {
      "epoch": 2.1668674698795183,
      "grad_norm": 0.45240136981010437,
      "learning_rate": 2.2936746987951806e-06,
      "loss": 0.1643,
      "step": 3597
    },
    {
      "epoch": 2.1674698795180722,
      "grad_norm": 1.8161901235580444,
      "learning_rate": 2.292921686746988e-06,
      "loss": 0.2293,
      "step": 3598
    },
    {
      "epoch": 2.1680722891566266,
      "grad_norm": 0.5999189019203186,
      "learning_rate": 2.2921686746987953e-06,
      "loss": 0.1881,
      "step": 3599
    },
    {
      "epoch": 2.1686746987951806,
      "grad_norm": 0.5600195527076721,
      "learning_rate": 2.2914156626506027e-06,
      "loss": 0.1925,
      "step": 3600
    },
    {
      "epoch": 2.169277108433735,
      "grad_norm": 0.4356423318386078,
      "learning_rate": 2.29066265060241e-06,
      "loss": 0.1478,
      "step": 3601
    },
    {
      "epoch": 2.169879518072289,
      "grad_norm": 0.580790638923645,
      "learning_rate": 2.2899096385542174e-06,
      "loss": 0.2041,
      "step": 3602
    },
    {
      "epoch": 2.1704819277108434,
      "grad_norm": 0.5405210852622986,
      "learning_rate": 2.2891566265060243e-06,
      "loss": 0.1465,
      "step": 3603
    },
    {
      "epoch": 2.1710843373493978,
      "grad_norm": 0.6043232083320618,
      "learning_rate": 2.2884036144578316e-06,
      "loss": 0.1939,
      "step": 3604
    },
    {
      "epoch": 2.1716867469879517,
      "grad_norm": 0.4683106541633606,
      "learning_rate": 2.2876506024096386e-06,
      "loss": 0.1609,
      "step": 3605
    },
    {
      "epoch": 2.172289156626506,
      "grad_norm": 0.5264662504196167,
      "learning_rate": 2.286897590361446e-06,
      "loss": 0.1724,
      "step": 3606
    },
    {
      "epoch": 2.17289156626506,
      "grad_norm": 0.5616036653518677,
      "learning_rate": 2.2861445783132533e-06,
      "loss": 0.1918,
      "step": 3607
    },
    {
      "epoch": 2.1734939759036145,
      "grad_norm": 0.5167319774627686,
      "learning_rate": 2.2853915662650606e-06,
      "loss": 0.1517,
      "step": 3608
    },
    {
      "epoch": 2.1740963855421684,
      "grad_norm": 0.593604564666748,
      "learning_rate": 2.2846385542168675e-06,
      "loss": 0.2067,
      "step": 3609
    },
    {
      "epoch": 2.174698795180723,
      "grad_norm": 0.6770036220550537,
      "learning_rate": 2.283885542168675e-06,
      "loss": 0.2117,
      "step": 3610
    },
    {
      "epoch": 2.1753012048192772,
      "grad_norm": 0.5357100963592529,
      "learning_rate": 2.2831325301204822e-06,
      "loss": 0.1441,
      "step": 3611
    },
    {
      "epoch": 2.175903614457831,
      "grad_norm": 0.5643417239189148,
      "learning_rate": 2.282379518072289e-06,
      "loss": 0.193,
      "step": 3612
    },
    {
      "epoch": 2.1765060240963856,
      "grad_norm": 1.0013219118118286,
      "learning_rate": 2.2816265060240965e-06,
      "loss": 0.1901,
      "step": 3613
    },
    {
      "epoch": 2.1771084337349396,
      "grad_norm": 0.49362605810165405,
      "learning_rate": 2.280873493975904e-06,
      "loss": 0.1727,
      "step": 3614
    },
    {
      "epoch": 2.177710843373494,
      "grad_norm": 0.5564943552017212,
      "learning_rate": 2.2801204819277108e-06,
      "loss": 0.1513,
      "step": 3615
    },
    {
      "epoch": 2.1783132530120484,
      "grad_norm": 0.4228406846523285,
      "learning_rate": 2.279367469879518e-06,
      "loss": 0.1483,
      "step": 3616
    },
    {
      "epoch": 2.1789156626506023,
      "grad_norm": 0.46256688237190247,
      "learning_rate": 2.2786144578313255e-06,
      "loss": 0.1446,
      "step": 3617
    },
    {
      "epoch": 2.1795180722891567,
      "grad_norm": 0.5175780057907104,
      "learning_rate": 2.277861445783133e-06,
      "loss": 0.1608,
      "step": 3618
    },
    {
      "epoch": 2.1801204819277107,
      "grad_norm": 4.740566730499268,
      "learning_rate": 2.27710843373494e-06,
      "loss": 0.223,
      "step": 3619
    },
    {
      "epoch": 2.180722891566265,
      "grad_norm": 0.547705888748169,
      "learning_rate": 2.276355421686747e-06,
      "loss": 0.1933,
      "step": 3620
    },
    {
      "epoch": 2.1813253012048195,
      "grad_norm": 0.9706922173500061,
      "learning_rate": 2.2756024096385544e-06,
      "loss": 0.2196,
      "step": 3621
    },
    {
      "epoch": 2.1819277108433734,
      "grad_norm": 0.5663418769836426,
      "learning_rate": 2.2748493975903614e-06,
      "loss": 0.1942,
      "step": 3622
    },
    {
      "epoch": 2.182530120481928,
      "grad_norm": 0.5023713707923889,
      "learning_rate": 2.2740963855421687e-06,
      "loss": 0.1703,
      "step": 3623
    },
    {
      "epoch": 2.183132530120482,
      "grad_norm": 0.5954869389533997,
      "learning_rate": 2.273343373493976e-06,
      "loss": 0.2103,
      "step": 3624
    },
    {
      "epoch": 2.183734939759036,
      "grad_norm": 0.48739704489707947,
      "learning_rate": 2.2725903614457834e-06,
      "loss": 0.1579,
      "step": 3625
    },
    {
      "epoch": 2.18433734939759,
      "grad_norm": 0.48975902795791626,
      "learning_rate": 2.2718373493975908e-06,
      "loss": 0.1398,
      "step": 3626
    },
    {
      "epoch": 2.1849397590361446,
      "grad_norm": 0.5857231020927429,
      "learning_rate": 2.2710843373493977e-06,
      "loss": 0.2064,
      "step": 3627
    },
    {
      "epoch": 2.185542168674699,
      "grad_norm": 0.48798611760139465,
      "learning_rate": 2.270331325301205e-06,
      "loss": 0.1555,
      "step": 3628
    },
    {
      "epoch": 2.186144578313253,
      "grad_norm": 0.6903200745582581,
      "learning_rate": 2.2695783132530124e-06,
      "loss": 0.1854,
      "step": 3629
    },
    {
      "epoch": 2.1867469879518073,
      "grad_norm": 0.5016528964042664,
      "learning_rate": 2.2688253012048193e-06,
      "loss": 0.171,
      "step": 3630
    },
    {
      "epoch": 2.1873493975903613,
      "grad_norm": 0.5591575503349304,
      "learning_rate": 2.2680722891566267e-06,
      "loss": 0.1696,
      "step": 3631
    },
    {
      "epoch": 2.1879518072289157,
      "grad_norm": 0.5952154397964478,
      "learning_rate": 2.267319277108434e-06,
      "loss": 0.2086,
      "step": 3632
    },
    {
      "epoch": 2.1885542168674696,
      "grad_norm": 0.46930667757987976,
      "learning_rate": 2.266566265060241e-06,
      "loss": 0.1505,
      "step": 3633
    },
    {
      "epoch": 2.189156626506024,
      "grad_norm": 0.5484940409660339,
      "learning_rate": 2.2658132530120483e-06,
      "loss": 0.1744,
      "step": 3634
    },
    {
      "epoch": 2.1897590361445785,
      "grad_norm": 0.5978969931602478,
      "learning_rate": 2.2650602409638556e-06,
      "loss": 0.1697,
      "step": 3635
    },
    {
      "epoch": 2.1903614457831324,
      "grad_norm": 0.620206892490387,
      "learning_rate": 2.264307228915663e-06,
      "loss": 0.1764,
      "step": 3636
    },
    {
      "epoch": 2.190963855421687,
      "grad_norm": 0.45103636384010315,
      "learning_rate": 2.2635542168674703e-06,
      "loss": 0.1707,
      "step": 3637
    },
    {
      "epoch": 2.1915662650602408,
      "grad_norm": 0.6715410947799683,
      "learning_rate": 2.2628012048192773e-06,
      "loss": 0.2509,
      "step": 3638
    },
    {
      "epoch": 2.192168674698795,
      "grad_norm": 0.4748251140117645,
      "learning_rate": 2.2620481927710846e-06,
      "loss": 0.1661,
      "step": 3639
    },
    {
      "epoch": 2.1927710843373496,
      "grad_norm": 0.4611234664916992,
      "learning_rate": 2.2612951807228915e-06,
      "loss": 0.1572,
      "step": 3640
    },
    {
      "epoch": 2.1933734939759035,
      "grad_norm": 0.48826178908348083,
      "learning_rate": 2.260542168674699e-06,
      "loss": 0.1326,
      "step": 3641
    },
    {
      "epoch": 2.193975903614458,
      "grad_norm": 0.5303505659103394,
      "learning_rate": 2.2597891566265062e-06,
      "loss": 0.1728,
      "step": 3642
    },
    {
      "epoch": 2.194578313253012,
      "grad_norm": 0.47306379675865173,
      "learning_rate": 2.2590361445783136e-06,
      "loss": 0.1528,
      "step": 3643
    },
    {
      "epoch": 2.1951807228915663,
      "grad_norm": 0.5569709539413452,
      "learning_rate": 2.258283132530121e-06,
      "loss": 0.1788,
      "step": 3644
    },
    {
      "epoch": 2.1957831325301207,
      "grad_norm": 0.49703559279441833,
      "learning_rate": 2.257530120481928e-06,
      "loss": 0.1835,
      "step": 3645
    },
    {
      "epoch": 2.1963855421686747,
      "grad_norm": 0.5565189719200134,
      "learning_rate": 2.256777108433735e-06,
      "loss": 0.1907,
      "step": 3646
    },
    {
      "epoch": 2.196987951807229,
      "grad_norm": 1.7780036926269531,
      "learning_rate": 2.256024096385542e-06,
      "loss": 0.1662,
      "step": 3647
    },
    {
      "epoch": 2.197590361445783,
      "grad_norm": 0.5134896039962769,
      "learning_rate": 2.2552710843373495e-06,
      "loss": 0.1642,
      "step": 3648
    },
    {
      "epoch": 2.1981927710843374,
      "grad_norm": 0.5004843473434448,
      "learning_rate": 2.254518072289157e-06,
      "loss": 0.158,
      "step": 3649
    },
    {
      "epoch": 2.1987951807228914,
      "grad_norm": 0.4906473457813263,
      "learning_rate": 2.253765060240964e-06,
      "loss": 0.1361,
      "step": 3650
    },
    {
      "epoch": 2.1993975903614458,
      "grad_norm": 0.6850360631942749,
      "learning_rate": 2.253012048192771e-06,
      "loss": 0.2092,
      "step": 3651
    },
    {
      "epoch": 2.2,
      "grad_norm": 0.5224124193191528,
      "learning_rate": 2.2522590361445784e-06,
      "loss": 0.1497,
      "step": 3652
    },
    {
      "epoch": 2.200602409638554,
      "grad_norm": 0.7108229398727417,
      "learning_rate": 2.2515060240963858e-06,
      "loss": 0.1545,
      "step": 3653
    },
    {
      "epoch": 2.2012048192771085,
      "grad_norm": 0.4642769992351532,
      "learning_rate": 2.250753012048193e-06,
      "loss": 0.1317,
      "step": 3654
    },
    {
      "epoch": 2.2018072289156625,
      "grad_norm": 0.6204792261123657,
      "learning_rate": 2.25e-06,
      "loss": 0.2174,
      "step": 3655
    },
    {
      "epoch": 2.202409638554217,
      "grad_norm": 0.5177855491638184,
      "learning_rate": 2.2492469879518074e-06,
      "loss": 0.1549,
      "step": 3656
    },
    {
      "epoch": 2.203012048192771,
      "grad_norm": 0.537735641002655,
      "learning_rate": 2.2484939759036143e-06,
      "loss": 0.1608,
      "step": 3657
    },
    {
      "epoch": 2.2036144578313253,
      "grad_norm": 0.5618892908096313,
      "learning_rate": 2.2477409638554217e-06,
      "loss": 0.1383,
      "step": 3658
    },
    {
      "epoch": 2.2042168674698797,
      "grad_norm": 0.632786750793457,
      "learning_rate": 2.246987951807229e-06,
      "loss": 0.2049,
      "step": 3659
    },
    {
      "epoch": 2.2048192771084336,
      "grad_norm": 0.5739105939865112,
      "learning_rate": 2.2462349397590364e-06,
      "loss": 0.2093,
      "step": 3660
    },
    {
      "epoch": 2.205421686746988,
      "grad_norm": 0.5190401673316956,
      "learning_rate": 2.2454819277108437e-06,
      "loss": 0.1373,
      "step": 3661
    },
    {
      "epoch": 2.206024096385542,
      "grad_norm": 0.4992542564868927,
      "learning_rate": 2.244728915662651e-06,
      "loss": 0.1575,
      "step": 3662
    },
    {
      "epoch": 2.2066265060240964,
      "grad_norm": 0.6307022571563721,
      "learning_rate": 2.243975903614458e-06,
      "loss": 0.1438,
      "step": 3663
    },
    {
      "epoch": 2.207228915662651,
      "grad_norm": 0.5718417763710022,
      "learning_rate": 2.2432228915662653e-06,
      "loss": 0.1798,
      "step": 3664
    },
    {
      "epoch": 2.2078313253012047,
      "grad_norm": 0.5644486546516418,
      "learning_rate": 2.2424698795180723e-06,
      "loss": 0.2044,
      "step": 3665
    },
    {
      "epoch": 2.208433734939759,
      "grad_norm": 0.5669780373573303,
      "learning_rate": 2.2417168674698796e-06,
      "loss": 0.1706,
      "step": 3666
    },
    {
      "epoch": 2.209036144578313,
      "grad_norm": 0.5415276885032654,
      "learning_rate": 2.240963855421687e-06,
      "loss": 0.1985,
      "step": 3667
    },
    {
      "epoch": 2.2096385542168675,
      "grad_norm": 0.5422386527061462,
      "learning_rate": 2.2402108433734943e-06,
      "loss": 0.1835,
      "step": 3668
    },
    {
      "epoch": 2.210240963855422,
      "grad_norm": 0.5576711297035217,
      "learning_rate": 2.2394578313253012e-06,
      "loss": 0.192,
      "step": 3669
    },
    {
      "epoch": 2.210843373493976,
      "grad_norm": 0.6019232273101807,
      "learning_rate": 2.2387048192771086e-06,
      "loss": 0.1697,
      "step": 3670
    },
    {
      "epoch": 2.2114457831325303,
      "grad_norm": 0.5286216735839844,
      "learning_rate": 2.237951807228916e-06,
      "loss": 0.1446,
      "step": 3671
    },
    {
      "epoch": 2.212048192771084,
      "grad_norm": 0.5379740595817566,
      "learning_rate": 2.2371987951807233e-06,
      "loss": 0.1668,
      "step": 3672
    },
    {
      "epoch": 2.2126506024096386,
      "grad_norm": 0.6738650798797607,
      "learning_rate": 2.23644578313253e-06,
      "loss": 0.2178,
      "step": 3673
    },
    {
      "epoch": 2.2132530120481926,
      "grad_norm": 0.5061847567558289,
      "learning_rate": 2.2356927710843376e-06,
      "loss": 0.1554,
      "step": 3674
    },
    {
      "epoch": 2.213855421686747,
      "grad_norm": 0.4315747916698456,
      "learning_rate": 2.2349397590361445e-06,
      "loss": 0.1563,
      "step": 3675
    },
    {
      "epoch": 2.2144578313253014,
      "grad_norm": 0.5610545873641968,
      "learning_rate": 2.234186746987952e-06,
      "loss": 0.163,
      "step": 3676
    },
    {
      "epoch": 2.2150602409638553,
      "grad_norm": 0.5101777911186218,
      "learning_rate": 2.233433734939759e-06,
      "loss": 0.1884,
      "step": 3677
    },
    {
      "epoch": 2.2156626506024097,
      "grad_norm": 0.5769356489181519,
      "learning_rate": 2.2326807228915665e-06,
      "loss": 0.159,
      "step": 3678
    },
    {
      "epoch": 2.2162650602409637,
      "grad_norm": 0.5719647407531738,
      "learning_rate": 2.231927710843374e-06,
      "loss": 0.1561,
      "step": 3679
    },
    {
      "epoch": 2.216867469879518,
      "grad_norm": 0.5434595346450806,
      "learning_rate": 2.231174698795181e-06,
      "loss": 0.1562,
      "step": 3680
    },
    {
      "epoch": 2.217469879518072,
      "grad_norm": 0.5537197589874268,
      "learning_rate": 2.230421686746988e-06,
      "loss": 0.1601,
      "step": 3681
    },
    {
      "epoch": 2.2180722891566265,
      "grad_norm": 0.48412734270095825,
      "learning_rate": 2.229668674698795e-06,
      "loss": 0.1537,
      "step": 3682
    },
    {
      "epoch": 2.218674698795181,
      "grad_norm": 0.5210707187652588,
      "learning_rate": 2.2289156626506024e-06,
      "loss": 0.1512,
      "step": 3683
    },
    {
      "epoch": 2.219277108433735,
      "grad_norm": 0.49674978852272034,
      "learning_rate": 2.2281626506024098e-06,
      "loss": 0.1734,
      "step": 3684
    },
    {
      "epoch": 2.2198795180722892,
      "grad_norm": 0.5264500379562378,
      "learning_rate": 2.227409638554217e-06,
      "loss": 0.1616,
      "step": 3685
    },
    {
      "epoch": 2.220481927710843,
      "grad_norm": 0.5060766935348511,
      "learning_rate": 2.2266566265060245e-06,
      "loss": 0.173,
      "step": 3686
    },
    {
      "epoch": 2.2210843373493976,
      "grad_norm": 0.5363143086433411,
      "learning_rate": 2.2259036144578314e-06,
      "loss": 0.1685,
      "step": 3687
    },
    {
      "epoch": 2.221686746987952,
      "grad_norm": 0.5398833751678467,
      "learning_rate": 2.2251506024096387e-06,
      "loss": 0.1479,
      "step": 3688
    },
    {
      "epoch": 2.222289156626506,
      "grad_norm": 0.5527290105819702,
      "learning_rate": 2.224397590361446e-06,
      "loss": 0.1753,
      "step": 3689
    },
    {
      "epoch": 2.2228915662650603,
      "grad_norm": 0.6309878826141357,
      "learning_rate": 2.223644578313253e-06,
      "loss": 0.1281,
      "step": 3690
    },
    {
      "epoch": 2.2234939759036143,
      "grad_norm": 0.5912216901779175,
      "learning_rate": 2.2228915662650604e-06,
      "loss": 0.2026,
      "step": 3691
    },
    {
      "epoch": 2.2240963855421687,
      "grad_norm": 0.7880052924156189,
      "learning_rate": 2.2221385542168677e-06,
      "loss": 0.209,
      "step": 3692
    },
    {
      "epoch": 2.224698795180723,
      "grad_norm": 0.5330648422241211,
      "learning_rate": 2.2213855421686746e-06,
      "loss": 0.1414,
      "step": 3693
    },
    {
      "epoch": 2.225301204819277,
      "grad_norm": 0.557641327381134,
      "learning_rate": 2.220632530120482e-06,
      "loss": 0.1538,
      "step": 3694
    },
    {
      "epoch": 2.2259036144578315,
      "grad_norm": 0.7026185393333435,
      "learning_rate": 2.2198795180722893e-06,
      "loss": 0.1363,
      "step": 3695
    },
    {
      "epoch": 2.2265060240963854,
      "grad_norm": 0.47420865297317505,
      "learning_rate": 2.2191265060240967e-06,
      "loss": 0.1541,
      "step": 3696
    },
    {
      "epoch": 2.22710843373494,
      "grad_norm": 0.5849379897117615,
      "learning_rate": 2.218373493975904e-06,
      "loss": 0.1676,
      "step": 3697
    },
    {
      "epoch": 2.227710843373494,
      "grad_norm": 0.5538244843482971,
      "learning_rate": 2.217620481927711e-06,
      "loss": 0.2001,
      "step": 3698
    },
    {
      "epoch": 2.228313253012048,
      "grad_norm": 0.6630135178565979,
      "learning_rate": 2.2168674698795183e-06,
      "loss": 0.1792,
      "step": 3699
    },
    {
      "epoch": 2.2289156626506026,
      "grad_norm": 0.605418860912323,
      "learning_rate": 2.2161144578313252e-06,
      "loss": 0.1688,
      "step": 3700
    },
    {
      "epoch": 2.2295180722891565,
      "grad_norm": 0.4563440680503845,
      "learning_rate": 2.2153614457831326e-06,
      "loss": 0.135,
      "step": 3701
    },
    {
      "epoch": 2.230120481927711,
      "grad_norm": 0.6006196737289429,
      "learning_rate": 2.21460843373494e-06,
      "loss": 0.1456,
      "step": 3702
    },
    {
      "epoch": 2.230722891566265,
      "grad_norm": 0.4916671812534332,
      "learning_rate": 2.2138554216867473e-06,
      "loss": 0.1607,
      "step": 3703
    },
    {
      "epoch": 2.2313253012048193,
      "grad_norm": 0.47579702734947205,
      "learning_rate": 2.2131024096385546e-06,
      "loss": 0.1585,
      "step": 3704
    },
    {
      "epoch": 2.2319277108433733,
      "grad_norm": 0.7340522408485413,
      "learning_rate": 2.2123493975903615e-06,
      "loss": 0.2326,
      "step": 3705
    },
    {
      "epoch": 2.2325301204819277,
      "grad_norm": 0.5357441306114197,
      "learning_rate": 2.211596385542169e-06,
      "loss": 0.1372,
      "step": 3706
    },
    {
      "epoch": 2.233132530120482,
      "grad_norm": 0.5570527911186218,
      "learning_rate": 2.2108433734939762e-06,
      "loss": 0.1408,
      "step": 3707
    },
    {
      "epoch": 2.233734939759036,
      "grad_norm": 0.4445191025733948,
      "learning_rate": 2.210090361445783e-06,
      "loss": 0.162,
      "step": 3708
    },
    {
      "epoch": 2.2343373493975904,
      "grad_norm": 0.4979178309440613,
      "learning_rate": 2.2093373493975905e-06,
      "loss": 0.1747,
      "step": 3709
    },
    {
      "epoch": 2.2349397590361444,
      "grad_norm": 0.5038431882858276,
      "learning_rate": 2.208584337349398e-06,
      "loss": 0.1425,
      "step": 3710
    },
    {
      "epoch": 2.235542168674699,
      "grad_norm": 0.4288870692253113,
      "learning_rate": 2.207831325301205e-06,
      "loss": 0.1296,
      "step": 3711
    },
    {
      "epoch": 2.236144578313253,
      "grad_norm": 0.5431573390960693,
      "learning_rate": 2.207078313253012e-06,
      "loss": 0.1662,
      "step": 3712
    },
    {
      "epoch": 2.236746987951807,
      "grad_norm": 0.49814003705978394,
      "learning_rate": 2.2063253012048195e-06,
      "loss": 0.1329,
      "step": 3713
    },
    {
      "epoch": 2.2373493975903616,
      "grad_norm": 0.49657681584358215,
      "learning_rate": 2.205572289156627e-06,
      "loss": 0.1571,
      "step": 3714
    },
    {
      "epoch": 2.2379518072289155,
      "grad_norm": 0.5453788638114929,
      "learning_rate": 2.2048192771084338e-06,
      "loss": 0.1112,
      "step": 3715
    },
    {
      "epoch": 2.23855421686747,
      "grad_norm": 0.6238593459129333,
      "learning_rate": 2.204066265060241e-06,
      "loss": 0.2176,
      "step": 3716
    },
    {
      "epoch": 2.2391566265060243,
      "grad_norm": 0.755698025226593,
      "learning_rate": 2.203313253012048e-06,
      "loss": 0.1933,
      "step": 3717
    },
    {
      "epoch": 2.2397590361445783,
      "grad_norm": 0.6308760643005371,
      "learning_rate": 2.2025602409638554e-06,
      "loss": 0.1935,
      "step": 3718
    },
    {
      "epoch": 2.2403614457831327,
      "grad_norm": 0.6282895803451538,
      "learning_rate": 2.2018072289156627e-06,
      "loss": 0.1761,
      "step": 3719
    },
    {
      "epoch": 2.2409638554216866,
      "grad_norm": 0.4705149233341217,
      "learning_rate": 2.20105421686747e-06,
      "loss": 0.1677,
      "step": 3720
    },
    {
      "epoch": 2.241566265060241,
      "grad_norm": 0.48604658246040344,
      "learning_rate": 2.2003012048192774e-06,
      "loss": 0.1591,
      "step": 3721
    },
    {
      "epoch": 2.242168674698795,
      "grad_norm": 0.6594461798667908,
      "learning_rate": 2.1995481927710848e-06,
      "loss": 0.1719,
      "step": 3722
    },
    {
      "epoch": 2.2427710843373494,
      "grad_norm": 0.46919870376586914,
      "learning_rate": 2.1987951807228917e-06,
      "loss": 0.1756,
      "step": 3723
    },
    {
      "epoch": 2.243373493975904,
      "grad_norm": 0.6013577580451965,
      "learning_rate": 2.198042168674699e-06,
      "loss": 0.1545,
      "step": 3724
    },
    {
      "epoch": 2.2439759036144578,
      "grad_norm": 0.5587168335914612,
      "learning_rate": 2.197289156626506e-06,
      "loss": 0.1702,
      "step": 3725
    },
    {
      "epoch": 2.244578313253012,
      "grad_norm": 0.5560436248779297,
      "learning_rate": 2.1965361445783133e-06,
      "loss": 0.1455,
      "step": 3726
    },
    {
      "epoch": 2.245180722891566,
      "grad_norm": 0.48008114099502563,
      "learning_rate": 2.1957831325301207e-06,
      "loss": 0.1567,
      "step": 3727
    },
    {
      "epoch": 2.2457831325301205,
      "grad_norm": 0.559245228767395,
      "learning_rate": 2.195030120481928e-06,
      "loss": 0.1973,
      "step": 3728
    },
    {
      "epoch": 2.2463855421686745,
      "grad_norm": 0.5611222386360168,
      "learning_rate": 2.194277108433735e-06,
      "loss": 0.1323,
      "step": 3729
    },
    {
      "epoch": 2.246987951807229,
      "grad_norm": 0.51621013879776,
      "learning_rate": 2.1935240963855423e-06,
      "loss": 0.1285,
      "step": 3730
    },
    {
      "epoch": 2.2475903614457833,
      "grad_norm": 0.4710789620876312,
      "learning_rate": 2.1927710843373496e-06,
      "loss": 0.1561,
      "step": 3731
    },
    {
      "epoch": 2.2481927710843372,
      "grad_norm": 0.5071591734886169,
      "learning_rate": 2.192018072289157e-06,
      "loss": 0.1455,
      "step": 3732
    },
    {
      "epoch": 2.2487951807228916,
      "grad_norm": 0.5072444677352905,
      "learning_rate": 2.191265060240964e-06,
      "loss": 0.1756,
      "step": 3733
    },
    {
      "epoch": 2.2493975903614456,
      "grad_norm": 0.5703566074371338,
      "learning_rate": 2.1905120481927713e-06,
      "loss": 0.2006,
      "step": 3734
    },
    {
      "epoch": 2.25,
      "grad_norm": 0.41175103187561035,
      "learning_rate": 2.189759036144578e-06,
      "loss": 0.1666,
      "step": 3735
    },
    {
      "epoch": 2.2506024096385544,
      "grad_norm": 0.5068253874778748,
      "learning_rate": 2.1890060240963855e-06,
      "loss": 0.1871,
      "step": 3736
    },
    {
      "epoch": 2.2512048192771084,
      "grad_norm": 0.48760539293289185,
      "learning_rate": 2.188253012048193e-06,
      "loss": 0.151,
      "step": 3737
    },
    {
      "epoch": 2.2518072289156628,
      "grad_norm": 0.5767492651939392,
      "learning_rate": 2.1875000000000002e-06,
      "loss": 0.1816,
      "step": 3738
    },
    {
      "epoch": 2.2524096385542167,
      "grad_norm": 0.593317449092865,
      "learning_rate": 2.1867469879518076e-06,
      "loss": 0.1889,
      "step": 3739
    },
    {
      "epoch": 2.253012048192771,
      "grad_norm": 0.612756073474884,
      "learning_rate": 2.185993975903615e-06,
      "loss": 0.1891,
      "step": 3740
    },
    {
      "epoch": 2.2536144578313255,
      "grad_norm": 0.5922912955284119,
      "learning_rate": 2.185240963855422e-06,
      "loss": 0.1644,
      "step": 3741
    },
    {
      "epoch": 2.2542168674698795,
      "grad_norm": 0.5352540016174316,
      "learning_rate": 2.184487951807229e-06,
      "loss": 0.1426,
      "step": 3742
    },
    {
      "epoch": 2.254819277108434,
      "grad_norm": 0.5350024104118347,
      "learning_rate": 2.183734939759036e-06,
      "loss": 0.1503,
      "step": 3743
    },
    {
      "epoch": 2.255421686746988,
      "grad_norm": 0.637159526348114,
      "learning_rate": 2.1829819277108435e-06,
      "loss": 0.1674,
      "step": 3744
    },
    {
      "epoch": 2.2560240963855422,
      "grad_norm": 0.5068968534469604,
      "learning_rate": 2.182228915662651e-06,
      "loss": 0.1337,
      "step": 3745
    },
    {
      "epoch": 2.256626506024096,
      "grad_norm": 0.5069523453712463,
      "learning_rate": 2.181475903614458e-06,
      "loss": 0.1509,
      "step": 3746
    },
    {
      "epoch": 2.2572289156626506,
      "grad_norm": 0.5752357244491577,
      "learning_rate": 2.1807228915662655e-06,
      "loss": 0.1973,
      "step": 3747
    },
    {
      "epoch": 2.257831325301205,
      "grad_norm": 0.45794394612312317,
      "learning_rate": 2.1799698795180724e-06,
      "loss": 0.148,
      "step": 3748
    },
    {
      "epoch": 2.258433734939759,
      "grad_norm": 0.49312084913253784,
      "learning_rate": 2.17921686746988e-06,
      "loss": 0.1578,
      "step": 3749
    },
    {
      "epoch": 2.2590361445783134,
      "grad_norm": 0.502831220626831,
      "learning_rate": 2.1784638554216867e-06,
      "loss": 0.1615,
      "step": 3750
    },
    {
      "epoch": 2.2596385542168673,
      "grad_norm": 0.7060057520866394,
      "learning_rate": 2.177710843373494e-06,
      "loss": 0.2433,
      "step": 3751
    },
    {
      "epoch": 2.2602409638554217,
      "grad_norm": 0.677200973033905,
      "learning_rate": 2.1769578313253014e-06,
      "loss": 0.2439,
      "step": 3752
    },
    {
      "epoch": 2.2608433734939757,
      "grad_norm": 0.545147180557251,
      "learning_rate": 2.1762048192771088e-06,
      "loss": 0.1753,
      "step": 3753
    },
    {
      "epoch": 2.26144578313253,
      "grad_norm": 0.6135803461074829,
      "learning_rate": 2.1754518072289157e-06,
      "loss": 0.2099,
      "step": 3754
    },
    {
      "epoch": 2.2620481927710845,
      "grad_norm": 0.5931994318962097,
      "learning_rate": 2.174698795180723e-06,
      "loss": 0.1669,
      "step": 3755
    },
    {
      "epoch": 2.2626506024096384,
      "grad_norm": 0.5633494257926941,
      "learning_rate": 2.1739457831325304e-06,
      "loss": 0.1907,
      "step": 3756
    },
    {
      "epoch": 2.263253012048193,
      "grad_norm": 0.6583285927772522,
      "learning_rate": 2.1731927710843377e-06,
      "loss": 0.1966,
      "step": 3757
    },
    {
      "epoch": 2.263855421686747,
      "grad_norm": 0.5285703539848328,
      "learning_rate": 2.1724397590361447e-06,
      "loss": 0.1282,
      "step": 3758
    },
    {
      "epoch": 2.264457831325301,
      "grad_norm": 0.8168036937713623,
      "learning_rate": 2.171686746987952e-06,
      "loss": 0.1796,
      "step": 3759
    },
    {
      "epoch": 2.2650602409638556,
      "grad_norm": 0.48343417048454285,
      "learning_rate": 2.170933734939759e-06,
      "loss": 0.1329,
      "step": 3760
    },
    {
      "epoch": 2.2656626506024096,
      "grad_norm": 0.5797908306121826,
      "learning_rate": 2.1701807228915663e-06,
      "loss": 0.1554,
      "step": 3761
    },
    {
      "epoch": 2.266265060240964,
      "grad_norm": 0.5489475727081299,
      "learning_rate": 2.1694277108433736e-06,
      "loss": 0.1459,
      "step": 3762
    },
    {
      "epoch": 2.266867469879518,
      "grad_norm": 0.5946868658065796,
      "learning_rate": 2.168674698795181e-06,
      "loss": 0.157,
      "step": 3763
    },
    {
      "epoch": 2.2674698795180723,
      "grad_norm": 0.5270150899887085,
      "learning_rate": 2.1679216867469883e-06,
      "loss": 0.179,
      "step": 3764
    },
    {
      "epoch": 2.2680722891566267,
      "grad_norm": 0.5229004621505737,
      "learning_rate": 2.1671686746987957e-06,
      "loss": 0.1538,
      "step": 3765
    },
    {
      "epoch": 2.2686746987951807,
      "grad_norm": 0.5212498307228088,
      "learning_rate": 2.1664156626506026e-06,
      "loss": 0.1449,
      "step": 3766
    },
    {
      "epoch": 2.269277108433735,
      "grad_norm": 0.48585841059684753,
      "learning_rate": 2.16566265060241e-06,
      "loss": 0.1621,
      "step": 3767
    },
    {
      "epoch": 2.269879518072289,
      "grad_norm": 0.732038140296936,
      "learning_rate": 2.164909638554217e-06,
      "loss": 0.1504,
      "step": 3768
    },
    {
      "epoch": 2.2704819277108435,
      "grad_norm": 0.497651606798172,
      "learning_rate": 2.1641566265060242e-06,
      "loss": 0.1768,
      "step": 3769
    },
    {
      "epoch": 2.2710843373493974,
      "grad_norm": 0.5457140803337097,
      "learning_rate": 2.1634036144578316e-06,
      "loss": 0.1599,
      "step": 3770
    },
    {
      "epoch": 2.271686746987952,
      "grad_norm": 0.7113444805145264,
      "learning_rate": 2.162650602409639e-06,
      "loss": 0.186,
      "step": 3771
    },
    {
      "epoch": 2.272289156626506,
      "grad_norm": 0.4589328467845917,
      "learning_rate": 2.161897590361446e-06,
      "loss": 0.1157,
      "step": 3772
    },
    {
      "epoch": 2.27289156626506,
      "grad_norm": 0.4584510922431946,
      "learning_rate": 2.161144578313253e-06,
      "loss": 0.1255,
      "step": 3773
    },
    {
      "epoch": 2.2734939759036146,
      "grad_norm": 0.690290093421936,
      "learning_rate": 2.1603915662650605e-06,
      "loss": 0.1524,
      "step": 3774
    },
    {
      "epoch": 2.2740963855421685,
      "grad_norm": 0.5612690448760986,
      "learning_rate": 2.159638554216868e-06,
      "loss": 0.1899,
      "step": 3775
    },
    {
      "epoch": 2.274698795180723,
      "grad_norm": 0.4814954698085785,
      "learning_rate": 2.158885542168675e-06,
      "loss": 0.1145,
      "step": 3776
    },
    {
      "epoch": 2.275301204819277,
      "grad_norm": 0.5365502238273621,
      "learning_rate": 2.158132530120482e-06,
      "loss": 0.151,
      "step": 3777
    },
    {
      "epoch": 2.2759036144578313,
      "grad_norm": 0.548042893409729,
      "learning_rate": 2.157379518072289e-06,
      "loss": 0.1472,
      "step": 3778
    },
    {
      "epoch": 2.2765060240963857,
      "grad_norm": 0.7087414264678955,
      "learning_rate": 2.1566265060240964e-06,
      "loss": 0.2099,
      "step": 3779
    },
    {
      "epoch": 2.2771084337349397,
      "grad_norm": 0.6093297004699707,
      "learning_rate": 2.1558734939759038e-06,
      "loss": 0.1816,
      "step": 3780
    },
    {
      "epoch": 2.277710843373494,
      "grad_norm": 0.5134868025779724,
      "learning_rate": 2.155120481927711e-06,
      "loss": 0.1684,
      "step": 3781
    },
    {
      "epoch": 2.278313253012048,
      "grad_norm": 0.6745860576629639,
      "learning_rate": 2.1543674698795185e-06,
      "loss": 0.2511,
      "step": 3782
    },
    {
      "epoch": 2.2789156626506024,
      "grad_norm": 0.4801945090293884,
      "learning_rate": 2.1536144578313254e-06,
      "loss": 0.1615,
      "step": 3783
    },
    {
      "epoch": 2.279518072289157,
      "grad_norm": 0.794806957244873,
      "learning_rate": 2.1528614457831328e-06,
      "loss": 0.231,
      "step": 3784
    },
    {
      "epoch": 2.2801204819277108,
      "grad_norm": 0.5637804269790649,
      "learning_rate": 2.1521084337349397e-06,
      "loss": 0.1704,
      "step": 3785
    },
    {
      "epoch": 2.280722891566265,
      "grad_norm": 0.5851844549179077,
      "learning_rate": 2.151355421686747e-06,
      "loss": 0.1384,
      "step": 3786
    },
    {
      "epoch": 2.281325301204819,
      "grad_norm": 0.5915206670761108,
      "learning_rate": 2.1506024096385544e-06,
      "loss": 0.1477,
      "step": 3787
    },
    {
      "epoch": 2.2819277108433735,
      "grad_norm": 0.529572069644928,
      "learning_rate": 2.1498493975903617e-06,
      "loss": 0.2055,
      "step": 3788
    },
    {
      "epoch": 2.282530120481928,
      "grad_norm": 0.5899465680122375,
      "learning_rate": 2.149096385542169e-06,
      "loss": 0.1687,
      "step": 3789
    },
    {
      "epoch": 2.283132530120482,
      "grad_norm": 0.5603160858154297,
      "learning_rate": 2.148343373493976e-06,
      "loss": 0.1668,
      "step": 3790
    },
    {
      "epoch": 2.2837349397590363,
      "grad_norm": 0.6967077255249023,
      "learning_rate": 2.1475903614457833e-06,
      "loss": 0.2304,
      "step": 3791
    },
    {
      "epoch": 2.2843373493975903,
      "grad_norm": 0.5334923267364502,
      "learning_rate": 2.1468373493975907e-06,
      "loss": 0.161,
      "step": 3792
    },
    {
      "epoch": 2.2849397590361447,
      "grad_norm": 0.5310150980949402,
      "learning_rate": 2.1460843373493976e-06,
      "loss": 0.1333,
      "step": 3793
    },
    {
      "epoch": 2.2855421686746986,
      "grad_norm": 0.5758684277534485,
      "learning_rate": 2.145331325301205e-06,
      "loss": 0.1635,
      "step": 3794
    },
    {
      "epoch": 2.286144578313253,
      "grad_norm": 0.5518945455551147,
      "learning_rate": 2.1445783132530123e-06,
      "loss": 0.163,
      "step": 3795
    },
    {
      "epoch": 2.2867469879518074,
      "grad_norm": 0.5624819397926331,
      "learning_rate": 2.1438253012048192e-06,
      "loss": 0.1833,
      "step": 3796
    },
    {
      "epoch": 2.2873493975903614,
      "grad_norm": 0.48999232053756714,
      "learning_rate": 2.1430722891566266e-06,
      "loss": 0.1382,
      "step": 3797
    },
    {
      "epoch": 2.287951807228916,
      "grad_norm": 0.6585630178451538,
      "learning_rate": 2.142319277108434e-06,
      "loss": 0.1529,
      "step": 3798
    },
    {
      "epoch": 2.2885542168674697,
      "grad_norm": 0.621425449848175,
      "learning_rate": 2.1415662650602413e-06,
      "loss": 0.2,
      "step": 3799
    },
    {
      "epoch": 2.289156626506024,
      "grad_norm": 0.5067756175994873,
      "learning_rate": 2.1408132530120486e-06,
      "loss": 0.1444,
      "step": 3800
    },
    {
      "epoch": 2.289759036144578,
      "grad_norm": 0.5571483373641968,
      "learning_rate": 2.1400602409638556e-06,
      "loss": 0.1376,
      "step": 3801
    },
    {
      "epoch": 2.2903614457831325,
      "grad_norm": 0.49091532826423645,
      "learning_rate": 2.139307228915663e-06,
      "loss": 0.1179,
      "step": 3802
    },
    {
      "epoch": 2.290963855421687,
      "grad_norm": 0.5467177629470825,
      "learning_rate": 2.13855421686747e-06,
      "loss": 0.1486,
      "step": 3803
    },
    {
      "epoch": 2.291566265060241,
      "grad_norm": 0.564932644367218,
      "learning_rate": 2.137801204819277e-06,
      "loss": 0.1536,
      "step": 3804
    },
    {
      "epoch": 2.2921686746987953,
      "grad_norm": 0.6665163040161133,
      "learning_rate": 2.1370481927710845e-06,
      "loss": 0.1859,
      "step": 3805
    },
    {
      "epoch": 2.292771084337349,
      "grad_norm": 0.5120118856430054,
      "learning_rate": 2.136295180722892e-06,
      "loss": 0.1316,
      "step": 3806
    },
    {
      "epoch": 2.2933734939759036,
      "grad_norm": 0.5687161684036255,
      "learning_rate": 2.1355421686746992e-06,
      "loss": 0.1644,
      "step": 3807
    },
    {
      "epoch": 2.293975903614458,
      "grad_norm": 0.47920700907707214,
      "learning_rate": 2.134789156626506e-06,
      "loss": 0.1285,
      "step": 3808
    },
    {
      "epoch": 2.294578313253012,
      "grad_norm": 0.4807124435901642,
      "learning_rate": 2.1340361445783135e-06,
      "loss": 0.1681,
      "step": 3809
    },
    {
      "epoch": 2.2951807228915664,
      "grad_norm": 0.5127354264259338,
      "learning_rate": 2.133283132530121e-06,
      "loss": 0.1502,
      "step": 3810
    },
    {
      "epoch": 2.2957831325301203,
      "grad_norm": 0.4527367353439331,
      "learning_rate": 2.1325301204819278e-06,
      "loss": 0.1486,
      "step": 3811
    },
    {
      "epoch": 2.2963855421686747,
      "grad_norm": 0.5713668465614319,
      "learning_rate": 2.131777108433735e-06,
      "loss": 0.161,
      "step": 3812
    },
    {
      "epoch": 2.296987951807229,
      "grad_norm": 0.5642938613891602,
      "learning_rate": 2.1310240963855425e-06,
      "loss": 0.1717,
      "step": 3813
    },
    {
      "epoch": 2.297590361445783,
      "grad_norm": 0.49891623854637146,
      "learning_rate": 2.1302710843373494e-06,
      "loss": 0.1407,
      "step": 3814
    },
    {
      "epoch": 2.2981927710843375,
      "grad_norm": 0.4937070310115814,
      "learning_rate": 2.1295180722891567e-06,
      "loss": 0.1479,
      "step": 3815
    },
    {
      "epoch": 2.2987951807228915,
      "grad_norm": 0.4379613697528839,
      "learning_rate": 2.128765060240964e-06,
      "loss": 0.1266,
      "step": 3816
    },
    {
      "epoch": 2.299397590361446,
      "grad_norm": 0.4649953246116638,
      "learning_rate": 2.1280120481927714e-06,
      "loss": 0.1374,
      "step": 3817
    },
    {
      "epoch": 2.3,
      "grad_norm": 0.580449640750885,
      "learning_rate": 2.1272590361445784e-06,
      "loss": 0.1957,
      "step": 3818
    },
    {
      "epoch": 2.3006024096385542,
      "grad_norm": 0.4967065155506134,
      "learning_rate": 2.1265060240963857e-06,
      "loss": 0.1575,
      "step": 3819
    },
    {
      "epoch": 2.3012048192771086,
      "grad_norm": 0.5352981686592102,
      "learning_rate": 2.1257530120481926e-06,
      "loss": 0.1355,
      "step": 3820
    },
    {
      "epoch": 2.3018072289156626,
      "grad_norm": 0.5719363689422607,
      "learning_rate": 2.125e-06,
      "loss": 0.1684,
      "step": 3821
    },
    {
      "epoch": 2.302409638554217,
      "grad_norm": 0.7386544942855835,
      "learning_rate": 2.1242469879518073e-06,
      "loss": 0.1486,
      "step": 3822
    },
    {
      "epoch": 2.303012048192771,
      "grad_norm": 0.46710872650146484,
      "learning_rate": 2.1234939759036147e-06,
      "loss": 0.1411,
      "step": 3823
    },
    {
      "epoch": 2.3036144578313253,
      "grad_norm": 0.5077013969421387,
      "learning_rate": 2.122740963855422e-06,
      "loss": 0.1418,
      "step": 3824
    },
    {
      "epoch": 2.3042168674698793,
      "grad_norm": 0.5541077852249146,
      "learning_rate": 2.1219879518072294e-06,
      "loss": 0.1632,
      "step": 3825
    },
    {
      "epoch": 2.3048192771084337,
      "grad_norm": 0.5253390073776245,
      "learning_rate": 2.1212349397590363e-06,
      "loss": 0.1543,
      "step": 3826
    },
    {
      "epoch": 2.305421686746988,
      "grad_norm": 0.5283558964729309,
      "learning_rate": 2.1204819277108437e-06,
      "loss": 0.1936,
      "step": 3827
    },
    {
      "epoch": 2.306024096385542,
      "grad_norm": 0.5305636525154114,
      "learning_rate": 2.1197289156626506e-06,
      "loss": 0.1353,
      "step": 3828
    },
    {
      "epoch": 2.3066265060240965,
      "grad_norm": 0.5317910313606262,
      "learning_rate": 2.118975903614458e-06,
      "loss": 0.1519,
      "step": 3829
    },
    {
      "epoch": 2.3072289156626504,
      "grad_norm": 0.4660445749759674,
      "learning_rate": 2.1182228915662653e-06,
      "loss": 0.15,
      "step": 3830
    },
    {
      "epoch": 2.307831325301205,
      "grad_norm": 0.575971245765686,
      "learning_rate": 2.1174698795180726e-06,
      "loss": 0.1525,
      "step": 3831
    },
    {
      "epoch": 2.3084337349397592,
      "grad_norm": 0.6551117897033691,
      "learning_rate": 2.1167168674698795e-06,
      "loss": 0.1286,
      "step": 3832
    },
    {
      "epoch": 2.309036144578313,
      "grad_norm": 0.5753527879714966,
      "learning_rate": 2.115963855421687e-06,
      "loss": 0.1613,
      "step": 3833
    },
    {
      "epoch": 2.3096385542168676,
      "grad_norm": 0.6330319046974182,
      "learning_rate": 2.1152108433734942e-06,
      "loss": 0.1916,
      "step": 3834
    },
    {
      "epoch": 2.3102409638554215,
      "grad_norm": 0.46424978971481323,
      "learning_rate": 2.1144578313253016e-06,
      "loss": 0.1168,
      "step": 3835
    },
    {
      "epoch": 2.310843373493976,
      "grad_norm": 0.6400728821754456,
      "learning_rate": 2.1137048192771085e-06,
      "loss": 0.1508,
      "step": 3836
    },
    {
      "epoch": 2.3114457831325304,
      "grad_norm": 0.48695576190948486,
      "learning_rate": 2.112951807228916e-06,
      "loss": 0.1379,
      "step": 3837
    },
    {
      "epoch": 2.3120481927710843,
      "grad_norm": 0.7989090085029602,
      "learning_rate": 2.1121987951807228e-06,
      "loss": 0.2177,
      "step": 3838
    },
    {
      "epoch": 2.3126506024096387,
      "grad_norm": 0.4915392994880676,
      "learning_rate": 2.11144578313253e-06,
      "loss": 0.1455,
      "step": 3839
    },
    {
      "epoch": 2.3132530120481927,
      "grad_norm": 0.5055021643638611,
      "learning_rate": 2.1106927710843375e-06,
      "loss": 0.1468,
      "step": 3840
    },
    {
      "epoch": 2.313855421686747,
      "grad_norm": 0.5504138469696045,
      "learning_rate": 2.109939759036145e-06,
      "loss": 0.2062,
      "step": 3841
    },
    {
      "epoch": 2.314457831325301,
      "grad_norm": 0.7089802622795105,
      "learning_rate": 2.109186746987952e-06,
      "loss": 0.2611,
      "step": 3842
    },
    {
      "epoch": 2.3150602409638554,
      "grad_norm": 0.563983142375946,
      "learning_rate": 2.1084337349397595e-06,
      "loss": 0.1612,
      "step": 3843
    },
    {
      "epoch": 2.31566265060241,
      "grad_norm": 0.5664888024330139,
      "learning_rate": 2.1076807228915665e-06,
      "loss": 0.1589,
      "step": 3844
    },
    {
      "epoch": 2.316265060240964,
      "grad_norm": 0.6326716542243958,
      "learning_rate": 2.106927710843374e-06,
      "loss": 0.1513,
      "step": 3845
    },
    {
      "epoch": 2.316867469879518,
      "grad_norm": 0.49389854073524475,
      "learning_rate": 2.1061746987951807e-06,
      "loss": 0.144,
      "step": 3846
    },
    {
      "epoch": 2.317469879518072,
      "grad_norm": 0.526832640171051,
      "learning_rate": 2.105421686746988e-06,
      "loss": 0.1177,
      "step": 3847
    },
    {
      "epoch": 2.3180722891566266,
      "grad_norm": 0.8892759680747986,
      "learning_rate": 2.1046686746987954e-06,
      "loss": 0.219,
      "step": 3848
    },
    {
      "epoch": 2.3186746987951805,
      "grad_norm": 0.5117316842079163,
      "learning_rate": 2.1039156626506028e-06,
      "loss": 0.15,
      "step": 3849
    },
    {
      "epoch": 2.319277108433735,
      "grad_norm": 0.4561167061328888,
      "learning_rate": 2.1031626506024097e-06,
      "loss": 0.1443,
      "step": 3850
    },
    {
      "epoch": 2.3198795180722893,
      "grad_norm": 0.535975992679596,
      "learning_rate": 2.102409638554217e-06,
      "loss": 0.1751,
      "step": 3851
    },
    {
      "epoch": 2.3204819277108433,
      "grad_norm": 0.5766882300376892,
      "learning_rate": 2.1016566265060244e-06,
      "loss": 0.1717,
      "step": 3852
    },
    {
      "epoch": 2.3210843373493977,
      "grad_norm": 0.5866538286209106,
      "learning_rate": 2.1009036144578313e-06,
      "loss": 0.1279,
      "step": 3853
    },
    {
      "epoch": 2.3216867469879516,
      "grad_norm": 0.5615955591201782,
      "learning_rate": 2.1001506024096387e-06,
      "loss": 0.2271,
      "step": 3854
    },
    {
      "epoch": 2.322289156626506,
      "grad_norm": 0.7399449944496155,
      "learning_rate": 2.099397590361446e-06,
      "loss": 0.2213,
      "step": 3855
    },
    {
      "epoch": 2.32289156626506,
      "grad_norm": 5.861934661865234,
      "learning_rate": 2.098644578313253e-06,
      "loss": 0.1705,
      "step": 3856
    },
    {
      "epoch": 2.3234939759036144,
      "grad_norm": 0.6258026957511902,
      "learning_rate": 2.0978915662650603e-06,
      "loss": 0.1819,
      "step": 3857
    },
    {
      "epoch": 2.324096385542169,
      "grad_norm": 0.6283110976219177,
      "learning_rate": 2.0971385542168676e-06,
      "loss": 0.1663,
      "step": 3858
    },
    {
      "epoch": 2.3246987951807228,
      "grad_norm": 0.5371145009994507,
      "learning_rate": 2.096385542168675e-06,
      "loss": 0.1646,
      "step": 3859
    },
    {
      "epoch": 2.325301204819277,
      "grad_norm": 0.5765466094017029,
      "learning_rate": 2.0956325301204823e-06,
      "loss": 0.1808,
      "step": 3860
    },
    {
      "epoch": 2.3259036144578316,
      "grad_norm": 0.536558210849762,
      "learning_rate": 2.0948795180722893e-06,
      "loss": 0.2041,
      "step": 3861
    },
    {
      "epoch": 2.3265060240963855,
      "grad_norm": 0.5116857886314392,
      "learning_rate": 2.0941265060240966e-06,
      "loss": 0.1291,
      "step": 3862
    },
    {
      "epoch": 2.32710843373494,
      "grad_norm": 0.5210431218147278,
      "learning_rate": 2.0933734939759035e-06,
      "loss": 0.1368,
      "step": 3863
    },
    {
      "epoch": 2.327710843373494,
      "grad_norm": 0.5381796956062317,
      "learning_rate": 2.092620481927711e-06,
      "loss": 0.1437,
      "step": 3864
    },
    {
      "epoch": 2.3283132530120483,
      "grad_norm": 0.6854526400566101,
      "learning_rate": 2.0918674698795182e-06,
      "loss": 0.1788,
      "step": 3865
    },
    {
      "epoch": 2.3289156626506022,
      "grad_norm": 0.6934382915496826,
      "learning_rate": 2.0911144578313256e-06,
      "loss": 0.1943,
      "step": 3866
    },
    {
      "epoch": 2.3295180722891566,
      "grad_norm": 0.5532026290893555,
      "learning_rate": 2.090361445783133e-06,
      "loss": 0.1697,
      "step": 3867
    },
    {
      "epoch": 2.330120481927711,
      "grad_norm": 0.5494378209114075,
      "learning_rate": 2.08960843373494e-06,
      "loss": 0.166,
      "step": 3868
    },
    {
      "epoch": 2.330722891566265,
      "grad_norm": 0.5590512752532959,
      "learning_rate": 2.088855421686747e-06,
      "loss": 0.2045,
      "step": 3869
    },
    {
      "epoch": 2.3313253012048194,
      "grad_norm": 0.6563134789466858,
      "learning_rate": 2.0881024096385545e-06,
      "loss": 0.2326,
      "step": 3870
    },
    {
      "epoch": 2.3319277108433734,
      "grad_norm": 0.7259384393692017,
      "learning_rate": 2.0873493975903615e-06,
      "loss": 0.2064,
      "step": 3871
    },
    {
      "epoch": 2.3325301204819278,
      "grad_norm": 0.5599428415298462,
      "learning_rate": 2.086596385542169e-06,
      "loss": 0.1416,
      "step": 3872
    },
    {
      "epoch": 2.3331325301204817,
      "grad_norm": 0.4702172577381134,
      "learning_rate": 2.085843373493976e-06,
      "loss": 0.1445,
      "step": 3873
    },
    {
      "epoch": 2.333734939759036,
      "grad_norm": 0.6241464018821716,
      "learning_rate": 2.085090361445783e-06,
      "loss": 0.243,
      "step": 3874
    },
    {
      "epoch": 2.3343373493975905,
      "grad_norm": 0.5095946788787842,
      "learning_rate": 2.0843373493975904e-06,
      "loss": 0.1357,
      "step": 3875
    },
    {
      "epoch": 2.3349397590361445,
      "grad_norm": 0.5716551542282104,
      "learning_rate": 2.083584337349398e-06,
      "loss": 0.1924,
      "step": 3876
    },
    {
      "epoch": 2.335542168674699,
      "grad_norm": 0.5284208059310913,
      "learning_rate": 2.082831325301205e-06,
      "loss": 0.1639,
      "step": 3877
    },
    {
      "epoch": 2.336144578313253,
      "grad_norm": 0.522492527961731,
      "learning_rate": 2.0820783132530125e-06,
      "loss": 0.139,
      "step": 3878
    },
    {
      "epoch": 2.3367469879518072,
      "grad_norm": 1.067576289176941,
      "learning_rate": 2.0813253012048194e-06,
      "loss": 0.1329,
      "step": 3879
    },
    {
      "epoch": 2.337349397590361,
      "grad_norm": 0.5133296251296997,
      "learning_rate": 2.0805722891566268e-06,
      "loss": 0.1316,
      "step": 3880
    },
    {
      "epoch": 2.3379518072289156,
      "grad_norm": 0.44465669989585876,
      "learning_rate": 2.0798192771084337e-06,
      "loss": 0.141,
      "step": 3881
    },
    {
      "epoch": 2.33855421686747,
      "grad_norm": 0.6059428453445435,
      "learning_rate": 2.079066265060241e-06,
      "loss": 0.1546,
      "step": 3882
    },
    {
      "epoch": 2.339156626506024,
      "grad_norm": 0.5161722302436829,
      "learning_rate": 2.0783132530120484e-06,
      "loss": 0.1458,
      "step": 3883
    },
    {
      "epoch": 2.3397590361445784,
      "grad_norm": 0.47165507078170776,
      "learning_rate": 2.0775602409638557e-06,
      "loss": 0.1338,
      "step": 3884
    },
    {
      "epoch": 2.3403614457831328,
      "grad_norm": 0.5759283900260925,
      "learning_rate": 2.076807228915663e-06,
      "loss": 0.1127,
      "step": 3885
    },
    {
      "epoch": 2.3409638554216867,
      "grad_norm": 0.6222696304321289,
      "learning_rate": 2.07605421686747e-06,
      "loss": 0.1395,
      "step": 3886
    },
    {
      "epoch": 2.341566265060241,
      "grad_norm": 0.5271247625350952,
      "learning_rate": 2.0753012048192774e-06,
      "loss": 0.1517,
      "step": 3887
    },
    {
      "epoch": 2.342168674698795,
      "grad_norm": 0.48372727632522583,
      "learning_rate": 2.0745481927710847e-06,
      "loss": 0.1642,
      "step": 3888
    },
    {
      "epoch": 2.3427710843373495,
      "grad_norm": 0.46723654866218567,
      "learning_rate": 2.0737951807228916e-06,
      "loss": 0.1442,
      "step": 3889
    },
    {
      "epoch": 2.3433734939759034,
      "grad_norm": 0.6811040043830872,
      "learning_rate": 2.073042168674699e-06,
      "loss": 0.2222,
      "step": 3890
    },
    {
      "epoch": 2.343975903614458,
      "grad_norm": 0.492850661277771,
      "learning_rate": 2.0722891566265063e-06,
      "loss": 0.1411,
      "step": 3891
    },
    {
      "epoch": 2.3445783132530122,
      "grad_norm": 0.5461441278457642,
      "learning_rate": 2.0715361445783132e-06,
      "loss": 0.155,
      "step": 3892
    },
    {
      "epoch": 2.345180722891566,
      "grad_norm": 0.6012535095214844,
      "learning_rate": 2.0707831325301206e-06,
      "loss": 0.1507,
      "step": 3893
    },
    {
      "epoch": 2.3457831325301206,
      "grad_norm": 0.6171985864639282,
      "learning_rate": 2.070030120481928e-06,
      "loss": 0.1957,
      "step": 3894
    },
    {
      "epoch": 2.3463855421686746,
      "grad_norm": 0.49385446310043335,
      "learning_rate": 2.0692771084337353e-06,
      "loss": 0.1503,
      "step": 3895
    },
    {
      "epoch": 2.346987951807229,
      "grad_norm": 0.5749733448028564,
      "learning_rate": 2.0685240963855422e-06,
      "loss": 0.1772,
      "step": 3896
    },
    {
      "epoch": 2.347590361445783,
      "grad_norm": 0.5581448078155518,
      "learning_rate": 2.0677710843373496e-06,
      "loss": 0.1579,
      "step": 3897
    },
    {
      "epoch": 2.3481927710843373,
      "grad_norm": 0.595051109790802,
      "learning_rate": 2.0670180722891565e-06,
      "loss": 0.1734,
      "step": 3898
    },
    {
      "epoch": 2.3487951807228917,
      "grad_norm": 0.8864203095436096,
      "learning_rate": 2.066265060240964e-06,
      "loss": 0.2301,
      "step": 3899
    },
    {
      "epoch": 2.3493975903614457,
      "grad_norm": 0.586534321308136,
      "learning_rate": 2.065512048192771e-06,
      "loss": 0.1814,
      "step": 3900
    },
    {
      "epoch": 2.35,
      "grad_norm": 0.46929335594177246,
      "learning_rate": 2.0647590361445785e-06,
      "loss": 0.1432,
      "step": 3901
    },
    {
      "epoch": 2.350602409638554,
      "grad_norm": 0.6153831481933594,
      "learning_rate": 2.064006024096386e-06,
      "loss": 0.1952,
      "step": 3902
    },
    {
      "epoch": 2.3512048192771084,
      "grad_norm": 0.46812760829925537,
      "learning_rate": 2.0632530120481932e-06,
      "loss": 0.1067,
      "step": 3903
    },
    {
      "epoch": 2.3518072289156624,
      "grad_norm": 0.4602348208427429,
      "learning_rate": 2.0625e-06,
      "loss": 0.1092,
      "step": 3904
    },
    {
      "epoch": 2.352409638554217,
      "grad_norm": 0.5462153553962708,
      "learning_rate": 2.0617469879518075e-06,
      "loss": 0.1674,
      "step": 3905
    },
    {
      "epoch": 2.353012048192771,
      "grad_norm": 0.517433762550354,
      "learning_rate": 2.0609939759036144e-06,
      "loss": 0.1356,
      "step": 3906
    },
    {
      "epoch": 2.353614457831325,
      "grad_norm": 0.5163314342498779,
      "learning_rate": 2.0602409638554218e-06,
      "loss": 0.143,
      "step": 3907
    },
    {
      "epoch": 2.3542168674698796,
      "grad_norm": 0.6844715476036072,
      "learning_rate": 2.059487951807229e-06,
      "loss": 0.1907,
      "step": 3908
    },
    {
      "epoch": 2.354819277108434,
      "grad_norm": 0.6314796209335327,
      "learning_rate": 2.0587349397590365e-06,
      "loss": 0.2053,
      "step": 3909
    },
    {
      "epoch": 2.355421686746988,
      "grad_norm": 0.4908135235309601,
      "learning_rate": 2.0579819277108434e-06,
      "loss": 0.1525,
      "step": 3910
    },
    {
      "epoch": 2.3560240963855423,
      "grad_norm": 0.5857958197593689,
      "learning_rate": 2.0572289156626507e-06,
      "loss": 0.1917,
      "step": 3911
    },
    {
      "epoch": 2.3566265060240963,
      "grad_norm": 0.4755145013332367,
      "learning_rate": 2.056475903614458e-06,
      "loss": 0.1561,
      "step": 3912
    },
    {
      "epoch": 2.3572289156626507,
      "grad_norm": 0.5039830207824707,
      "learning_rate": 2.0557228915662654e-06,
      "loss": 0.204,
      "step": 3913
    },
    {
      "epoch": 2.3578313253012047,
      "grad_norm": 0.5165543556213379,
      "learning_rate": 2.0549698795180724e-06,
      "loss": 0.1968,
      "step": 3914
    },
    {
      "epoch": 2.358433734939759,
      "grad_norm": 0.4374615550041199,
      "learning_rate": 2.0542168674698797e-06,
      "loss": 0.1101,
      "step": 3915
    },
    {
      "epoch": 2.3590361445783135,
      "grad_norm": 0.4559916853904724,
      "learning_rate": 2.0534638554216866e-06,
      "loss": 0.1303,
      "step": 3916
    },
    {
      "epoch": 2.3596385542168674,
      "grad_norm": 0.7114110589027405,
      "learning_rate": 2.052710843373494e-06,
      "loss": 0.1971,
      "step": 3917
    },
    {
      "epoch": 2.360240963855422,
      "grad_norm": 0.6166625618934631,
      "learning_rate": 2.0519578313253013e-06,
      "loss": 0.1416,
      "step": 3918
    },
    {
      "epoch": 2.3608433734939758,
      "grad_norm": 0.44684725999832153,
      "learning_rate": 2.0512048192771087e-06,
      "loss": 0.1433,
      "step": 3919
    },
    {
      "epoch": 2.36144578313253,
      "grad_norm": 1.1172659397125244,
      "learning_rate": 2.050451807228916e-06,
      "loss": 0.1353,
      "step": 3920
    },
    {
      "epoch": 2.362048192771084,
      "grad_norm": 0.4753265380859375,
      "learning_rate": 2.0496987951807234e-06,
      "loss": 0.1652,
      "step": 3921
    },
    {
      "epoch": 2.3626506024096385,
      "grad_norm": 0.6722498536109924,
      "learning_rate": 2.0489457831325303e-06,
      "loss": 0.1724,
      "step": 3922
    },
    {
      "epoch": 2.363253012048193,
      "grad_norm": 0.6589455604553223,
      "learning_rate": 2.0481927710843377e-06,
      "loss": 0.1677,
      "step": 3923
    },
    {
      "epoch": 2.363855421686747,
      "grad_norm": 0.5648583769798279,
      "learning_rate": 2.0474397590361446e-06,
      "loss": 0.1751,
      "step": 3924
    },
    {
      "epoch": 2.3644578313253013,
      "grad_norm": 0.646152913570404,
      "learning_rate": 2.046686746987952e-06,
      "loss": 0.2379,
      "step": 3925
    },
    {
      "epoch": 2.3650602409638553,
      "grad_norm": 0.6418784260749817,
      "learning_rate": 2.0459337349397593e-06,
      "loss": 0.2115,
      "step": 3926
    },
    {
      "epoch": 2.3656626506024097,
      "grad_norm": 0.9447388648986816,
      "learning_rate": 2.0451807228915666e-06,
      "loss": 0.1629,
      "step": 3927
    },
    {
      "epoch": 2.3662650602409636,
      "grad_norm": 0.5427955389022827,
      "learning_rate": 2.0444277108433736e-06,
      "loss": 0.1387,
      "step": 3928
    },
    {
      "epoch": 2.366867469879518,
      "grad_norm": 0.45460155606269836,
      "learning_rate": 2.043674698795181e-06,
      "loss": 0.1477,
      "step": 3929
    },
    {
      "epoch": 2.3674698795180724,
      "grad_norm": 0.4047146737575531,
      "learning_rate": 2.0429216867469883e-06,
      "loss": 0.142,
      "step": 3930
    },
    {
      "epoch": 2.3680722891566264,
      "grad_norm": 0.4874359965324402,
      "learning_rate": 2.042168674698795e-06,
      "loss": 0.1593,
      "step": 3931
    },
    {
      "epoch": 2.3686746987951808,
      "grad_norm": 0.5143808126449585,
      "learning_rate": 2.0414156626506025e-06,
      "loss": 0.1332,
      "step": 3932
    },
    {
      "epoch": 2.369277108433735,
      "grad_norm": 0.5042517185211182,
      "learning_rate": 2.04066265060241e-06,
      "loss": 0.1736,
      "step": 3933
    },
    {
      "epoch": 2.369879518072289,
      "grad_norm": 0.764906108379364,
      "learning_rate": 2.039909638554217e-06,
      "loss": 0.2178,
      "step": 3934
    },
    {
      "epoch": 2.3704819277108435,
      "grad_norm": 0.5578353404998779,
      "learning_rate": 2.039156626506024e-06,
      "loss": 0.1544,
      "step": 3935
    },
    {
      "epoch": 2.3710843373493975,
      "grad_norm": 0.651928186416626,
      "learning_rate": 2.0384036144578315e-06,
      "loss": 0.1982,
      "step": 3936
    },
    {
      "epoch": 2.371686746987952,
      "grad_norm": 0.45120173692703247,
      "learning_rate": 2.037650602409639e-06,
      "loss": 0.1434,
      "step": 3937
    },
    {
      "epoch": 2.372289156626506,
      "grad_norm": 0.5547022223472595,
      "learning_rate": 2.036897590361446e-06,
      "loss": 0.1523,
      "step": 3938
    },
    {
      "epoch": 2.3728915662650603,
      "grad_norm": 0.5146163702011108,
      "learning_rate": 2.036144578313253e-06,
      "loss": 0.132,
      "step": 3939
    },
    {
      "epoch": 2.3734939759036147,
      "grad_norm": 0.6576047539710999,
      "learning_rate": 2.0353915662650605e-06,
      "loss": 0.1746,
      "step": 3940
    },
    {
      "epoch": 2.3740963855421686,
      "grad_norm": 0.4518273174762726,
      "learning_rate": 2.0346385542168674e-06,
      "loss": 0.152,
      "step": 3941
    },
    {
      "epoch": 2.374698795180723,
      "grad_norm": 0.6346928477287292,
      "learning_rate": 2.0338855421686747e-06,
      "loss": 0.1722,
      "step": 3942
    },
    {
      "epoch": 2.375301204819277,
      "grad_norm": 0.5210906863212585,
      "learning_rate": 2.033132530120482e-06,
      "loss": 0.1663,
      "step": 3943
    },
    {
      "epoch": 2.3759036144578314,
      "grad_norm": 0.4717615842819214,
      "learning_rate": 2.0323795180722894e-06,
      "loss": 0.1506,
      "step": 3944
    },
    {
      "epoch": 2.3765060240963853,
      "grad_norm": 0.4437341094017029,
      "learning_rate": 2.0316265060240968e-06,
      "loss": 0.1479,
      "step": 3945
    },
    {
      "epoch": 2.3771084337349397,
      "grad_norm": 0.4825930595397949,
      "learning_rate": 2.0308734939759037e-06,
      "loss": 0.1498,
      "step": 3946
    },
    {
      "epoch": 2.377710843373494,
      "grad_norm": 0.5518764853477478,
      "learning_rate": 2.030120481927711e-06,
      "loss": 0.1714,
      "step": 3947
    },
    {
      "epoch": 2.378313253012048,
      "grad_norm": 0.7072255611419678,
      "learning_rate": 2.0293674698795184e-06,
      "loss": 0.1918,
      "step": 3948
    },
    {
      "epoch": 2.3789156626506025,
      "grad_norm": 0.5721593499183655,
      "learning_rate": 2.0286144578313253e-06,
      "loss": 0.1855,
      "step": 3949
    },
    {
      "epoch": 2.3795180722891565,
      "grad_norm": 0.5328173041343689,
      "learning_rate": 2.0278614457831327e-06,
      "loss": 0.1445,
      "step": 3950
    },
    {
      "epoch": 2.380120481927711,
      "grad_norm": 0.5548717975616455,
      "learning_rate": 2.02710843373494e-06,
      "loss": 0.2082,
      "step": 3951
    },
    {
      "epoch": 2.380722891566265,
      "grad_norm": 0.5237057209014893,
      "learning_rate": 2.026355421686747e-06,
      "loss": 0.1286,
      "step": 3952
    },
    {
      "epoch": 2.3813253012048192,
      "grad_norm": 0.44222912192344666,
      "learning_rate": 2.0256024096385543e-06,
      "loss": 0.1385,
      "step": 3953
    },
    {
      "epoch": 2.3819277108433736,
      "grad_norm": 0.5659552216529846,
      "learning_rate": 2.0248493975903616e-06,
      "loss": 0.1193,
      "step": 3954
    },
    {
      "epoch": 2.3825301204819276,
      "grad_norm": 0.5432837605476379,
      "learning_rate": 2.024096385542169e-06,
      "loss": 0.1458,
      "step": 3955
    },
    {
      "epoch": 2.383132530120482,
      "grad_norm": 0.5407996773719788,
      "learning_rate": 2.0233433734939763e-06,
      "loss": 0.1619,
      "step": 3956
    },
    {
      "epoch": 2.3837349397590364,
      "grad_norm": 0.4993298649787903,
      "learning_rate": 2.0225903614457833e-06,
      "loss": 0.16,
      "step": 3957
    },
    {
      "epoch": 2.3843373493975903,
      "grad_norm": 0.626196563243866,
      "learning_rate": 2.0218373493975906e-06,
      "loss": 0.1219,
      "step": 3958
    },
    {
      "epoch": 2.3849397590361447,
      "grad_norm": 0.5312374234199524,
      "learning_rate": 2.0210843373493975e-06,
      "loss": 0.1621,
      "step": 3959
    },
    {
      "epoch": 2.3855421686746987,
      "grad_norm": 0.5355760455131531,
      "learning_rate": 2.020331325301205e-06,
      "loss": 0.1676,
      "step": 3960
    },
    {
      "epoch": 2.386144578313253,
      "grad_norm": 0.6092126965522766,
      "learning_rate": 2.0195783132530122e-06,
      "loss": 0.1766,
      "step": 3961
    },
    {
      "epoch": 2.386746987951807,
      "grad_norm": 0.541938304901123,
      "learning_rate": 2.0188253012048196e-06,
      "loss": 0.1751,
      "step": 3962
    },
    {
      "epoch": 2.3873493975903615,
      "grad_norm": 0.5336629152297974,
      "learning_rate": 2.018072289156627e-06,
      "loss": 0.1545,
      "step": 3963
    },
    {
      "epoch": 2.387951807228916,
      "grad_norm": 0.5746732950210571,
      "learning_rate": 2.017319277108434e-06,
      "loss": 0.1615,
      "step": 3964
    },
    {
      "epoch": 2.38855421686747,
      "grad_norm": 0.5867305994033813,
      "learning_rate": 2.016566265060241e-06,
      "loss": 0.2333,
      "step": 3965
    },
    {
      "epoch": 2.3891566265060242,
      "grad_norm": 0.5471062660217285,
      "learning_rate": 2.015813253012048e-06,
      "loss": 0.1494,
      "step": 3966
    },
    {
      "epoch": 2.389759036144578,
      "grad_norm": 0.5303135514259338,
      "learning_rate": 2.0150602409638555e-06,
      "loss": 0.1568,
      "step": 3967
    },
    {
      "epoch": 2.3903614457831326,
      "grad_norm": 0.555569589138031,
      "learning_rate": 2.014307228915663e-06,
      "loss": 0.1589,
      "step": 3968
    },
    {
      "epoch": 2.3909638554216865,
      "grad_norm": 0.6929572820663452,
      "learning_rate": 2.01355421686747e-06,
      "loss": 0.168,
      "step": 3969
    },
    {
      "epoch": 2.391566265060241,
      "grad_norm": 0.6774054169654846,
      "learning_rate": 2.012801204819277e-06,
      "loss": 0.235,
      "step": 3970
    },
    {
      "epoch": 2.3921686746987953,
      "grad_norm": 0.5458376407623291,
      "learning_rate": 2.0120481927710845e-06,
      "loss": 0.1584,
      "step": 3971
    },
    {
      "epoch": 2.3927710843373493,
      "grad_norm": 0.5055717825889587,
      "learning_rate": 2.011295180722892e-06,
      "loss": 0.1313,
      "step": 3972
    },
    {
      "epoch": 2.3933734939759037,
      "grad_norm": 0.5064873695373535,
      "learning_rate": 2.010542168674699e-06,
      "loss": 0.1702,
      "step": 3973
    },
    {
      "epoch": 2.3939759036144577,
      "grad_norm": 0.5064427256584167,
      "learning_rate": 2.009789156626506e-06,
      "loss": 0.2067,
      "step": 3974
    },
    {
      "epoch": 2.394578313253012,
      "grad_norm": 0.6929488182067871,
      "learning_rate": 2.0090361445783134e-06,
      "loss": 0.1927,
      "step": 3975
    },
    {
      "epoch": 2.395180722891566,
      "grad_norm": 0.5996243357658386,
      "learning_rate": 2.0082831325301203e-06,
      "loss": 0.1552,
      "step": 3976
    },
    {
      "epoch": 2.3957831325301204,
      "grad_norm": 0.5151338577270508,
      "learning_rate": 2.0075301204819277e-06,
      "loss": 0.1406,
      "step": 3977
    },
    {
      "epoch": 2.396385542168675,
      "grad_norm": 0.5302402973175049,
      "learning_rate": 2.006777108433735e-06,
      "loss": 0.1912,
      "step": 3978
    },
    {
      "epoch": 2.396987951807229,
      "grad_norm": 0.5547770261764526,
      "learning_rate": 2.0060240963855424e-06,
      "loss": 0.1528,
      "step": 3979
    },
    {
      "epoch": 2.397590361445783,
      "grad_norm": 1.0196614265441895,
      "learning_rate": 2.0052710843373497e-06,
      "loss": 0.2608,
      "step": 3980
    },
    {
      "epoch": 2.3981927710843376,
      "grad_norm": 0.85981285572052,
      "learning_rate": 2.004518072289157e-06,
      "loss": 0.2252,
      "step": 3981
    },
    {
      "epoch": 2.3987951807228916,
      "grad_norm": 0.9206973314285278,
      "learning_rate": 2.003765060240964e-06,
      "loss": 0.2851,
      "step": 3982
    },
    {
      "epoch": 2.399397590361446,
      "grad_norm": 0.6840278506278992,
      "learning_rate": 2.0030120481927714e-06,
      "loss": 0.247,
      "step": 3983
    },
    {
      "epoch": 2.4,
      "grad_norm": 0.7819807529449463,
      "learning_rate": 2.0022590361445783e-06,
      "loss": 0.2807,
      "step": 3984
    },
    {
      "epoch": 2.4006024096385543,
      "grad_norm": 0.8715072870254517,
      "learning_rate": 2.0015060240963856e-06,
      "loss": 0.2861,
      "step": 3985
    },
    {
      "epoch": 2.4012048192771083,
      "grad_norm": 0.7107157111167908,
      "learning_rate": 2.000753012048193e-06,
      "loss": 0.3064,
      "step": 3986
    },
    {
      "epoch": 2.4018072289156627,
      "grad_norm": 0.809806227684021,
      "learning_rate": 2.0000000000000003e-06,
      "loss": 0.2925,
      "step": 3987
    },
    {
      "epoch": 2.402409638554217,
      "grad_norm": 1.0185253620147705,
      "learning_rate": 1.9992469879518073e-06,
      "loss": 0.2859,
      "step": 3988
    },
    {
      "epoch": 2.403012048192771,
      "grad_norm": 0.7767285704612732,
      "learning_rate": 1.9984939759036146e-06,
      "loss": 0.2662,
      "step": 3989
    },
    {
      "epoch": 2.4036144578313254,
      "grad_norm": 0.7056714296340942,
      "learning_rate": 1.997740963855422e-06,
      "loss": 0.2663,
      "step": 3990
    },
    {
      "epoch": 2.4042168674698794,
      "grad_norm": 0.661688506603241,
      "learning_rate": 1.9969879518072293e-06,
      "loss": 0.2447,
      "step": 3991
    },
    {
      "epoch": 2.404819277108434,
      "grad_norm": 0.6701342463493347,
      "learning_rate": 1.9962349397590362e-06,
      "loss": 0.2099,
      "step": 3992
    },
    {
      "epoch": 2.4054216867469878,
      "grad_norm": 0.600692868232727,
      "learning_rate": 1.9954819277108436e-06,
      "loss": 0.2372,
      "step": 3993
    },
    {
      "epoch": 2.406024096385542,
      "grad_norm": 0.6148808002471924,
      "learning_rate": 1.9947289156626505e-06,
      "loss": 0.2366,
      "step": 3994
    },
    {
      "epoch": 2.4066265060240966,
      "grad_norm": 0.6844013333320618,
      "learning_rate": 1.993975903614458e-06,
      "loss": 0.2092,
      "step": 3995
    },
    {
      "epoch": 2.4072289156626505,
      "grad_norm": 0.7787164449691772,
      "learning_rate": 1.993222891566265e-06,
      "loss": 0.2689,
      "step": 3996
    },
    {
      "epoch": 2.407831325301205,
      "grad_norm": 0.5895111560821533,
      "learning_rate": 1.9924698795180725e-06,
      "loss": 0.2196,
      "step": 3997
    },
    {
      "epoch": 2.408433734939759,
      "grad_norm": 0.6260574460029602,
      "learning_rate": 1.99171686746988e-06,
      "loss": 0.2391,
      "step": 3998
    },
    {
      "epoch": 2.4090361445783133,
      "grad_norm": 0.6619284749031067,
      "learning_rate": 1.990963855421687e-06,
      "loss": 0.2263,
      "step": 3999
    },
    {
      "epoch": 2.4096385542168672,
      "grad_norm": 0.6154717206954956,
      "learning_rate": 1.990210843373494e-06,
      "loss": 0.2096,
      "step": 4000
    },
    {
      "epoch": 2.4102409638554216,
      "grad_norm": 0.5924729108810425,
      "learning_rate": 1.989457831325301e-06,
      "loss": 0.2172,
      "step": 4001
    },
    {
      "epoch": 2.410843373493976,
      "grad_norm": 0.6578376889228821,
      "learning_rate": 1.9887048192771084e-06,
      "loss": 0.2367,
      "step": 4002
    },
    {
      "epoch": 2.41144578313253,
      "grad_norm": 0.6662833094596863,
      "learning_rate": 1.987951807228916e-06,
      "loss": 0.2415,
      "step": 4003
    },
    {
      "epoch": 2.4120481927710844,
      "grad_norm": 0.5396203994750977,
      "learning_rate": 1.987198795180723e-06,
      "loss": 0.2515,
      "step": 4004
    },
    {
      "epoch": 2.412650602409639,
      "grad_norm": 0.6331636309623718,
      "learning_rate": 1.9864457831325305e-06,
      "loss": 0.2463,
      "step": 4005
    },
    {
      "epoch": 2.4132530120481928,
      "grad_norm": 0.6816784739494324,
      "learning_rate": 1.9856927710843374e-06,
      "loss": 0.2729,
      "step": 4006
    },
    {
      "epoch": 2.413855421686747,
      "grad_norm": 0.5031815767288208,
      "learning_rate": 1.9849397590361448e-06,
      "loss": 0.2583,
      "step": 4007
    },
    {
      "epoch": 2.414457831325301,
      "grad_norm": 0.6514737010002136,
      "learning_rate": 1.984186746987952e-06,
      "loss": 0.248,
      "step": 4008
    },
    {
      "epoch": 2.4150602409638555,
      "grad_norm": 0.589351236820221,
      "learning_rate": 1.983433734939759e-06,
      "loss": 0.2422,
      "step": 4009
    },
    {
      "epoch": 2.4156626506024095,
      "grad_norm": 0.7342782020568848,
      "learning_rate": 1.9826807228915664e-06,
      "loss": 0.2766,
      "step": 4010
    },
    {
      "epoch": 2.416265060240964,
      "grad_norm": 0.5904234051704407,
      "learning_rate": 1.9819277108433737e-06,
      "loss": 0.2276,
      "step": 4011
    },
    {
      "epoch": 2.4168674698795183,
      "grad_norm": 0.5740951895713806,
      "learning_rate": 1.9811746987951807e-06,
      "loss": 0.2309,
      "step": 4012
    },
    {
      "epoch": 2.4174698795180722,
      "grad_norm": 0.5987600088119507,
      "learning_rate": 1.980421686746988e-06,
      "loss": 0.2239,
      "step": 4013
    },
    {
      "epoch": 2.4180722891566266,
      "grad_norm": 0.5751389265060425,
      "learning_rate": 1.9796686746987954e-06,
      "loss": 0.2656,
      "step": 4014
    },
    {
      "epoch": 2.4186746987951806,
      "grad_norm": 0.5426429510116577,
      "learning_rate": 1.9789156626506027e-06,
      "loss": 0.2432,
      "step": 4015
    },
    {
      "epoch": 2.419277108433735,
      "grad_norm": 0.5438750386238098,
      "learning_rate": 1.97816265060241e-06,
      "loss": 0.2089,
      "step": 4016
    },
    {
      "epoch": 2.419879518072289,
      "grad_norm": 0.6172377467155457,
      "learning_rate": 1.977409638554217e-06,
      "loss": 0.2526,
      "step": 4017
    },
    {
      "epoch": 2.4204819277108434,
      "grad_norm": 0.6231994032859802,
      "learning_rate": 1.9766566265060243e-06,
      "loss": 0.2398,
      "step": 4018
    },
    {
      "epoch": 2.4210843373493978,
      "grad_norm": 0.6319229602813721,
      "learning_rate": 1.9759036144578312e-06,
      "loss": 0.2269,
      "step": 4019
    },
    {
      "epoch": 2.4216867469879517,
      "grad_norm": 0.6174767017364502,
      "learning_rate": 1.9751506024096386e-06,
      "loss": 0.2562,
      "step": 4020
    },
    {
      "epoch": 2.422289156626506,
      "grad_norm": 0.6344251036643982,
      "learning_rate": 1.974397590361446e-06,
      "loss": 0.2782,
      "step": 4021
    },
    {
      "epoch": 2.42289156626506,
      "grad_norm": 0.519610583782196,
      "learning_rate": 1.9736445783132533e-06,
      "loss": 0.2191,
      "step": 4022
    },
    {
      "epoch": 2.4234939759036145,
      "grad_norm": 0.547511100769043,
      "learning_rate": 1.9728915662650606e-06,
      "loss": 0.2604,
      "step": 4023
    },
    {
      "epoch": 2.4240963855421684,
      "grad_norm": 0.5917853713035583,
      "learning_rate": 1.9721385542168676e-06,
      "loss": 0.2555,
      "step": 4024
    },
    {
      "epoch": 2.424698795180723,
      "grad_norm": 0.5890570282936096,
      "learning_rate": 1.971385542168675e-06,
      "loss": 0.2573,
      "step": 4025
    },
    {
      "epoch": 2.4253012048192772,
      "grad_norm": 0.5003855228424072,
      "learning_rate": 1.9706325301204823e-06,
      "loss": 0.2349,
      "step": 4026
    },
    {
      "epoch": 2.425903614457831,
      "grad_norm": 0.5829842686653137,
      "learning_rate": 1.969879518072289e-06,
      "loss": 0.2768,
      "step": 4027
    },
    {
      "epoch": 2.4265060240963856,
      "grad_norm": 0.7440627813339233,
      "learning_rate": 1.9691265060240965e-06,
      "loss": 0.2318,
      "step": 4028
    },
    {
      "epoch": 2.42710843373494,
      "grad_norm": 0.556801438331604,
      "learning_rate": 1.968373493975904e-06,
      "loss": 0.2148,
      "step": 4029
    },
    {
      "epoch": 2.427710843373494,
      "grad_norm": 0.5653356313705444,
      "learning_rate": 1.967620481927711e-06,
      "loss": 0.2568,
      "step": 4030
    },
    {
      "epoch": 2.4283132530120484,
      "grad_norm": 0.6792851686477661,
      "learning_rate": 1.966867469879518e-06,
      "loss": 0.2695,
      "step": 4031
    },
    {
      "epoch": 2.4289156626506023,
      "grad_norm": 0.5874502062797546,
      "learning_rate": 1.9661144578313255e-06,
      "loss": 0.2682,
      "step": 4032
    },
    {
      "epoch": 2.4295180722891567,
      "grad_norm": 0.6133532524108887,
      "learning_rate": 1.965361445783133e-06,
      "loss": 0.2296,
      "step": 4033
    },
    {
      "epoch": 2.4301204819277107,
      "grad_norm": 0.5898541808128357,
      "learning_rate": 1.9646084337349398e-06,
      "loss": 0.2334,
      "step": 4034
    },
    {
      "epoch": 2.430722891566265,
      "grad_norm": 0.5408706068992615,
      "learning_rate": 1.963855421686747e-06,
      "loss": 0.2766,
      "step": 4035
    },
    {
      "epoch": 2.4313253012048195,
      "grad_norm": 0.5347334742546082,
      "learning_rate": 1.963102409638554e-06,
      "loss": 0.2019,
      "step": 4036
    },
    {
      "epoch": 2.4319277108433734,
      "grad_norm": 0.5590751767158508,
      "learning_rate": 1.9623493975903614e-06,
      "loss": 0.1923,
      "step": 4037
    },
    {
      "epoch": 2.432530120481928,
      "grad_norm": 0.5700901746749878,
      "learning_rate": 1.9615963855421687e-06,
      "loss": 0.1949,
      "step": 4038
    },
    {
      "epoch": 2.433132530120482,
      "grad_norm": 0.5347194075584412,
      "learning_rate": 1.960843373493976e-06,
      "loss": 0.2292,
      "step": 4039
    },
    {
      "epoch": 2.433734939759036,
      "grad_norm": 0.7636248469352722,
      "learning_rate": 1.9600903614457834e-06,
      "loss": 0.3209,
      "step": 4040
    },
    {
      "epoch": 2.43433734939759,
      "grad_norm": 0.5599395632743835,
      "learning_rate": 1.959337349397591e-06,
      "loss": 0.2384,
      "step": 4041
    },
    {
      "epoch": 2.4349397590361446,
      "grad_norm": 0.663159191608429,
      "learning_rate": 1.9585843373493977e-06,
      "loss": 0.3022,
      "step": 4042
    },
    {
      "epoch": 2.435542168674699,
      "grad_norm": 0.5283423066139221,
      "learning_rate": 1.957831325301205e-06,
      "loss": 0.2114,
      "step": 4043
    },
    {
      "epoch": 2.436144578313253,
      "grad_norm": 0.6129359602928162,
      "learning_rate": 1.957078313253012e-06,
      "loss": 0.2651,
      "step": 4044
    },
    {
      "epoch": 2.4367469879518073,
      "grad_norm": 0.5382372736930847,
      "learning_rate": 1.9563253012048193e-06,
      "loss": 0.2264,
      "step": 4045
    },
    {
      "epoch": 2.4373493975903613,
      "grad_norm": 0.5447978973388672,
      "learning_rate": 1.9555722891566267e-06,
      "loss": 0.2351,
      "step": 4046
    },
    {
      "epoch": 2.4379518072289157,
      "grad_norm": 0.6311960816383362,
      "learning_rate": 1.954819277108434e-06,
      "loss": 0.2893,
      "step": 4047
    },
    {
      "epoch": 2.4385542168674696,
      "grad_norm": 0.6828269958496094,
      "learning_rate": 1.954066265060241e-06,
      "loss": 0.2463,
      "step": 4048
    },
    {
      "epoch": 2.439156626506024,
      "grad_norm": 0.5757770538330078,
      "learning_rate": 1.9533132530120483e-06,
      "loss": 0.2025,
      "step": 4049
    },
    {
      "epoch": 2.4397590361445785,
      "grad_norm": 0.5571977496147156,
      "learning_rate": 1.9525602409638557e-06,
      "loss": 0.2391,
      "step": 4050
    },
    {
      "epoch": 2.4403614457831324,
      "grad_norm": 0.6100050210952759,
      "learning_rate": 1.951807228915663e-06,
      "loss": 0.2462,
      "step": 4051
    },
    {
      "epoch": 2.440963855421687,
      "grad_norm": 0.6378921270370483,
      "learning_rate": 1.95105421686747e-06,
      "loss": 0.2413,
      "step": 4052
    },
    {
      "epoch": 2.4415662650602408,
      "grad_norm": 0.6298341155052185,
      "learning_rate": 1.9503012048192773e-06,
      "loss": 0.2725,
      "step": 4053
    },
    {
      "epoch": 2.442168674698795,
      "grad_norm": 0.49416103959083557,
      "learning_rate": 1.949548192771084e-06,
      "loss": 0.2225,
      "step": 4054
    },
    {
      "epoch": 2.4427710843373496,
      "grad_norm": 0.641808271408081,
      "learning_rate": 1.9487951807228916e-06,
      "loss": 0.2523,
      "step": 4055
    },
    {
      "epoch": 2.4433734939759035,
      "grad_norm": 0.5828956961631775,
      "learning_rate": 1.948042168674699e-06,
      "loss": 0.2306,
      "step": 4056
    },
    {
      "epoch": 2.443975903614458,
      "grad_norm": 0.600966215133667,
      "learning_rate": 1.9472891566265062e-06,
      "loss": 0.3159,
      "step": 4057
    },
    {
      "epoch": 2.444578313253012,
      "grad_norm": 0.6432302594184875,
      "learning_rate": 1.9465361445783136e-06,
      "loss": 0.27,
      "step": 4058
    },
    {
      "epoch": 2.4451807228915663,
      "grad_norm": 0.6364191770553589,
      "learning_rate": 1.945783132530121e-06,
      "loss": 0.2622,
      "step": 4059
    },
    {
      "epoch": 2.4457831325301207,
      "grad_norm": 0.5801843404769897,
      "learning_rate": 1.945030120481928e-06,
      "loss": 0.2354,
      "step": 4060
    },
    {
      "epoch": 2.4463855421686747,
      "grad_norm": 0.5758733749389648,
      "learning_rate": 1.9442771084337352e-06,
      "loss": 0.1876,
      "step": 4061
    },
    {
      "epoch": 2.446987951807229,
      "grad_norm": 0.5600336790084839,
      "learning_rate": 1.943524096385542e-06,
      "loss": 0.2066,
      "step": 4062
    },
    {
      "epoch": 2.447590361445783,
      "grad_norm": 0.5826074481010437,
      "learning_rate": 1.9427710843373495e-06,
      "loss": 0.2232,
      "step": 4063
    },
    {
      "epoch": 2.4481927710843374,
      "grad_norm": 0.5485101342201233,
      "learning_rate": 1.942018072289157e-06,
      "loss": 0.2665,
      "step": 4064
    },
    {
      "epoch": 2.4487951807228914,
      "grad_norm": 0.5599848628044128,
      "learning_rate": 1.941265060240964e-06,
      "loss": 0.2461,
      "step": 4065
    },
    {
      "epoch": 2.4493975903614458,
      "grad_norm": 0.6943188905715942,
      "learning_rate": 1.940512048192771e-06,
      "loss": 0.2315,
      "step": 4066
    },
    {
      "epoch": 2.45,
      "grad_norm": 0.6125723123550415,
      "learning_rate": 1.9397590361445785e-06,
      "loss": 0.2818,
      "step": 4067
    },
    {
      "epoch": 2.450602409638554,
      "grad_norm": 0.6243128180503845,
      "learning_rate": 1.939006024096386e-06,
      "loss": 0.2392,
      "step": 4068
    },
    {
      "epoch": 2.4512048192771085,
      "grad_norm": 0.5535086989402771,
      "learning_rate": 1.9382530120481927e-06,
      "loss": 0.2389,
      "step": 4069
    },
    {
      "epoch": 2.4518072289156625,
      "grad_norm": 0.5917933583259583,
      "learning_rate": 1.9375e-06,
      "loss": 0.199,
      "step": 4070
    },
    {
      "epoch": 2.452409638554217,
      "grad_norm": 0.6277459859848022,
      "learning_rate": 1.9367469879518074e-06,
      "loss": 0.2263,
      "step": 4071
    },
    {
      "epoch": 2.453012048192771,
      "grad_norm": 0.5395311713218689,
      "learning_rate": 1.9359939759036144e-06,
      "loss": 0.2439,
      "step": 4072
    },
    {
      "epoch": 2.4536144578313253,
      "grad_norm": 0.5252392888069153,
      "learning_rate": 1.9352409638554217e-06,
      "loss": 0.2644,
      "step": 4073
    },
    {
      "epoch": 2.4542168674698797,
      "grad_norm": 0.5103875994682312,
      "learning_rate": 1.934487951807229e-06,
      "loss": 0.1889,
      "step": 4074
    },
    {
      "epoch": 2.4548192771084336,
      "grad_norm": 0.6597719788551331,
      "learning_rate": 1.9337349397590364e-06,
      "loss": 0.3371,
      "step": 4075
    },
    {
      "epoch": 2.455421686746988,
      "grad_norm": 0.5915153622627258,
      "learning_rate": 1.9329819277108438e-06,
      "loss": 0.249,
      "step": 4076
    },
    {
      "epoch": 2.456024096385542,
      "grad_norm": 0.644243061542511,
      "learning_rate": 1.9322289156626507e-06,
      "loss": 0.2715,
      "step": 4077
    },
    {
      "epoch": 2.4566265060240964,
      "grad_norm": 0.5416055917739868,
      "learning_rate": 1.931475903614458e-06,
      "loss": 0.1967,
      "step": 4078
    },
    {
      "epoch": 2.457228915662651,
      "grad_norm": 0.513384222984314,
      "learning_rate": 1.930722891566265e-06,
      "loss": 0.2266,
      "step": 4079
    },
    {
      "epoch": 2.4578313253012047,
      "grad_norm": 0.5542532801628113,
      "learning_rate": 1.9299698795180723e-06,
      "loss": 0.2671,
      "step": 4080
    },
    {
      "epoch": 2.458433734939759,
      "grad_norm": 0.594348669052124,
      "learning_rate": 1.9292168674698796e-06,
      "loss": 0.2753,
      "step": 4081
    },
    {
      "epoch": 2.459036144578313,
      "grad_norm": 0.6398956775665283,
      "learning_rate": 1.928463855421687e-06,
      "loss": 0.2655,
      "step": 4082
    },
    {
      "epoch": 2.4596385542168675,
      "grad_norm": 0.5644626021385193,
      "learning_rate": 1.9277108433734943e-06,
      "loss": 0.214,
      "step": 4083
    },
    {
      "epoch": 2.460240963855422,
      "grad_norm": 0.5919389128684998,
      "learning_rate": 1.9269578313253013e-06,
      "loss": 0.2723,
      "step": 4084
    },
    {
      "epoch": 2.460843373493976,
      "grad_norm": 0.5532826781272888,
      "learning_rate": 1.9262048192771086e-06,
      "loss": 0.1973,
      "step": 4085
    },
    {
      "epoch": 2.4614457831325303,
      "grad_norm": 0.5709428191184998,
      "learning_rate": 1.925451807228916e-06,
      "loss": 0.2533,
      "step": 4086
    },
    {
      "epoch": 2.462048192771084,
      "grad_norm": 0.5846443176269531,
      "learning_rate": 1.924698795180723e-06,
      "loss": 0.224,
      "step": 4087
    },
    {
      "epoch": 2.4626506024096386,
      "grad_norm": 0.6445053815841675,
      "learning_rate": 1.9239457831325302e-06,
      "loss": 0.2711,
      "step": 4088
    },
    {
      "epoch": 2.4632530120481926,
      "grad_norm": 0.5703477263450623,
      "learning_rate": 1.9231927710843376e-06,
      "loss": 0.2426,
      "step": 4089
    },
    {
      "epoch": 2.463855421686747,
      "grad_norm": 0.5986958742141724,
      "learning_rate": 1.9224397590361445e-06,
      "loss": 0.2492,
      "step": 4090
    },
    {
      "epoch": 2.4644578313253014,
      "grad_norm": 0.5973945260047913,
      "learning_rate": 1.921686746987952e-06,
      "loss": 0.2373,
      "step": 4091
    },
    {
      "epoch": 2.4650602409638553,
      "grad_norm": 0.5349066853523254,
      "learning_rate": 1.920933734939759e-06,
      "loss": 0.2455,
      "step": 4092
    },
    {
      "epoch": 2.4656626506024097,
      "grad_norm": 0.520725667476654,
      "learning_rate": 1.9201807228915666e-06,
      "loss": 0.2466,
      "step": 4093
    },
    {
      "epoch": 2.4662650602409637,
      "grad_norm": 0.47822305560112,
      "learning_rate": 1.919427710843374e-06,
      "loss": 0.2114,
      "step": 4094
    },
    {
      "epoch": 2.466867469879518,
      "grad_norm": 0.5206749439239502,
      "learning_rate": 1.918674698795181e-06,
      "loss": 0.2067,
      "step": 4095
    },
    {
      "epoch": 2.467469879518072,
      "grad_norm": 0.5366492867469788,
      "learning_rate": 1.917921686746988e-06,
      "loss": 0.221,
      "step": 4096
    },
    {
      "epoch": 2.4680722891566265,
      "grad_norm": 0.5910221934318542,
      "learning_rate": 1.917168674698795e-06,
      "loss": 0.2587,
      "step": 4097
    },
    {
      "epoch": 2.468674698795181,
      "grad_norm": 0.5729392170906067,
      "learning_rate": 1.9164156626506025e-06,
      "loss": 0.2373,
      "step": 4098
    },
    {
      "epoch": 2.469277108433735,
      "grad_norm": 0.5326836705207825,
      "learning_rate": 1.91566265060241e-06,
      "loss": 0.2208,
      "step": 4099
    },
    {
      "epoch": 2.4698795180722892,
      "grad_norm": 0.6141873598098755,
      "learning_rate": 1.914909638554217e-06,
      "loss": 0.3026,
      "step": 4100
    },
    {
      "epoch": 2.470481927710843,
      "grad_norm": 0.5143375992774963,
      "learning_rate": 1.9141566265060245e-06,
      "loss": 0.2155,
      "step": 4101
    },
    {
      "epoch": 2.4710843373493976,
      "grad_norm": 0.5270258188247681,
      "learning_rate": 1.9134036144578314e-06,
      "loss": 0.2161,
      "step": 4102
    },
    {
      "epoch": 2.471686746987952,
      "grad_norm": 0.5499141216278076,
      "learning_rate": 1.9126506024096388e-06,
      "loss": 0.2248,
      "step": 4103
    },
    {
      "epoch": 2.472289156626506,
      "grad_norm": 0.5027323365211487,
      "learning_rate": 1.9118975903614457e-06,
      "loss": 0.2379,
      "step": 4104
    },
    {
      "epoch": 2.4728915662650603,
      "grad_norm": 0.5448102355003357,
      "learning_rate": 1.911144578313253e-06,
      "loss": 0.2102,
      "step": 4105
    },
    {
      "epoch": 2.4734939759036143,
      "grad_norm": 0.6101401448249817,
      "learning_rate": 1.9103915662650604e-06,
      "loss": 0.2466,
      "step": 4106
    },
    {
      "epoch": 2.4740963855421687,
      "grad_norm": 0.5525549650192261,
      "learning_rate": 1.9096385542168677e-06,
      "loss": 0.2242,
      "step": 4107
    },
    {
      "epoch": 2.474698795180723,
      "grad_norm": 0.5343763828277588,
      "learning_rate": 1.9088855421686747e-06,
      "loss": 0.2529,
      "step": 4108
    },
    {
      "epoch": 2.475301204819277,
      "grad_norm": 0.5408691763877869,
      "learning_rate": 1.908132530120482e-06,
      "loss": 0.231,
      "step": 4109
    },
    {
      "epoch": 2.4759036144578315,
      "grad_norm": 0.4996368885040283,
      "learning_rate": 1.9073795180722894e-06,
      "loss": 0.203,
      "step": 4110
    },
    {
      "epoch": 2.4765060240963854,
      "grad_norm": 0.6953019499778748,
      "learning_rate": 1.9066265060240965e-06,
      "loss": 0.2783,
      "step": 4111
    },
    {
      "epoch": 2.47710843373494,
      "grad_norm": 0.5993898510932922,
      "learning_rate": 1.9058734939759038e-06,
      "loss": 0.2621,
      "step": 4112
    },
    {
      "epoch": 2.477710843373494,
      "grad_norm": 0.5121602416038513,
      "learning_rate": 1.9051204819277112e-06,
      "loss": 0.2154,
      "step": 4113
    },
    {
      "epoch": 2.478313253012048,
      "grad_norm": 0.6890925168991089,
      "learning_rate": 1.9043674698795181e-06,
      "loss": 0.26,
      "step": 4114
    },
    {
      "epoch": 2.4789156626506026,
      "grad_norm": 0.5613242387771606,
      "learning_rate": 1.9036144578313255e-06,
      "loss": 0.2054,
      "step": 4115
    },
    {
      "epoch": 2.4795180722891565,
      "grad_norm": 0.6627657413482666,
      "learning_rate": 1.9028614457831326e-06,
      "loss": 0.2873,
      "step": 4116
    },
    {
      "epoch": 2.480120481927711,
      "grad_norm": 0.6628952622413635,
      "learning_rate": 1.90210843373494e-06,
      "loss": 0.2034,
      "step": 4117
    },
    {
      "epoch": 2.480722891566265,
      "grad_norm": 0.5339920520782471,
      "learning_rate": 1.901355421686747e-06,
      "loss": 0.2799,
      "step": 4118
    },
    {
      "epoch": 2.4813253012048193,
      "grad_norm": 0.7432783246040344,
      "learning_rate": 1.9006024096385544e-06,
      "loss": 0.2717,
      "step": 4119
    },
    {
      "epoch": 2.4819277108433733,
      "grad_norm": 0.5236830115318298,
      "learning_rate": 1.8998493975903614e-06,
      "loss": 0.2175,
      "step": 4120
    },
    {
      "epoch": 2.4825301204819277,
      "grad_norm": 0.5854840874671936,
      "learning_rate": 1.8990963855421687e-06,
      "loss": 0.2991,
      "step": 4121
    },
    {
      "epoch": 2.483132530120482,
      "grad_norm": 0.48892948031425476,
      "learning_rate": 1.898343373493976e-06,
      "loss": 0.1962,
      "step": 4122
    },
    {
      "epoch": 2.483734939759036,
      "grad_norm": 0.47073498368263245,
      "learning_rate": 1.8975903614457832e-06,
      "loss": 0.2256,
      "step": 4123
    },
    {
      "epoch": 2.4843373493975904,
      "grad_norm": 0.5434174537658691,
      "learning_rate": 1.8968373493975905e-06,
      "loss": 0.2522,
      "step": 4124
    },
    {
      "epoch": 2.4849397590361444,
      "grad_norm": 0.5725901126861572,
      "learning_rate": 1.8960843373493979e-06,
      "loss": 0.2219,
      "step": 4125
    },
    {
      "epoch": 2.485542168674699,
      "grad_norm": 0.7521374225616455,
      "learning_rate": 1.8953313253012048e-06,
      "loss": 0.3108,
      "step": 4126
    },
    {
      "epoch": 2.486144578313253,
      "grad_norm": 0.6105799674987793,
      "learning_rate": 1.8945783132530122e-06,
      "loss": 0.2639,
      "step": 4127
    },
    {
      "epoch": 2.486746987951807,
      "grad_norm": 0.6016235947608948,
      "learning_rate": 1.8938253012048193e-06,
      "loss": 0.1994,
      "step": 4128
    },
    {
      "epoch": 2.4873493975903616,
      "grad_norm": 0.5756626725196838,
      "learning_rate": 1.8930722891566267e-06,
      "loss": 0.2966,
      "step": 4129
    },
    {
      "epoch": 2.4879518072289155,
      "grad_norm": 0.5395975112915039,
      "learning_rate": 1.892319277108434e-06,
      "loss": 0.226,
      "step": 4130
    },
    {
      "epoch": 2.48855421686747,
      "grad_norm": 0.5361174941062927,
      "learning_rate": 1.8915662650602411e-06,
      "loss": 0.2265,
      "step": 4131
    },
    {
      "epoch": 2.4891566265060243,
      "grad_norm": 0.5554705262184143,
      "learning_rate": 1.8908132530120483e-06,
      "loss": 0.2397,
      "step": 4132
    },
    {
      "epoch": 2.4897590361445783,
      "grad_norm": 0.6239950656890869,
      "learning_rate": 1.8900602409638554e-06,
      "loss": 0.2861,
      "step": 4133
    },
    {
      "epoch": 2.4903614457831327,
      "grad_norm": 0.5005346536636353,
      "learning_rate": 1.8893072289156628e-06,
      "loss": 0.2096,
      "step": 4134
    },
    {
      "epoch": 2.4909638554216866,
      "grad_norm": 0.6449179649353027,
      "learning_rate": 1.8885542168674701e-06,
      "loss": 0.2315,
      "step": 4135
    },
    {
      "epoch": 2.491566265060241,
      "grad_norm": 0.6212722659111023,
      "learning_rate": 1.8878012048192772e-06,
      "loss": 0.2708,
      "step": 4136
    },
    {
      "epoch": 2.492168674698795,
      "grad_norm": 0.6949707269668579,
      "learning_rate": 1.8870481927710846e-06,
      "loss": 0.2267,
      "step": 4137
    },
    {
      "epoch": 2.4927710843373494,
      "grad_norm": 0.5638089776039124,
      "learning_rate": 1.8862951807228915e-06,
      "loss": 0.2802,
      "step": 4138
    },
    {
      "epoch": 2.493373493975904,
      "grad_norm": 0.5678189992904663,
      "learning_rate": 1.8855421686746989e-06,
      "loss": 0.2566,
      "step": 4139
    },
    {
      "epoch": 2.4939759036144578,
      "grad_norm": 0.5563007593154907,
      "learning_rate": 1.8847891566265062e-06,
      "loss": 0.2458,
      "step": 4140
    },
    {
      "epoch": 2.494578313253012,
      "grad_norm": 0.6175590753555298,
      "learning_rate": 1.8840361445783133e-06,
      "loss": 0.262,
      "step": 4141
    },
    {
      "epoch": 2.495180722891566,
      "grad_norm": 0.5978707671165466,
      "learning_rate": 1.8832831325301207e-06,
      "loss": 0.3031,
      "step": 4142
    },
    {
      "epoch": 2.4957831325301205,
      "grad_norm": 1.7960487604141235,
      "learning_rate": 1.882530120481928e-06,
      "loss": 0.2296,
      "step": 4143
    },
    {
      "epoch": 2.4963855421686745,
      "grad_norm": 0.571688711643219,
      "learning_rate": 1.881777108433735e-06,
      "loss": 0.2188,
      "step": 4144
    },
    {
      "epoch": 2.496987951807229,
      "grad_norm": 0.5895612835884094,
      "learning_rate": 1.8810240963855423e-06,
      "loss": 0.2786,
      "step": 4145
    },
    {
      "epoch": 2.4975903614457833,
      "grad_norm": 0.5540425777435303,
      "learning_rate": 1.8802710843373495e-06,
      "loss": 0.3006,
      "step": 4146
    },
    {
      "epoch": 2.4981927710843372,
      "grad_norm": 0.4893565773963928,
      "learning_rate": 1.8795180722891568e-06,
      "loss": 0.2215,
      "step": 4147
    },
    {
      "epoch": 2.4987951807228916,
      "grad_norm": 0.5500717759132385,
      "learning_rate": 1.8787650602409642e-06,
      "loss": 0.2034,
      "step": 4148
    },
    {
      "epoch": 2.4993975903614456,
      "grad_norm": 0.5218420028686523,
      "learning_rate": 1.8780120481927713e-06,
      "loss": 0.2177,
      "step": 4149
    },
    {
      "epoch": 2.5,
      "grad_norm": 0.5612185597419739,
      "learning_rate": 1.8772590361445784e-06,
      "loss": 0.2216,
      "step": 4150
    },
    {
      "epoch": 2.500602409638554,
      "grad_norm": 0.5174645781517029,
      "learning_rate": 1.8765060240963856e-06,
      "loss": 0.1894,
      "step": 4151
    },
    {
      "epoch": 2.5012048192771084,
      "grad_norm": 0.540307879447937,
      "learning_rate": 1.875753012048193e-06,
      "loss": 0.2075,
      "step": 4152
    },
    {
      "epoch": 2.5018072289156628,
      "grad_norm": 0.5437012910842896,
      "learning_rate": 1.8750000000000003e-06,
      "loss": 0.2017,
      "step": 4153
    },
    {
      "epoch": 2.5024096385542167,
      "grad_norm": 0.533671498298645,
      "learning_rate": 1.8742469879518074e-06,
      "loss": 0.2271,
      "step": 4154
    },
    {
      "epoch": 2.503012048192771,
      "grad_norm": 0.5381912589073181,
      "learning_rate": 1.8734939759036147e-06,
      "loss": 0.2269,
      "step": 4155
    },
    {
      "epoch": 2.5036144578313255,
      "grad_norm": 0.5800511240959167,
      "learning_rate": 1.8727409638554219e-06,
      "loss": 0.2274,
      "step": 4156
    },
    {
      "epoch": 2.5042168674698795,
      "grad_norm": 0.5145320296287537,
      "learning_rate": 1.871987951807229e-06,
      "loss": 0.1991,
      "step": 4157
    },
    {
      "epoch": 2.504819277108434,
      "grad_norm": 0.5702425837516785,
      "learning_rate": 1.8712349397590362e-06,
      "loss": 0.2675,
      "step": 4158
    },
    {
      "epoch": 2.505421686746988,
      "grad_norm": 0.6247693300247192,
      "learning_rate": 1.8704819277108435e-06,
      "loss": 0.2438,
      "step": 4159
    },
    {
      "epoch": 2.5060240963855422,
      "grad_norm": 0.5399026870727539,
      "learning_rate": 1.8697289156626509e-06,
      "loss": 0.2111,
      "step": 4160
    },
    {
      "epoch": 2.506626506024096,
      "grad_norm": 0.4851428270339966,
      "learning_rate": 1.868975903614458e-06,
      "loss": 0.2156,
      "step": 4161
    },
    {
      "epoch": 2.5072289156626506,
      "grad_norm": 0.5392449498176575,
      "learning_rate": 1.8682228915662653e-06,
      "loss": 0.2205,
      "step": 4162
    },
    {
      "epoch": 2.507831325301205,
      "grad_norm": 0.5452139377593994,
      "learning_rate": 1.8674698795180723e-06,
      "loss": 0.2055,
      "step": 4163
    },
    {
      "epoch": 2.508433734939759,
      "grad_norm": 0.5606639981269836,
      "learning_rate": 1.8667168674698796e-06,
      "loss": 0.2066,
      "step": 4164
    },
    {
      "epoch": 2.5090361445783134,
      "grad_norm": 0.5731418132781982,
      "learning_rate": 1.865963855421687e-06,
      "loss": 0.2453,
      "step": 4165
    },
    {
      "epoch": 2.5096385542168673,
      "grad_norm": 0.5352692008018494,
      "learning_rate": 1.865210843373494e-06,
      "loss": 0.2136,
      "step": 4166
    },
    {
      "epoch": 2.5102409638554217,
      "grad_norm": 0.5675219893455505,
      "learning_rate": 1.8644578313253014e-06,
      "loss": 0.2306,
      "step": 4167
    },
    {
      "epoch": 2.5108433734939757,
      "grad_norm": 0.5302751064300537,
      "learning_rate": 1.8637048192771088e-06,
      "loss": 0.2598,
      "step": 4168
    },
    {
      "epoch": 2.51144578313253,
      "grad_norm": 0.7032073736190796,
      "learning_rate": 1.8629518072289157e-06,
      "loss": 0.2672,
      "step": 4169
    },
    {
      "epoch": 2.5120481927710845,
      "grad_norm": 0.5713899731636047,
      "learning_rate": 1.862198795180723e-06,
      "loss": 0.2338,
      "step": 4170
    },
    {
      "epoch": 2.5126506024096384,
      "grad_norm": 0.6343503594398499,
      "learning_rate": 1.8614457831325302e-06,
      "loss": 0.2262,
      "step": 4171
    },
    {
      "epoch": 2.513253012048193,
      "grad_norm": 1.7264524698257446,
      "learning_rate": 1.8606927710843375e-06,
      "loss": 0.222,
      "step": 4172
    },
    {
      "epoch": 2.5138554216867472,
      "grad_norm": 0.5606080889701843,
      "learning_rate": 1.859939759036145e-06,
      "loss": 0.2241,
      "step": 4173
    },
    {
      "epoch": 2.514457831325301,
      "grad_norm": 0.5329409837722778,
      "learning_rate": 1.859186746987952e-06,
      "loss": 0.2533,
      "step": 4174
    },
    {
      "epoch": 2.515060240963855,
      "grad_norm": 0.5746586322784424,
      "learning_rate": 1.8584337349397592e-06,
      "loss": 0.2203,
      "step": 4175
    },
    {
      "epoch": 2.5156626506024096,
      "grad_norm": 0.5973500609397888,
      "learning_rate": 1.8576807228915663e-06,
      "loss": 0.2334,
      "step": 4176
    },
    {
      "epoch": 2.516265060240964,
      "grad_norm": 0.5652442574501038,
      "learning_rate": 1.8569277108433737e-06,
      "loss": 0.2074,
      "step": 4177
    },
    {
      "epoch": 2.516867469879518,
      "grad_norm": 0.5594117045402527,
      "learning_rate": 1.856174698795181e-06,
      "loss": 0.2534,
      "step": 4178
    },
    {
      "epoch": 2.5174698795180723,
      "grad_norm": 0.6675346493721008,
      "learning_rate": 1.8554216867469881e-06,
      "loss": 0.2719,
      "step": 4179
    },
    {
      "epoch": 2.5180722891566267,
      "grad_norm": 0.6170796751976013,
      "learning_rate": 1.8546686746987955e-06,
      "loss": 0.2081,
      "step": 4180
    },
    {
      "epoch": 2.5186746987951807,
      "grad_norm": 0.5352886319160461,
      "learning_rate": 1.8539156626506024e-06,
      "loss": 0.207,
      "step": 4181
    },
    {
      "epoch": 2.519277108433735,
      "grad_norm": 0.5367038249969482,
      "learning_rate": 1.8531626506024098e-06,
      "loss": 0.2081,
      "step": 4182
    },
    {
      "epoch": 2.519879518072289,
      "grad_norm": 0.5493195652961731,
      "learning_rate": 1.8524096385542171e-06,
      "loss": 0.2156,
      "step": 4183
    },
    {
      "epoch": 2.5204819277108435,
      "grad_norm": 0.5033552646636963,
      "learning_rate": 1.8516566265060242e-06,
      "loss": 0.2426,
      "step": 4184
    },
    {
      "epoch": 2.5210843373493974,
      "grad_norm": 4.5502800941467285,
      "learning_rate": 1.8509036144578316e-06,
      "loss": 0.204,
      "step": 4185
    },
    {
      "epoch": 2.521686746987952,
      "grad_norm": 0.557880163192749,
      "learning_rate": 1.850150602409639e-06,
      "loss": 0.2184,
      "step": 4186
    },
    {
      "epoch": 2.522289156626506,
      "grad_norm": 0.613723874092102,
      "learning_rate": 1.8493975903614459e-06,
      "loss": 0.2973,
      "step": 4187
    },
    {
      "epoch": 2.52289156626506,
      "grad_norm": 0.5954106450080872,
      "learning_rate": 1.8486445783132532e-06,
      "loss": 0.2501,
      "step": 4188
    },
    {
      "epoch": 2.5234939759036146,
      "grad_norm": 0.6316177845001221,
      "learning_rate": 1.8478915662650604e-06,
      "loss": 0.2991,
      "step": 4189
    },
    {
      "epoch": 2.5240963855421685,
      "grad_norm": 0.47586992383003235,
      "learning_rate": 1.8471385542168677e-06,
      "loss": 0.1714,
      "step": 4190
    },
    {
      "epoch": 2.524698795180723,
      "grad_norm": 0.540404736995697,
      "learning_rate": 1.8463855421686748e-06,
      "loss": 0.2398,
      "step": 4191
    },
    {
      "epoch": 2.525301204819277,
      "grad_norm": 0.5857585072517395,
      "learning_rate": 1.8456325301204822e-06,
      "loss": 0.2552,
      "step": 4192
    },
    {
      "epoch": 2.5259036144578313,
      "grad_norm": 0.6201839447021484,
      "learning_rate": 1.8448795180722891e-06,
      "loss": 0.2405,
      "step": 4193
    },
    {
      "epoch": 2.5265060240963857,
      "grad_norm": 0.6038265824317932,
      "learning_rate": 1.8441265060240965e-06,
      "loss": 0.2265,
      "step": 4194
    },
    {
      "epoch": 2.5271084337349397,
      "grad_norm": 0.6193519234657288,
      "learning_rate": 1.8433734939759038e-06,
      "loss": 0.288,
      "step": 4195
    },
    {
      "epoch": 2.527710843373494,
      "grad_norm": 0.6227746605873108,
      "learning_rate": 1.842620481927711e-06,
      "loss": 0.2656,
      "step": 4196
    },
    {
      "epoch": 2.5283132530120485,
      "grad_norm": 0.4912360906600952,
      "learning_rate": 1.8418674698795183e-06,
      "loss": 0.1763,
      "step": 4197
    },
    {
      "epoch": 2.5289156626506024,
      "grad_norm": 0.5799663662910461,
      "learning_rate": 1.8411144578313256e-06,
      "loss": 0.2057,
      "step": 4198
    },
    {
      "epoch": 2.5295180722891564,
      "grad_norm": 0.5497810244560242,
      "learning_rate": 1.8403614457831326e-06,
      "loss": 0.2599,
      "step": 4199
    },
    {
      "epoch": 2.5301204819277108,
      "grad_norm": 0.6079164147377014,
      "learning_rate": 1.83960843373494e-06,
      "loss": 0.2367,
      "step": 4200
    },
    {
      "epoch": 2.530722891566265,
      "grad_norm": 0.8268604874610901,
      "learning_rate": 1.838855421686747e-06,
      "loss": 0.2654,
      "step": 4201
    },
    {
      "epoch": 2.531325301204819,
      "grad_norm": 0.5525985956192017,
      "learning_rate": 1.8381024096385544e-06,
      "loss": 0.2174,
      "step": 4202
    },
    {
      "epoch": 2.5319277108433735,
      "grad_norm": 0.6761370301246643,
      "learning_rate": 1.8373493975903617e-06,
      "loss": 0.2873,
      "step": 4203
    },
    {
      "epoch": 2.532530120481928,
      "grad_norm": 0.6462472081184387,
      "learning_rate": 1.8365963855421689e-06,
      "loss": 0.2805,
      "step": 4204
    },
    {
      "epoch": 2.533132530120482,
      "grad_norm": 0.514712393283844,
      "learning_rate": 1.835843373493976e-06,
      "loss": 0.196,
      "step": 4205
    },
    {
      "epoch": 2.5337349397590363,
      "grad_norm": 0.52213054895401,
      "learning_rate": 1.8350903614457832e-06,
      "loss": 0.2501,
      "step": 4206
    },
    {
      "epoch": 2.5343373493975903,
      "grad_norm": 0.5123235583305359,
      "learning_rate": 1.8343373493975905e-06,
      "loss": 0.1749,
      "step": 4207
    },
    {
      "epoch": 2.5349397590361447,
      "grad_norm": 0.6374816298484802,
      "learning_rate": 1.8335843373493979e-06,
      "loss": 0.2491,
      "step": 4208
    },
    {
      "epoch": 2.5355421686746986,
      "grad_norm": 0.48250898718833923,
      "learning_rate": 1.832831325301205e-06,
      "loss": 0.2337,
      "step": 4209
    },
    {
      "epoch": 2.536144578313253,
      "grad_norm": 0.5268365740776062,
      "learning_rate": 1.8320783132530123e-06,
      "loss": 0.2282,
      "step": 4210
    },
    {
      "epoch": 2.5367469879518074,
      "grad_norm": 0.6775372624397278,
      "learning_rate": 1.8313253012048193e-06,
      "loss": 0.268,
      "step": 4211
    },
    {
      "epoch": 2.5373493975903614,
      "grad_norm": 0.5528488755226135,
      "learning_rate": 1.8305722891566266e-06,
      "loss": 0.2027,
      "step": 4212
    },
    {
      "epoch": 2.537951807228916,
      "grad_norm": 0.5805331468582153,
      "learning_rate": 1.829819277108434e-06,
      "loss": 0.2523,
      "step": 4213
    },
    {
      "epoch": 2.5385542168674697,
      "grad_norm": 0.549247682094574,
      "learning_rate": 1.829066265060241e-06,
      "loss": 0.2483,
      "step": 4214
    },
    {
      "epoch": 2.539156626506024,
      "grad_norm": 0.5967830419540405,
      "learning_rate": 1.8283132530120484e-06,
      "loss": 0.2548,
      "step": 4215
    },
    {
      "epoch": 2.539759036144578,
      "grad_norm": 0.5121080875396729,
      "learning_rate": 1.8275602409638558e-06,
      "loss": 0.2404,
      "step": 4216
    },
    {
      "epoch": 2.5403614457831325,
      "grad_norm": 0.518923282623291,
      "learning_rate": 1.8268072289156627e-06,
      "loss": 0.2109,
      "step": 4217
    },
    {
      "epoch": 2.540963855421687,
      "grad_norm": 0.5197032690048218,
      "learning_rate": 1.82605421686747e-06,
      "loss": 0.2293,
      "step": 4218
    },
    {
      "epoch": 2.541566265060241,
      "grad_norm": 0.5145350098609924,
      "learning_rate": 1.8253012048192772e-06,
      "loss": 0.2521,
      "step": 4219
    },
    {
      "epoch": 2.5421686746987953,
      "grad_norm": 0.623474657535553,
      "learning_rate": 1.8245481927710846e-06,
      "loss": 0.2704,
      "step": 4220
    },
    {
      "epoch": 2.5427710843373497,
      "grad_norm": 0.612031102180481,
      "learning_rate": 1.823795180722892e-06,
      "loss": 0.2561,
      "step": 4221
    },
    {
      "epoch": 2.5433734939759036,
      "grad_norm": 0.5840293765068054,
      "learning_rate": 1.823042168674699e-06,
      "loss": 0.217,
      "step": 4222
    },
    {
      "epoch": 2.5439759036144576,
      "grad_norm": 0.5276907086372375,
      "learning_rate": 1.8222891566265062e-06,
      "loss": 0.2382,
      "step": 4223
    },
    {
      "epoch": 2.544578313253012,
      "grad_norm": 0.6341540217399597,
      "learning_rate": 1.8215361445783133e-06,
      "loss": 0.2715,
      "step": 4224
    },
    {
      "epoch": 2.5451807228915664,
      "grad_norm": 0.5586344003677368,
      "learning_rate": 1.8207831325301207e-06,
      "loss": 0.2551,
      "step": 4225
    },
    {
      "epoch": 2.5457831325301203,
      "grad_norm": 0.5423018932342529,
      "learning_rate": 1.8200301204819278e-06,
      "loss": 0.2727,
      "step": 4226
    },
    {
      "epoch": 2.5463855421686747,
      "grad_norm": 0.5802916884422302,
      "learning_rate": 1.8192771084337351e-06,
      "loss": 0.2531,
      "step": 4227
    },
    {
      "epoch": 2.546987951807229,
      "grad_norm": 0.4857810437679291,
      "learning_rate": 1.8185240963855425e-06,
      "loss": 0.1846,
      "step": 4228
    },
    {
      "epoch": 2.547590361445783,
      "grad_norm": 0.5841271281242371,
      "learning_rate": 1.8177710843373494e-06,
      "loss": 0.28,
      "step": 4229
    },
    {
      "epoch": 2.5481927710843375,
      "grad_norm": 0.5471778512001038,
      "learning_rate": 1.8170180722891568e-06,
      "loss": 0.2175,
      "step": 4230
    },
    {
      "epoch": 2.5487951807228915,
      "grad_norm": 0.5012534856796265,
      "learning_rate": 1.816265060240964e-06,
      "loss": 0.2219,
      "step": 4231
    },
    {
      "epoch": 2.549397590361446,
      "grad_norm": 0.5356009602546692,
      "learning_rate": 1.8155120481927713e-06,
      "loss": 0.2414,
      "step": 4232
    },
    {
      "epoch": 2.55,
      "grad_norm": 0.5195894837379456,
      "learning_rate": 1.8147590361445786e-06,
      "loss": 0.2497,
      "step": 4233
    },
    {
      "epoch": 2.5506024096385542,
      "grad_norm": 0.6729724407196045,
      "learning_rate": 1.8140060240963857e-06,
      "loss": 0.2975,
      "step": 4234
    },
    {
      "epoch": 2.5512048192771086,
      "grad_norm": 0.6137320399284363,
      "learning_rate": 1.8132530120481929e-06,
      "loss": 0.2794,
      "step": 4235
    },
    {
      "epoch": 2.5518072289156626,
      "grad_norm": 0.5517352223396301,
      "learning_rate": 1.8125e-06,
      "loss": 0.2255,
      "step": 4236
    },
    {
      "epoch": 2.552409638554217,
      "grad_norm": 0.671077311038971,
      "learning_rate": 1.8117469879518074e-06,
      "loss": 0.3441,
      "step": 4237
    },
    {
      "epoch": 2.553012048192771,
      "grad_norm": 0.5793914794921875,
      "learning_rate": 1.8109939759036147e-06,
      "loss": 0.2211,
      "step": 4238
    },
    {
      "epoch": 2.5536144578313253,
      "grad_norm": 0.6317911744117737,
      "learning_rate": 1.8102409638554218e-06,
      "loss": 0.2236,
      "step": 4239
    },
    {
      "epoch": 2.5542168674698793,
      "grad_norm": 0.557706356048584,
      "learning_rate": 1.8094879518072292e-06,
      "loss": 0.232,
      "step": 4240
    },
    {
      "epoch": 2.5548192771084337,
      "grad_norm": 0.5404340624809265,
      "learning_rate": 1.8087349397590361e-06,
      "loss": 0.252,
      "step": 4241
    },
    {
      "epoch": 2.555421686746988,
      "grad_norm": 0.5983055233955383,
      "learning_rate": 1.8079819277108435e-06,
      "loss": 0.27,
      "step": 4242
    },
    {
      "epoch": 2.556024096385542,
      "grad_norm": 0.5750996470451355,
      "learning_rate": 1.8072289156626508e-06,
      "loss": 0.2162,
      "step": 4243
    },
    {
      "epoch": 2.5566265060240965,
      "grad_norm": 0.6744373440742493,
      "learning_rate": 1.806475903614458e-06,
      "loss": 0.2268,
      "step": 4244
    },
    {
      "epoch": 2.557228915662651,
      "grad_norm": 0.5503731369972229,
      "learning_rate": 1.8057228915662653e-06,
      "loss": 0.2374,
      "step": 4245
    },
    {
      "epoch": 2.557831325301205,
      "grad_norm": 0.5297878980636597,
      "learning_rate": 1.8049698795180726e-06,
      "loss": 0.2006,
      "step": 4246
    },
    {
      "epoch": 2.558433734939759,
      "grad_norm": 0.557522714138031,
      "learning_rate": 1.8042168674698796e-06,
      "loss": 0.203,
      "step": 4247
    },
    {
      "epoch": 2.559036144578313,
      "grad_norm": 0.5217505097389221,
      "learning_rate": 1.803463855421687e-06,
      "loss": 0.2287,
      "step": 4248
    },
    {
      "epoch": 2.5596385542168676,
      "grad_norm": 0.5055585503578186,
      "learning_rate": 1.802710843373494e-06,
      "loss": 0.2071,
      "step": 4249
    },
    {
      "epoch": 2.5602409638554215,
      "grad_norm": 0.5571619868278503,
      "learning_rate": 1.8019578313253014e-06,
      "loss": 0.2042,
      "step": 4250
    },
    {
      "epoch": 2.560843373493976,
      "grad_norm": 0.5258644223213196,
      "learning_rate": 1.8012048192771088e-06,
      "loss": 0.1829,
      "step": 4251
    },
    {
      "epoch": 2.5614457831325304,
      "grad_norm": 0.5413935780525208,
      "learning_rate": 1.8004518072289159e-06,
      "loss": 0.2258,
      "step": 4252
    },
    {
      "epoch": 2.5620481927710843,
      "grad_norm": 0.5364790558815002,
      "learning_rate": 1.799698795180723e-06,
      "loss": 0.2377,
      "step": 4253
    },
    {
      "epoch": 2.5626506024096387,
      "grad_norm": 0.5431966781616211,
      "learning_rate": 1.7989457831325302e-06,
      "loss": 0.2038,
      "step": 4254
    },
    {
      "epoch": 2.5632530120481927,
      "grad_norm": 0.5274239182472229,
      "learning_rate": 1.7981927710843375e-06,
      "loss": 0.202,
      "step": 4255
    },
    {
      "epoch": 2.563855421686747,
      "grad_norm": 0.5196870565414429,
      "learning_rate": 1.7974397590361449e-06,
      "loss": 0.1754,
      "step": 4256
    },
    {
      "epoch": 2.564457831325301,
      "grad_norm": 0.4631022810935974,
      "learning_rate": 1.796686746987952e-06,
      "loss": 0.1915,
      "step": 4257
    },
    {
      "epoch": 2.5650602409638554,
      "grad_norm": 0.5223018527030945,
      "learning_rate": 1.7959337349397593e-06,
      "loss": 0.1999,
      "step": 4258
    },
    {
      "epoch": 2.56566265060241,
      "grad_norm": 0.5976635813713074,
      "learning_rate": 1.7951807228915663e-06,
      "loss": 0.2064,
      "step": 4259
    },
    {
      "epoch": 2.566265060240964,
      "grad_norm": 0.5931481719017029,
      "learning_rate": 1.7944277108433736e-06,
      "loss": 0.2666,
      "step": 4260
    },
    {
      "epoch": 2.566867469879518,
      "grad_norm": 0.5038749575614929,
      "learning_rate": 1.7936746987951808e-06,
      "loss": 0.2488,
      "step": 4261
    },
    {
      "epoch": 2.567469879518072,
      "grad_norm": 0.6082159876823425,
      "learning_rate": 1.792921686746988e-06,
      "loss": 0.2232,
      "step": 4262
    },
    {
      "epoch": 2.5680722891566266,
      "grad_norm": 0.5662474036216736,
      "learning_rate": 1.7921686746987955e-06,
      "loss": 0.2423,
      "step": 4263
    },
    {
      "epoch": 2.5686746987951805,
      "grad_norm": 0.6676283478736877,
      "learning_rate": 1.7914156626506026e-06,
      "loss": 0.2302,
      "step": 4264
    },
    {
      "epoch": 2.569277108433735,
      "grad_norm": 0.4941927492618561,
      "learning_rate": 1.7906626506024097e-06,
      "loss": 0.2024,
      "step": 4265
    },
    {
      "epoch": 2.5698795180722893,
      "grad_norm": 0.6568368673324585,
      "learning_rate": 1.7899096385542169e-06,
      "loss": 0.2712,
      "step": 4266
    },
    {
      "epoch": 2.5704819277108433,
      "grad_norm": 0.5813097953796387,
      "learning_rate": 1.7891566265060242e-06,
      "loss": 0.2688,
      "step": 4267
    },
    {
      "epoch": 2.5710843373493977,
      "grad_norm": 0.4769667983055115,
      "learning_rate": 1.7884036144578316e-06,
      "loss": 0.1885,
      "step": 4268
    },
    {
      "epoch": 2.571686746987952,
      "grad_norm": 0.6002476215362549,
      "learning_rate": 1.7876506024096387e-06,
      "loss": 0.2764,
      "step": 4269
    },
    {
      "epoch": 2.572289156626506,
      "grad_norm": 0.5028219223022461,
      "learning_rate": 1.786897590361446e-06,
      "loss": 0.2189,
      "step": 4270
    },
    {
      "epoch": 2.57289156626506,
      "grad_norm": 0.5240089297294617,
      "learning_rate": 1.786144578313253e-06,
      "loss": 0.2176,
      "step": 4271
    },
    {
      "epoch": 2.5734939759036144,
      "grad_norm": 0.6348810195922852,
      "learning_rate": 1.7853915662650603e-06,
      "loss": 0.2048,
      "step": 4272
    },
    {
      "epoch": 2.574096385542169,
      "grad_norm": 0.5334307551383972,
      "learning_rate": 1.7846385542168677e-06,
      "loss": 0.1988,
      "step": 4273
    },
    {
      "epoch": 2.5746987951807228,
      "grad_norm": 0.49065372347831726,
      "learning_rate": 1.7838855421686748e-06,
      "loss": 0.2259,
      "step": 4274
    },
    {
      "epoch": 2.575301204819277,
      "grad_norm": 0.6109629273414612,
      "learning_rate": 1.7831325301204822e-06,
      "loss": 0.2294,
      "step": 4275
    },
    {
      "epoch": 2.5759036144578316,
      "grad_norm": 0.5323820114135742,
      "learning_rate": 1.7823795180722895e-06,
      "loss": 0.1871,
      "step": 4276
    },
    {
      "epoch": 2.5765060240963855,
      "grad_norm": 0.5623540878295898,
      "learning_rate": 1.7816265060240964e-06,
      "loss": 0.1851,
      "step": 4277
    },
    {
      "epoch": 2.57710843373494,
      "grad_norm": 0.5668086409568787,
      "learning_rate": 1.7808734939759038e-06,
      "loss": 0.239,
      "step": 4278
    },
    {
      "epoch": 2.577710843373494,
      "grad_norm": 0.5467504262924194,
      "learning_rate": 1.780120481927711e-06,
      "loss": 0.1987,
      "step": 4279
    },
    {
      "epoch": 2.5783132530120483,
      "grad_norm": 0.6111195087432861,
      "learning_rate": 1.7793674698795183e-06,
      "loss": 0.2479,
      "step": 4280
    },
    {
      "epoch": 2.5789156626506022,
      "grad_norm": 0.6068180203437805,
      "learning_rate": 1.7786144578313256e-06,
      "loss": 0.2226,
      "step": 4281
    },
    {
      "epoch": 2.5795180722891566,
      "grad_norm": 0.5558971166610718,
      "learning_rate": 1.7778614457831327e-06,
      "loss": 0.2497,
      "step": 4282
    },
    {
      "epoch": 2.580120481927711,
      "grad_norm": 0.5564739108085632,
      "learning_rate": 1.7771084337349399e-06,
      "loss": 0.2075,
      "step": 4283
    },
    {
      "epoch": 2.580722891566265,
      "grad_norm": 0.6017014980316162,
      "learning_rate": 1.776355421686747e-06,
      "loss": 0.2213,
      "step": 4284
    },
    {
      "epoch": 2.5813253012048194,
      "grad_norm": 0.5232479572296143,
      "learning_rate": 1.7756024096385544e-06,
      "loss": 0.2141,
      "step": 4285
    },
    {
      "epoch": 2.5819277108433734,
      "grad_norm": 0.5722922682762146,
      "learning_rate": 1.7748493975903617e-06,
      "loss": 0.2256,
      "step": 4286
    },
    {
      "epoch": 2.5825301204819278,
      "grad_norm": 0.5601784586906433,
      "learning_rate": 1.7740963855421688e-06,
      "loss": 0.2359,
      "step": 4287
    },
    {
      "epoch": 2.5831325301204817,
      "grad_norm": 0.5612789988517761,
      "learning_rate": 1.7733433734939762e-06,
      "loss": 0.1964,
      "step": 4288
    },
    {
      "epoch": 2.583734939759036,
      "grad_norm": 0.6663238406181335,
      "learning_rate": 1.7725903614457831e-06,
      "loss": 0.264,
      "step": 4289
    },
    {
      "epoch": 2.5843373493975905,
      "grad_norm": 0.5582734942436218,
      "learning_rate": 1.7718373493975905e-06,
      "loss": 0.2311,
      "step": 4290
    },
    {
      "epoch": 2.5849397590361445,
      "grad_norm": 0.5377799868583679,
      "learning_rate": 1.7710843373493978e-06,
      "loss": 0.2548,
      "step": 4291
    },
    {
      "epoch": 2.585542168674699,
      "grad_norm": 0.5517174601554871,
      "learning_rate": 1.770331325301205e-06,
      "loss": 0.2597,
      "step": 4292
    },
    {
      "epoch": 2.5861445783132533,
      "grad_norm": 0.5709183812141418,
      "learning_rate": 1.7695783132530123e-06,
      "loss": 0.218,
      "step": 4293
    },
    {
      "epoch": 2.5867469879518072,
      "grad_norm": 0.7011615037918091,
      "learning_rate": 1.7688253012048194e-06,
      "loss": 0.2524,
      "step": 4294
    },
    {
      "epoch": 2.587349397590361,
      "grad_norm": 0.5951325297355652,
      "learning_rate": 1.7680722891566266e-06,
      "loss": 0.2406,
      "step": 4295
    },
    {
      "epoch": 2.5879518072289156,
      "grad_norm": 0.7477993369102478,
      "learning_rate": 1.7673192771084337e-06,
      "loss": 0.2749,
      "step": 4296
    },
    {
      "epoch": 2.58855421686747,
      "grad_norm": 0.5039039254188538,
      "learning_rate": 1.766566265060241e-06,
      "loss": 0.2205,
      "step": 4297
    },
    {
      "epoch": 2.589156626506024,
      "grad_norm": 0.5513409972190857,
      "learning_rate": 1.7658132530120484e-06,
      "loss": 0.2255,
      "step": 4298
    },
    {
      "epoch": 2.5897590361445784,
      "grad_norm": 0.48655641078948975,
      "learning_rate": 1.7650602409638555e-06,
      "loss": 0.1925,
      "step": 4299
    },
    {
      "epoch": 2.5903614457831328,
      "grad_norm": 0.582520067691803,
      "learning_rate": 1.764307228915663e-06,
      "loss": 0.2414,
      "step": 4300
    },
    {
      "epoch": 2.5909638554216867,
      "grad_norm": 0.681857705116272,
      "learning_rate": 1.7635542168674698e-06,
      "loss": 0.2522,
      "step": 4301
    },
    {
      "epoch": 2.591566265060241,
      "grad_norm": 0.5649619698524475,
      "learning_rate": 1.7628012048192772e-06,
      "loss": 0.2376,
      "step": 4302
    },
    {
      "epoch": 2.592168674698795,
      "grad_norm": 0.509868323802948,
      "learning_rate": 1.7620481927710845e-06,
      "loss": 0.1996,
      "step": 4303
    },
    {
      "epoch": 2.5927710843373495,
      "grad_norm": 0.9880267977714539,
      "learning_rate": 1.7612951807228917e-06,
      "loss": 0.246,
      "step": 4304
    },
    {
      "epoch": 2.5933734939759034,
      "grad_norm": 0.5994728803634644,
      "learning_rate": 1.760542168674699e-06,
      "loss": 0.2355,
      "step": 4305
    },
    {
      "epoch": 2.593975903614458,
      "grad_norm": 0.5344545841217041,
      "learning_rate": 1.7597891566265064e-06,
      "loss": 0.2432,
      "step": 4306
    },
    {
      "epoch": 2.5945783132530122,
      "grad_norm": 0.4858497083187103,
      "learning_rate": 1.7590361445783133e-06,
      "loss": 0.23,
      "step": 4307
    },
    {
      "epoch": 2.595180722891566,
      "grad_norm": 0.5676752924919128,
      "learning_rate": 1.7582831325301206e-06,
      "loss": 0.2295,
      "step": 4308
    },
    {
      "epoch": 2.5957831325301206,
      "grad_norm": 0.5847275853157043,
      "learning_rate": 1.7575301204819278e-06,
      "loss": 0.2426,
      "step": 4309
    },
    {
      "epoch": 2.5963855421686746,
      "grad_norm": 0.49099230766296387,
      "learning_rate": 1.7567771084337351e-06,
      "loss": 0.2217,
      "step": 4310
    },
    {
      "epoch": 2.596987951807229,
      "grad_norm": 0.5336955189704895,
      "learning_rate": 1.7560240963855425e-06,
      "loss": 0.2281,
      "step": 4311
    },
    {
      "epoch": 2.597590361445783,
      "grad_norm": 0.56120765209198,
      "learning_rate": 1.7552710843373496e-06,
      "loss": 0.2148,
      "step": 4312
    },
    {
      "epoch": 2.5981927710843373,
      "grad_norm": 0.6219309568405151,
      "learning_rate": 1.7545180722891567e-06,
      "loss": 0.2845,
      "step": 4313
    },
    {
      "epoch": 2.5987951807228917,
      "grad_norm": 0.5937452912330627,
      "learning_rate": 1.7537650602409639e-06,
      "loss": 0.2342,
      "step": 4314
    },
    {
      "epoch": 2.5993975903614457,
      "grad_norm": 0.568697988986969,
      "learning_rate": 1.7530120481927712e-06,
      "loss": 0.2137,
      "step": 4315
    },
    {
      "epoch": 2.6,
      "grad_norm": 0.5145043730735779,
      "learning_rate": 1.7522590361445786e-06,
      "loss": 0.2083,
      "step": 4316
    },
    {
      "epoch": 2.6006024096385545,
      "grad_norm": 0.5541939735412598,
      "learning_rate": 1.7515060240963857e-06,
      "loss": 0.2523,
      "step": 4317
    },
    {
      "epoch": 2.6012048192771084,
      "grad_norm": 0.6020549535751343,
      "learning_rate": 1.750753012048193e-06,
      "loss": 0.2402,
      "step": 4318
    },
    {
      "epoch": 2.6018072289156624,
      "grad_norm": 0.5849775671958923,
      "learning_rate": 1.75e-06,
      "loss": 0.2302,
      "step": 4319
    },
    {
      "epoch": 2.602409638554217,
      "grad_norm": 0.5200479030609131,
      "learning_rate": 1.7492469879518073e-06,
      "loss": 0.1988,
      "step": 4320
    },
    {
      "epoch": 2.603012048192771,
      "grad_norm": 0.6384446620941162,
      "learning_rate": 1.7484939759036147e-06,
      "loss": 0.2305,
      "step": 4321
    },
    {
      "epoch": 2.603614457831325,
      "grad_norm": 0.6957262754440308,
      "learning_rate": 1.7477409638554218e-06,
      "loss": 0.2794,
      "step": 4322
    },
    {
      "epoch": 2.6042168674698796,
      "grad_norm": 0.6054891347885132,
      "learning_rate": 1.7469879518072292e-06,
      "loss": 0.2693,
      "step": 4323
    },
    {
      "epoch": 2.604819277108434,
      "grad_norm": 0.5168997645378113,
      "learning_rate": 1.7462349397590365e-06,
      "loss": 0.197,
      "step": 4324
    },
    {
      "epoch": 2.605421686746988,
      "grad_norm": 0.5457873344421387,
      "learning_rate": 1.7454819277108434e-06,
      "loss": 0.2237,
      "step": 4325
    },
    {
      "epoch": 2.6060240963855423,
      "grad_norm": 0.5165482759475708,
      "learning_rate": 1.7447289156626508e-06,
      "loss": 0.2132,
      "step": 4326
    },
    {
      "epoch": 2.6066265060240963,
      "grad_norm": 0.5692732334136963,
      "learning_rate": 1.743975903614458e-06,
      "loss": 0.2752,
      "step": 4327
    },
    {
      "epoch": 2.6072289156626507,
      "grad_norm": 0.5631607174873352,
      "learning_rate": 1.7432228915662653e-06,
      "loss": 0.2531,
      "step": 4328
    },
    {
      "epoch": 2.6078313253012047,
      "grad_norm": 0.5452633500099182,
      "learning_rate": 1.7424698795180724e-06,
      "loss": 0.2571,
      "step": 4329
    },
    {
      "epoch": 2.608433734939759,
      "grad_norm": 0.5218328833580017,
      "learning_rate": 1.7417168674698797e-06,
      "loss": 0.2121,
      "step": 4330
    },
    {
      "epoch": 2.6090361445783135,
      "grad_norm": 0.4815235137939453,
      "learning_rate": 1.7409638554216867e-06,
      "loss": 0.2067,
      "step": 4331
    },
    {
      "epoch": 2.6096385542168674,
      "grad_norm": 0.5927565693855286,
      "learning_rate": 1.740210843373494e-06,
      "loss": 0.2263,
      "step": 4332
    },
    {
      "epoch": 2.610240963855422,
      "grad_norm": 0.6265795826911926,
      "learning_rate": 1.7394578313253014e-06,
      "loss": 0.2662,
      "step": 4333
    },
    {
      "epoch": 2.6108433734939758,
      "grad_norm": 0.516245424747467,
      "learning_rate": 1.7387048192771085e-06,
      "loss": 0.1635,
      "step": 4334
    },
    {
      "epoch": 2.61144578313253,
      "grad_norm": 0.4838390350341797,
      "learning_rate": 1.7379518072289159e-06,
      "loss": 0.1865,
      "step": 4335
    },
    {
      "epoch": 2.612048192771084,
      "grad_norm": 0.5637917518615723,
      "learning_rate": 1.7371987951807232e-06,
      "loss": 0.2219,
      "step": 4336
    },
    {
      "epoch": 2.6126506024096385,
      "grad_norm": 0.6019954085350037,
      "learning_rate": 1.7364457831325301e-06,
      "loss": 0.2457,
      "step": 4337
    },
    {
      "epoch": 2.613253012048193,
      "grad_norm": 0.5739369988441467,
      "learning_rate": 1.7356927710843375e-06,
      "loss": 0.2391,
      "step": 4338
    },
    {
      "epoch": 2.613855421686747,
      "grad_norm": 0.4747115671634674,
      "learning_rate": 1.7349397590361446e-06,
      "loss": 0.2165,
      "step": 4339
    },
    {
      "epoch": 2.6144578313253013,
      "grad_norm": 0.47290077805519104,
      "learning_rate": 1.734186746987952e-06,
      "loss": 0.201,
      "step": 4340
    },
    {
      "epoch": 2.6150602409638557,
      "grad_norm": 0.568848729133606,
      "learning_rate": 1.7334337349397593e-06,
      "loss": 0.2394,
      "step": 4341
    },
    {
      "epoch": 2.6156626506024097,
      "grad_norm": 0.4918191432952881,
      "learning_rate": 1.7326807228915664e-06,
      "loss": 0.1844,
      "step": 4342
    },
    {
      "epoch": 2.6162650602409636,
      "grad_norm": 0.5189889669418335,
      "learning_rate": 1.7319277108433736e-06,
      "loss": 0.2767,
      "step": 4343
    },
    {
      "epoch": 2.616867469879518,
      "grad_norm": 0.5081055164337158,
      "learning_rate": 1.7311746987951807e-06,
      "loss": 0.1794,
      "step": 4344
    },
    {
      "epoch": 2.6174698795180724,
      "grad_norm": 0.5324563384056091,
      "learning_rate": 1.730421686746988e-06,
      "loss": 0.247,
      "step": 4345
    },
    {
      "epoch": 2.6180722891566264,
      "grad_norm": 0.5112658143043518,
      "learning_rate": 1.7296686746987954e-06,
      "loss": 0.2152,
      "step": 4346
    },
    {
      "epoch": 2.6186746987951808,
      "grad_norm": 0.5704466104507446,
      "learning_rate": 1.7289156626506026e-06,
      "loss": 0.2961,
      "step": 4347
    },
    {
      "epoch": 2.619277108433735,
      "grad_norm": 0.6160090565681458,
      "learning_rate": 1.72816265060241e-06,
      "loss": 0.2525,
      "step": 4348
    },
    {
      "epoch": 2.619879518072289,
      "grad_norm": 0.6314095258712769,
      "learning_rate": 1.7274096385542168e-06,
      "loss": 0.2568,
      "step": 4349
    },
    {
      "epoch": 2.6204819277108435,
      "grad_norm": 0.5670902729034424,
      "learning_rate": 1.7266566265060242e-06,
      "loss": 0.2237,
      "step": 4350
    },
    {
      "epoch": 2.6210843373493975,
      "grad_norm": 0.5201743245124817,
      "learning_rate": 1.7259036144578315e-06,
      "loss": 0.179,
      "step": 4351
    },
    {
      "epoch": 2.621686746987952,
      "grad_norm": 0.5281701683998108,
      "learning_rate": 1.7251506024096387e-06,
      "loss": 0.1876,
      "step": 4352
    },
    {
      "epoch": 2.622289156626506,
      "grad_norm": 0.6233518719673157,
      "learning_rate": 1.724397590361446e-06,
      "loss": 0.2316,
      "step": 4353
    },
    {
      "epoch": 2.6228915662650603,
      "grad_norm": 0.5422371625900269,
      "learning_rate": 1.7236445783132534e-06,
      "loss": 0.2341,
      "step": 4354
    },
    {
      "epoch": 2.6234939759036147,
      "grad_norm": 0.6108988523483276,
      "learning_rate": 1.7228915662650603e-06,
      "loss": 0.2801,
      "step": 4355
    },
    {
      "epoch": 2.6240963855421686,
      "grad_norm": 0.49594834446907043,
      "learning_rate": 1.7221385542168676e-06,
      "loss": 0.2081,
      "step": 4356
    },
    {
      "epoch": 2.624698795180723,
      "grad_norm": 0.5387618541717529,
      "learning_rate": 1.7213855421686748e-06,
      "loss": 0.22,
      "step": 4357
    },
    {
      "epoch": 2.625301204819277,
      "grad_norm": 0.608498215675354,
      "learning_rate": 1.7206325301204821e-06,
      "loss": 0.2463,
      "step": 4358
    },
    {
      "epoch": 2.6259036144578314,
      "grad_norm": 0.6451829671859741,
      "learning_rate": 1.7198795180722895e-06,
      "loss": 0.2212,
      "step": 4359
    },
    {
      "epoch": 2.6265060240963853,
      "grad_norm": 0.47683751583099365,
      "learning_rate": 1.7191265060240966e-06,
      "loss": 0.2095,
      "step": 4360
    },
    {
      "epoch": 2.6271084337349397,
      "grad_norm": 0.6587517857551575,
      "learning_rate": 1.7183734939759037e-06,
      "loss": 0.2821,
      "step": 4361
    },
    {
      "epoch": 2.627710843373494,
      "grad_norm": 0.5053170323371887,
      "learning_rate": 1.7176204819277109e-06,
      "loss": 0.2088,
      "step": 4362
    },
    {
      "epoch": 2.628313253012048,
      "grad_norm": 0.5169045925140381,
      "learning_rate": 1.7168674698795182e-06,
      "loss": 0.2295,
      "step": 4363
    },
    {
      "epoch": 2.6289156626506025,
      "grad_norm": 0.6040881276130676,
      "learning_rate": 1.7161144578313256e-06,
      "loss": 0.245,
      "step": 4364
    },
    {
      "epoch": 2.6295180722891565,
      "grad_norm": 0.6707270741462708,
      "learning_rate": 1.7153614457831327e-06,
      "loss": 0.281,
      "step": 4365
    },
    {
      "epoch": 2.630120481927711,
      "grad_norm": 0.5449720621109009,
      "learning_rate": 1.71460843373494e-06,
      "loss": 0.2087,
      "step": 4366
    },
    {
      "epoch": 2.630722891566265,
      "grad_norm": 0.6237499713897705,
      "learning_rate": 1.713855421686747e-06,
      "loss": 0.2158,
      "step": 4367
    },
    {
      "epoch": 2.6313253012048192,
      "grad_norm": 0.4898340404033661,
      "learning_rate": 1.7131024096385543e-06,
      "loss": 0.1729,
      "step": 4368
    },
    {
      "epoch": 2.6319277108433736,
      "grad_norm": 0.5812150239944458,
      "learning_rate": 1.7123493975903615e-06,
      "loss": 0.2238,
      "step": 4369
    },
    {
      "epoch": 2.6325301204819276,
      "grad_norm": 0.5280584096908569,
      "learning_rate": 1.7115963855421688e-06,
      "loss": 0.2,
      "step": 4370
    },
    {
      "epoch": 2.633132530120482,
      "grad_norm": 0.6085312366485596,
      "learning_rate": 1.7108433734939762e-06,
      "loss": 0.2104,
      "step": 4371
    },
    {
      "epoch": 2.6337349397590364,
      "grad_norm": 0.5710425972938538,
      "learning_rate": 1.7100903614457833e-06,
      "loss": 0.1933,
      "step": 4372
    },
    {
      "epoch": 2.6343373493975903,
      "grad_norm": 0.5297381281852722,
      "learning_rate": 1.7093373493975904e-06,
      "loss": 0.198,
      "step": 4373
    },
    {
      "epoch": 2.6349397590361443,
      "grad_norm": 0.5394760966300964,
      "learning_rate": 1.7085843373493976e-06,
      "loss": 0.215,
      "step": 4374
    },
    {
      "epoch": 2.6355421686746987,
      "grad_norm": 0.5161314010620117,
      "learning_rate": 1.707831325301205e-06,
      "loss": 0.2011,
      "step": 4375
    },
    {
      "epoch": 2.636144578313253,
      "grad_norm": 0.5806403756141663,
      "learning_rate": 1.7070783132530123e-06,
      "loss": 0.2484,
      "step": 4376
    },
    {
      "epoch": 2.636746987951807,
      "grad_norm": 0.5188677906990051,
      "learning_rate": 1.7063253012048194e-06,
      "loss": 0.1969,
      "step": 4377
    },
    {
      "epoch": 2.6373493975903615,
      "grad_norm": 0.5275024771690369,
      "learning_rate": 1.7055722891566268e-06,
      "loss": 0.2113,
      "step": 4378
    },
    {
      "epoch": 2.637951807228916,
      "grad_norm": 0.578940749168396,
      "learning_rate": 1.7048192771084337e-06,
      "loss": 0.2215,
      "step": 4379
    },
    {
      "epoch": 2.63855421686747,
      "grad_norm": 0.5493052005767822,
      "learning_rate": 1.704066265060241e-06,
      "loss": 0.1992,
      "step": 4380
    },
    {
      "epoch": 2.6391566265060242,
      "grad_norm": 0.6070588231086731,
      "learning_rate": 1.7033132530120484e-06,
      "loss": 0.2621,
      "step": 4381
    },
    {
      "epoch": 2.639759036144578,
      "grad_norm": 0.5123577117919922,
      "learning_rate": 1.7025602409638555e-06,
      "loss": 0.2228,
      "step": 4382
    },
    {
      "epoch": 2.6403614457831326,
      "grad_norm": 0.5333943963050842,
      "learning_rate": 1.7018072289156629e-06,
      "loss": 0.207,
      "step": 4383
    },
    {
      "epoch": 2.6409638554216865,
      "grad_norm": 0.5738697648048401,
      "learning_rate": 1.7010542168674702e-06,
      "loss": 0.2498,
      "step": 4384
    },
    {
      "epoch": 2.641566265060241,
      "grad_norm": 0.6188221573829651,
      "learning_rate": 1.7003012048192771e-06,
      "loss": 0.2072,
      "step": 4385
    },
    {
      "epoch": 2.6421686746987953,
      "grad_norm": 0.5663334727287292,
      "learning_rate": 1.6995481927710845e-06,
      "loss": 0.2082,
      "step": 4386
    },
    {
      "epoch": 2.6427710843373493,
      "grad_norm": 0.6195275783538818,
      "learning_rate": 1.6987951807228916e-06,
      "loss": 0.2227,
      "step": 4387
    },
    {
      "epoch": 2.6433734939759037,
      "grad_norm": 0.5339210033416748,
      "learning_rate": 1.698042168674699e-06,
      "loss": 0.2451,
      "step": 4388
    },
    {
      "epoch": 2.6439759036144577,
      "grad_norm": 0.5546751022338867,
      "learning_rate": 1.6972891566265063e-06,
      "loss": 0.2055,
      "step": 4389
    },
    {
      "epoch": 2.644578313253012,
      "grad_norm": 0.5516820549964905,
      "learning_rate": 1.6965361445783135e-06,
      "loss": 0.2131,
      "step": 4390
    },
    {
      "epoch": 2.645180722891566,
      "grad_norm": 0.5088054537773132,
      "learning_rate": 1.6957831325301206e-06,
      "loss": 0.1814,
      "step": 4391
    },
    {
      "epoch": 2.6457831325301204,
      "grad_norm": 0.669166624546051,
      "learning_rate": 1.6950301204819277e-06,
      "loss": 0.2518,
      "step": 4392
    },
    {
      "epoch": 2.646385542168675,
      "grad_norm": 0.537164568901062,
      "learning_rate": 1.694277108433735e-06,
      "loss": 0.2408,
      "step": 4393
    },
    {
      "epoch": 2.646987951807229,
      "grad_norm": 0.5198744535446167,
      "learning_rate": 1.6935240963855424e-06,
      "loss": 0.2107,
      "step": 4394
    },
    {
      "epoch": 2.647590361445783,
      "grad_norm": 0.47222721576690674,
      "learning_rate": 1.6927710843373496e-06,
      "loss": 0.2205,
      "step": 4395
    },
    {
      "epoch": 2.6481927710843376,
      "grad_norm": 0.4799058735370636,
      "learning_rate": 1.692018072289157e-06,
      "loss": 0.1933,
      "step": 4396
    },
    {
      "epoch": 2.6487951807228916,
      "grad_norm": 0.571098268032074,
      "learning_rate": 1.6912650602409638e-06,
      "loss": 0.1781,
      "step": 4397
    },
    {
      "epoch": 2.6493975903614455,
      "grad_norm": 0.6537742018699646,
      "learning_rate": 1.6905120481927712e-06,
      "loss": 0.2318,
      "step": 4398
    },
    {
      "epoch": 2.65,
      "grad_norm": 0.5580315589904785,
      "learning_rate": 1.6897590361445785e-06,
      "loss": 0.2466,
      "step": 4399
    },
    {
      "epoch": 2.6506024096385543,
      "grad_norm": 0.8770593404769897,
      "learning_rate": 1.6890060240963857e-06,
      "loss": 0.2566,
      "step": 4400
    },
    {
      "epoch": 2.6512048192771083,
      "grad_norm": 0.8087116479873657,
      "learning_rate": 1.688253012048193e-06,
      "loss": 0.247,
      "step": 4401
    },
    {
      "epoch": 2.6518072289156627,
      "grad_norm": 0.8637090921401978,
      "learning_rate": 1.6875000000000001e-06,
      "loss": 0.2969,
      "step": 4402
    },
    {
      "epoch": 2.652409638554217,
      "grad_norm": 0.7240155339241028,
      "learning_rate": 1.6867469879518073e-06,
      "loss": 0.2008,
      "step": 4403
    },
    {
      "epoch": 2.653012048192771,
      "grad_norm": 0.939714252948761,
      "learning_rate": 1.6859939759036144e-06,
      "loss": 0.2549,
      "step": 4404
    },
    {
      "epoch": 2.6536144578313254,
      "grad_norm": 0.7738871574401855,
      "learning_rate": 1.6852409638554218e-06,
      "loss": 0.2523,
      "step": 4405
    },
    {
      "epoch": 2.6542168674698794,
      "grad_norm": 0.7970753908157349,
      "learning_rate": 1.6844879518072291e-06,
      "loss": 0.31,
      "step": 4406
    },
    {
      "epoch": 2.654819277108434,
      "grad_norm": 0.6580480933189392,
      "learning_rate": 1.6837349397590363e-06,
      "loss": 0.2973,
      "step": 4407
    },
    {
      "epoch": 2.6554216867469878,
      "grad_norm": 0.7753187417984009,
      "learning_rate": 1.6829819277108436e-06,
      "loss": 0.359,
      "step": 4408
    },
    {
      "epoch": 2.656024096385542,
      "grad_norm": 0.7940113544464111,
      "learning_rate": 1.6822289156626505e-06,
      "loss": 0.2808,
      "step": 4409
    },
    {
      "epoch": 2.6566265060240966,
      "grad_norm": 0.8010037541389465,
      "learning_rate": 1.6814759036144579e-06,
      "loss": 0.2053,
      "step": 4410
    },
    {
      "epoch": 2.6572289156626505,
      "grad_norm": 0.5967245101928711,
      "learning_rate": 1.6807228915662652e-06,
      "loss": 0.2503,
      "step": 4411
    },
    {
      "epoch": 2.657831325301205,
      "grad_norm": 0.7109561562538147,
      "learning_rate": 1.6799698795180724e-06,
      "loss": 0.2517,
      "step": 4412
    },
    {
      "epoch": 2.658433734939759,
      "grad_norm": 0.7458604574203491,
      "learning_rate": 1.6792168674698797e-06,
      "loss": 0.2955,
      "step": 4413
    },
    {
      "epoch": 2.6590361445783133,
      "grad_norm": 0.6930814981460571,
      "learning_rate": 1.678463855421687e-06,
      "loss": 0.2666,
      "step": 4414
    },
    {
      "epoch": 2.6596385542168672,
      "grad_norm": 0.6515039205551147,
      "learning_rate": 1.677710843373494e-06,
      "loss": 0.2511,
      "step": 4415
    },
    {
      "epoch": 2.6602409638554216,
      "grad_norm": 0.643106997013092,
      "learning_rate": 1.6769578313253013e-06,
      "loss": 0.2313,
      "step": 4416
    },
    {
      "epoch": 2.660843373493976,
      "grad_norm": 0.6498941779136658,
      "learning_rate": 1.6762048192771085e-06,
      "loss": 0.2314,
      "step": 4417
    },
    {
      "epoch": 2.66144578313253,
      "grad_norm": 0.6381072402000427,
      "learning_rate": 1.6754518072289158e-06,
      "loss": 0.26,
      "step": 4418
    },
    {
      "epoch": 2.6620481927710844,
      "grad_norm": 0.6587713956832886,
      "learning_rate": 1.6746987951807232e-06,
      "loss": 0.2754,
      "step": 4419
    },
    {
      "epoch": 2.662650602409639,
      "grad_norm": 0.663955569267273,
      "learning_rate": 1.6739457831325303e-06,
      "loss": 0.2554,
      "step": 4420
    },
    {
      "epoch": 2.6632530120481928,
      "grad_norm": 0.6497356295585632,
      "learning_rate": 1.6731927710843374e-06,
      "loss": 0.2282,
      "step": 4421
    },
    {
      "epoch": 2.6638554216867467,
      "grad_norm": 0.6551410555839539,
      "learning_rate": 1.6724397590361446e-06,
      "loss": 0.2944,
      "step": 4422
    },
    {
      "epoch": 2.664457831325301,
      "grad_norm": 0.6256902813911438,
      "learning_rate": 1.671686746987952e-06,
      "loss": 0.238,
      "step": 4423
    },
    {
      "epoch": 2.6650602409638555,
      "grad_norm": 0.6266414523124695,
      "learning_rate": 1.6709337349397593e-06,
      "loss": 0.2584,
      "step": 4424
    },
    {
      "epoch": 2.6656626506024095,
      "grad_norm": 0.6052184700965881,
      "learning_rate": 1.6701807228915664e-06,
      "loss": 0.2489,
      "step": 4425
    },
    {
      "epoch": 2.666265060240964,
      "grad_norm": 0.6625708937644958,
      "learning_rate": 1.6694277108433738e-06,
      "loss": 0.2482,
      "step": 4426
    },
    {
      "epoch": 2.6668674698795183,
      "grad_norm": 0.650913417339325,
      "learning_rate": 1.6686746987951807e-06,
      "loss": 0.2673,
      "step": 4427
    },
    {
      "epoch": 2.6674698795180722,
      "grad_norm": 1.4395034313201904,
      "learning_rate": 1.667921686746988e-06,
      "loss": 0.3145,
      "step": 4428
    },
    {
      "epoch": 2.6680722891566266,
      "grad_norm": 0.5993432998657227,
      "learning_rate": 1.6671686746987954e-06,
      "loss": 0.1989,
      "step": 4429
    },
    {
      "epoch": 2.6686746987951806,
      "grad_norm": 0.7228291630744934,
      "learning_rate": 1.6664156626506025e-06,
      "loss": 0.31,
      "step": 4430
    },
    {
      "epoch": 2.669277108433735,
      "grad_norm": 0.6917998194694519,
      "learning_rate": 1.6656626506024099e-06,
      "loss": 0.2244,
      "step": 4431
    },
    {
      "epoch": 2.669879518072289,
      "grad_norm": 0.6202335357666016,
      "learning_rate": 1.6649096385542172e-06,
      "loss": 0.2846,
      "step": 4432
    },
    {
      "epoch": 2.6704819277108434,
      "grad_norm": 2.278876543045044,
      "learning_rate": 1.6641566265060241e-06,
      "loss": 0.2781,
      "step": 4433
    },
    {
      "epoch": 2.6710843373493978,
      "grad_norm": 0.662446141242981,
      "learning_rate": 1.6634036144578315e-06,
      "loss": 0.2033,
      "step": 4434
    },
    {
      "epoch": 2.6716867469879517,
      "grad_norm": 0.6181145906448364,
      "learning_rate": 1.6626506024096386e-06,
      "loss": 0.3035,
      "step": 4435
    },
    {
      "epoch": 2.672289156626506,
      "grad_norm": 0.7206887602806091,
      "learning_rate": 1.661897590361446e-06,
      "loss": 0.303,
      "step": 4436
    },
    {
      "epoch": 2.67289156626506,
      "grad_norm": 0.6666911840438843,
      "learning_rate": 1.6611445783132531e-06,
      "loss": 0.2566,
      "step": 4437
    },
    {
      "epoch": 2.6734939759036145,
      "grad_norm": 0.5768724679946899,
      "learning_rate": 1.6603915662650605e-06,
      "loss": 0.2726,
      "step": 4438
    },
    {
      "epoch": 2.6740963855421684,
      "grad_norm": 0.5975784063339233,
      "learning_rate": 1.6596385542168674e-06,
      "loss": 0.2212,
      "step": 4439
    },
    {
      "epoch": 2.674698795180723,
      "grad_norm": 0.6112765669822693,
      "learning_rate": 1.6588855421686747e-06,
      "loss": 0.3164,
      "step": 4440
    },
    {
      "epoch": 2.6753012048192772,
      "grad_norm": 0.612309992313385,
      "learning_rate": 1.658132530120482e-06,
      "loss": 0.2634,
      "step": 4441
    },
    {
      "epoch": 2.675903614457831,
      "grad_norm": 0.5688291192054749,
      "learning_rate": 1.6573795180722892e-06,
      "loss": 0.2567,
      "step": 4442
    },
    {
      "epoch": 2.6765060240963856,
      "grad_norm": 0.6079491972923279,
      "learning_rate": 1.6566265060240966e-06,
      "loss": 0.2655,
      "step": 4443
    },
    {
      "epoch": 2.67710843373494,
      "grad_norm": 0.607227623462677,
      "learning_rate": 1.655873493975904e-06,
      "loss": 0.2524,
      "step": 4444
    },
    {
      "epoch": 2.677710843373494,
      "grad_norm": 0.6196323037147522,
      "learning_rate": 1.6551204819277108e-06,
      "loss": 0.278,
      "step": 4445
    },
    {
      "epoch": 2.678313253012048,
      "grad_norm": 0.6181778907775879,
      "learning_rate": 1.6543674698795182e-06,
      "loss": 0.2221,
      "step": 4446
    },
    {
      "epoch": 2.6789156626506023,
      "grad_norm": 0.5732786059379578,
      "learning_rate": 1.6536144578313253e-06,
      "loss": 0.2507,
      "step": 4447
    },
    {
      "epoch": 2.6795180722891567,
      "grad_norm": 0.6633967161178589,
      "learning_rate": 1.6528614457831327e-06,
      "loss": 0.2653,
      "step": 4448
    },
    {
      "epoch": 2.6801204819277107,
      "grad_norm": 0.6775539517402649,
      "learning_rate": 1.65210843373494e-06,
      "loss": 0.2209,
      "step": 4449
    },
    {
      "epoch": 2.680722891566265,
      "grad_norm": 0.6497113704681396,
      "learning_rate": 1.6513554216867472e-06,
      "loss": 0.2221,
      "step": 4450
    },
    {
      "epoch": 2.6813253012048195,
      "grad_norm": 0.6603158712387085,
      "learning_rate": 1.6506024096385543e-06,
      "loss": 0.2881,
      "step": 4451
    },
    {
      "epoch": 2.6819277108433734,
      "grad_norm": 0.6434375643730164,
      "learning_rate": 1.6498493975903614e-06,
      "loss": 0.2706,
      "step": 4452
    },
    {
      "epoch": 2.682530120481928,
      "grad_norm": 0.5791488289833069,
      "learning_rate": 1.6490963855421688e-06,
      "loss": 0.2581,
      "step": 4453
    },
    {
      "epoch": 2.683132530120482,
      "grad_norm": 0.6658916473388672,
      "learning_rate": 1.6483433734939761e-06,
      "loss": 0.232,
      "step": 4454
    },
    {
      "epoch": 2.683734939759036,
      "grad_norm": 0.6145418286323547,
      "learning_rate": 1.6475903614457833e-06,
      "loss": 0.2782,
      "step": 4455
    },
    {
      "epoch": 2.68433734939759,
      "grad_norm": 0.6460703015327454,
      "learning_rate": 1.6468373493975906e-06,
      "loss": 0.2927,
      "step": 4456
    },
    {
      "epoch": 2.6849397590361446,
      "grad_norm": 0.5889331698417664,
      "learning_rate": 1.6460843373493975e-06,
      "loss": 0.2382,
      "step": 4457
    },
    {
      "epoch": 2.685542168674699,
      "grad_norm": 0.602208137512207,
      "learning_rate": 1.6453313253012049e-06,
      "loss": 0.2358,
      "step": 4458
    },
    {
      "epoch": 2.686144578313253,
      "grad_norm": 0.6009784936904907,
      "learning_rate": 1.6445783132530122e-06,
      "loss": 0.2846,
      "step": 4459
    },
    {
      "epoch": 2.6867469879518073,
      "grad_norm": 0.5982524156570435,
      "learning_rate": 1.6438253012048194e-06,
      "loss": 0.2341,
      "step": 4460
    },
    {
      "epoch": 2.6873493975903613,
      "grad_norm": 0.6624574661254883,
      "learning_rate": 1.6430722891566267e-06,
      "loss": 0.2191,
      "step": 4461
    },
    {
      "epoch": 2.6879518072289157,
      "grad_norm": 0.5450979471206665,
      "learning_rate": 1.642319277108434e-06,
      "loss": 0.1987,
      "step": 4462
    },
    {
      "epoch": 2.6885542168674696,
      "grad_norm": 0.6833645105361938,
      "learning_rate": 1.641566265060241e-06,
      "loss": 0.3159,
      "step": 4463
    },
    {
      "epoch": 2.689156626506024,
      "grad_norm": 0.5592530965805054,
      "learning_rate": 1.6408132530120483e-06,
      "loss": 0.1931,
      "step": 4464
    },
    {
      "epoch": 2.6897590361445785,
      "grad_norm": 0.5409401059150696,
      "learning_rate": 1.6400602409638555e-06,
      "loss": 0.2144,
      "step": 4465
    },
    {
      "epoch": 2.6903614457831324,
      "grad_norm": 0.5456299781799316,
      "learning_rate": 1.6393072289156628e-06,
      "loss": 0.2587,
      "step": 4466
    },
    {
      "epoch": 2.690963855421687,
      "grad_norm": 0.5313324928283691,
      "learning_rate": 1.6385542168674702e-06,
      "loss": 0.2012,
      "step": 4467
    },
    {
      "epoch": 2.691566265060241,
      "grad_norm": 0.6473678350448608,
      "learning_rate": 1.6378012048192773e-06,
      "loss": 0.2398,
      "step": 4468
    },
    {
      "epoch": 2.692168674698795,
      "grad_norm": 0.5519393682479858,
      "learning_rate": 1.6370481927710844e-06,
      "loss": 0.249,
      "step": 4469
    },
    {
      "epoch": 2.692771084337349,
      "grad_norm": 0.5819231867790222,
      "learning_rate": 1.6362951807228916e-06,
      "loss": 0.2807,
      "step": 4470
    },
    {
      "epoch": 2.6933734939759035,
      "grad_norm": 0.6064189672470093,
      "learning_rate": 1.635542168674699e-06,
      "loss": 0.2023,
      "step": 4471
    },
    {
      "epoch": 2.693975903614458,
      "grad_norm": 0.6106704473495483,
      "learning_rate": 1.634789156626506e-06,
      "loss": 0.2347,
      "step": 4472
    },
    {
      "epoch": 2.694578313253012,
      "grad_norm": 0.588127851486206,
      "learning_rate": 1.6340361445783134e-06,
      "loss": 0.2596,
      "step": 4473
    },
    {
      "epoch": 2.6951807228915663,
      "grad_norm": 0.5761200189590454,
      "learning_rate": 1.6332831325301208e-06,
      "loss": 0.2725,
      "step": 4474
    },
    {
      "epoch": 2.6957831325301207,
      "grad_norm": 0.664280116558075,
      "learning_rate": 1.6325301204819277e-06,
      "loss": 0.2452,
      "step": 4475
    },
    {
      "epoch": 2.6963855421686747,
      "grad_norm": 0.7043305039405823,
      "learning_rate": 1.631777108433735e-06,
      "loss": 0.268,
      "step": 4476
    },
    {
      "epoch": 2.696987951807229,
      "grad_norm": 0.6339544653892517,
      "learning_rate": 1.6310240963855422e-06,
      "loss": 0.3223,
      "step": 4477
    },
    {
      "epoch": 2.697590361445783,
      "grad_norm": 0.5639068484306335,
      "learning_rate": 1.6302710843373495e-06,
      "loss": 0.2507,
      "step": 4478
    },
    {
      "epoch": 2.6981927710843374,
      "grad_norm": 0.6261877417564392,
      "learning_rate": 1.6295180722891569e-06,
      "loss": 0.2124,
      "step": 4479
    },
    {
      "epoch": 2.6987951807228914,
      "grad_norm": 0.5787057876586914,
      "learning_rate": 1.628765060240964e-06,
      "loss": 0.2705,
      "step": 4480
    },
    {
      "epoch": 2.6993975903614458,
      "grad_norm": 0.5827649831771851,
      "learning_rate": 1.6280120481927711e-06,
      "loss": 0.2277,
      "step": 4481
    },
    {
      "epoch": 2.7,
      "grad_norm": 0.5468004941940308,
      "learning_rate": 1.6272590361445783e-06,
      "loss": 0.2288,
      "step": 4482
    },
    {
      "epoch": 2.700602409638554,
      "grad_norm": 0.6205294728279114,
      "learning_rate": 1.6265060240963856e-06,
      "loss": 0.2538,
      "step": 4483
    },
    {
      "epoch": 2.7012048192771085,
      "grad_norm": 0.599643349647522,
      "learning_rate": 1.625753012048193e-06,
      "loss": 0.2242,
      "step": 4484
    },
    {
      "epoch": 2.7018072289156625,
      "grad_norm": 0.6146158576011658,
      "learning_rate": 1.6250000000000001e-06,
      "loss": 0.2335,
      "step": 4485
    },
    {
      "epoch": 2.702409638554217,
      "grad_norm": 0.6240710616111755,
      "learning_rate": 1.6242469879518075e-06,
      "loss": 0.3079,
      "step": 4486
    },
    {
      "epoch": 2.703012048192771,
      "grad_norm": 0.6015558242797852,
      "learning_rate": 1.6234939759036144e-06,
      "loss": 0.2268,
      "step": 4487
    },
    {
      "epoch": 2.7036144578313253,
      "grad_norm": 0.5586503148078918,
      "learning_rate": 1.6227409638554217e-06,
      "loss": 0.2351,
      "step": 4488
    },
    {
      "epoch": 2.7042168674698797,
      "grad_norm": 0.5893977880477905,
      "learning_rate": 1.621987951807229e-06,
      "loss": 0.1934,
      "step": 4489
    },
    {
      "epoch": 2.7048192771084336,
      "grad_norm": 0.5462479591369629,
      "learning_rate": 1.6212349397590362e-06,
      "loss": 0.2463,
      "step": 4490
    },
    {
      "epoch": 2.705421686746988,
      "grad_norm": 0.6408177614212036,
      "learning_rate": 1.6204819277108436e-06,
      "loss": 0.2306,
      "step": 4491
    },
    {
      "epoch": 2.7060240963855424,
      "grad_norm": 0.7133157253265381,
      "learning_rate": 1.619728915662651e-06,
      "loss": 0.2711,
      "step": 4492
    },
    {
      "epoch": 2.7066265060240964,
      "grad_norm": 0.5865838527679443,
      "learning_rate": 1.6189759036144578e-06,
      "loss": 0.2399,
      "step": 4493
    },
    {
      "epoch": 2.7072289156626503,
      "grad_norm": 0.5259664058685303,
      "learning_rate": 1.6182228915662652e-06,
      "loss": 0.213,
      "step": 4494
    },
    {
      "epoch": 2.7078313253012047,
      "grad_norm": 0.5688808560371399,
      "learning_rate": 1.6174698795180723e-06,
      "loss": 0.2138,
      "step": 4495
    },
    {
      "epoch": 2.708433734939759,
      "grad_norm": 0.5716438293457031,
      "learning_rate": 1.6167168674698797e-06,
      "loss": 0.3041,
      "step": 4496
    },
    {
      "epoch": 2.709036144578313,
      "grad_norm": 0.6005349159240723,
      "learning_rate": 1.615963855421687e-06,
      "loss": 0.2559,
      "step": 4497
    },
    {
      "epoch": 2.7096385542168675,
      "grad_norm": 0.7149357795715332,
      "learning_rate": 1.6152108433734942e-06,
      "loss": 0.3264,
      "step": 4498
    },
    {
      "epoch": 2.710240963855422,
      "grad_norm": 0.5815614461898804,
      "learning_rate": 1.6144578313253013e-06,
      "loss": 0.241,
      "step": 4499
    },
    {
      "epoch": 2.710843373493976,
      "grad_norm": 0.6999351382255554,
      "learning_rate": 1.6137048192771084e-06,
      "loss": 0.1966,
      "step": 4500
    },
    {
      "epoch": 2.7114457831325303,
      "grad_norm": 0.5608813166618347,
      "learning_rate": 1.6129518072289158e-06,
      "loss": 0.2115,
      "step": 4501
    },
    {
      "epoch": 2.712048192771084,
      "grad_norm": 0.5520842671394348,
      "learning_rate": 1.6121987951807231e-06,
      "loss": 0.2805,
      "step": 4502
    },
    {
      "epoch": 2.7126506024096386,
      "grad_norm": 0.5861421823501587,
      "learning_rate": 1.6114457831325303e-06,
      "loss": 0.2278,
      "step": 4503
    },
    {
      "epoch": 2.7132530120481926,
      "grad_norm": 0.5692676901817322,
      "learning_rate": 1.6106927710843376e-06,
      "loss": 0.21,
      "step": 4504
    },
    {
      "epoch": 2.713855421686747,
      "grad_norm": 0.5790886878967285,
      "learning_rate": 1.6099397590361445e-06,
      "loss": 0.2506,
      "step": 4505
    },
    {
      "epoch": 2.7144578313253014,
      "grad_norm": 0.6143351197242737,
      "learning_rate": 1.6091867469879519e-06,
      "loss": 0.2492,
      "step": 4506
    },
    {
      "epoch": 2.7150602409638553,
      "grad_norm": 0.6247516870498657,
      "learning_rate": 1.608433734939759e-06,
      "loss": 0.2351,
      "step": 4507
    },
    {
      "epoch": 2.7156626506024097,
      "grad_norm": 0.5941426753997803,
      "learning_rate": 1.6076807228915664e-06,
      "loss": 0.244,
      "step": 4508
    },
    {
      "epoch": 2.7162650602409637,
      "grad_norm": 0.6642501354217529,
      "learning_rate": 1.6069277108433737e-06,
      "loss": 0.2686,
      "step": 4509
    },
    {
      "epoch": 2.716867469879518,
      "grad_norm": 0.6075600981712341,
      "learning_rate": 1.6061746987951809e-06,
      "loss": 0.3022,
      "step": 4510
    },
    {
      "epoch": 2.717469879518072,
      "grad_norm": 0.7868668437004089,
      "learning_rate": 1.605421686746988e-06,
      "loss": 0.251,
      "step": 4511
    },
    {
      "epoch": 2.7180722891566265,
      "grad_norm": 0.60221928358078,
      "learning_rate": 1.6046686746987951e-06,
      "loss": 0.2475,
      "step": 4512
    },
    {
      "epoch": 2.718674698795181,
      "grad_norm": 0.6763430833816528,
      "learning_rate": 1.6039156626506025e-06,
      "loss": 0.272,
      "step": 4513
    },
    {
      "epoch": 2.719277108433735,
      "grad_norm": 0.6401152014732361,
      "learning_rate": 1.6031626506024098e-06,
      "loss": 0.3009,
      "step": 4514
    },
    {
      "epoch": 2.7198795180722892,
      "grad_norm": 0.5938454270362854,
      "learning_rate": 1.602409638554217e-06,
      "loss": 0.2526,
      "step": 4515
    },
    {
      "epoch": 2.7204819277108436,
      "grad_norm": 0.6399839520454407,
      "learning_rate": 1.6016566265060243e-06,
      "loss": 0.2484,
      "step": 4516
    },
    {
      "epoch": 2.7210843373493976,
      "grad_norm": 0.6405185461044312,
      "learning_rate": 1.6009036144578312e-06,
      "loss": 0.2622,
      "step": 4517
    },
    {
      "epoch": 2.7216867469879515,
      "grad_norm": 0.616367757320404,
      "learning_rate": 1.6001506024096386e-06,
      "loss": 0.2774,
      "step": 4518
    },
    {
      "epoch": 2.722289156626506,
      "grad_norm": 0.5610241889953613,
      "learning_rate": 1.599397590361446e-06,
      "loss": 0.2914,
      "step": 4519
    },
    {
      "epoch": 2.7228915662650603,
      "grad_norm": 0.7056912779808044,
      "learning_rate": 1.598644578313253e-06,
      "loss": 0.2119,
      "step": 4520
    },
    {
      "epoch": 2.7234939759036143,
      "grad_norm": 0.6596294641494751,
      "learning_rate": 1.5978915662650604e-06,
      "loss": 0.1957,
      "step": 4521
    },
    {
      "epoch": 2.7240963855421687,
      "grad_norm": 0.6777074933052063,
      "learning_rate": 1.5971385542168678e-06,
      "loss": 0.2601,
      "step": 4522
    },
    {
      "epoch": 2.724698795180723,
      "grad_norm": 0.5957334637641907,
      "learning_rate": 1.5963855421686747e-06,
      "loss": 0.2535,
      "step": 4523
    },
    {
      "epoch": 2.725301204819277,
      "grad_norm": 0.5594730377197266,
      "learning_rate": 1.595632530120482e-06,
      "loss": 0.2153,
      "step": 4524
    },
    {
      "epoch": 2.7259036144578315,
      "grad_norm": 0.5658909678459167,
      "learning_rate": 1.5948795180722892e-06,
      "loss": 0.2175,
      "step": 4525
    },
    {
      "epoch": 2.7265060240963854,
      "grad_norm": 0.6707599759101868,
      "learning_rate": 1.5941265060240965e-06,
      "loss": 0.26,
      "step": 4526
    },
    {
      "epoch": 2.72710843373494,
      "grad_norm": 0.5331064462661743,
      "learning_rate": 1.5933734939759039e-06,
      "loss": 0.2081,
      "step": 4527
    },
    {
      "epoch": 2.727710843373494,
      "grad_norm": 0.6477978825569153,
      "learning_rate": 1.592620481927711e-06,
      "loss": 0.2705,
      "step": 4528
    },
    {
      "epoch": 2.728313253012048,
      "grad_norm": 0.7298976182937622,
      "learning_rate": 1.5918674698795181e-06,
      "loss": 0.2281,
      "step": 4529
    },
    {
      "epoch": 2.7289156626506026,
      "grad_norm": 0.5567004680633545,
      "learning_rate": 1.5911144578313253e-06,
      "loss": 0.2573,
      "step": 4530
    },
    {
      "epoch": 2.7295180722891565,
      "grad_norm": 0.5836341381072998,
      "learning_rate": 1.5903614457831326e-06,
      "loss": 0.2601,
      "step": 4531
    },
    {
      "epoch": 2.730120481927711,
      "grad_norm": 0.5587891340255737,
      "learning_rate": 1.58960843373494e-06,
      "loss": 0.203,
      "step": 4532
    },
    {
      "epoch": 2.730722891566265,
      "grad_norm": 0.6322687864303589,
      "learning_rate": 1.5888554216867471e-06,
      "loss": 0.238,
      "step": 4533
    },
    {
      "epoch": 2.7313253012048193,
      "grad_norm": 0.6095695495605469,
      "learning_rate": 1.5881024096385545e-06,
      "loss": 0.2285,
      "step": 4534
    },
    {
      "epoch": 2.7319277108433733,
      "grad_norm": 0.6387162804603577,
      "learning_rate": 1.5873493975903614e-06,
      "loss": 0.2894,
      "step": 4535
    },
    {
      "epoch": 2.7325301204819277,
      "grad_norm": 0.5736321210861206,
      "learning_rate": 1.5865963855421687e-06,
      "loss": 0.216,
      "step": 4536
    },
    {
      "epoch": 2.733132530120482,
      "grad_norm": 0.6630303263664246,
      "learning_rate": 1.585843373493976e-06,
      "loss": 0.2235,
      "step": 4537
    },
    {
      "epoch": 2.733734939759036,
      "grad_norm": 0.6023959517478943,
      "learning_rate": 1.5850903614457832e-06,
      "loss": 0.2091,
      "step": 4538
    },
    {
      "epoch": 2.7343373493975904,
      "grad_norm": 0.5715170502662659,
      "learning_rate": 1.5843373493975906e-06,
      "loss": 0.2346,
      "step": 4539
    },
    {
      "epoch": 2.734939759036145,
      "grad_norm": 0.5231756567955017,
      "learning_rate": 1.583584337349398e-06,
      "loss": 0.1831,
      "step": 4540
    },
    {
      "epoch": 2.735542168674699,
      "grad_norm": 0.5676418542861938,
      "learning_rate": 1.5828313253012048e-06,
      "loss": 0.2358,
      "step": 4541
    },
    {
      "epoch": 2.7361445783132528,
      "grad_norm": 0.5516143441200256,
      "learning_rate": 1.5820783132530122e-06,
      "loss": 0.2307,
      "step": 4542
    },
    {
      "epoch": 2.736746987951807,
      "grad_norm": 0.7118211984634399,
      "learning_rate": 1.5813253012048193e-06,
      "loss": 0.2768,
      "step": 4543
    },
    {
      "epoch": 2.7373493975903616,
      "grad_norm": 0.592710018157959,
      "learning_rate": 1.5805722891566267e-06,
      "loss": 0.2197,
      "step": 4544
    },
    {
      "epoch": 2.7379518072289155,
      "grad_norm": 0.5754128098487854,
      "learning_rate": 1.5798192771084338e-06,
      "loss": 0.2036,
      "step": 4545
    },
    {
      "epoch": 2.73855421686747,
      "grad_norm": 0.5551764369010925,
      "learning_rate": 1.5790662650602412e-06,
      "loss": 0.2421,
      "step": 4546
    },
    {
      "epoch": 2.7391566265060243,
      "grad_norm": 0.6489976048469543,
      "learning_rate": 1.578313253012048e-06,
      "loss": 0.3007,
      "step": 4547
    },
    {
      "epoch": 2.7397590361445783,
      "grad_norm": 0.554986834526062,
      "learning_rate": 1.5775602409638554e-06,
      "loss": 0.2424,
      "step": 4548
    },
    {
      "epoch": 2.7403614457831327,
      "grad_norm": 0.561497688293457,
      "learning_rate": 1.5768072289156628e-06,
      "loss": 0.2572,
      "step": 4549
    },
    {
      "epoch": 2.7409638554216866,
      "grad_norm": 0.5044786930084229,
      "learning_rate": 1.57605421686747e-06,
      "loss": 0.2089,
      "step": 4550
    },
    {
      "epoch": 2.741566265060241,
      "grad_norm": 0.6735852956771851,
      "learning_rate": 1.5753012048192773e-06,
      "loss": 0.193,
      "step": 4551
    },
    {
      "epoch": 2.742168674698795,
      "grad_norm": 0.6040337085723877,
      "learning_rate": 1.5745481927710846e-06,
      "loss": 0.2536,
      "step": 4552
    },
    {
      "epoch": 2.7427710843373494,
      "grad_norm": 0.6348381042480469,
      "learning_rate": 1.5737951807228915e-06,
      "loss": 0.2263,
      "step": 4553
    },
    {
      "epoch": 2.743373493975904,
      "grad_norm": 0.6296606063842773,
      "learning_rate": 1.5730421686746989e-06,
      "loss": 0.2519,
      "step": 4554
    },
    {
      "epoch": 2.7439759036144578,
      "grad_norm": 0.6836308240890503,
      "learning_rate": 1.572289156626506e-06,
      "loss": 0.2502,
      "step": 4555
    },
    {
      "epoch": 2.744578313253012,
      "grad_norm": 0.5635195970535278,
      "learning_rate": 1.5715361445783134e-06,
      "loss": 0.2715,
      "step": 4556
    },
    {
      "epoch": 2.745180722891566,
      "grad_norm": 0.688867449760437,
      "learning_rate": 1.5707831325301207e-06,
      "loss": 0.2891,
      "step": 4557
    },
    {
      "epoch": 2.7457831325301205,
      "grad_norm": 0.634097158908844,
      "learning_rate": 1.5700301204819279e-06,
      "loss": 0.2772,
      "step": 4558
    },
    {
      "epoch": 2.7463855421686745,
      "grad_norm": 0.6007941961288452,
      "learning_rate": 1.569277108433735e-06,
      "loss": 0.2336,
      "step": 4559
    },
    {
      "epoch": 2.746987951807229,
      "grad_norm": 0.5601251721382141,
      "learning_rate": 1.5685240963855421e-06,
      "loss": 0.256,
      "step": 4560
    },
    {
      "epoch": 2.7475903614457833,
      "grad_norm": 0.7228143215179443,
      "learning_rate": 1.5677710843373495e-06,
      "loss": 0.275,
      "step": 4561
    },
    {
      "epoch": 2.7481927710843372,
      "grad_norm": 0.5785177946090698,
      "learning_rate": 1.5670180722891568e-06,
      "loss": 0.2025,
      "step": 4562
    },
    {
      "epoch": 2.7487951807228916,
      "grad_norm": 0.6535505652427673,
      "learning_rate": 1.566265060240964e-06,
      "loss": 0.2278,
      "step": 4563
    },
    {
      "epoch": 2.749397590361446,
      "grad_norm": 0.587653636932373,
      "learning_rate": 1.5655120481927713e-06,
      "loss": 0.2677,
      "step": 4564
    },
    {
      "epoch": 2.75,
      "grad_norm": 0.6345002055168152,
      "learning_rate": 1.5647590361445782e-06,
      "loss": 0.2758,
      "step": 4565
    },
    {
      "epoch": 2.750602409638554,
      "grad_norm": 0.5957338213920593,
      "learning_rate": 1.5640060240963856e-06,
      "loss": 0.1925,
      "step": 4566
    },
    {
      "epoch": 2.7512048192771084,
      "grad_norm": 0.6000422239303589,
      "learning_rate": 1.563253012048193e-06,
      "loss": 0.2533,
      "step": 4567
    },
    {
      "epoch": 2.7518072289156628,
      "grad_norm": 0.6652962565422058,
      "learning_rate": 1.5625e-06,
      "loss": 0.2618,
      "step": 4568
    },
    {
      "epoch": 2.7524096385542167,
      "grad_norm": 0.6617314219474792,
      "learning_rate": 1.5617469879518074e-06,
      "loss": 0.2818,
      "step": 4569
    },
    {
      "epoch": 2.753012048192771,
      "grad_norm": 0.7005105018615723,
      "learning_rate": 1.5609939759036148e-06,
      "loss": 0.2543,
      "step": 4570
    },
    {
      "epoch": 2.7536144578313255,
      "grad_norm": 0.5934430360794067,
      "learning_rate": 1.560240963855422e-06,
      "loss": 0.2443,
      "step": 4571
    },
    {
      "epoch": 2.7542168674698795,
      "grad_norm": 0.6014845371246338,
      "learning_rate": 1.559487951807229e-06,
      "loss": 0.1809,
      "step": 4572
    },
    {
      "epoch": 2.754819277108434,
      "grad_norm": 0.7267695665359497,
      "learning_rate": 1.5587349397590362e-06,
      "loss": 0.3087,
      "step": 4573
    },
    {
      "epoch": 2.755421686746988,
      "grad_norm": 0.5545285940170288,
      "learning_rate": 1.5579819277108435e-06,
      "loss": 0.2416,
      "step": 4574
    },
    {
      "epoch": 2.7560240963855422,
      "grad_norm": 0.5725294351577759,
      "learning_rate": 1.5572289156626509e-06,
      "loss": 0.2017,
      "step": 4575
    },
    {
      "epoch": 2.756626506024096,
      "grad_norm": 2.498354196548462,
      "learning_rate": 1.556475903614458e-06,
      "loss": 0.2351,
      "step": 4576
    },
    {
      "epoch": 2.7572289156626506,
      "grad_norm": 0.6194804310798645,
      "learning_rate": 1.5557228915662654e-06,
      "loss": 0.298,
      "step": 4577
    },
    {
      "epoch": 2.757831325301205,
      "grad_norm": 0.625217854976654,
      "learning_rate": 1.5549698795180723e-06,
      "loss": 0.2569,
      "step": 4578
    },
    {
      "epoch": 2.758433734939759,
      "grad_norm": 0.6736142039299011,
      "learning_rate": 1.5542168674698796e-06,
      "loss": 0.2261,
      "step": 4579
    },
    {
      "epoch": 2.7590361445783134,
      "grad_norm": 0.7644485831260681,
      "learning_rate": 1.5534638554216868e-06,
      "loss": 0.2746,
      "step": 4580
    },
    {
      "epoch": 2.7596385542168673,
      "grad_norm": 0.5590135455131531,
      "learning_rate": 1.5527108433734941e-06,
      "loss": 0.1977,
      "step": 4581
    },
    {
      "epoch": 2.7602409638554217,
      "grad_norm": 0.5229946374893188,
      "learning_rate": 1.5519578313253015e-06,
      "loss": 0.1711,
      "step": 4582
    },
    {
      "epoch": 2.7608433734939757,
      "grad_norm": 0.5858097076416016,
      "learning_rate": 1.5512048192771086e-06,
      "loss": 0.24,
      "step": 4583
    },
    {
      "epoch": 2.76144578313253,
      "grad_norm": 0.6372383236885071,
      "learning_rate": 1.5504518072289157e-06,
      "loss": 0.2274,
      "step": 4584
    },
    {
      "epoch": 2.7620481927710845,
      "grad_norm": 0.6563240885734558,
      "learning_rate": 1.5496987951807229e-06,
      "loss": 0.2685,
      "step": 4585
    },
    {
      "epoch": 2.7626506024096384,
      "grad_norm": 0.5545639395713806,
      "learning_rate": 1.5489457831325302e-06,
      "loss": 0.2669,
      "step": 4586
    },
    {
      "epoch": 2.763253012048193,
      "grad_norm": 0.6432810425758362,
      "learning_rate": 1.5481927710843376e-06,
      "loss": 0.2489,
      "step": 4587
    },
    {
      "epoch": 2.7638554216867472,
      "grad_norm": 0.7389436364173889,
      "learning_rate": 1.5474397590361447e-06,
      "loss": 0.2935,
      "step": 4588
    },
    {
      "epoch": 2.764457831325301,
      "grad_norm": 0.7075236439704895,
      "learning_rate": 1.546686746987952e-06,
      "loss": 0.2924,
      "step": 4589
    },
    {
      "epoch": 2.765060240963855,
      "grad_norm": 0.6853054165840149,
      "learning_rate": 1.545933734939759e-06,
      "loss": 0.3088,
      "step": 4590
    },
    {
      "epoch": 2.7656626506024096,
      "grad_norm": 0.6581664681434631,
      "learning_rate": 1.5451807228915663e-06,
      "loss": 0.2343,
      "step": 4591
    },
    {
      "epoch": 2.766265060240964,
      "grad_norm": 0.6321586966514587,
      "learning_rate": 1.5444277108433737e-06,
      "loss": 0.2118,
      "step": 4592
    },
    {
      "epoch": 2.766867469879518,
      "grad_norm": 0.6720075011253357,
      "learning_rate": 1.5436746987951808e-06,
      "loss": 0.2214,
      "step": 4593
    },
    {
      "epoch": 2.7674698795180723,
      "grad_norm": 0.6886455416679382,
      "learning_rate": 1.5429216867469882e-06,
      "loss": 0.2028,
      "step": 4594
    },
    {
      "epoch": 2.7680722891566267,
      "grad_norm": 0.6325438022613525,
      "learning_rate": 1.5421686746987955e-06,
      "loss": 0.2604,
      "step": 4595
    },
    {
      "epoch": 2.7686746987951807,
      "grad_norm": 0.5760014653205872,
      "learning_rate": 1.5414156626506024e-06,
      "loss": 0.3087,
      "step": 4596
    },
    {
      "epoch": 2.769277108433735,
      "grad_norm": 0.697693943977356,
      "learning_rate": 1.5406626506024098e-06,
      "loss": 0.1789,
      "step": 4597
    },
    {
      "epoch": 2.769879518072289,
      "grad_norm": 0.5706793665885925,
      "learning_rate": 1.539909638554217e-06,
      "loss": 0.2536,
      "step": 4598
    },
    {
      "epoch": 2.7704819277108435,
      "grad_norm": 0.5770470499992371,
      "learning_rate": 1.5391566265060243e-06,
      "loss": 0.2149,
      "step": 4599
    },
    {
      "epoch": 2.7710843373493974,
      "grad_norm": 0.6980696320533752,
      "learning_rate": 1.5384036144578316e-06,
      "loss": 0.2825,
      "step": 4600
    },
    {
      "epoch": 2.771686746987952,
      "grad_norm": 0.5825514197349548,
      "learning_rate": 1.5376506024096388e-06,
      "loss": 0.2512,
      "step": 4601
    },
    {
      "epoch": 2.772289156626506,
      "grad_norm": 0.5341805219650269,
      "learning_rate": 1.536897590361446e-06,
      "loss": 0.2081,
      "step": 4602
    },
    {
      "epoch": 2.77289156626506,
      "grad_norm": 0.5880827903747559,
      "learning_rate": 1.536144578313253e-06,
      "loss": 0.2562,
      "step": 4603
    },
    {
      "epoch": 2.7734939759036146,
      "grad_norm": 0.6453466415405273,
      "learning_rate": 1.5353915662650604e-06,
      "loss": 0.2955,
      "step": 4604
    },
    {
      "epoch": 2.7740963855421685,
      "grad_norm": 0.6054948568344116,
      "learning_rate": 1.5346385542168677e-06,
      "loss": 0.2555,
      "step": 4605
    },
    {
      "epoch": 2.774698795180723,
      "grad_norm": 0.5973819494247437,
      "learning_rate": 1.5338855421686749e-06,
      "loss": 0.2195,
      "step": 4606
    },
    {
      "epoch": 2.775301204819277,
      "grad_norm": 0.6294402480125427,
      "learning_rate": 1.5331325301204822e-06,
      "loss": 0.2469,
      "step": 4607
    },
    {
      "epoch": 2.7759036144578313,
      "grad_norm": 0.5949419736862183,
      "learning_rate": 1.5323795180722891e-06,
      "loss": 0.2787,
      "step": 4608
    },
    {
      "epoch": 2.7765060240963857,
      "grad_norm": 0.5259424448013306,
      "learning_rate": 1.5316265060240965e-06,
      "loss": 0.2428,
      "step": 4609
    },
    {
      "epoch": 2.7771084337349397,
      "grad_norm": 0.5841641426086426,
      "learning_rate": 1.5308734939759038e-06,
      "loss": 0.24,
      "step": 4610
    },
    {
      "epoch": 2.777710843373494,
      "grad_norm": 0.7212451100349426,
      "learning_rate": 1.530120481927711e-06,
      "loss": 0.3494,
      "step": 4611
    },
    {
      "epoch": 2.7783132530120485,
      "grad_norm": 0.6443002223968506,
      "learning_rate": 1.5293674698795183e-06,
      "loss": 0.308,
      "step": 4612
    },
    {
      "epoch": 2.7789156626506024,
      "grad_norm": 0.5581598281860352,
      "learning_rate": 1.5286144578313255e-06,
      "loss": 0.2274,
      "step": 4613
    },
    {
      "epoch": 2.7795180722891564,
      "grad_norm": 0.564289927482605,
      "learning_rate": 1.5278614457831326e-06,
      "loss": 0.2837,
      "step": 4614
    },
    {
      "epoch": 2.7801204819277108,
      "grad_norm": 0.6247539520263672,
      "learning_rate": 1.5271084337349397e-06,
      "loss": 0.2791,
      "step": 4615
    },
    {
      "epoch": 2.780722891566265,
      "grad_norm": 0.5838277339935303,
      "learning_rate": 1.526355421686747e-06,
      "loss": 0.2655,
      "step": 4616
    },
    {
      "epoch": 2.781325301204819,
      "grad_norm": 0.6321502327919006,
      "learning_rate": 1.5256024096385544e-06,
      "loss": 0.2914,
      "step": 4617
    },
    {
      "epoch": 2.7819277108433735,
      "grad_norm": 0.6178601980209351,
      "learning_rate": 1.5248493975903616e-06,
      "loss": 0.2442,
      "step": 4618
    },
    {
      "epoch": 2.782530120481928,
      "grad_norm": 0.5658487677574158,
      "learning_rate": 1.524096385542169e-06,
      "loss": 0.2719,
      "step": 4619
    },
    {
      "epoch": 2.783132530120482,
      "grad_norm": 0.627058207988739,
      "learning_rate": 1.5233433734939758e-06,
      "loss": 0.2027,
      "step": 4620
    },
    {
      "epoch": 2.7837349397590363,
      "grad_norm": 0.5702061653137207,
      "learning_rate": 1.5225903614457832e-06,
      "loss": 0.2934,
      "step": 4621
    },
    {
      "epoch": 2.7843373493975903,
      "grad_norm": 0.6399821043014526,
      "learning_rate": 1.5218373493975905e-06,
      "loss": 0.289,
      "step": 4622
    },
    {
      "epoch": 2.7849397590361447,
      "grad_norm": 0.554502010345459,
      "learning_rate": 1.5210843373493977e-06,
      "loss": 0.2739,
      "step": 4623
    },
    {
      "epoch": 2.7855421686746986,
      "grad_norm": 0.6905977725982666,
      "learning_rate": 1.520331325301205e-06,
      "loss": 0.2853,
      "step": 4624
    },
    {
      "epoch": 2.786144578313253,
      "grad_norm": 0.5797497034072876,
      "learning_rate": 1.5195783132530124e-06,
      "loss": 0.2322,
      "step": 4625
    },
    {
      "epoch": 2.7867469879518074,
      "grad_norm": 0.8773181438446045,
      "learning_rate": 1.5188253012048193e-06,
      "loss": 0.2439,
      "step": 4626
    },
    {
      "epoch": 2.7873493975903614,
      "grad_norm": 0.6289732456207275,
      "learning_rate": 1.5180722891566266e-06,
      "loss": 0.2708,
      "step": 4627
    },
    {
      "epoch": 2.787951807228916,
      "grad_norm": 0.6282503008842468,
      "learning_rate": 1.5173192771084338e-06,
      "loss": 0.2644,
      "step": 4628
    },
    {
      "epoch": 2.7885542168674697,
      "grad_norm": 0.6981490850448608,
      "learning_rate": 1.5165662650602411e-06,
      "loss": 0.2015,
      "step": 4629
    },
    {
      "epoch": 2.789156626506024,
      "grad_norm": 0.6033496856689453,
      "learning_rate": 1.5158132530120485e-06,
      "loss": 0.2642,
      "step": 4630
    },
    {
      "epoch": 2.789759036144578,
      "grad_norm": 0.5895792245864868,
      "learning_rate": 1.5150602409638556e-06,
      "loss": 0.207,
      "step": 4631
    },
    {
      "epoch": 2.7903614457831325,
      "grad_norm": 0.6034475564956665,
      "learning_rate": 1.5143072289156627e-06,
      "loss": 0.2458,
      "step": 4632
    },
    {
      "epoch": 2.790963855421687,
      "grad_norm": 0.5772455334663391,
      "learning_rate": 1.5135542168674699e-06,
      "loss": 0.2148,
      "step": 4633
    },
    {
      "epoch": 2.791566265060241,
      "grad_norm": 0.55391925573349,
      "learning_rate": 1.5128012048192772e-06,
      "loss": 0.2291,
      "step": 4634
    },
    {
      "epoch": 2.7921686746987953,
      "grad_norm": 0.6662060022354126,
      "learning_rate": 1.5120481927710846e-06,
      "loss": 0.2282,
      "step": 4635
    },
    {
      "epoch": 2.7927710843373497,
      "grad_norm": 0.5533339381217957,
      "learning_rate": 1.5112951807228917e-06,
      "loss": 0.2257,
      "step": 4636
    },
    {
      "epoch": 2.7933734939759036,
      "grad_norm": 0.7438618540763855,
      "learning_rate": 1.510542168674699e-06,
      "loss": 0.2539,
      "step": 4637
    },
    {
      "epoch": 2.7939759036144576,
      "grad_norm": 0.6277410984039307,
      "learning_rate": 1.509789156626506e-06,
      "loss": 0.1883,
      "step": 4638
    },
    {
      "epoch": 2.794578313253012,
      "grad_norm": 0.7038280963897705,
      "learning_rate": 1.5090361445783133e-06,
      "loss": 0.2603,
      "step": 4639
    },
    {
      "epoch": 2.7951807228915664,
      "grad_norm": 0.5365794897079468,
      "learning_rate": 1.5082831325301207e-06,
      "loss": 0.1887,
      "step": 4640
    },
    {
      "epoch": 2.7957831325301203,
      "grad_norm": 1.1648389101028442,
      "learning_rate": 1.5075301204819278e-06,
      "loss": 0.3396,
      "step": 4641
    },
    {
      "epoch": 2.7963855421686747,
      "grad_norm": 0.5424053072929382,
      "learning_rate": 1.5067771084337352e-06,
      "loss": 0.2054,
      "step": 4642
    },
    {
      "epoch": 2.796987951807229,
      "grad_norm": 0.5891216397285461,
      "learning_rate": 1.5060240963855425e-06,
      "loss": 0.2786,
      "step": 4643
    },
    {
      "epoch": 2.797590361445783,
      "grad_norm": 0.6165879964828491,
      "learning_rate": 1.5052710843373494e-06,
      "loss": 0.2315,
      "step": 4644
    },
    {
      "epoch": 2.7981927710843375,
      "grad_norm": 0.5833665728569031,
      "learning_rate": 1.5045180722891568e-06,
      "loss": 0.2399,
      "step": 4645
    },
    {
      "epoch": 2.7987951807228915,
      "grad_norm": 0.6233952641487122,
      "learning_rate": 1.503765060240964e-06,
      "loss": 0.2125,
      "step": 4646
    },
    {
      "epoch": 2.799397590361446,
      "grad_norm": 0.5918872952461243,
      "learning_rate": 1.5030120481927713e-06,
      "loss": 0.2089,
      "step": 4647
    },
    {
      "epoch": 2.8,
      "grad_norm": 0.7425259351730347,
      "learning_rate": 1.5022590361445784e-06,
      "loss": 0.2071,
      "step": 4648
    },
    {
      "epoch": 2.8006024096385542,
      "grad_norm": 0.5529218316078186,
      "learning_rate": 1.5015060240963858e-06,
      "loss": 0.2604,
      "step": 4649
    },
    {
      "epoch": 2.8012048192771086,
      "grad_norm": 0.6233651041984558,
      "learning_rate": 1.5007530120481927e-06,
      "loss": 0.2229,
      "step": 4650
    },
    {
      "epoch": 2.8018072289156626,
      "grad_norm": 0.6092690825462341,
      "learning_rate": 1.5e-06,
      "loss": 0.2211,
      "step": 4651
    },
    {
      "epoch": 2.802409638554217,
      "grad_norm": 0.6909400224685669,
      "learning_rate": 1.4992469879518074e-06,
      "loss": 0.2346,
      "step": 4652
    },
    {
      "epoch": 2.803012048192771,
      "grad_norm": 0.5903735160827637,
      "learning_rate": 1.4984939759036145e-06,
      "loss": 0.3048,
      "step": 4653
    },
    {
      "epoch": 2.8036144578313253,
      "grad_norm": 0.6033309698104858,
      "learning_rate": 1.4977409638554219e-06,
      "loss": 0.2958,
      "step": 4654
    },
    {
      "epoch": 2.8042168674698793,
      "grad_norm": 0.7495138645172119,
      "learning_rate": 1.4969879518072292e-06,
      "loss": 0.2528,
      "step": 4655
    },
    {
      "epoch": 2.8048192771084337,
      "grad_norm": 0.7401688098907471,
      "learning_rate": 1.4962349397590361e-06,
      "loss": 0.2897,
      "step": 4656
    },
    {
      "epoch": 2.805421686746988,
      "grad_norm": 0.7210056185722351,
      "learning_rate": 1.4954819277108435e-06,
      "loss": 0.326,
      "step": 4657
    },
    {
      "epoch": 2.806024096385542,
      "grad_norm": 0.5698343515396118,
      "learning_rate": 1.4947289156626506e-06,
      "loss": 0.243,
      "step": 4658
    },
    {
      "epoch": 2.8066265060240965,
      "grad_norm": 0.7129036784172058,
      "learning_rate": 1.493975903614458e-06,
      "loss": 0.2946,
      "step": 4659
    },
    {
      "epoch": 2.807228915662651,
      "grad_norm": 0.547774076461792,
      "learning_rate": 1.4932228915662653e-06,
      "loss": 0.2682,
      "step": 4660
    },
    {
      "epoch": 2.807831325301205,
      "grad_norm": 0.5851855278015137,
      "learning_rate": 1.4924698795180725e-06,
      "loss": 0.2219,
      "step": 4661
    },
    {
      "epoch": 2.808433734939759,
      "grad_norm": 0.6398654580116272,
      "learning_rate": 1.4917168674698796e-06,
      "loss": 0.2824,
      "step": 4662
    },
    {
      "epoch": 2.809036144578313,
      "grad_norm": 0.6050485372543335,
      "learning_rate": 1.4909638554216867e-06,
      "loss": 0.2729,
      "step": 4663
    },
    {
      "epoch": 2.8096385542168676,
      "grad_norm": 0.669201672077179,
      "learning_rate": 1.490210843373494e-06,
      "loss": 0.2815,
      "step": 4664
    },
    {
      "epoch": 2.8102409638554215,
      "grad_norm": 0.6983674764633179,
      "learning_rate": 1.4894578313253014e-06,
      "loss": 0.2502,
      "step": 4665
    },
    {
      "epoch": 2.810843373493976,
      "grad_norm": 0.8158520460128784,
      "learning_rate": 1.4887048192771086e-06,
      "loss": 0.3078,
      "step": 4666
    },
    {
      "epoch": 2.8114457831325304,
      "grad_norm": 0.5986252427101135,
      "learning_rate": 1.487951807228916e-06,
      "loss": 0.2571,
      "step": 4667
    },
    {
      "epoch": 2.8120481927710843,
      "grad_norm": 0.640637218952179,
      "learning_rate": 1.4871987951807228e-06,
      "loss": 0.2461,
      "step": 4668
    },
    {
      "epoch": 2.8126506024096387,
      "grad_norm": 0.6502708792686462,
      "learning_rate": 1.4864457831325302e-06,
      "loss": 0.2499,
      "step": 4669
    },
    {
      "epoch": 2.8132530120481927,
      "grad_norm": 0.6001766920089722,
      "learning_rate": 1.4856927710843375e-06,
      "loss": 0.1903,
      "step": 4670
    },
    {
      "epoch": 2.813855421686747,
      "grad_norm": 0.6136929988861084,
      "learning_rate": 1.4849397590361447e-06,
      "loss": 0.2518,
      "step": 4671
    },
    {
      "epoch": 2.814457831325301,
      "grad_norm": 0.6051228046417236,
      "learning_rate": 1.484186746987952e-06,
      "loss": 0.2007,
      "step": 4672
    },
    {
      "epoch": 2.8150602409638554,
      "grad_norm": 0.5473788380622864,
      "learning_rate": 1.4834337349397594e-06,
      "loss": 0.2237,
      "step": 4673
    },
    {
      "epoch": 2.81566265060241,
      "grad_norm": 0.6092745661735535,
      "learning_rate": 1.4826807228915663e-06,
      "loss": 0.2297,
      "step": 4674
    },
    {
      "epoch": 2.816265060240964,
      "grad_norm": 0.6783872246742249,
      "learning_rate": 1.4819277108433736e-06,
      "loss": 0.2572,
      "step": 4675
    },
    {
      "epoch": 2.816867469879518,
      "grad_norm": 0.6727229356765747,
      "learning_rate": 1.4811746987951808e-06,
      "loss": 0.2784,
      "step": 4676
    },
    {
      "epoch": 2.817469879518072,
      "grad_norm": 0.5756008625030518,
      "learning_rate": 1.4804216867469881e-06,
      "loss": 0.2383,
      "step": 4677
    },
    {
      "epoch": 2.8180722891566266,
      "grad_norm": 0.551114559173584,
      "learning_rate": 1.4796686746987955e-06,
      "loss": 0.259,
      "step": 4678
    },
    {
      "epoch": 2.8186746987951805,
      "grad_norm": 0.6656395792961121,
      "learning_rate": 1.4789156626506026e-06,
      "loss": 0.2408,
      "step": 4679
    },
    {
      "epoch": 2.819277108433735,
      "grad_norm": 0.5568209290504456,
      "learning_rate": 1.4781626506024098e-06,
      "loss": 0.2555,
      "step": 4680
    },
    {
      "epoch": 2.8198795180722893,
      "grad_norm": 0.6286381483078003,
      "learning_rate": 1.4774096385542169e-06,
      "loss": 0.2684,
      "step": 4681
    },
    {
      "epoch": 2.8204819277108433,
      "grad_norm": 0.6532778143882751,
      "learning_rate": 1.4766566265060242e-06,
      "loss": 0.2788,
      "step": 4682
    },
    {
      "epoch": 2.8210843373493977,
      "grad_norm": 0.6226255297660828,
      "learning_rate": 1.4759036144578314e-06,
      "loss": 0.2027,
      "step": 4683
    },
    {
      "epoch": 2.821686746987952,
      "grad_norm": 0.6410249471664429,
      "learning_rate": 1.4751506024096387e-06,
      "loss": 0.2683,
      "step": 4684
    },
    {
      "epoch": 2.822289156626506,
      "grad_norm": 0.7801054120063782,
      "learning_rate": 1.474397590361446e-06,
      "loss": 0.3327,
      "step": 4685
    },
    {
      "epoch": 2.82289156626506,
      "grad_norm": 0.6585883498191833,
      "learning_rate": 1.473644578313253e-06,
      "loss": 0.2755,
      "step": 4686
    },
    {
      "epoch": 2.8234939759036144,
      "grad_norm": 0.6429021954536438,
      "learning_rate": 1.4728915662650603e-06,
      "loss": 0.2338,
      "step": 4687
    },
    {
      "epoch": 2.824096385542169,
      "grad_norm": 0.5640220642089844,
      "learning_rate": 1.4721385542168675e-06,
      "loss": 0.2495,
      "step": 4688
    },
    {
      "epoch": 2.8246987951807228,
      "grad_norm": 0.5841077566146851,
      "learning_rate": 1.4713855421686748e-06,
      "loss": 0.2662,
      "step": 4689
    },
    {
      "epoch": 2.825301204819277,
      "grad_norm": 0.6900468468666077,
      "learning_rate": 1.4706325301204822e-06,
      "loss": 0.2762,
      "step": 4690
    },
    {
      "epoch": 2.8259036144578316,
      "grad_norm": 0.5803337693214417,
      "learning_rate": 1.4698795180722893e-06,
      "loss": 0.2253,
      "step": 4691
    },
    {
      "epoch": 2.8265060240963855,
      "grad_norm": 0.5949167013168335,
      "learning_rate": 1.4691265060240965e-06,
      "loss": 0.2291,
      "step": 4692
    },
    {
      "epoch": 2.82710843373494,
      "grad_norm": 0.7512699961662292,
      "learning_rate": 1.4683734939759036e-06,
      "loss": 0.2646,
      "step": 4693
    },
    {
      "epoch": 2.827710843373494,
      "grad_norm": 0.6611175537109375,
      "learning_rate": 1.467620481927711e-06,
      "loss": 0.2859,
      "step": 4694
    },
    {
      "epoch": 2.8283132530120483,
      "grad_norm": 0.5616543889045715,
      "learning_rate": 1.4668674698795183e-06,
      "loss": 0.2415,
      "step": 4695
    },
    {
      "epoch": 2.8289156626506022,
      "grad_norm": 0.6561079621315002,
      "learning_rate": 1.4661144578313254e-06,
      "loss": 0.2356,
      "step": 4696
    },
    {
      "epoch": 2.8295180722891566,
      "grad_norm": 0.6310067176818848,
      "learning_rate": 1.4653614457831328e-06,
      "loss": 0.272,
      "step": 4697
    },
    {
      "epoch": 2.830120481927711,
      "grad_norm": 0.6077042818069458,
      "learning_rate": 1.4646084337349397e-06,
      "loss": 0.2676,
      "step": 4698
    },
    {
      "epoch": 2.830722891566265,
      "grad_norm": 0.6063459515571594,
      "learning_rate": 1.463855421686747e-06,
      "loss": 0.2913,
      "step": 4699
    },
    {
      "epoch": 2.8313253012048194,
      "grad_norm": 0.5884646773338318,
      "learning_rate": 1.4631024096385544e-06,
      "loss": 0.2302,
      "step": 4700
    },
    {
      "epoch": 2.8319277108433734,
      "grad_norm": 0.6094974279403687,
      "learning_rate": 1.4623493975903615e-06,
      "loss": 0.2606,
      "step": 4701
    },
    {
      "epoch": 2.8325301204819278,
      "grad_norm": 0.582394003868103,
      "learning_rate": 1.4615963855421689e-06,
      "loss": 0.2661,
      "step": 4702
    },
    {
      "epoch": 2.8331325301204817,
      "grad_norm": 0.4916447699069977,
      "learning_rate": 1.4608433734939762e-06,
      "loss": 0.2226,
      "step": 4703
    },
    {
      "epoch": 2.833734939759036,
      "grad_norm": 0.5717194080352783,
      "learning_rate": 1.4600903614457831e-06,
      "loss": 0.1926,
      "step": 4704
    },
    {
      "epoch": 2.8343373493975905,
      "grad_norm": 0.6208549737930298,
      "learning_rate": 1.4593373493975905e-06,
      "loss": 0.2274,
      "step": 4705
    },
    {
      "epoch": 2.8349397590361445,
      "grad_norm": 0.5808967351913452,
      "learning_rate": 1.4585843373493976e-06,
      "loss": 0.2761,
      "step": 4706
    },
    {
      "epoch": 2.835542168674699,
      "grad_norm": 0.742693305015564,
      "learning_rate": 1.457831325301205e-06,
      "loss": 0.3154,
      "step": 4707
    },
    {
      "epoch": 2.8361445783132533,
      "grad_norm": 0.588748037815094,
      "learning_rate": 1.4570783132530123e-06,
      "loss": 0.2364,
      "step": 4708
    },
    {
      "epoch": 2.8367469879518072,
      "grad_norm": 0.6066392660140991,
      "learning_rate": 1.4563253012048195e-06,
      "loss": 0.3017,
      "step": 4709
    },
    {
      "epoch": 2.837349397590361,
      "grad_norm": 0.5410419702529907,
      "learning_rate": 1.4555722891566266e-06,
      "loss": 0.2062,
      "step": 4710
    },
    {
      "epoch": 2.8379518072289156,
      "grad_norm": 0.5133593678474426,
      "learning_rate": 1.4548192771084337e-06,
      "loss": 0.1941,
      "step": 4711
    },
    {
      "epoch": 2.83855421686747,
      "grad_norm": 0.7485877275466919,
      "learning_rate": 1.454066265060241e-06,
      "loss": 0.2292,
      "step": 4712
    },
    {
      "epoch": 2.839156626506024,
      "grad_norm": 0.6761966943740845,
      "learning_rate": 1.4533132530120484e-06,
      "loss": 0.2749,
      "step": 4713
    },
    {
      "epoch": 2.8397590361445784,
      "grad_norm": 0.6556760668754578,
      "learning_rate": 1.4525602409638556e-06,
      "loss": 0.278,
      "step": 4714
    },
    {
      "epoch": 2.8403614457831328,
      "grad_norm": 0.6549644470214844,
      "learning_rate": 1.451807228915663e-06,
      "loss": 0.3025,
      "step": 4715
    },
    {
      "epoch": 2.8409638554216867,
      "grad_norm": 0.5409745573997498,
      "learning_rate": 1.4510542168674698e-06,
      "loss": 0.2027,
      "step": 4716
    },
    {
      "epoch": 2.841566265060241,
      "grad_norm": 0.6001907587051392,
      "learning_rate": 1.4503012048192772e-06,
      "loss": 0.2628,
      "step": 4717
    },
    {
      "epoch": 2.842168674698795,
      "grad_norm": 0.5609132051467896,
      "learning_rate": 1.4495481927710845e-06,
      "loss": 0.2082,
      "step": 4718
    },
    {
      "epoch": 2.8427710843373495,
      "grad_norm": 0.6094481348991394,
      "learning_rate": 1.4487951807228917e-06,
      "loss": 0.2529,
      "step": 4719
    },
    {
      "epoch": 2.8433734939759034,
      "grad_norm": 0.6065123677253723,
      "learning_rate": 1.448042168674699e-06,
      "loss": 0.2608,
      "step": 4720
    },
    {
      "epoch": 2.843975903614458,
      "grad_norm": 0.6286376714706421,
      "learning_rate": 1.4472891566265062e-06,
      "loss": 0.3167,
      "step": 4721
    },
    {
      "epoch": 2.8445783132530122,
      "grad_norm": 0.6186703443527222,
      "learning_rate": 1.4465361445783133e-06,
      "loss": 0.2627,
      "step": 4722
    },
    {
      "epoch": 2.845180722891566,
      "grad_norm": 0.5806115865707397,
      "learning_rate": 1.4457831325301204e-06,
      "loss": 0.2381,
      "step": 4723
    },
    {
      "epoch": 2.8457831325301206,
      "grad_norm": 0.635809600353241,
      "learning_rate": 1.4450301204819278e-06,
      "loss": 0.2819,
      "step": 4724
    },
    {
      "epoch": 2.8463855421686746,
      "grad_norm": 0.5568793416023254,
      "learning_rate": 1.4442771084337351e-06,
      "loss": 0.2614,
      "step": 4725
    },
    {
      "epoch": 2.846987951807229,
      "grad_norm": 0.5716134905815125,
      "learning_rate": 1.4435240963855423e-06,
      "loss": 0.2504,
      "step": 4726
    },
    {
      "epoch": 2.847590361445783,
      "grad_norm": 0.6058735847473145,
      "learning_rate": 1.4427710843373496e-06,
      "loss": 0.2782,
      "step": 4727
    },
    {
      "epoch": 2.8481927710843373,
      "grad_norm": 0.5486566424369812,
      "learning_rate": 1.4420180722891565e-06,
      "loss": 0.2316,
      "step": 4728
    },
    {
      "epoch": 2.8487951807228917,
      "grad_norm": 0.6184929013252258,
      "learning_rate": 1.441265060240964e-06,
      "loss": 0.2756,
      "step": 4729
    },
    {
      "epoch": 2.8493975903614457,
      "grad_norm": 0.6311301589012146,
      "learning_rate": 1.4405120481927712e-06,
      "loss": 0.2803,
      "step": 4730
    },
    {
      "epoch": 2.85,
      "grad_norm": 0.6483370661735535,
      "learning_rate": 1.4397590361445784e-06,
      "loss": 0.2244,
      "step": 4731
    },
    {
      "epoch": 2.8506024096385545,
      "grad_norm": 0.6446520090103149,
      "learning_rate": 1.4390060240963857e-06,
      "loss": 0.2531,
      "step": 4732
    },
    {
      "epoch": 2.8512048192771084,
      "grad_norm": 0.5216512084007263,
      "learning_rate": 1.438253012048193e-06,
      "loss": 0.2214,
      "step": 4733
    },
    {
      "epoch": 2.8518072289156624,
      "grad_norm": 0.6916137337684631,
      "learning_rate": 1.4375e-06,
      "loss": 0.3067,
      "step": 4734
    },
    {
      "epoch": 2.852409638554217,
      "grad_norm": 0.4815938174724579,
      "learning_rate": 1.4367469879518073e-06,
      "loss": 0.1939,
      "step": 4735
    },
    {
      "epoch": 2.853012048192771,
      "grad_norm": 0.713367760181427,
      "learning_rate": 1.4359939759036145e-06,
      "loss": 0.2841,
      "step": 4736
    },
    {
      "epoch": 2.853614457831325,
      "grad_norm": 0.6016532778739929,
      "learning_rate": 1.4352409638554218e-06,
      "loss": 0.2171,
      "step": 4737
    },
    {
      "epoch": 2.8542168674698796,
      "grad_norm": 0.6908681392669678,
      "learning_rate": 1.4344879518072292e-06,
      "loss": 0.2496,
      "step": 4738
    },
    {
      "epoch": 2.854819277108434,
      "grad_norm": 0.6668313145637512,
      "learning_rate": 1.4337349397590363e-06,
      "loss": 0.2424,
      "step": 4739
    },
    {
      "epoch": 2.855421686746988,
      "grad_norm": 0.6389822959899902,
      "learning_rate": 1.4329819277108435e-06,
      "loss": 0.2878,
      "step": 4740
    },
    {
      "epoch": 2.8560240963855423,
      "grad_norm": 0.5835608243942261,
      "learning_rate": 1.4322289156626506e-06,
      "loss": 0.2221,
      "step": 4741
    },
    {
      "epoch": 2.8566265060240963,
      "grad_norm": 0.5422695279121399,
      "learning_rate": 1.431475903614458e-06,
      "loss": 0.2233,
      "step": 4742
    },
    {
      "epoch": 2.8572289156626507,
      "grad_norm": 0.5729630589485168,
      "learning_rate": 1.4307228915662653e-06,
      "loss": 0.2328,
      "step": 4743
    },
    {
      "epoch": 2.8578313253012047,
      "grad_norm": 0.6436915993690491,
      "learning_rate": 1.4299698795180724e-06,
      "loss": 0.2536,
      "step": 4744
    },
    {
      "epoch": 2.858433734939759,
      "grad_norm": 0.532287061214447,
      "learning_rate": 1.4292168674698798e-06,
      "loss": 0.2472,
      "step": 4745
    },
    {
      "epoch": 2.8590361445783135,
      "grad_norm": 0.5648745894432068,
      "learning_rate": 1.4284638554216867e-06,
      "loss": 0.2515,
      "step": 4746
    },
    {
      "epoch": 2.8596385542168674,
      "grad_norm": 0.5997214913368225,
      "learning_rate": 1.427710843373494e-06,
      "loss": 0.2524,
      "step": 4747
    },
    {
      "epoch": 2.860240963855422,
      "grad_norm": 0.5805976390838623,
      "learning_rate": 1.4269578313253014e-06,
      "loss": 0.2391,
      "step": 4748
    },
    {
      "epoch": 2.8608433734939758,
      "grad_norm": 0.6174880266189575,
      "learning_rate": 1.4262048192771085e-06,
      "loss": 0.2754,
      "step": 4749
    },
    {
      "epoch": 2.86144578313253,
      "grad_norm": 0.5599544048309326,
      "learning_rate": 1.4254518072289159e-06,
      "loss": 0.2719,
      "step": 4750
    },
    {
      "epoch": 2.862048192771084,
      "grad_norm": 0.6887100338935852,
      "learning_rate": 1.4246987951807232e-06,
      "loss": 0.2742,
      "step": 4751
    },
    {
      "epoch": 2.8626506024096385,
      "grad_norm": 0.5662026405334473,
      "learning_rate": 1.4239457831325302e-06,
      "loss": 0.2351,
      "step": 4752
    },
    {
      "epoch": 2.863253012048193,
      "grad_norm": 0.6106133460998535,
      "learning_rate": 1.4231927710843375e-06,
      "loss": 0.2317,
      "step": 4753
    },
    {
      "epoch": 2.863855421686747,
      "grad_norm": 0.5540133118629456,
      "learning_rate": 1.4224397590361446e-06,
      "loss": 0.2264,
      "step": 4754
    },
    {
      "epoch": 2.8644578313253013,
      "grad_norm": 0.598273515701294,
      "learning_rate": 1.421686746987952e-06,
      "loss": 0.2895,
      "step": 4755
    },
    {
      "epoch": 2.8650602409638557,
      "grad_norm": 0.7420627474784851,
      "learning_rate": 1.4209337349397591e-06,
      "loss": 0.302,
      "step": 4756
    },
    {
      "epoch": 2.8656626506024097,
      "grad_norm": 0.5884485244750977,
      "learning_rate": 1.4201807228915665e-06,
      "loss": 0.2711,
      "step": 4757
    },
    {
      "epoch": 2.8662650602409636,
      "grad_norm": 0.6121874451637268,
      "learning_rate": 1.4194277108433734e-06,
      "loss": 0.279,
      "step": 4758
    },
    {
      "epoch": 2.866867469879518,
      "grad_norm": 0.574495255947113,
      "learning_rate": 1.4186746987951807e-06,
      "loss": 0.2411,
      "step": 4759
    },
    {
      "epoch": 2.8674698795180724,
      "grad_norm": 0.6296667456626892,
      "learning_rate": 1.417921686746988e-06,
      "loss": 0.2988,
      "step": 4760
    },
    {
      "epoch": 2.8680722891566264,
      "grad_norm": 0.5655316710472107,
      "learning_rate": 1.4171686746987952e-06,
      "loss": 0.2001,
      "step": 4761
    },
    {
      "epoch": 2.8686746987951808,
      "grad_norm": 2.146512031555176,
      "learning_rate": 1.4164156626506026e-06,
      "loss": 0.3277,
      "step": 4762
    },
    {
      "epoch": 2.869277108433735,
      "grad_norm": 0.6757389307022095,
      "learning_rate": 1.41566265060241e-06,
      "loss": 0.2104,
      "step": 4763
    },
    {
      "epoch": 2.869879518072289,
      "grad_norm": 0.6183788776397705,
      "learning_rate": 1.4149096385542169e-06,
      "loss": 0.2037,
      "step": 4764
    },
    {
      "epoch": 2.8704819277108435,
      "grad_norm": 0.6413282752037048,
      "learning_rate": 1.4141566265060242e-06,
      "loss": 0.1998,
      "step": 4765
    },
    {
      "epoch": 2.8710843373493975,
      "grad_norm": 0.5327916741371155,
      "learning_rate": 1.4134036144578313e-06,
      "loss": 0.2269,
      "step": 4766
    },
    {
      "epoch": 2.871686746987952,
      "grad_norm": 0.8406874537467957,
      "learning_rate": 1.4126506024096387e-06,
      "loss": 0.3058,
      "step": 4767
    },
    {
      "epoch": 2.872289156626506,
      "grad_norm": 0.6698435544967651,
      "learning_rate": 1.411897590361446e-06,
      "loss": 0.2668,
      "step": 4768
    },
    {
      "epoch": 2.8728915662650603,
      "grad_norm": 0.5839793086051941,
      "learning_rate": 1.4111445783132532e-06,
      "loss": 0.2189,
      "step": 4769
    },
    {
      "epoch": 2.8734939759036147,
      "grad_norm": 0.834536075592041,
      "learning_rate": 1.4103915662650603e-06,
      "loss": 0.3317,
      "step": 4770
    },
    {
      "epoch": 2.8740963855421686,
      "grad_norm": 0.6203224062919617,
      "learning_rate": 1.4096385542168674e-06,
      "loss": 0.235,
      "step": 4771
    },
    {
      "epoch": 2.874698795180723,
      "grad_norm": 0.5950739979743958,
      "learning_rate": 1.4088855421686748e-06,
      "loss": 0.2801,
      "step": 4772
    },
    {
      "epoch": 2.875301204819277,
      "grad_norm": 0.5875653624534607,
      "learning_rate": 1.4081325301204821e-06,
      "loss": 0.2128,
      "step": 4773
    },
    {
      "epoch": 2.8759036144578314,
      "grad_norm": 0.5795519948005676,
      "learning_rate": 1.4073795180722893e-06,
      "loss": 0.2511,
      "step": 4774
    },
    {
      "epoch": 2.8765060240963853,
      "grad_norm": 0.6322454810142517,
      "learning_rate": 1.4066265060240966e-06,
      "loss": 0.3018,
      "step": 4775
    },
    {
      "epoch": 2.8771084337349397,
      "grad_norm": 0.5299115180969238,
      "learning_rate": 1.4058734939759036e-06,
      "loss": 0.2261,
      "step": 4776
    },
    {
      "epoch": 2.877710843373494,
      "grad_norm": 0.5742791295051575,
      "learning_rate": 1.405120481927711e-06,
      "loss": 0.2456,
      "step": 4777
    },
    {
      "epoch": 2.878313253012048,
      "grad_norm": 0.6290103197097778,
      "learning_rate": 1.4043674698795182e-06,
      "loss": 0.2096,
      "step": 4778
    },
    {
      "epoch": 2.8789156626506025,
      "grad_norm": 0.6189995408058167,
      "learning_rate": 1.4036144578313254e-06,
      "loss": 0.2077,
      "step": 4779
    },
    {
      "epoch": 2.8795180722891565,
      "grad_norm": 0.5982128381729126,
      "learning_rate": 1.4028614457831327e-06,
      "loss": 0.3073,
      "step": 4780
    },
    {
      "epoch": 2.880120481927711,
      "grad_norm": 0.6384310126304626,
      "learning_rate": 1.40210843373494e-06,
      "loss": 0.2639,
      "step": 4781
    },
    {
      "epoch": 2.880722891566265,
      "grad_norm": 0.5900040864944458,
      "learning_rate": 1.401355421686747e-06,
      "loss": 0.2663,
      "step": 4782
    },
    {
      "epoch": 2.8813253012048192,
      "grad_norm": 0.6590578556060791,
      "learning_rate": 1.4006024096385544e-06,
      "loss": 0.2788,
      "step": 4783
    },
    {
      "epoch": 2.8819277108433736,
      "grad_norm": 0.554377555847168,
      "learning_rate": 1.3998493975903615e-06,
      "loss": 0.2567,
      "step": 4784
    },
    {
      "epoch": 2.8825301204819276,
      "grad_norm": 0.6468251347541809,
      "learning_rate": 1.3990963855421688e-06,
      "loss": 0.3116,
      "step": 4785
    },
    {
      "epoch": 2.883132530120482,
      "grad_norm": 0.668225884437561,
      "learning_rate": 1.3983433734939762e-06,
      "loss": 0.2799,
      "step": 4786
    },
    {
      "epoch": 2.8837349397590364,
      "grad_norm": 0.7048038244247437,
      "learning_rate": 1.3975903614457833e-06,
      "loss": 0.2454,
      "step": 4787
    },
    {
      "epoch": 2.8843373493975903,
      "grad_norm": 0.5670482516288757,
      "learning_rate": 1.3968373493975905e-06,
      "loss": 0.2362,
      "step": 4788
    },
    {
      "epoch": 2.8849397590361443,
      "grad_norm": 0.5725186467170715,
      "learning_rate": 1.3960843373493976e-06,
      "loss": 0.2344,
      "step": 4789
    },
    {
      "epoch": 2.8855421686746987,
      "grad_norm": 0.6614006757736206,
      "learning_rate": 1.395331325301205e-06,
      "loss": 0.3209,
      "step": 4790
    },
    {
      "epoch": 2.886144578313253,
      "grad_norm": 0.5297855138778687,
      "learning_rate": 1.394578313253012e-06,
      "loss": 0.2312,
      "step": 4791
    },
    {
      "epoch": 2.886746987951807,
      "grad_norm": 0.7188472747802734,
      "learning_rate": 1.3938253012048194e-06,
      "loss": 0.2846,
      "step": 4792
    },
    {
      "epoch": 2.8873493975903615,
      "grad_norm": 0.6573063135147095,
      "learning_rate": 1.3930722891566268e-06,
      "loss": 0.2716,
      "step": 4793
    },
    {
      "epoch": 2.887951807228916,
      "grad_norm": 0.5550808906555176,
      "learning_rate": 1.3923192771084337e-06,
      "loss": 0.2667,
      "step": 4794
    },
    {
      "epoch": 2.88855421686747,
      "grad_norm": 0.6636071801185608,
      "learning_rate": 1.391566265060241e-06,
      "loss": 0.2777,
      "step": 4795
    },
    {
      "epoch": 2.8891566265060242,
      "grad_norm": 0.6399260759353638,
      "learning_rate": 1.3908132530120482e-06,
      "loss": 0.2885,
      "step": 4796
    },
    {
      "epoch": 2.889759036144578,
      "grad_norm": 0.6205365657806396,
      "learning_rate": 1.3900602409638555e-06,
      "loss": 0.265,
      "step": 4797
    },
    {
      "epoch": 2.8903614457831326,
      "grad_norm": 0.5492144227027893,
      "learning_rate": 1.3893072289156629e-06,
      "loss": 0.24,
      "step": 4798
    },
    {
      "epoch": 2.8909638554216865,
      "grad_norm": 0.5662696957588196,
      "learning_rate": 1.38855421686747e-06,
      "loss": 0.215,
      "step": 4799
    },
    {
      "epoch": 2.891566265060241,
      "grad_norm": 0.6828129887580872,
      "learning_rate": 1.3878012048192772e-06,
      "loss": 0.308,
      "step": 4800
    },
    {
      "epoch": 2.8921686746987953,
      "grad_norm": 0.573358952999115,
      "learning_rate": 1.3870481927710843e-06,
      "loss": 0.255,
      "step": 4801
    },
    {
      "epoch": 2.8927710843373493,
      "grad_norm": 0.7039363384246826,
      "learning_rate": 1.3862951807228916e-06,
      "loss": 0.2411,
      "step": 4802
    },
    {
      "epoch": 2.8933734939759037,
      "grad_norm": 0.5823262929916382,
      "learning_rate": 1.385542168674699e-06,
      "loss": 0.2401,
      "step": 4803
    },
    {
      "epoch": 2.8939759036144577,
      "grad_norm": 0.6533313989639282,
      "learning_rate": 1.3847891566265061e-06,
      "loss": 0.216,
      "step": 4804
    },
    {
      "epoch": 2.894578313253012,
      "grad_norm": 0.584689199924469,
      "learning_rate": 1.3840361445783135e-06,
      "loss": 0.2881,
      "step": 4805
    },
    {
      "epoch": 2.895180722891566,
      "grad_norm": 0.6173144578933716,
      "learning_rate": 1.3832831325301204e-06,
      "loss": 0.2343,
      "step": 4806
    },
    {
      "epoch": 2.8957831325301204,
      "grad_norm": 0.5678063035011292,
      "learning_rate": 1.3825301204819278e-06,
      "loss": 0.2008,
      "step": 4807
    },
    {
      "epoch": 2.896385542168675,
      "grad_norm": 0.6768901348114014,
      "learning_rate": 1.381777108433735e-06,
      "loss": 0.2434,
      "step": 4808
    },
    {
      "epoch": 2.896987951807229,
      "grad_norm": 0.7338475584983826,
      "learning_rate": 1.3810240963855422e-06,
      "loss": 0.3455,
      "step": 4809
    },
    {
      "epoch": 2.897590361445783,
      "grad_norm": 0.6687947511672974,
      "learning_rate": 1.3802710843373496e-06,
      "loss": 0.2634,
      "step": 4810
    },
    {
      "epoch": 2.8981927710843376,
      "grad_norm": 0.5522205829620361,
      "learning_rate": 1.379518072289157e-06,
      "loss": 0.183,
      "step": 4811
    },
    {
      "epoch": 2.8987951807228916,
      "grad_norm": 0.6901101469993591,
      "learning_rate": 1.3787650602409639e-06,
      "loss": 0.2743,
      "step": 4812
    },
    {
      "epoch": 2.8993975903614455,
      "grad_norm": 0.5848546028137207,
      "learning_rate": 1.3780120481927712e-06,
      "loss": 0.2783,
      "step": 4813
    },
    {
      "epoch": 2.9,
      "grad_norm": 0.5596975684165955,
      "learning_rate": 1.3772590361445783e-06,
      "loss": 0.2707,
      "step": 4814
    },
    {
      "epoch": 2.9006024096385543,
      "grad_norm": 0.6269801259040833,
      "learning_rate": 1.3765060240963857e-06,
      "loss": 0.2696,
      "step": 4815
    },
    {
      "epoch": 2.9012048192771083,
      "grad_norm": 0.5519245862960815,
      "learning_rate": 1.375753012048193e-06,
      "loss": 0.2281,
      "step": 4816
    },
    {
      "epoch": 2.9018072289156627,
      "grad_norm": 0.6905240416526794,
      "learning_rate": 1.3750000000000002e-06,
      "loss": 0.273,
      "step": 4817
    },
    {
      "epoch": 2.902409638554217,
      "grad_norm": 0.5751949548721313,
      "learning_rate": 1.3742469879518073e-06,
      "loss": 0.2972,
      "step": 4818
    },
    {
      "epoch": 2.903012048192771,
      "grad_norm": 0.648350179195404,
      "learning_rate": 1.3734939759036144e-06,
      "loss": 0.2796,
      "step": 4819
    },
    {
      "epoch": 2.9036144578313254,
      "grad_norm": 0.6377880573272705,
      "learning_rate": 1.3727409638554218e-06,
      "loss": 0.3202,
      "step": 4820
    },
    {
      "epoch": 2.9042168674698794,
      "grad_norm": 0.6188780069351196,
      "learning_rate": 1.3719879518072291e-06,
      "loss": 0.2542,
      "step": 4821
    },
    {
      "epoch": 2.904819277108434,
      "grad_norm": 0.6873153448104858,
      "learning_rate": 1.3712349397590363e-06,
      "loss": 0.2578,
      "step": 4822
    },
    {
      "epoch": 2.9054216867469878,
      "grad_norm": 0.6564432978630066,
      "learning_rate": 1.3704819277108436e-06,
      "loss": 0.2523,
      "step": 4823
    },
    {
      "epoch": 2.906024096385542,
      "grad_norm": 0.6323334574699402,
      "learning_rate": 1.3697289156626506e-06,
      "loss": 0.2509,
      "step": 4824
    },
    {
      "epoch": 2.9066265060240966,
      "grad_norm": 0.5517905950546265,
      "learning_rate": 1.368975903614458e-06,
      "loss": 0.2235,
      "step": 4825
    },
    {
      "epoch": 2.9072289156626505,
      "grad_norm": 0.7179818153381348,
      "learning_rate": 1.368222891566265e-06,
      "loss": 0.3364,
      "step": 4826
    },
    {
      "epoch": 2.907831325301205,
      "grad_norm": 0.5802550911903381,
      "learning_rate": 1.3674698795180724e-06,
      "loss": 0.2562,
      "step": 4827
    },
    {
      "epoch": 2.908433734939759,
      "grad_norm": 0.5929319262504578,
      "learning_rate": 1.3667168674698797e-06,
      "loss": 0.2683,
      "step": 4828
    },
    {
      "epoch": 2.9090361445783133,
      "grad_norm": 1.5551764965057373,
      "learning_rate": 1.3659638554216869e-06,
      "loss": 0.2369,
      "step": 4829
    },
    {
      "epoch": 2.9096385542168672,
      "grad_norm": 0.5965036749839783,
      "learning_rate": 1.365210843373494e-06,
      "loss": 0.2253,
      "step": 4830
    },
    {
      "epoch": 2.9102409638554216,
      "grad_norm": 0.6046726107597351,
      "learning_rate": 1.3644578313253011e-06,
      "loss": 0.276,
      "step": 4831
    },
    {
      "epoch": 2.910843373493976,
      "grad_norm": 0.5844764113426208,
      "learning_rate": 1.3637048192771085e-06,
      "loss": 0.2074,
      "step": 4832
    },
    {
      "epoch": 2.91144578313253,
      "grad_norm": 0.540414571762085,
      "learning_rate": 1.3629518072289158e-06,
      "loss": 0.2287,
      "step": 4833
    },
    {
      "epoch": 2.9120481927710844,
      "grad_norm": 0.5686106085777283,
      "learning_rate": 1.362198795180723e-06,
      "loss": 0.2295,
      "step": 4834
    },
    {
      "epoch": 2.912650602409639,
      "grad_norm": 0.6352917551994324,
      "learning_rate": 1.3614457831325303e-06,
      "loss": 0.244,
      "step": 4835
    },
    {
      "epoch": 2.9132530120481928,
      "grad_norm": 0.5282195806503296,
      "learning_rate": 1.3606927710843373e-06,
      "loss": 0.2271,
      "step": 4836
    },
    {
      "epoch": 2.9138554216867467,
      "grad_norm": 0.593732476234436,
      "learning_rate": 1.3599397590361446e-06,
      "loss": 0.2366,
      "step": 4837
    },
    {
      "epoch": 2.914457831325301,
      "grad_norm": 0.5794097185134888,
      "learning_rate": 1.359186746987952e-06,
      "loss": 0.2734,
      "step": 4838
    },
    {
      "epoch": 2.9150602409638555,
      "grad_norm": 0.6067430973052979,
      "learning_rate": 1.358433734939759e-06,
      "loss": 0.2677,
      "step": 4839
    },
    {
      "epoch": 2.9156626506024095,
      "grad_norm": 0.6164113283157349,
      "learning_rate": 1.3576807228915664e-06,
      "loss": 0.2705,
      "step": 4840
    },
    {
      "epoch": 2.916265060240964,
      "grad_norm": 0.5530939102172852,
      "learning_rate": 1.3569277108433738e-06,
      "loss": 0.2606,
      "step": 4841
    },
    {
      "epoch": 2.9168674698795183,
      "grad_norm": 0.5789459347724915,
      "learning_rate": 1.3561746987951807e-06,
      "loss": 0.2414,
      "step": 4842
    },
    {
      "epoch": 2.9174698795180722,
      "grad_norm": 0.6227068901062012,
      "learning_rate": 1.355421686746988e-06,
      "loss": 0.2349,
      "step": 4843
    },
    {
      "epoch": 2.9180722891566266,
      "grad_norm": 0.6471777558326721,
      "learning_rate": 1.3546686746987952e-06,
      "loss": 0.2644,
      "step": 4844
    },
    {
      "epoch": 2.9186746987951806,
      "grad_norm": 0.628544807434082,
      "learning_rate": 1.3539156626506025e-06,
      "loss": 0.2669,
      "step": 4845
    },
    {
      "epoch": 2.919277108433735,
      "grad_norm": 0.6012495160102844,
      "learning_rate": 1.3531626506024099e-06,
      "loss": 0.2364,
      "step": 4846
    },
    {
      "epoch": 2.919879518072289,
      "grad_norm": 0.5832234621047974,
      "learning_rate": 1.352409638554217e-06,
      "loss": 0.2427,
      "step": 4847
    },
    {
      "epoch": 2.9204819277108434,
      "grad_norm": 0.7008675932884216,
      "learning_rate": 1.3516566265060242e-06,
      "loss": 0.2562,
      "step": 4848
    },
    {
      "epoch": 2.9210843373493978,
      "grad_norm": 0.6046977639198303,
      "learning_rate": 1.3509036144578313e-06,
      "loss": 0.214,
      "step": 4849
    },
    {
      "epoch": 2.9216867469879517,
      "grad_norm": 0.619307816028595,
      "learning_rate": 1.3501506024096386e-06,
      "loss": 0.2533,
      "step": 4850
    },
    {
      "epoch": 2.922289156626506,
      "grad_norm": 0.5906996130943298,
      "learning_rate": 1.349397590361446e-06,
      "loss": 0.2824,
      "step": 4851
    },
    {
      "epoch": 2.92289156626506,
      "grad_norm": 0.5599767565727234,
      "learning_rate": 1.3486445783132531e-06,
      "loss": 0.2224,
      "step": 4852
    },
    {
      "epoch": 2.9234939759036145,
      "grad_norm": 0.6319376230239868,
      "learning_rate": 1.3478915662650605e-06,
      "loss": 0.2122,
      "step": 4853
    },
    {
      "epoch": 2.9240963855421684,
      "grad_norm": 0.5518833994865417,
      "learning_rate": 1.3471385542168674e-06,
      "loss": 0.1879,
      "step": 4854
    },
    {
      "epoch": 2.924698795180723,
      "grad_norm": 0.6009470820426941,
      "learning_rate": 1.3463855421686748e-06,
      "loss": 0.2449,
      "step": 4855
    },
    {
      "epoch": 2.9253012048192772,
      "grad_norm": 0.6417607665061951,
      "learning_rate": 1.345632530120482e-06,
      "loss": 0.2691,
      "step": 4856
    },
    {
      "epoch": 2.925903614457831,
      "grad_norm": 0.5613283514976501,
      "learning_rate": 1.3448795180722892e-06,
      "loss": 0.1853,
      "step": 4857
    },
    {
      "epoch": 2.9265060240963856,
      "grad_norm": 0.5454849004745483,
      "learning_rate": 1.3441265060240966e-06,
      "loss": 0.2025,
      "step": 4858
    },
    {
      "epoch": 2.92710843373494,
      "grad_norm": 0.683769166469574,
      "learning_rate": 1.3433734939759037e-06,
      "loss": 0.2813,
      "step": 4859
    },
    {
      "epoch": 2.927710843373494,
      "grad_norm": 0.5633506774902344,
      "learning_rate": 1.3426204819277109e-06,
      "loss": 0.2021,
      "step": 4860
    },
    {
      "epoch": 2.928313253012048,
      "grad_norm": 0.5728706121444702,
      "learning_rate": 1.341867469879518e-06,
      "loss": 0.2373,
      "step": 4861
    },
    {
      "epoch": 2.9289156626506023,
      "grad_norm": 0.6174541115760803,
      "learning_rate": 1.3411144578313253e-06,
      "loss": 0.1911,
      "step": 4862
    },
    {
      "epoch": 2.9295180722891567,
      "grad_norm": 0.6397342681884766,
      "learning_rate": 1.3403614457831327e-06,
      "loss": 0.2678,
      "step": 4863
    },
    {
      "epoch": 2.9301204819277107,
      "grad_norm": 0.716921865940094,
      "learning_rate": 1.3396084337349398e-06,
      "loss": 0.27,
      "step": 4864
    },
    {
      "epoch": 2.930722891566265,
      "grad_norm": 0.5352630019187927,
      "learning_rate": 1.3388554216867472e-06,
      "loss": 0.1905,
      "step": 4865
    },
    {
      "epoch": 2.9313253012048195,
      "grad_norm": 0.5781171917915344,
      "learning_rate": 1.338102409638554e-06,
      "loss": 0.2428,
      "step": 4866
    },
    {
      "epoch": 2.9319277108433734,
      "grad_norm": 0.679656982421875,
      "learning_rate": 1.3373493975903615e-06,
      "loss": 0.2637,
      "step": 4867
    },
    {
      "epoch": 2.932530120481928,
      "grad_norm": 0.6709834337234497,
      "learning_rate": 1.3365963855421688e-06,
      "loss": 0.2497,
      "step": 4868
    },
    {
      "epoch": 2.933132530120482,
      "grad_norm": 0.6121527552604675,
      "learning_rate": 1.335843373493976e-06,
      "loss": 0.2497,
      "step": 4869
    },
    {
      "epoch": 2.933734939759036,
      "grad_norm": 0.5232771635055542,
      "learning_rate": 1.3350903614457833e-06,
      "loss": 0.1822,
      "step": 4870
    },
    {
      "epoch": 2.93433734939759,
      "grad_norm": 0.6354292631149292,
      "learning_rate": 1.3343373493975906e-06,
      "loss": 0.1937,
      "step": 4871
    },
    {
      "epoch": 2.9349397590361446,
      "grad_norm": 0.6406040787696838,
      "learning_rate": 1.3335843373493976e-06,
      "loss": 0.2778,
      "step": 4872
    },
    {
      "epoch": 2.935542168674699,
      "grad_norm": 0.6264313459396362,
      "learning_rate": 1.332831325301205e-06,
      "loss": 0.2589,
      "step": 4873
    },
    {
      "epoch": 2.936144578313253,
      "grad_norm": 0.5436741709709167,
      "learning_rate": 1.332078313253012e-06,
      "loss": 0.2352,
      "step": 4874
    },
    {
      "epoch": 2.9367469879518073,
      "grad_norm": 0.6142818331718445,
      "learning_rate": 1.3313253012048194e-06,
      "loss": 0.2212,
      "step": 4875
    },
    {
      "epoch": 2.9373493975903613,
      "grad_norm": 0.5530625581741333,
      "learning_rate": 1.3305722891566267e-06,
      "loss": 0.1971,
      "step": 4876
    },
    {
      "epoch": 2.9379518072289157,
      "grad_norm": 0.5792460441589355,
      "learning_rate": 1.3298192771084339e-06,
      "loss": 0.2362,
      "step": 4877
    },
    {
      "epoch": 2.9385542168674696,
      "grad_norm": 0.5957861542701721,
      "learning_rate": 1.329066265060241e-06,
      "loss": 0.1936,
      "step": 4878
    },
    {
      "epoch": 2.939156626506024,
      "grad_norm": 0.5963243842124939,
      "learning_rate": 1.3283132530120482e-06,
      "loss": 0.2032,
      "step": 4879
    },
    {
      "epoch": 2.9397590361445785,
      "grad_norm": 0.6389296650886536,
      "learning_rate": 1.3275602409638555e-06,
      "loss": 0.315,
      "step": 4880
    },
    {
      "epoch": 2.9403614457831324,
      "grad_norm": 0.6224761009216309,
      "learning_rate": 1.3268072289156628e-06,
      "loss": 0.2903,
      "step": 4881
    },
    {
      "epoch": 2.940963855421687,
      "grad_norm": 0.6490850448608398,
      "learning_rate": 1.32605421686747e-06,
      "loss": 0.2461,
      "step": 4882
    },
    {
      "epoch": 2.941566265060241,
      "grad_norm": 0.6998862028121948,
      "learning_rate": 1.3253012048192773e-06,
      "loss": 0.2417,
      "step": 4883
    },
    {
      "epoch": 2.942168674698795,
      "grad_norm": 0.5426592230796814,
      "learning_rate": 1.3245481927710843e-06,
      "loss": 0.2648,
      "step": 4884
    },
    {
      "epoch": 2.942771084337349,
      "grad_norm": 0.596144437789917,
      "learning_rate": 1.3237951807228916e-06,
      "loss": 0.2033,
      "step": 4885
    },
    {
      "epoch": 2.9433734939759035,
      "grad_norm": 0.5735474824905396,
      "learning_rate": 1.323042168674699e-06,
      "loss": 0.181,
      "step": 4886
    },
    {
      "epoch": 2.943975903614458,
      "grad_norm": 0.6527611613273621,
      "learning_rate": 1.322289156626506e-06,
      "loss": 0.2893,
      "step": 4887
    },
    {
      "epoch": 2.944578313253012,
      "grad_norm": 0.7593522071838379,
      "learning_rate": 1.3215361445783134e-06,
      "loss": 0.2356,
      "step": 4888
    },
    {
      "epoch": 2.9451807228915663,
      "grad_norm": 0.6503915786743164,
      "learning_rate": 1.3207831325301208e-06,
      "loss": 0.1991,
      "step": 4889
    },
    {
      "epoch": 2.9457831325301207,
      "grad_norm": 0.602847695350647,
      "learning_rate": 1.3200301204819277e-06,
      "loss": 0.2277,
      "step": 4890
    },
    {
      "epoch": 2.9463855421686747,
      "grad_norm": 0.8824388384819031,
      "learning_rate": 1.319277108433735e-06,
      "loss": 0.2737,
      "step": 4891
    },
    {
      "epoch": 2.946987951807229,
      "grad_norm": 0.6466855406761169,
      "learning_rate": 1.3185240963855422e-06,
      "loss": 0.2517,
      "step": 4892
    },
    {
      "epoch": 2.947590361445783,
      "grad_norm": 0.6025578379631042,
      "learning_rate": 1.3177710843373495e-06,
      "loss": 0.1954,
      "step": 4893
    },
    {
      "epoch": 2.9481927710843374,
      "grad_norm": 0.5563565492630005,
      "learning_rate": 1.317018072289157e-06,
      "loss": 0.2028,
      "step": 4894
    },
    {
      "epoch": 2.9487951807228914,
      "grad_norm": 0.6516399383544922,
      "learning_rate": 1.316265060240964e-06,
      "loss": 0.2815,
      "step": 4895
    },
    {
      "epoch": 2.9493975903614458,
      "grad_norm": 0.4811806082725525,
      "learning_rate": 1.315512048192771e-06,
      "loss": 0.1766,
      "step": 4896
    },
    {
      "epoch": 2.95,
      "grad_norm": 0.545639157295227,
      "learning_rate": 1.3147590361445783e-06,
      "loss": 0.224,
      "step": 4897
    },
    {
      "epoch": 2.950602409638554,
      "grad_norm": 0.627121090888977,
      "learning_rate": 1.3140060240963857e-06,
      "loss": 0.2838,
      "step": 4898
    },
    {
      "epoch": 2.9512048192771085,
      "grad_norm": 0.602104902267456,
      "learning_rate": 1.3132530120481928e-06,
      "loss": 0.2642,
      "step": 4899
    },
    {
      "epoch": 2.9518072289156625,
      "grad_norm": 0.7399469614028931,
      "learning_rate": 1.3125000000000001e-06,
      "loss": 0.2934,
      "step": 4900
    },
    {
      "epoch": 2.952409638554217,
      "grad_norm": 0.6857088208198547,
      "learning_rate": 1.3117469879518075e-06,
      "loss": 0.2663,
      "step": 4901
    },
    {
      "epoch": 2.953012048192771,
      "grad_norm": 0.7314457297325134,
      "learning_rate": 1.3109939759036144e-06,
      "loss": 0.2981,
      "step": 4902
    },
    {
      "epoch": 2.9536144578313253,
      "grad_norm": 0.6684088110923767,
      "learning_rate": 1.3102409638554218e-06,
      "loss": 0.2003,
      "step": 4903
    },
    {
      "epoch": 2.9542168674698797,
      "grad_norm": 0.6632817983627319,
      "learning_rate": 1.309487951807229e-06,
      "loss": 0.2503,
      "step": 4904
    },
    {
      "epoch": 2.9548192771084336,
      "grad_norm": 0.6689189076423645,
      "learning_rate": 1.3087349397590362e-06,
      "loss": 0.2578,
      "step": 4905
    },
    {
      "epoch": 2.955421686746988,
      "grad_norm": 0.614353358745575,
      "learning_rate": 1.3079819277108436e-06,
      "loss": 0.2704,
      "step": 4906
    },
    {
      "epoch": 2.9560240963855424,
      "grad_norm": 0.5306063890457153,
      "learning_rate": 1.3072289156626507e-06,
      "loss": 0.214,
      "step": 4907
    },
    {
      "epoch": 2.9566265060240964,
      "grad_norm": 0.7493179440498352,
      "learning_rate": 1.3064759036144579e-06,
      "loss": 0.2668,
      "step": 4908
    },
    {
      "epoch": 2.9572289156626503,
      "grad_norm": 0.6200408339500427,
      "learning_rate": 1.305722891566265e-06,
      "loss": 0.2707,
      "step": 4909
    },
    {
      "epoch": 2.9578313253012047,
      "grad_norm": 0.5427231788635254,
      "learning_rate": 1.3049698795180724e-06,
      "loss": 0.2337,
      "step": 4910
    },
    {
      "epoch": 2.958433734939759,
      "grad_norm": 0.6178680658340454,
      "learning_rate": 1.3042168674698797e-06,
      "loss": 0.2664,
      "step": 4911
    },
    {
      "epoch": 2.959036144578313,
      "grad_norm": 0.6644139289855957,
      "learning_rate": 1.3034638554216868e-06,
      "loss": 0.2458,
      "step": 4912
    },
    {
      "epoch": 2.9596385542168675,
      "grad_norm": 0.5720956921577454,
      "learning_rate": 1.3027108433734942e-06,
      "loss": 0.2092,
      "step": 4913
    },
    {
      "epoch": 2.960240963855422,
      "grad_norm": 0.5994450449943542,
      "learning_rate": 1.3019578313253011e-06,
      "loss": 0.2067,
      "step": 4914
    },
    {
      "epoch": 2.960843373493976,
      "grad_norm": 0.6013241410255432,
      "learning_rate": 1.3012048192771085e-06,
      "loss": 0.241,
      "step": 4915
    },
    {
      "epoch": 2.9614457831325303,
      "grad_norm": 0.5963831543922424,
      "learning_rate": 1.3004518072289158e-06,
      "loss": 0.2461,
      "step": 4916
    },
    {
      "epoch": 2.962048192771084,
      "grad_norm": 0.5913958549499512,
      "learning_rate": 1.299698795180723e-06,
      "loss": 0.2436,
      "step": 4917
    },
    {
      "epoch": 2.9626506024096386,
      "grad_norm": 0.6024211645126343,
      "learning_rate": 1.2989457831325303e-06,
      "loss": 0.2596,
      "step": 4918
    },
    {
      "epoch": 2.9632530120481926,
      "grad_norm": 0.5731518268585205,
      "learning_rate": 1.2981927710843376e-06,
      "loss": 0.2335,
      "step": 4919
    },
    {
      "epoch": 2.963855421686747,
      "grad_norm": 0.6271291375160217,
      "learning_rate": 1.2974397590361446e-06,
      "loss": 0.2599,
      "step": 4920
    },
    {
      "epoch": 2.9644578313253014,
      "grad_norm": 0.6367258429527283,
      "learning_rate": 1.296686746987952e-06,
      "loss": 0.2191,
      "step": 4921
    },
    {
      "epoch": 2.9650602409638553,
      "grad_norm": 0.745089054107666,
      "learning_rate": 1.295933734939759e-06,
      "loss": 0.272,
      "step": 4922
    },
    {
      "epoch": 2.9656626506024097,
      "grad_norm": 0.6108855605125427,
      "learning_rate": 1.2951807228915664e-06,
      "loss": 0.238,
      "step": 4923
    },
    {
      "epoch": 2.9662650602409637,
      "grad_norm": 0.9155471324920654,
      "learning_rate": 1.2944277108433737e-06,
      "loss": 0.3235,
      "step": 4924
    },
    {
      "epoch": 2.966867469879518,
      "grad_norm": 0.659448504447937,
      "learning_rate": 1.2936746987951809e-06,
      "loss": 0.2863,
      "step": 4925
    },
    {
      "epoch": 2.967469879518072,
      "grad_norm": 0.5808709263801575,
      "learning_rate": 1.292921686746988e-06,
      "loss": 0.2548,
      "step": 4926
    },
    {
      "epoch": 2.9680722891566265,
      "grad_norm": 0.7155962586402893,
      "learning_rate": 1.2921686746987952e-06,
      "loss": 0.245,
      "step": 4927
    },
    {
      "epoch": 2.968674698795181,
      "grad_norm": 0.6500198841094971,
      "learning_rate": 1.2914156626506025e-06,
      "loss": 0.3227,
      "step": 4928
    },
    {
      "epoch": 2.969277108433735,
      "grad_norm": 0.7063173651695251,
      "learning_rate": 1.2906626506024099e-06,
      "loss": 0.3303,
      "step": 4929
    },
    {
      "epoch": 2.9698795180722892,
      "grad_norm": 0.579744279384613,
      "learning_rate": 1.289909638554217e-06,
      "loss": 0.2278,
      "step": 4930
    },
    {
      "epoch": 2.9704819277108436,
      "grad_norm": 0.5872757434844971,
      "learning_rate": 1.2891566265060243e-06,
      "loss": 0.2329,
      "step": 4931
    },
    {
      "epoch": 2.9710843373493976,
      "grad_norm": 0.5933862328529358,
      "learning_rate": 1.2884036144578313e-06,
      "loss": 0.2568,
      "step": 4932
    },
    {
      "epoch": 2.9716867469879515,
      "grad_norm": 0.6231021881103516,
      "learning_rate": 1.2876506024096386e-06,
      "loss": 0.2854,
      "step": 4933
    },
    {
      "epoch": 2.972289156626506,
      "grad_norm": 0.6041174530982971,
      "learning_rate": 1.2868975903614457e-06,
      "loss": 0.2036,
      "step": 4934
    },
    {
      "epoch": 2.9728915662650603,
      "grad_norm": 0.6270573139190674,
      "learning_rate": 1.286144578313253e-06,
      "loss": 0.1845,
      "step": 4935
    },
    {
      "epoch": 2.9734939759036143,
      "grad_norm": 0.7149269580841064,
      "learning_rate": 1.2853915662650604e-06,
      "loss": 0.2871,
      "step": 4936
    },
    {
      "epoch": 2.9740963855421687,
      "grad_norm": 0.5701087713241577,
      "learning_rate": 1.2846385542168676e-06,
      "loss": 0.2512,
      "step": 4937
    },
    {
      "epoch": 2.974698795180723,
      "grad_norm": 0.668405294418335,
      "learning_rate": 1.2838855421686747e-06,
      "loss": 0.2667,
      "step": 4938
    },
    {
      "epoch": 2.975301204819277,
      "grad_norm": 0.6176686882972717,
      "learning_rate": 1.2831325301204819e-06,
      "loss": 0.2465,
      "step": 4939
    },
    {
      "epoch": 2.9759036144578315,
      "grad_norm": 0.6224400401115417,
      "learning_rate": 1.2823795180722892e-06,
      "loss": 0.2117,
      "step": 4940
    },
    {
      "epoch": 2.9765060240963854,
      "grad_norm": 0.6618009209632874,
      "learning_rate": 1.2816265060240966e-06,
      "loss": 0.2315,
      "step": 4941
    },
    {
      "epoch": 2.97710843373494,
      "grad_norm": 0.5794188380241394,
      "learning_rate": 1.2808734939759037e-06,
      "loss": 0.2291,
      "step": 4942
    },
    {
      "epoch": 2.977710843373494,
      "grad_norm": 0.6514433026313782,
      "learning_rate": 1.280120481927711e-06,
      "loss": 0.2878,
      "step": 4943
    },
    {
      "epoch": 2.978313253012048,
      "grad_norm": 0.5479929447174072,
      "learning_rate": 1.279367469879518e-06,
      "loss": 0.2307,
      "step": 4944
    },
    {
      "epoch": 2.9789156626506026,
      "grad_norm": 0.658103346824646,
      "learning_rate": 1.2786144578313253e-06,
      "loss": 0.2492,
      "step": 4945
    },
    {
      "epoch": 2.9795180722891565,
      "grad_norm": 0.5336573123931885,
      "learning_rate": 1.2778614457831327e-06,
      "loss": 0.2711,
      "step": 4946
    },
    {
      "epoch": 2.980120481927711,
      "grad_norm": 0.7323068380355835,
      "learning_rate": 1.2771084337349398e-06,
      "loss": 0.2858,
      "step": 4947
    },
    {
      "epoch": 2.980722891566265,
      "grad_norm": 0.6058430671691895,
      "learning_rate": 1.2763554216867471e-06,
      "loss": 0.2992,
      "step": 4948
    },
    {
      "epoch": 2.9813253012048193,
      "grad_norm": 0.6051003932952881,
      "learning_rate": 1.2756024096385545e-06,
      "loss": 0.2192,
      "step": 4949
    },
    {
      "epoch": 2.9819277108433733,
      "grad_norm": 0.5837526321411133,
      "learning_rate": 1.2748493975903614e-06,
      "loss": 0.3089,
      "step": 4950
    },
    {
      "epoch": 2.9825301204819277,
      "grad_norm": 0.5788500308990479,
      "learning_rate": 1.2740963855421688e-06,
      "loss": 0.2661,
      "step": 4951
    },
    {
      "epoch": 2.983132530120482,
      "grad_norm": 0.5569809675216675,
      "learning_rate": 1.273343373493976e-06,
      "loss": 0.2057,
      "step": 4952
    },
    {
      "epoch": 2.983734939759036,
      "grad_norm": 0.5844735503196716,
      "learning_rate": 1.2725903614457833e-06,
      "loss": 0.2051,
      "step": 4953
    },
    {
      "epoch": 2.9843373493975904,
      "grad_norm": 0.65166175365448,
      "learning_rate": 1.2718373493975906e-06,
      "loss": 0.2749,
      "step": 4954
    },
    {
      "epoch": 2.984939759036145,
      "grad_norm": 0.6437130570411682,
      "learning_rate": 1.2710843373493977e-06,
      "loss": 0.2725,
      "step": 4955
    },
    {
      "epoch": 2.985542168674699,
      "grad_norm": 0.747538149356842,
      "learning_rate": 1.2703313253012049e-06,
      "loss": 0.3252,
      "step": 4956
    },
    {
      "epoch": 2.9861445783132528,
      "grad_norm": 0.6295781135559082,
      "learning_rate": 1.269578313253012e-06,
      "loss": 0.2983,
      "step": 4957
    },
    {
      "epoch": 2.986746987951807,
      "grad_norm": 0.7887668013572693,
      "learning_rate": 1.2688253012048194e-06,
      "loss": 0.3276,
      "step": 4958
    },
    {
      "epoch": 2.9873493975903616,
      "grad_norm": 0.589730978012085,
      "learning_rate": 1.2680722891566267e-06,
      "loss": 0.2724,
      "step": 4959
    },
    {
      "epoch": 2.9879518072289155,
      "grad_norm": 0.5224625468254089,
      "learning_rate": 1.2673192771084338e-06,
      "loss": 0.2351,
      "step": 4960
    },
    {
      "epoch": 2.98855421686747,
      "grad_norm": 0.6919628381729126,
      "learning_rate": 1.2665662650602412e-06,
      "loss": 0.2857,
      "step": 4961
    },
    {
      "epoch": 2.9891566265060243,
      "grad_norm": 0.6413465738296509,
      "learning_rate": 1.2658132530120481e-06,
      "loss": 0.2057,
      "step": 4962
    },
    {
      "epoch": 2.9897590361445783,
      "grad_norm": 0.7139220237731934,
      "learning_rate": 1.2650602409638555e-06,
      "loss": 0.3297,
      "step": 4963
    },
    {
      "epoch": 2.9903614457831327,
      "grad_norm": 0.5832318067550659,
      "learning_rate": 1.2643072289156628e-06,
      "loss": 0.2356,
      "step": 4964
    },
    {
      "epoch": 2.9909638554216866,
      "grad_norm": 0.6687843203544617,
      "learning_rate": 1.26355421686747e-06,
      "loss": 0.2861,
      "step": 4965
    },
    {
      "epoch": 2.991566265060241,
      "grad_norm": 0.5898920297622681,
      "learning_rate": 1.2628012048192773e-06,
      "loss": 0.2699,
      "step": 4966
    },
    {
      "epoch": 2.992168674698795,
      "grad_norm": 0.6310703158378601,
      "learning_rate": 1.2620481927710844e-06,
      "loss": 0.2641,
      "step": 4967
    },
    {
      "epoch": 2.9927710843373494,
      "grad_norm": 0.6136808395385742,
      "learning_rate": 1.2612951807228916e-06,
      "loss": 0.2447,
      "step": 4968
    },
    {
      "epoch": 2.993373493975904,
      "grad_norm": 0.6627180576324463,
      "learning_rate": 1.2605421686746987e-06,
      "loss": 0.2481,
      "step": 4969
    },
    {
      "epoch": 2.9939759036144578,
      "grad_norm": 0.5994783639907837,
      "learning_rate": 1.259789156626506e-06,
      "loss": 0.2692,
      "step": 4970
    },
    {
      "epoch": 2.994578313253012,
      "grad_norm": 0.6095844507217407,
      "learning_rate": 1.2590361445783134e-06,
      "loss": 0.2009,
      "step": 4971
    },
    {
      "epoch": 2.995180722891566,
      "grad_norm": 0.6743597984313965,
      "learning_rate": 1.2582831325301205e-06,
      "loss": 0.2579,
      "step": 4972
    },
    {
      "epoch": 2.9957831325301205,
      "grad_norm": 0.6745828986167908,
      "learning_rate": 1.2575301204819279e-06,
      "loss": 0.267,
      "step": 4973
    },
    {
      "epoch": 2.9963855421686745,
      "grad_norm": 0.5368560552597046,
      "learning_rate": 1.2567771084337348e-06,
      "loss": 0.2258,
      "step": 4974
    },
    {
      "epoch": 2.996987951807229,
      "grad_norm": 0.6464745402336121,
      "learning_rate": 1.2560240963855422e-06,
      "loss": 0.3201,
      "step": 4975
    },
    {
      "epoch": 2.9975903614457833,
      "grad_norm": 0.6782286167144775,
      "learning_rate": 1.2552710843373495e-06,
      "loss": 0.2633,
      "step": 4976
    },
    {
      "epoch": 2.9981927710843372,
      "grad_norm": 0.5495943427085876,
      "learning_rate": 1.2545180722891566e-06,
      "loss": 0.1951,
      "step": 4977
    },
    {
      "epoch": 2.9987951807228916,
      "grad_norm": 0.5913993716239929,
      "learning_rate": 1.253765060240964e-06,
      "loss": 0.2417,
      "step": 4978
    },
    {
      "epoch": 2.999397590361446,
      "grad_norm": 0.5936346650123596,
      "learning_rate": 1.2530120481927713e-06,
      "loss": 0.2176,
      "step": 4979
    },
    {
      "epoch": 3.0,
      "grad_norm": 0.6561074256896973,
      "learning_rate": 1.2522590361445783e-06,
      "loss": 0.3041,
      "step": 4980
    },
    {
      "epoch": 3.0006024096385544,
      "grad_norm": 0.8487846851348877,
      "learning_rate": 1.2515060240963856e-06,
      "loss": 0.158,
      "step": 4981
    },
    {
      "epoch": 3.0012048192771084,
      "grad_norm": 0.7344579100608826,
      "learning_rate": 1.2507530120481928e-06,
      "loss": 0.1668,
      "step": 4982
    },
    {
      "epoch": 3.0018072289156628,
      "grad_norm": 0.7295433878898621,
      "learning_rate": 1.25e-06,
      "loss": 0.1609,
      "step": 4983
    },
    {
      "epoch": 3.0024096385542167,
      "grad_norm": 0.7999886870384216,
      "learning_rate": 1.2492469879518075e-06,
      "loss": 0.1995,
      "step": 4984
    },
    {
      "epoch": 3.003012048192771,
      "grad_norm": 0.8567662835121155,
      "learning_rate": 1.2484939759036146e-06,
      "loss": 0.1889,
      "step": 4985
    },
    {
      "epoch": 3.003614457831325,
      "grad_norm": 0.9518760442733765,
      "learning_rate": 1.2477409638554217e-06,
      "loss": 0.1824,
      "step": 4986
    },
    {
      "epoch": 3.0042168674698795,
      "grad_norm": 0.7410907745361328,
      "learning_rate": 1.246987951807229e-06,
      "loss": 0.1985,
      "step": 4987
    },
    {
      "epoch": 3.004819277108434,
      "grad_norm": 0.7263430953025818,
      "learning_rate": 1.2462349397590362e-06,
      "loss": 0.2092,
      "step": 4988
    },
    {
      "epoch": 3.005421686746988,
      "grad_norm": 0.7293878197669983,
      "learning_rate": 1.2454819277108436e-06,
      "loss": 0.2257,
      "step": 4989
    },
    {
      "epoch": 3.0060240963855422,
      "grad_norm": 0.6392402052879333,
      "learning_rate": 1.2447289156626507e-06,
      "loss": 0.1492,
      "step": 4990
    },
    {
      "epoch": 3.006626506024096,
      "grad_norm": 0.7292010188102722,
      "learning_rate": 1.2439759036144578e-06,
      "loss": 0.1818,
      "step": 4991
    },
    {
      "epoch": 3.0072289156626506,
      "grad_norm": 0.6267089247703552,
      "learning_rate": 1.2432228915662652e-06,
      "loss": 0.1979,
      "step": 4992
    },
    {
      "epoch": 3.007831325301205,
      "grad_norm": 0.679283082485199,
      "learning_rate": 1.2424698795180725e-06,
      "loss": 0.2106,
      "step": 4993
    },
    {
      "epoch": 3.008433734939759,
      "grad_norm": 0.7656932473182678,
      "learning_rate": 1.2417168674698797e-06,
      "loss": 0.143,
      "step": 4994
    },
    {
      "epoch": 3.0090361445783134,
      "grad_norm": 0.7451380491256714,
      "learning_rate": 1.2409638554216868e-06,
      "loss": 0.2065,
      "step": 4995
    },
    {
      "epoch": 3.0096385542168673,
      "grad_norm": 0.6330296397209167,
      "learning_rate": 1.2402108433734941e-06,
      "loss": 0.1428,
      "step": 4996
    },
    {
      "epoch": 3.0102409638554217,
      "grad_norm": 0.7184004187583923,
      "learning_rate": 1.2394578313253013e-06,
      "loss": 0.1834,
      "step": 4997
    },
    {
      "epoch": 3.0108433734939757,
      "grad_norm": 0.8535894155502319,
      "learning_rate": 1.2387048192771086e-06,
      "loss": 0.2037,
      "step": 4998
    },
    {
      "epoch": 3.01144578313253,
      "grad_norm": 0.6909769773483276,
      "learning_rate": 1.2379518072289158e-06,
      "loss": 0.2049,
      "step": 4999
    },
    {
      "epoch": 3.0120481927710845,
      "grad_norm": 0.5839298963546753,
      "learning_rate": 1.237198795180723e-06,
      "loss": 0.1657,
      "step": 5000
    },
    {
      "epoch": 3.0126506024096384,
      "grad_norm": 0.7576466798782349,
      "learning_rate": 1.2364457831325303e-06,
      "loss": 0.1702,
      "step": 5001
    },
    {
      "epoch": 3.013253012048193,
      "grad_norm": 0.7332337498664856,
      "learning_rate": 1.2356927710843374e-06,
      "loss": 0.1754,
      "step": 5002
    },
    {
      "epoch": 3.013855421686747,
      "grad_norm": 0.7877196669578552,
      "learning_rate": 1.2349397590361445e-06,
      "loss": 0.2137,
      "step": 5003
    },
    {
      "epoch": 3.014457831325301,
      "grad_norm": 0.7098110914230347,
      "learning_rate": 1.2341867469879519e-06,
      "loss": 0.1639,
      "step": 5004
    },
    {
      "epoch": 3.0150602409638556,
      "grad_norm": 0.6675961017608643,
      "learning_rate": 1.2334337349397592e-06,
      "loss": 0.1871,
      "step": 5005
    },
    {
      "epoch": 3.0156626506024096,
      "grad_norm": 0.6793242692947388,
      "learning_rate": 1.2326807228915664e-06,
      "loss": 0.1866,
      "step": 5006
    },
    {
      "epoch": 3.016265060240964,
      "grad_norm": 0.596156895160675,
      "learning_rate": 1.2319277108433735e-06,
      "loss": 0.2348,
      "step": 5007
    },
    {
      "epoch": 3.016867469879518,
      "grad_norm": 0.7199549078941345,
      "learning_rate": 1.2311746987951808e-06,
      "loss": 0.1421,
      "step": 5008
    },
    {
      "epoch": 3.0174698795180723,
      "grad_norm": 0.6359248161315918,
      "learning_rate": 1.230421686746988e-06,
      "loss": 0.1594,
      "step": 5009
    },
    {
      "epoch": 3.0180722891566263,
      "grad_norm": 0.6385653614997864,
      "learning_rate": 1.2296686746987953e-06,
      "loss": 0.1502,
      "step": 5010
    },
    {
      "epoch": 3.0186746987951807,
      "grad_norm": 0.6974989175796509,
      "learning_rate": 1.2289156626506025e-06,
      "loss": 0.1444,
      "step": 5011
    },
    {
      "epoch": 3.019277108433735,
      "grad_norm": 0.6179484128952026,
      "learning_rate": 1.2281626506024096e-06,
      "loss": 0.155,
      "step": 5012
    },
    {
      "epoch": 3.019879518072289,
      "grad_norm": 0.6236611604690552,
      "learning_rate": 1.227409638554217e-06,
      "loss": 0.1767,
      "step": 5013
    },
    {
      "epoch": 3.0204819277108435,
      "grad_norm": 0.6678981781005859,
      "learning_rate": 1.2266566265060243e-06,
      "loss": 0.1849,
      "step": 5014
    },
    {
      "epoch": 3.0210843373493974,
      "grad_norm": 0.6182441711425781,
      "learning_rate": 1.2259036144578314e-06,
      "loss": 0.1609,
      "step": 5015
    },
    {
      "epoch": 3.021686746987952,
      "grad_norm": 0.6831615567207336,
      "learning_rate": 1.2251506024096386e-06,
      "loss": 0.1811,
      "step": 5016
    },
    {
      "epoch": 3.022289156626506,
      "grad_norm": 0.5718511939048767,
      "learning_rate": 1.224397590361446e-06,
      "loss": 0.181,
      "step": 5017
    },
    {
      "epoch": 3.02289156626506,
      "grad_norm": 0.620753824710846,
      "learning_rate": 1.223644578313253e-06,
      "loss": 0.2339,
      "step": 5018
    },
    {
      "epoch": 3.0234939759036146,
      "grad_norm": 0.567703127861023,
      "learning_rate": 1.2228915662650604e-06,
      "loss": 0.1836,
      "step": 5019
    },
    {
      "epoch": 3.0240963855421685,
      "grad_norm": 0.6558853387832642,
      "learning_rate": 1.2221385542168675e-06,
      "loss": 0.1416,
      "step": 5020
    },
    {
      "epoch": 3.024698795180723,
      "grad_norm": 0.6074650287628174,
      "learning_rate": 1.2213855421686747e-06,
      "loss": 0.1464,
      "step": 5021
    },
    {
      "epoch": 3.025301204819277,
      "grad_norm": 0.617461085319519,
      "learning_rate": 1.220632530120482e-06,
      "loss": 0.1662,
      "step": 5022
    },
    {
      "epoch": 3.0259036144578313,
      "grad_norm": 0.6352258324623108,
      "learning_rate": 1.2198795180722894e-06,
      "loss": 0.1428,
      "step": 5023
    },
    {
      "epoch": 3.0265060240963857,
      "grad_norm": 0.6188309192657471,
      "learning_rate": 1.2191265060240965e-06,
      "loss": 0.2255,
      "step": 5024
    },
    {
      "epoch": 3.0271084337349397,
      "grad_norm": 0.5871508121490479,
      "learning_rate": 1.2183734939759037e-06,
      "loss": 0.1843,
      "step": 5025
    },
    {
      "epoch": 3.027710843373494,
      "grad_norm": 6.302362442016602,
      "learning_rate": 1.217620481927711e-06,
      "loss": 0.2244,
      "step": 5026
    },
    {
      "epoch": 3.028313253012048,
      "grad_norm": 0.6916805505752563,
      "learning_rate": 1.2168674698795181e-06,
      "loss": 0.1427,
      "step": 5027
    },
    {
      "epoch": 3.0289156626506024,
      "grad_norm": 0.649472713470459,
      "learning_rate": 1.2161144578313255e-06,
      "loss": 0.1533,
      "step": 5028
    },
    {
      "epoch": 3.029518072289157,
      "grad_norm": 0.5973587036132812,
      "learning_rate": 1.2153614457831326e-06,
      "loss": 0.1621,
      "step": 5029
    },
    {
      "epoch": 3.0301204819277108,
      "grad_norm": 0.6605536341667175,
      "learning_rate": 1.2146084337349398e-06,
      "loss": 0.1693,
      "step": 5030
    },
    {
      "epoch": 3.030722891566265,
      "grad_norm": 0.5945831537246704,
      "learning_rate": 1.2138554216867471e-06,
      "loss": 0.1631,
      "step": 5031
    },
    {
      "epoch": 3.031325301204819,
      "grad_norm": 0.6011744141578674,
      "learning_rate": 1.2131024096385545e-06,
      "loss": 0.1632,
      "step": 5032
    },
    {
      "epoch": 3.0319277108433735,
      "grad_norm": 0.61741703748703,
      "learning_rate": 1.2123493975903616e-06,
      "loss": 0.1814,
      "step": 5033
    },
    {
      "epoch": 3.0325301204819275,
      "grad_norm": 0.6657369136810303,
      "learning_rate": 1.2115963855421687e-06,
      "loss": 0.1989,
      "step": 5034
    },
    {
      "epoch": 3.033132530120482,
      "grad_norm": 0.5229901671409607,
      "learning_rate": 1.210843373493976e-06,
      "loss": 0.1427,
      "step": 5035
    },
    {
      "epoch": 3.0337349397590363,
      "grad_norm": 0.5688685178756714,
      "learning_rate": 1.2100903614457832e-06,
      "loss": 0.2057,
      "step": 5036
    },
    {
      "epoch": 3.0343373493975903,
      "grad_norm": 0.5652226805686951,
      "learning_rate": 1.2093373493975904e-06,
      "loss": 0.1391,
      "step": 5037
    },
    {
      "epoch": 3.0349397590361447,
      "grad_norm": 0.5791670083999634,
      "learning_rate": 1.2085843373493977e-06,
      "loss": 0.1993,
      "step": 5038
    },
    {
      "epoch": 3.0355421686746986,
      "grad_norm": 0.6614599823951721,
      "learning_rate": 1.2078313253012048e-06,
      "loss": 0.1505,
      "step": 5039
    },
    {
      "epoch": 3.036144578313253,
      "grad_norm": 0.6508997678756714,
      "learning_rate": 1.2070783132530122e-06,
      "loss": 0.1691,
      "step": 5040
    },
    {
      "epoch": 3.0367469879518074,
      "grad_norm": 0.5653067231178284,
      "learning_rate": 1.2063253012048193e-06,
      "loss": 0.1663,
      "step": 5041
    },
    {
      "epoch": 3.0373493975903614,
      "grad_norm": 0.5205094218254089,
      "learning_rate": 1.2055722891566265e-06,
      "loss": 0.1629,
      "step": 5042
    },
    {
      "epoch": 3.037951807228916,
      "grad_norm": 0.5061512589454651,
      "learning_rate": 1.2048192771084338e-06,
      "loss": 0.1623,
      "step": 5043
    },
    {
      "epoch": 3.0385542168674697,
      "grad_norm": 0.6176304221153259,
      "learning_rate": 1.2040662650602412e-06,
      "loss": 0.2463,
      "step": 5044
    },
    {
      "epoch": 3.039156626506024,
      "grad_norm": 0.663375198841095,
      "learning_rate": 1.2033132530120483e-06,
      "loss": 0.148,
      "step": 5045
    },
    {
      "epoch": 3.039759036144578,
      "grad_norm": 0.5814908742904663,
      "learning_rate": 1.2025602409638554e-06,
      "loss": 0.1396,
      "step": 5046
    },
    {
      "epoch": 3.0403614457831325,
      "grad_norm": 0.7020396590232849,
      "learning_rate": 1.2018072289156628e-06,
      "loss": 0.1859,
      "step": 5047
    },
    {
      "epoch": 3.040963855421687,
      "grad_norm": 0.6513025760650635,
      "learning_rate": 1.20105421686747e-06,
      "loss": 0.1389,
      "step": 5048
    },
    {
      "epoch": 3.041566265060241,
      "grad_norm": 0.5687108039855957,
      "learning_rate": 1.2003012048192773e-06,
      "loss": 0.1781,
      "step": 5049
    },
    {
      "epoch": 3.0421686746987953,
      "grad_norm": 0.5885584354400635,
      "learning_rate": 1.1995481927710844e-06,
      "loss": 0.1332,
      "step": 5050
    },
    {
      "epoch": 3.042771084337349,
      "grad_norm": 0.6556810736656189,
      "learning_rate": 1.1987951807228915e-06,
      "loss": 0.2236,
      "step": 5051
    },
    {
      "epoch": 3.0433734939759036,
      "grad_norm": 0.5535926222801208,
      "learning_rate": 1.1980421686746989e-06,
      "loss": 0.147,
      "step": 5052
    },
    {
      "epoch": 3.043975903614458,
      "grad_norm": 0.6328010559082031,
      "learning_rate": 1.1972891566265062e-06,
      "loss": 0.1769,
      "step": 5053
    },
    {
      "epoch": 3.044578313253012,
      "grad_norm": 0.5510695576667786,
      "learning_rate": 1.1965361445783134e-06,
      "loss": 0.1795,
      "step": 5054
    },
    {
      "epoch": 3.0451807228915664,
      "grad_norm": 0.5473207831382751,
      "learning_rate": 1.1957831325301205e-06,
      "loss": 0.1893,
      "step": 5055
    },
    {
      "epoch": 3.0457831325301203,
      "grad_norm": 0.5762848258018494,
      "learning_rate": 1.1950301204819279e-06,
      "loss": 0.167,
      "step": 5056
    },
    {
      "epoch": 3.0463855421686747,
      "grad_norm": 0.6604876518249512,
      "learning_rate": 1.194277108433735e-06,
      "loss": 0.187,
      "step": 5057
    },
    {
      "epoch": 3.0469879518072287,
      "grad_norm": 0.8808084726333618,
      "learning_rate": 1.1935240963855423e-06,
      "loss": 0.1723,
      "step": 5058
    },
    {
      "epoch": 3.047590361445783,
      "grad_norm": 0.7618047595024109,
      "learning_rate": 1.1927710843373495e-06,
      "loss": 0.1664,
      "step": 5059
    },
    {
      "epoch": 3.0481927710843375,
      "grad_norm": 0.5758323669433594,
      "learning_rate": 1.1920180722891566e-06,
      "loss": 0.1895,
      "step": 5060
    },
    {
      "epoch": 3.0487951807228915,
      "grad_norm": 0.5480756163597107,
      "learning_rate": 1.191265060240964e-06,
      "loss": 0.1516,
      "step": 5061
    },
    {
      "epoch": 3.049397590361446,
      "grad_norm": 0.5054117441177368,
      "learning_rate": 1.1905120481927713e-06,
      "loss": 0.1471,
      "step": 5062
    },
    {
      "epoch": 3.05,
      "grad_norm": 0.5471703410148621,
      "learning_rate": 1.1897590361445784e-06,
      "loss": 0.1461,
      "step": 5063
    },
    {
      "epoch": 3.0506024096385542,
      "grad_norm": 0.6756473183631897,
      "learning_rate": 1.1890060240963856e-06,
      "loss": 0.2053,
      "step": 5064
    },
    {
      "epoch": 3.0512048192771086,
      "grad_norm": 0.5692649483680725,
      "learning_rate": 1.188253012048193e-06,
      "loss": 0.1847,
      "step": 5065
    },
    {
      "epoch": 3.0518072289156626,
      "grad_norm": 0.4887986183166504,
      "learning_rate": 1.1875e-06,
      "loss": 0.1556,
      "step": 5066
    },
    {
      "epoch": 3.052409638554217,
      "grad_norm": 0.5243996977806091,
      "learning_rate": 1.1867469879518074e-06,
      "loss": 0.1875,
      "step": 5067
    },
    {
      "epoch": 3.053012048192771,
      "grad_norm": 0.6462720632553101,
      "learning_rate": 1.1859939759036146e-06,
      "loss": 0.1357,
      "step": 5068
    },
    {
      "epoch": 3.0536144578313253,
      "grad_norm": 0.6138905882835388,
      "learning_rate": 1.1852409638554217e-06,
      "loss": 0.2127,
      "step": 5069
    },
    {
      "epoch": 3.0542168674698793,
      "grad_norm": 0.5761967301368713,
      "learning_rate": 1.184487951807229e-06,
      "loss": 0.145,
      "step": 5070
    },
    {
      "epoch": 3.0548192771084337,
      "grad_norm": 0.5419172644615173,
      "learning_rate": 1.1837349397590362e-06,
      "loss": 0.1518,
      "step": 5071
    },
    {
      "epoch": 3.055421686746988,
      "grad_norm": 0.5609956383705139,
      "learning_rate": 1.1829819277108433e-06,
      "loss": 0.1917,
      "step": 5072
    },
    {
      "epoch": 3.056024096385542,
      "grad_norm": 0.5827242136001587,
      "learning_rate": 1.1822289156626507e-06,
      "loss": 0.1607,
      "step": 5073
    },
    {
      "epoch": 3.0566265060240965,
      "grad_norm": 0.6077198386192322,
      "learning_rate": 1.181475903614458e-06,
      "loss": 0.1987,
      "step": 5074
    },
    {
      "epoch": 3.0572289156626504,
      "grad_norm": 0.5518220663070679,
      "learning_rate": 1.1807228915662651e-06,
      "loss": 0.1609,
      "step": 5075
    },
    {
      "epoch": 3.057831325301205,
      "grad_norm": 0.5145132541656494,
      "learning_rate": 1.1799698795180723e-06,
      "loss": 0.1657,
      "step": 5076
    },
    {
      "epoch": 3.0584337349397592,
      "grad_norm": 0.5263778567314148,
      "learning_rate": 1.1792168674698796e-06,
      "loss": 0.1623,
      "step": 5077
    },
    {
      "epoch": 3.059036144578313,
      "grad_norm": 0.5879799127578735,
      "learning_rate": 1.1784638554216868e-06,
      "loss": 0.1727,
      "step": 5078
    },
    {
      "epoch": 3.0596385542168676,
      "grad_norm": 0.571052074432373,
      "learning_rate": 1.1777108433734941e-06,
      "loss": 0.1701,
      "step": 5079
    },
    {
      "epoch": 3.0602409638554215,
      "grad_norm": 0.5136708617210388,
      "learning_rate": 1.1769578313253012e-06,
      "loss": 0.1609,
      "step": 5080
    },
    {
      "epoch": 3.060843373493976,
      "grad_norm": 0.4698545038700104,
      "learning_rate": 1.1762048192771084e-06,
      "loss": 0.1408,
      "step": 5081
    },
    {
      "epoch": 3.06144578313253,
      "grad_norm": 0.640107274055481,
      "learning_rate": 1.1754518072289157e-06,
      "loss": 0.2008,
      "step": 5082
    },
    {
      "epoch": 3.0620481927710843,
      "grad_norm": 0.5928495526313782,
      "learning_rate": 1.174698795180723e-06,
      "loss": 0.1924,
      "step": 5083
    },
    {
      "epoch": 3.0626506024096387,
      "grad_norm": 0.6231770515441895,
      "learning_rate": 1.1739457831325302e-06,
      "loss": 0.1599,
      "step": 5084
    },
    {
      "epoch": 3.0632530120481927,
      "grad_norm": 0.48918867111206055,
      "learning_rate": 1.1731927710843374e-06,
      "loss": 0.1302,
      "step": 5085
    },
    {
      "epoch": 3.063855421686747,
      "grad_norm": 0.6862396001815796,
      "learning_rate": 1.1724397590361447e-06,
      "loss": 0.197,
      "step": 5086
    },
    {
      "epoch": 3.064457831325301,
      "grad_norm": 0.4856809377670288,
      "learning_rate": 1.1716867469879518e-06,
      "loss": 0.1405,
      "step": 5087
    },
    {
      "epoch": 3.0650602409638554,
      "grad_norm": 0.7557579278945923,
      "learning_rate": 1.1709337349397592e-06,
      "loss": 0.237,
      "step": 5088
    },
    {
      "epoch": 3.06566265060241,
      "grad_norm": 0.6024797558784485,
      "learning_rate": 1.1701807228915663e-06,
      "loss": 0.1494,
      "step": 5089
    },
    {
      "epoch": 3.066265060240964,
      "grad_norm": 0.5668416619300842,
      "learning_rate": 1.1694277108433735e-06,
      "loss": 0.1449,
      "step": 5090
    },
    {
      "epoch": 3.066867469879518,
      "grad_norm": 0.5666597485542297,
      "learning_rate": 1.1686746987951808e-06,
      "loss": 0.1776,
      "step": 5091
    },
    {
      "epoch": 3.067469879518072,
      "grad_norm": 0.5472915768623352,
      "learning_rate": 1.1679216867469882e-06,
      "loss": 0.1666,
      "step": 5092
    },
    {
      "epoch": 3.0680722891566266,
      "grad_norm": 0.5610862970352173,
      "learning_rate": 1.1671686746987953e-06,
      "loss": 0.1744,
      "step": 5093
    },
    {
      "epoch": 3.0686746987951805,
      "grad_norm": 0.5850124359130859,
      "learning_rate": 1.1664156626506024e-06,
      "loss": 0.1448,
      "step": 5094
    },
    {
      "epoch": 3.069277108433735,
      "grad_norm": 0.5159695148468018,
      "learning_rate": 1.1656626506024098e-06,
      "loss": 0.1521,
      "step": 5095
    },
    {
      "epoch": 3.0698795180722893,
      "grad_norm": 0.614563524723053,
      "learning_rate": 1.164909638554217e-06,
      "loss": 0.1551,
      "step": 5096
    },
    {
      "epoch": 3.0704819277108433,
      "grad_norm": 0.5041068196296692,
      "learning_rate": 1.1641566265060243e-06,
      "loss": 0.1393,
      "step": 5097
    },
    {
      "epoch": 3.0710843373493977,
      "grad_norm": 0.75271075963974,
      "learning_rate": 1.1634036144578314e-06,
      "loss": 0.232,
      "step": 5098
    },
    {
      "epoch": 3.0716867469879516,
      "grad_norm": 0.480220228433609,
      "learning_rate": 1.1626506024096385e-06,
      "loss": 0.1584,
      "step": 5099
    },
    {
      "epoch": 3.072289156626506,
      "grad_norm": 0.5281603932380676,
      "learning_rate": 1.1618975903614459e-06,
      "loss": 0.1948,
      "step": 5100
    },
    {
      "epoch": 3.0728915662650604,
      "grad_norm": 0.5724743604660034,
      "learning_rate": 1.1611445783132532e-06,
      "loss": 0.2132,
      "step": 5101
    },
    {
      "epoch": 3.0734939759036144,
      "grad_norm": 0.5887677073478699,
      "learning_rate": 1.1603915662650604e-06,
      "loss": 0.1442,
      "step": 5102
    },
    {
      "epoch": 3.074096385542169,
      "grad_norm": 0.5317990183830261,
      "learning_rate": 1.1596385542168675e-06,
      "loss": 0.1726,
      "step": 5103
    },
    {
      "epoch": 3.0746987951807228,
      "grad_norm": 0.598302960395813,
      "learning_rate": 1.1588855421686749e-06,
      "loss": 0.1312,
      "step": 5104
    },
    {
      "epoch": 3.075301204819277,
      "grad_norm": 0.49177300930023193,
      "learning_rate": 1.158132530120482e-06,
      "loss": 0.1414,
      "step": 5105
    },
    {
      "epoch": 3.075903614457831,
      "grad_norm": 0.5811108350753784,
      "learning_rate": 1.1573795180722893e-06,
      "loss": 0.1889,
      "step": 5106
    },
    {
      "epoch": 3.0765060240963855,
      "grad_norm": 0.6302312612533569,
      "learning_rate": 1.1566265060240965e-06,
      "loss": 0.2126,
      "step": 5107
    },
    {
      "epoch": 3.07710843373494,
      "grad_norm": 0.49717894196510315,
      "learning_rate": 1.1558734939759036e-06,
      "loss": 0.1393,
      "step": 5108
    },
    {
      "epoch": 3.077710843373494,
      "grad_norm": 0.5181097388267517,
      "learning_rate": 1.155120481927711e-06,
      "loss": 0.2073,
      "step": 5109
    },
    {
      "epoch": 3.0783132530120483,
      "grad_norm": 0.6878955364227295,
      "learning_rate": 1.154367469879518e-06,
      "loss": 0.1979,
      "step": 5110
    },
    {
      "epoch": 3.0789156626506022,
      "grad_norm": 0.6710366010665894,
      "learning_rate": 1.1536144578313252e-06,
      "loss": 0.189,
      "step": 5111
    },
    {
      "epoch": 3.0795180722891566,
      "grad_norm": 0.6394988894462585,
      "learning_rate": 1.1528614457831326e-06,
      "loss": 0.185,
      "step": 5112
    },
    {
      "epoch": 3.080120481927711,
      "grad_norm": 0.6126066446304321,
      "learning_rate": 1.15210843373494e-06,
      "loss": 0.1475,
      "step": 5113
    },
    {
      "epoch": 3.080722891566265,
      "grad_norm": 0.5073965787887573,
      "learning_rate": 1.151355421686747e-06,
      "loss": 0.1457,
      "step": 5114
    },
    {
      "epoch": 3.0813253012048194,
      "grad_norm": 0.507497251033783,
      "learning_rate": 1.1506024096385542e-06,
      "loss": 0.1343,
      "step": 5115
    },
    {
      "epoch": 3.0819277108433734,
      "grad_norm": 0.6917203068733215,
      "learning_rate": 1.1498493975903616e-06,
      "loss": 0.2102,
      "step": 5116
    },
    {
      "epoch": 3.0825301204819278,
      "grad_norm": 0.5371774435043335,
      "learning_rate": 1.1490963855421687e-06,
      "loss": 0.1847,
      "step": 5117
    },
    {
      "epoch": 3.0831325301204817,
      "grad_norm": 0.8126659393310547,
      "learning_rate": 1.148343373493976e-06,
      "loss": 0.1538,
      "step": 5118
    },
    {
      "epoch": 3.083734939759036,
      "grad_norm": 0.5383499264717102,
      "learning_rate": 1.1475903614457832e-06,
      "loss": 0.1842,
      "step": 5119
    },
    {
      "epoch": 3.0843373493975905,
      "grad_norm": 0.5278468132019043,
      "learning_rate": 1.1468373493975903e-06,
      "loss": 0.1685,
      "step": 5120
    },
    {
      "epoch": 3.0849397590361445,
      "grad_norm": 0.5082219243049622,
      "learning_rate": 1.1460843373493977e-06,
      "loss": 0.1525,
      "step": 5121
    },
    {
      "epoch": 3.085542168674699,
      "grad_norm": 0.6105872988700867,
      "learning_rate": 1.145331325301205e-06,
      "loss": 0.1673,
      "step": 5122
    },
    {
      "epoch": 3.086144578313253,
      "grad_norm": 0.5416074991226196,
      "learning_rate": 1.1445783132530121e-06,
      "loss": 0.1606,
      "step": 5123
    },
    {
      "epoch": 3.0867469879518072,
      "grad_norm": 0.515709400177002,
      "learning_rate": 1.1438253012048193e-06,
      "loss": 0.1698,
      "step": 5124
    },
    {
      "epoch": 3.0873493975903616,
      "grad_norm": 0.4951046407222748,
      "learning_rate": 1.1430722891566266e-06,
      "loss": 0.1424,
      "step": 5125
    },
    {
      "epoch": 3.0879518072289156,
      "grad_norm": 0.5675585865974426,
      "learning_rate": 1.1423192771084338e-06,
      "loss": 0.1492,
      "step": 5126
    },
    {
      "epoch": 3.08855421686747,
      "grad_norm": 0.6038960218429565,
      "learning_rate": 1.1415662650602411e-06,
      "loss": 0.1795,
      "step": 5127
    },
    {
      "epoch": 3.089156626506024,
      "grad_norm": 0.6137565970420837,
      "learning_rate": 1.1408132530120483e-06,
      "loss": 0.1628,
      "step": 5128
    },
    {
      "epoch": 3.0897590361445784,
      "grad_norm": 0.5401650071144104,
      "learning_rate": 1.1400602409638554e-06,
      "loss": 0.1507,
      "step": 5129
    },
    {
      "epoch": 3.0903614457831323,
      "grad_norm": 0.5490005016326904,
      "learning_rate": 1.1393072289156627e-06,
      "loss": 0.1739,
      "step": 5130
    },
    {
      "epoch": 3.0909638554216867,
      "grad_norm": 0.528466522693634,
      "learning_rate": 1.13855421686747e-06,
      "loss": 0.1739,
      "step": 5131
    },
    {
      "epoch": 3.091566265060241,
      "grad_norm": 0.6428378820419312,
      "learning_rate": 1.1378012048192772e-06,
      "loss": 0.1873,
      "step": 5132
    },
    {
      "epoch": 3.092168674698795,
      "grad_norm": 0.5875986814498901,
      "learning_rate": 1.1370481927710844e-06,
      "loss": 0.1444,
      "step": 5133
    },
    {
      "epoch": 3.0927710843373495,
      "grad_norm": 0.5857048034667969,
      "learning_rate": 1.1362951807228917e-06,
      "loss": 0.159,
      "step": 5134
    },
    {
      "epoch": 3.0933734939759034,
      "grad_norm": 0.6598175764083862,
      "learning_rate": 1.1355421686746988e-06,
      "loss": 0.2261,
      "step": 5135
    },
    {
      "epoch": 3.093975903614458,
      "grad_norm": 0.6416999101638794,
      "learning_rate": 1.1347891566265062e-06,
      "loss": 0.1856,
      "step": 5136
    },
    {
      "epoch": 3.0945783132530122,
      "grad_norm": 0.614881157875061,
      "learning_rate": 1.1340361445783133e-06,
      "loss": 0.1695,
      "step": 5137
    },
    {
      "epoch": 3.095180722891566,
      "grad_norm": 0.5562107563018799,
      "learning_rate": 1.1332831325301205e-06,
      "loss": 0.1468,
      "step": 5138
    },
    {
      "epoch": 3.0957831325301206,
      "grad_norm": 0.6071352958679199,
      "learning_rate": 1.1325301204819278e-06,
      "loss": 0.1718,
      "step": 5139
    },
    {
      "epoch": 3.0963855421686746,
      "grad_norm": 0.5752347111701965,
      "learning_rate": 1.1317771084337352e-06,
      "loss": 0.1608,
      "step": 5140
    },
    {
      "epoch": 3.096987951807229,
      "grad_norm": 0.5018874406814575,
      "learning_rate": 1.1310240963855423e-06,
      "loss": 0.1428,
      "step": 5141
    },
    {
      "epoch": 3.097590361445783,
      "grad_norm": 0.5206802487373352,
      "learning_rate": 1.1302710843373494e-06,
      "loss": 0.1616,
      "step": 5142
    },
    {
      "epoch": 3.0981927710843373,
      "grad_norm": 0.5271408557891846,
      "learning_rate": 1.1295180722891568e-06,
      "loss": 0.1736,
      "step": 5143
    },
    {
      "epoch": 3.0987951807228917,
      "grad_norm": 0.4919545352458954,
      "learning_rate": 1.128765060240964e-06,
      "loss": 0.1491,
      "step": 5144
    },
    {
      "epoch": 3.0993975903614457,
      "grad_norm": 1.5335123538970947,
      "learning_rate": 1.128012048192771e-06,
      "loss": 0.2243,
      "step": 5145
    },
    {
      "epoch": 3.1,
      "grad_norm": 0.6355883479118347,
      "learning_rate": 1.1272590361445784e-06,
      "loss": 0.1641,
      "step": 5146
    },
    {
      "epoch": 3.100602409638554,
      "grad_norm": 0.7482320070266724,
      "learning_rate": 1.1265060240963855e-06,
      "loss": 0.2017,
      "step": 5147
    },
    {
      "epoch": 3.1012048192771084,
      "grad_norm": 0.552139163017273,
      "learning_rate": 1.1257530120481929e-06,
      "loss": 0.142,
      "step": 5148
    },
    {
      "epoch": 3.101807228915663,
      "grad_norm": 0.5287410616874695,
      "learning_rate": 1.125e-06,
      "loss": 0.1689,
      "step": 5149
    },
    {
      "epoch": 3.102409638554217,
      "grad_norm": 0.7674115300178528,
      "learning_rate": 1.1242469879518072e-06,
      "loss": 0.1759,
      "step": 5150
    },
    {
      "epoch": 3.103012048192771,
      "grad_norm": 0.4868782162666321,
      "learning_rate": 1.1234939759036145e-06,
      "loss": 0.1434,
      "step": 5151
    },
    {
      "epoch": 3.103614457831325,
      "grad_norm": 0.45838162302970886,
      "learning_rate": 1.1227409638554219e-06,
      "loss": 0.152,
      "step": 5152
    },
    {
      "epoch": 3.1042168674698796,
      "grad_norm": 0.712585985660553,
      "learning_rate": 1.121987951807229e-06,
      "loss": 0.1683,
      "step": 5153
    },
    {
      "epoch": 3.1048192771084335,
      "grad_norm": 0.5307594537734985,
      "learning_rate": 1.1212349397590361e-06,
      "loss": 0.1732,
      "step": 5154
    },
    {
      "epoch": 3.105421686746988,
      "grad_norm": 0.6138504147529602,
      "learning_rate": 1.1204819277108435e-06,
      "loss": 0.1767,
      "step": 5155
    },
    {
      "epoch": 3.1060240963855423,
      "grad_norm": 0.5034255385398865,
      "learning_rate": 1.1197289156626506e-06,
      "loss": 0.132,
      "step": 5156
    },
    {
      "epoch": 3.1066265060240963,
      "grad_norm": 0.5100631713867188,
      "learning_rate": 1.118975903614458e-06,
      "loss": 0.1416,
      "step": 5157
    },
    {
      "epoch": 3.1072289156626507,
      "grad_norm": 0.5716842412948608,
      "learning_rate": 1.118222891566265e-06,
      "loss": 0.1854,
      "step": 5158
    },
    {
      "epoch": 3.1078313253012047,
      "grad_norm": 0.4623824954032898,
      "learning_rate": 1.1174698795180722e-06,
      "loss": 0.1129,
      "step": 5159
    },
    {
      "epoch": 3.108433734939759,
      "grad_norm": 0.5816751718521118,
      "learning_rate": 1.1167168674698796e-06,
      "loss": 0.152,
      "step": 5160
    },
    {
      "epoch": 3.1090361445783135,
      "grad_norm": 0.5459251999855042,
      "learning_rate": 1.115963855421687e-06,
      "loss": 0.1831,
      "step": 5161
    },
    {
      "epoch": 3.1096385542168674,
      "grad_norm": 0.555082380771637,
      "learning_rate": 1.115210843373494e-06,
      "loss": 0.1376,
      "step": 5162
    },
    {
      "epoch": 3.110240963855422,
      "grad_norm": 0.5052923560142517,
      "learning_rate": 1.1144578313253012e-06,
      "loss": 0.1752,
      "step": 5163
    },
    {
      "epoch": 3.1108433734939758,
      "grad_norm": 0.6074184775352478,
      "learning_rate": 1.1137048192771086e-06,
      "loss": 0.1903,
      "step": 5164
    },
    {
      "epoch": 3.11144578313253,
      "grad_norm": 0.6101623177528381,
      "learning_rate": 1.1129518072289157e-06,
      "loss": 0.1858,
      "step": 5165
    },
    {
      "epoch": 3.112048192771084,
      "grad_norm": 0.5592107772827148,
      "learning_rate": 1.112198795180723e-06,
      "loss": 0.1725,
      "step": 5166
    },
    {
      "epoch": 3.1126506024096385,
      "grad_norm": 0.5200093388557434,
      "learning_rate": 1.1114457831325302e-06,
      "loss": 0.1343,
      "step": 5167
    },
    {
      "epoch": 3.113253012048193,
      "grad_norm": 0.6105448603630066,
      "learning_rate": 1.1106927710843373e-06,
      "loss": 0.1964,
      "step": 5168
    },
    {
      "epoch": 3.113855421686747,
      "grad_norm": 0.628559947013855,
      "learning_rate": 1.1099397590361447e-06,
      "loss": 0.198,
      "step": 5169
    },
    {
      "epoch": 3.1144578313253013,
      "grad_norm": 0.6259599924087524,
      "learning_rate": 1.109186746987952e-06,
      "loss": 0.169,
      "step": 5170
    },
    {
      "epoch": 3.1150602409638553,
      "grad_norm": 0.47415927052497864,
      "learning_rate": 1.1084337349397592e-06,
      "loss": 0.1017,
      "step": 5171
    },
    {
      "epoch": 3.1156626506024097,
      "grad_norm": 0.6334332823753357,
      "learning_rate": 1.1076807228915663e-06,
      "loss": 0.1855,
      "step": 5172
    },
    {
      "epoch": 3.116265060240964,
      "grad_norm": 0.670266330242157,
      "learning_rate": 1.1069277108433736e-06,
      "loss": 0.2015,
      "step": 5173
    },
    {
      "epoch": 3.116867469879518,
      "grad_norm": 0.5622692704200745,
      "learning_rate": 1.1061746987951808e-06,
      "loss": 0.1545,
      "step": 5174
    },
    {
      "epoch": 3.1174698795180724,
      "grad_norm": 0.6272456645965576,
      "learning_rate": 1.1054216867469881e-06,
      "loss": 0.1806,
      "step": 5175
    },
    {
      "epoch": 3.1180722891566264,
      "grad_norm": 0.595524787902832,
      "learning_rate": 1.1046686746987953e-06,
      "loss": 0.1822,
      "step": 5176
    },
    {
      "epoch": 3.1186746987951808,
      "grad_norm": 0.49885985255241394,
      "learning_rate": 1.1039156626506024e-06,
      "loss": 0.1448,
      "step": 5177
    },
    {
      "epoch": 3.1192771084337347,
      "grad_norm": 0.6109277606010437,
      "learning_rate": 1.1031626506024097e-06,
      "loss": 0.2044,
      "step": 5178
    },
    {
      "epoch": 3.119879518072289,
      "grad_norm": 0.5609768033027649,
      "learning_rate": 1.1024096385542169e-06,
      "loss": 0.1654,
      "step": 5179
    },
    {
      "epoch": 3.1204819277108435,
      "grad_norm": 0.5185201168060303,
      "learning_rate": 1.101656626506024e-06,
      "loss": 0.1315,
      "step": 5180
    },
    {
      "epoch": 3.1210843373493975,
      "grad_norm": 0.7771740555763245,
      "learning_rate": 1.1009036144578314e-06,
      "loss": 0.2047,
      "step": 5181
    },
    {
      "epoch": 3.121686746987952,
      "grad_norm": 0.575164794921875,
      "learning_rate": 1.1001506024096387e-06,
      "loss": 0.1581,
      "step": 5182
    },
    {
      "epoch": 3.122289156626506,
      "grad_norm": 0.7689051628112793,
      "learning_rate": 1.0993975903614459e-06,
      "loss": 0.2595,
      "step": 5183
    },
    {
      "epoch": 3.1228915662650603,
      "grad_norm": 0.4502428472042084,
      "learning_rate": 1.098644578313253e-06,
      "loss": 0.13,
      "step": 5184
    },
    {
      "epoch": 3.1234939759036147,
      "grad_norm": 1.5302292108535767,
      "learning_rate": 1.0978915662650603e-06,
      "loss": 0.1771,
      "step": 5185
    },
    {
      "epoch": 3.1240963855421686,
      "grad_norm": 0.4804289937019348,
      "learning_rate": 1.0971385542168675e-06,
      "loss": 0.1492,
      "step": 5186
    },
    {
      "epoch": 3.124698795180723,
      "grad_norm": 0.5807399153709412,
      "learning_rate": 1.0963855421686748e-06,
      "loss": 0.1738,
      "step": 5187
    },
    {
      "epoch": 3.125301204819277,
      "grad_norm": 0.528745710849762,
      "learning_rate": 1.095632530120482e-06,
      "loss": 0.1745,
      "step": 5188
    },
    {
      "epoch": 3.1259036144578314,
      "grad_norm": 0.4897746741771698,
      "learning_rate": 1.094879518072289e-06,
      "loss": 0.1291,
      "step": 5189
    },
    {
      "epoch": 3.1265060240963853,
      "grad_norm": 0.578691303730011,
      "learning_rate": 1.0941265060240964e-06,
      "loss": 0.172,
      "step": 5190
    },
    {
      "epoch": 3.1271084337349397,
      "grad_norm": 0.5173954963684082,
      "learning_rate": 1.0933734939759038e-06,
      "loss": 0.1514,
      "step": 5191
    },
    {
      "epoch": 3.127710843373494,
      "grad_norm": 0.7518668174743652,
      "learning_rate": 1.092620481927711e-06,
      "loss": 0.1958,
      "step": 5192
    },
    {
      "epoch": 3.128313253012048,
      "grad_norm": 0.6110166311264038,
      "learning_rate": 1.091867469879518e-06,
      "loss": 0.1839,
      "step": 5193
    },
    {
      "epoch": 3.1289156626506025,
      "grad_norm": 0.5027637481689453,
      "learning_rate": 1.0911144578313254e-06,
      "loss": 0.1492,
      "step": 5194
    },
    {
      "epoch": 3.1295180722891565,
      "grad_norm": 0.5126481652259827,
      "learning_rate": 1.0903614457831328e-06,
      "loss": 0.1432,
      "step": 5195
    },
    {
      "epoch": 3.130120481927711,
      "grad_norm": 0.5106405019760132,
      "learning_rate": 1.08960843373494e-06,
      "loss": 0.1579,
      "step": 5196
    },
    {
      "epoch": 3.1307228915662653,
      "grad_norm": 0.5278680324554443,
      "learning_rate": 1.088855421686747e-06,
      "loss": 0.1629,
      "step": 5197
    },
    {
      "epoch": 3.1313253012048192,
      "grad_norm": 0.4632438123226166,
      "learning_rate": 1.0881024096385544e-06,
      "loss": 0.1578,
      "step": 5198
    },
    {
      "epoch": 3.1319277108433736,
      "grad_norm": 0.6822875738143921,
      "learning_rate": 1.0873493975903615e-06,
      "loss": 0.1777,
      "step": 5199
    },
    {
      "epoch": 3.1325301204819276,
      "grad_norm": 0.6115267872810364,
      "learning_rate": 1.0865963855421689e-06,
      "loss": 0.1755,
      "step": 5200
    },
    {
      "epoch": 3.133132530120482,
      "grad_norm": 0.6220598220825195,
      "learning_rate": 1.085843373493976e-06,
      "loss": 0.1507,
      "step": 5201
    },
    {
      "epoch": 3.133734939759036,
      "grad_norm": 0.48115232586860657,
      "learning_rate": 1.0850903614457831e-06,
      "loss": 0.167,
      "step": 5202
    },
    {
      "epoch": 3.1343373493975903,
      "grad_norm": 0.5044226050376892,
      "learning_rate": 1.0843373493975905e-06,
      "loss": 0.1465,
      "step": 5203
    },
    {
      "epoch": 3.1349397590361447,
      "grad_norm": 0.595427930355072,
      "learning_rate": 1.0835843373493978e-06,
      "loss": 0.214,
      "step": 5204
    },
    {
      "epoch": 3.1355421686746987,
      "grad_norm": 0.5109073519706726,
      "learning_rate": 1.082831325301205e-06,
      "loss": 0.1442,
      "step": 5205
    },
    {
      "epoch": 3.136144578313253,
      "grad_norm": 0.6817694306373596,
      "learning_rate": 1.0820783132530121e-06,
      "loss": 0.1746,
      "step": 5206
    },
    {
      "epoch": 3.136746987951807,
      "grad_norm": 0.48040005564689636,
      "learning_rate": 1.0813253012048195e-06,
      "loss": 0.1345,
      "step": 5207
    },
    {
      "epoch": 3.1373493975903615,
      "grad_norm": 0.5178825855255127,
      "learning_rate": 1.0805722891566266e-06,
      "loss": 0.1824,
      "step": 5208
    },
    {
      "epoch": 3.137951807228916,
      "grad_norm": 0.667647123336792,
      "learning_rate": 1.079819277108434e-06,
      "loss": 0.2292,
      "step": 5209
    },
    {
      "epoch": 3.13855421686747,
      "grad_norm": 0.5576246380805969,
      "learning_rate": 1.079066265060241e-06,
      "loss": 0.1623,
      "step": 5210
    },
    {
      "epoch": 3.1391566265060242,
      "grad_norm": 0.508005678653717,
      "learning_rate": 1.0783132530120482e-06,
      "loss": 0.1147,
      "step": 5211
    },
    {
      "epoch": 3.139759036144578,
      "grad_norm": 0.49321943521499634,
      "learning_rate": 1.0775602409638556e-06,
      "loss": 0.1199,
      "step": 5212
    },
    {
      "epoch": 3.1403614457831326,
      "grad_norm": 0.5697120428085327,
      "learning_rate": 1.0768072289156627e-06,
      "loss": 0.1691,
      "step": 5213
    },
    {
      "epoch": 3.1409638554216865,
      "grad_norm": 0.8259084224700928,
      "learning_rate": 1.0760542168674698e-06,
      "loss": 0.2161,
      "step": 5214
    },
    {
      "epoch": 3.141566265060241,
      "grad_norm": 0.5607944130897522,
      "learning_rate": 1.0753012048192772e-06,
      "loss": 0.1614,
      "step": 5215
    },
    {
      "epoch": 3.1421686746987953,
      "grad_norm": 0.5825937390327454,
      "learning_rate": 1.0745481927710845e-06,
      "loss": 0.1759,
      "step": 5216
    },
    {
      "epoch": 3.1427710843373493,
      "grad_norm": 0.46595627069473267,
      "learning_rate": 1.0737951807228917e-06,
      "loss": 0.1398,
      "step": 5217
    },
    {
      "epoch": 3.1433734939759037,
      "grad_norm": 0.5174727439880371,
      "learning_rate": 1.0730421686746988e-06,
      "loss": 0.1784,
      "step": 5218
    },
    {
      "epoch": 3.1439759036144577,
      "grad_norm": 0.6366761922836304,
      "learning_rate": 1.0722891566265062e-06,
      "loss": 0.1952,
      "step": 5219
    },
    {
      "epoch": 3.144578313253012,
      "grad_norm": 0.608636736869812,
      "learning_rate": 1.0715361445783133e-06,
      "loss": 0.1687,
      "step": 5220
    },
    {
      "epoch": 3.1451807228915665,
      "grad_norm": 0.4749760329723358,
      "learning_rate": 1.0707831325301206e-06,
      "loss": 0.1387,
      "step": 5221
    },
    {
      "epoch": 3.1457831325301204,
      "grad_norm": 0.5694759488105774,
      "learning_rate": 1.0700301204819278e-06,
      "loss": 0.1538,
      "step": 5222
    },
    {
      "epoch": 3.146385542168675,
      "grad_norm": 0.5547411441802979,
      "learning_rate": 1.069277108433735e-06,
      "loss": 0.1573,
      "step": 5223
    },
    {
      "epoch": 3.146987951807229,
      "grad_norm": 0.46437573432922363,
      "learning_rate": 1.0685240963855423e-06,
      "loss": 0.1211,
      "step": 5224
    },
    {
      "epoch": 3.147590361445783,
      "grad_norm": 0.6426649689674377,
      "learning_rate": 1.0677710843373496e-06,
      "loss": 0.1781,
      "step": 5225
    },
    {
      "epoch": 3.148192771084337,
      "grad_norm": 0.5171571373939514,
      "learning_rate": 1.0670180722891567e-06,
      "loss": 0.1745,
      "step": 5226
    },
    {
      "epoch": 3.1487951807228916,
      "grad_norm": 0.5113810896873474,
      "learning_rate": 1.0662650602409639e-06,
      "loss": 0.1485,
      "step": 5227
    },
    {
      "epoch": 3.149397590361446,
      "grad_norm": 0.576261579990387,
      "learning_rate": 1.0655120481927712e-06,
      "loss": 0.1434,
      "step": 5228
    },
    {
      "epoch": 3.15,
      "grad_norm": 0.5814308524131775,
      "learning_rate": 1.0647590361445784e-06,
      "loss": 0.1677,
      "step": 5229
    },
    {
      "epoch": 3.1506024096385543,
      "grad_norm": 0.5316318869590759,
      "learning_rate": 1.0640060240963857e-06,
      "loss": 0.1636,
      "step": 5230
    },
    {
      "epoch": 3.1512048192771083,
      "grad_norm": 0.5317036509513855,
      "learning_rate": 1.0632530120481929e-06,
      "loss": 0.1589,
      "step": 5231
    },
    {
      "epoch": 3.1518072289156627,
      "grad_norm": 0.5234543681144714,
      "learning_rate": 1.0625e-06,
      "loss": 0.1307,
      "step": 5232
    },
    {
      "epoch": 3.152409638554217,
      "grad_norm": 0.5339511036872864,
      "learning_rate": 1.0617469879518073e-06,
      "loss": 0.1767,
      "step": 5233
    },
    {
      "epoch": 3.153012048192771,
      "grad_norm": 0.5712136030197144,
      "learning_rate": 1.0609939759036147e-06,
      "loss": 0.181,
      "step": 5234
    },
    {
      "epoch": 3.1536144578313254,
      "grad_norm": 0.5358912944793701,
      "learning_rate": 1.0602409638554218e-06,
      "loss": 0.1538,
      "step": 5235
    },
    {
      "epoch": 3.1542168674698794,
      "grad_norm": 0.5534693002700806,
      "learning_rate": 1.059487951807229e-06,
      "loss": 0.1635,
      "step": 5236
    },
    {
      "epoch": 3.154819277108434,
      "grad_norm": 0.6420358419418335,
      "learning_rate": 1.0587349397590363e-06,
      "loss": 0.2387,
      "step": 5237
    },
    {
      "epoch": 3.1554216867469878,
      "grad_norm": 0.5245552062988281,
      "learning_rate": 1.0579819277108434e-06,
      "loss": 0.1589,
      "step": 5238
    },
    {
      "epoch": 3.156024096385542,
      "grad_norm": 0.5990573763847351,
      "learning_rate": 1.0572289156626508e-06,
      "loss": 0.1681,
      "step": 5239
    },
    {
      "epoch": 3.1566265060240966,
      "grad_norm": 0.5545710325241089,
      "learning_rate": 1.056475903614458e-06,
      "loss": 0.1632,
      "step": 5240
    },
    {
      "epoch": 3.1572289156626505,
      "grad_norm": 0.5143934488296509,
      "learning_rate": 1.055722891566265e-06,
      "loss": 0.147,
      "step": 5241
    },
    {
      "epoch": 3.157831325301205,
      "grad_norm": 0.5085123777389526,
      "learning_rate": 1.0549698795180724e-06,
      "loss": 0.1335,
      "step": 5242
    },
    {
      "epoch": 3.158433734939759,
      "grad_norm": 0.5398206114768982,
      "learning_rate": 1.0542168674698798e-06,
      "loss": 0.1309,
      "step": 5243
    },
    {
      "epoch": 3.1590361445783133,
      "grad_norm": 0.6576086282730103,
      "learning_rate": 1.053463855421687e-06,
      "loss": 0.1956,
      "step": 5244
    },
    {
      "epoch": 3.1596385542168672,
      "grad_norm": 0.5170506834983826,
      "learning_rate": 1.052710843373494e-06,
      "loss": 0.1537,
      "step": 5245
    },
    {
      "epoch": 3.1602409638554216,
      "grad_norm": 0.4808579087257385,
      "learning_rate": 1.0519578313253014e-06,
      "loss": 0.1329,
      "step": 5246
    },
    {
      "epoch": 3.160843373493976,
      "grad_norm": 0.5548534989356995,
      "learning_rate": 1.0512048192771085e-06,
      "loss": 0.1753,
      "step": 5247
    },
    {
      "epoch": 3.16144578313253,
      "grad_norm": 0.5802605152130127,
      "learning_rate": 1.0504518072289157e-06,
      "loss": 0.1335,
      "step": 5248
    },
    {
      "epoch": 3.1620481927710844,
      "grad_norm": 0.509671688079834,
      "learning_rate": 1.049698795180723e-06,
      "loss": 0.1733,
      "step": 5249
    },
    {
      "epoch": 3.1626506024096384,
      "grad_norm": 0.5907443165779114,
      "learning_rate": 1.0489457831325301e-06,
      "loss": 0.1645,
      "step": 5250
    },
    {
      "epoch": 3.1632530120481928,
      "grad_norm": 0.5302299857139587,
      "learning_rate": 1.0481927710843375e-06,
      "loss": 0.152,
      "step": 5251
    },
    {
      "epoch": 3.163855421686747,
      "grad_norm": 0.48295536637306213,
      "learning_rate": 1.0474397590361446e-06,
      "loss": 0.1369,
      "step": 5252
    },
    {
      "epoch": 3.164457831325301,
      "grad_norm": 0.6505228877067566,
      "learning_rate": 1.0466867469879518e-06,
      "loss": 0.1266,
      "step": 5253
    },
    {
      "epoch": 3.1650602409638555,
      "grad_norm": 0.5023398995399475,
      "learning_rate": 1.0459337349397591e-06,
      "loss": 0.1536,
      "step": 5254
    },
    {
      "epoch": 3.1656626506024095,
      "grad_norm": 0.5084220767021179,
      "learning_rate": 1.0451807228915665e-06,
      "loss": 0.1437,
      "step": 5255
    },
    {
      "epoch": 3.166265060240964,
      "grad_norm": 0.7679403424263,
      "learning_rate": 1.0444277108433736e-06,
      "loss": 0.165,
      "step": 5256
    },
    {
      "epoch": 3.1668674698795183,
      "grad_norm": 0.5320769548416138,
      "learning_rate": 1.0436746987951807e-06,
      "loss": 0.1668,
      "step": 5257
    },
    {
      "epoch": 3.1674698795180722,
      "grad_norm": 0.5834804773330688,
      "learning_rate": 1.042921686746988e-06,
      "loss": 0.2065,
      "step": 5258
    },
    {
      "epoch": 3.1680722891566266,
      "grad_norm": 0.714146077632904,
      "learning_rate": 1.0421686746987952e-06,
      "loss": 0.1889,
      "step": 5259
    },
    {
      "epoch": 3.1686746987951806,
      "grad_norm": 0.6404336094856262,
      "learning_rate": 1.0414156626506026e-06,
      "loss": 0.1886,
      "step": 5260
    },
    {
      "epoch": 3.169277108433735,
      "grad_norm": 0.5043032765388489,
      "learning_rate": 1.0406626506024097e-06,
      "loss": 0.1392,
      "step": 5261
    },
    {
      "epoch": 3.169879518072289,
      "grad_norm": 0.6261718273162842,
      "learning_rate": 1.0399096385542168e-06,
      "loss": 0.1951,
      "step": 5262
    },
    {
      "epoch": 3.1704819277108434,
      "grad_norm": 0.5874800682067871,
      "learning_rate": 1.0391566265060242e-06,
      "loss": 0.1437,
      "step": 5263
    },
    {
      "epoch": 3.1710843373493978,
      "grad_norm": 0.6203688383102417,
      "learning_rate": 1.0384036144578315e-06,
      "loss": 0.1882,
      "step": 5264
    },
    {
      "epoch": 3.1716867469879517,
      "grad_norm": 0.5440269708633423,
      "learning_rate": 1.0376506024096387e-06,
      "loss": 0.1638,
      "step": 5265
    },
    {
      "epoch": 3.172289156626506,
      "grad_norm": 0.5039680600166321,
      "learning_rate": 1.0368975903614458e-06,
      "loss": 0.1606,
      "step": 5266
    },
    {
      "epoch": 3.17289156626506,
      "grad_norm": 0.594119131565094,
      "learning_rate": 1.0361445783132532e-06,
      "loss": 0.1766,
      "step": 5267
    },
    {
      "epoch": 3.1734939759036145,
      "grad_norm": 0.5646237730979919,
      "learning_rate": 1.0353915662650603e-06,
      "loss": 0.1452,
      "step": 5268
    },
    {
      "epoch": 3.1740963855421684,
      "grad_norm": 0.6496763825416565,
      "learning_rate": 1.0346385542168676e-06,
      "loss": 0.1905,
      "step": 5269
    },
    {
      "epoch": 3.174698795180723,
      "grad_norm": 0.68299400806427,
      "learning_rate": 1.0338855421686748e-06,
      "loss": 0.2008,
      "step": 5270
    },
    {
      "epoch": 3.1753012048192772,
      "grad_norm": 0.5354260802268982,
      "learning_rate": 1.033132530120482e-06,
      "loss": 0.1429,
      "step": 5271
    },
    {
      "epoch": 3.175903614457831,
      "grad_norm": 0.589504063129425,
      "learning_rate": 1.0323795180722893e-06,
      "loss": 0.1843,
      "step": 5272
    },
    {
      "epoch": 3.1765060240963856,
      "grad_norm": 0.5509579181671143,
      "learning_rate": 1.0316265060240966e-06,
      "loss": 0.1751,
      "step": 5273
    },
    {
      "epoch": 3.1771084337349396,
      "grad_norm": 0.5444483160972595,
      "learning_rate": 1.0308734939759038e-06,
      "loss": 0.1631,
      "step": 5274
    },
    {
      "epoch": 3.177710843373494,
      "grad_norm": 0.5419582724571228,
      "learning_rate": 1.0301204819277109e-06,
      "loss": 0.1383,
      "step": 5275
    },
    {
      "epoch": 3.1783132530120484,
      "grad_norm": 0.4716595709323883,
      "learning_rate": 1.0293674698795182e-06,
      "loss": 0.1462,
      "step": 5276
    },
    {
      "epoch": 3.1789156626506023,
      "grad_norm": 0.5405119061470032,
      "learning_rate": 1.0286144578313254e-06,
      "loss": 0.1376,
      "step": 5277
    },
    {
      "epoch": 3.1795180722891567,
      "grad_norm": 0.5535945296287537,
      "learning_rate": 1.0278614457831327e-06,
      "loss": 0.1551,
      "step": 5278
    },
    {
      "epoch": 3.1801204819277107,
      "grad_norm": 0.6692643761634827,
      "learning_rate": 1.0271084337349399e-06,
      "loss": 0.1977,
      "step": 5279
    },
    {
      "epoch": 3.180722891566265,
      "grad_norm": 0.563481867313385,
      "learning_rate": 1.026355421686747e-06,
      "loss": 0.1838,
      "step": 5280
    },
    {
      "epoch": 3.1813253012048195,
      "grad_norm": 0.8900289535522461,
      "learning_rate": 1.0256024096385543e-06,
      "loss": 0.2044,
      "step": 5281
    },
    {
      "epoch": 3.1819277108433734,
      "grad_norm": 0.6502664089202881,
      "learning_rate": 1.0248493975903617e-06,
      "loss": 0.1821,
      "step": 5282
    },
    {
      "epoch": 3.182530120481928,
      "grad_norm": 0.634569525718689,
      "learning_rate": 1.0240963855421688e-06,
      "loss": 0.1679,
      "step": 5283
    },
    {
      "epoch": 3.183132530120482,
      "grad_norm": 0.5954254269599915,
      "learning_rate": 1.023343373493976e-06,
      "loss": 0.1934,
      "step": 5284
    },
    {
      "epoch": 3.183734939759036,
      "grad_norm": 0.48725879192352295,
      "learning_rate": 1.0225903614457833e-06,
      "loss": 0.1515,
      "step": 5285
    },
    {
      "epoch": 3.18433734939759,
      "grad_norm": 0.4998698830604553,
      "learning_rate": 1.0218373493975905e-06,
      "loss": 0.1384,
      "step": 5286
    },
    {
      "epoch": 3.1849397590361446,
      "grad_norm": 0.5435535907745361,
      "learning_rate": 1.0210843373493976e-06,
      "loss": 0.1997,
      "step": 5287
    },
    {
      "epoch": 3.185542168674699,
      "grad_norm": 0.5516491532325745,
      "learning_rate": 1.020331325301205e-06,
      "loss": 0.146,
      "step": 5288
    },
    {
      "epoch": 3.186144578313253,
      "grad_norm": 0.6969375610351562,
      "learning_rate": 1.019578313253012e-06,
      "loss": 0.1754,
      "step": 5289
    },
    {
      "epoch": 3.1867469879518073,
      "grad_norm": 0.5447021126747131,
      "learning_rate": 1.0188253012048194e-06,
      "loss": 0.1619,
      "step": 5290
    },
    {
      "epoch": 3.1873493975903613,
      "grad_norm": 0.5319726467132568,
      "learning_rate": 1.0180722891566266e-06,
      "loss": 0.1582,
      "step": 5291
    },
    {
      "epoch": 3.1879518072289157,
      "grad_norm": 0.6315540671348572,
      "learning_rate": 1.0173192771084337e-06,
      "loss": 0.1956,
      "step": 5292
    },
    {
      "epoch": 3.1885542168674696,
      "grad_norm": 0.4801463186740875,
      "learning_rate": 1.016566265060241e-06,
      "loss": 0.1429,
      "step": 5293
    },
    {
      "epoch": 3.189156626506024,
      "grad_norm": 0.5916826128959656,
      "learning_rate": 1.0158132530120484e-06,
      "loss": 0.1731,
      "step": 5294
    },
    {
      "epoch": 3.1897590361445785,
      "grad_norm": 0.6127567887306213,
      "learning_rate": 1.0150602409638555e-06,
      "loss": 0.1551,
      "step": 5295
    },
    {
      "epoch": 3.1903614457831324,
      "grad_norm": 0.5782490968704224,
      "learning_rate": 1.0143072289156627e-06,
      "loss": 0.1709,
      "step": 5296
    },
    {
      "epoch": 3.190963855421687,
      "grad_norm": 0.5444541573524475,
      "learning_rate": 1.01355421686747e-06,
      "loss": 0.16,
      "step": 5297
    },
    {
      "epoch": 3.1915662650602408,
      "grad_norm": 0.6344524621963501,
      "learning_rate": 1.0128012048192771e-06,
      "loss": 0.2431,
      "step": 5298
    },
    {
      "epoch": 3.192168674698795,
      "grad_norm": 0.6127966046333313,
      "learning_rate": 1.0120481927710845e-06,
      "loss": 0.1642,
      "step": 5299
    },
    {
      "epoch": 3.1927710843373496,
      "grad_norm": 0.4730851948261261,
      "learning_rate": 1.0112951807228916e-06,
      "loss": 0.1488,
      "step": 5300
    },
    {
      "epoch": 3.1933734939759035,
      "grad_norm": 0.46347013115882874,
      "learning_rate": 1.0105421686746988e-06,
      "loss": 0.1249,
      "step": 5301
    },
    {
      "epoch": 3.193975903614458,
      "grad_norm": 0.4943861663341522,
      "learning_rate": 1.0097891566265061e-06,
      "loss": 0.1682,
      "step": 5302
    },
    {
      "epoch": 3.194578313253012,
      "grad_norm": 0.4880005717277527,
      "learning_rate": 1.0090361445783135e-06,
      "loss": 0.149,
      "step": 5303
    },
    {
      "epoch": 3.1951807228915663,
      "grad_norm": 0.5939868092536926,
      "learning_rate": 1.0082831325301206e-06,
      "loss": 0.163,
      "step": 5304
    },
    {
      "epoch": 3.1957831325301207,
      "grad_norm": 0.570191502571106,
      "learning_rate": 1.0075301204819277e-06,
      "loss": 0.1787,
      "step": 5305
    },
    {
      "epoch": 3.1963855421686747,
      "grad_norm": 0.5791629552841187,
      "learning_rate": 1.006777108433735e-06,
      "loss": 0.1699,
      "step": 5306
    },
    {
      "epoch": 3.196987951807229,
      "grad_norm": 0.5210433006286621,
      "learning_rate": 1.0060240963855422e-06,
      "loss": 0.1461,
      "step": 5307
    },
    {
      "epoch": 3.197590361445783,
      "grad_norm": 0.5919244289398193,
      "learning_rate": 1.0052710843373496e-06,
      "loss": 0.1571,
      "step": 5308
    },
    {
      "epoch": 3.1981927710843374,
      "grad_norm": 0.5410293936729431,
      "learning_rate": 1.0045180722891567e-06,
      "loss": 0.1554,
      "step": 5309
    },
    {
      "epoch": 3.1987951807228914,
      "grad_norm": 0.6735435724258423,
      "learning_rate": 1.0037650602409638e-06,
      "loss": 0.1354,
      "step": 5310
    },
    {
      "epoch": 3.1993975903614458,
      "grad_norm": 0.7066996097564697,
      "learning_rate": 1.0030120481927712e-06,
      "loss": 0.1994,
      "step": 5311
    },
    {
      "epoch": 3.2,
      "grad_norm": 0.5069745779037476,
      "learning_rate": 1.0022590361445785e-06,
      "loss": 0.146,
      "step": 5312
    },
    {
      "epoch": 3.200602409638554,
      "grad_norm": 0.5433117151260376,
      "learning_rate": 1.0015060240963857e-06,
      "loss": 0.152,
      "step": 5313
    },
    {
      "epoch": 3.2012048192771085,
      "grad_norm": 0.5559415817260742,
      "learning_rate": 1.0007530120481928e-06,
      "loss": 0.1306,
      "step": 5314
    },
    {
      "epoch": 3.2018072289156625,
      "grad_norm": 0.5985583066940308,
      "learning_rate": 1.0000000000000002e-06,
      "loss": 0.2096,
      "step": 5315
    },
    {
      "epoch": 3.202409638554217,
      "grad_norm": 0.5800871849060059,
      "learning_rate": 9.992469879518073e-07,
      "loss": 0.1559,
      "step": 5316
    },
    {
      "epoch": 3.203012048192771,
      "grad_norm": 0.6726689338684082,
      "learning_rate": 9.984939759036147e-07,
      "loss": 0.1573,
      "step": 5317
    },
    {
      "epoch": 3.2036144578313253,
      "grad_norm": 0.4821447730064392,
      "learning_rate": 9.977409638554218e-07,
      "loss": 0.1248,
      "step": 5318
    },
    {
      "epoch": 3.2042168674698797,
      "grad_norm": 0.6683820486068726,
      "learning_rate": 9.96987951807229e-07,
      "loss": 0.2004,
      "step": 5319
    },
    {
      "epoch": 3.2048192771084336,
      "grad_norm": 0.5304960012435913,
      "learning_rate": 9.962349397590363e-07,
      "loss": 0.1975,
      "step": 5320
    },
    {
      "epoch": 3.205421686746988,
      "grad_norm": 0.5850837826728821,
      "learning_rate": 9.954819277108434e-07,
      "loss": 0.1345,
      "step": 5321
    },
    {
      "epoch": 3.206024096385542,
      "grad_norm": 0.5600847601890564,
      "learning_rate": 9.947289156626505e-07,
      "loss": 0.1553,
      "step": 5322
    },
    {
      "epoch": 3.2066265060240964,
      "grad_norm": 0.49766120314598083,
      "learning_rate": 9.93975903614458e-07,
      "loss": 0.1377,
      "step": 5323
    },
    {
      "epoch": 3.207228915662651,
      "grad_norm": 0.6166731715202332,
      "learning_rate": 9.932228915662652e-07,
      "loss": 0.1677,
      "step": 5324
    },
    {
      "epoch": 3.2078313253012047,
      "grad_norm": 0.6008023023605347,
      "learning_rate": 9.924698795180724e-07,
      "loss": 0.1931,
      "step": 5325
    },
    {
      "epoch": 3.208433734939759,
      "grad_norm": 0.49388986825942993,
      "learning_rate": 9.917168674698795e-07,
      "loss": 0.168,
      "step": 5326
    },
    {
      "epoch": 3.209036144578313,
      "grad_norm": 0.6341795325279236,
      "learning_rate": 9.909638554216869e-07,
      "loss": 0.1935,
      "step": 5327
    },
    {
      "epoch": 3.2096385542168675,
      "grad_norm": 0.5743618607521057,
      "learning_rate": 9.90210843373494e-07,
      "loss": 0.178,
      "step": 5328
    },
    {
      "epoch": 3.210240963855422,
      "grad_norm": 0.6282970309257507,
      "learning_rate": 9.894578313253013e-07,
      "loss": 0.1801,
      "step": 5329
    },
    {
      "epoch": 3.210843373493976,
      "grad_norm": 0.526705801486969,
      "learning_rate": 9.887048192771085e-07,
      "loss": 0.1566,
      "step": 5330
    },
    {
      "epoch": 3.2114457831325303,
      "grad_norm": 0.5804296135902405,
      "learning_rate": 9.879518072289156e-07,
      "loss": 0.1385,
      "step": 5331
    },
    {
      "epoch": 3.212048192771084,
      "grad_norm": 0.47448575496673584,
      "learning_rate": 9.87198795180723e-07,
      "loss": 0.1597,
      "step": 5332
    },
    {
      "epoch": 3.2126506024096386,
      "grad_norm": 0.6433609127998352,
      "learning_rate": 9.864457831325303e-07,
      "loss": 0.2099,
      "step": 5333
    },
    {
      "epoch": 3.2132530120481926,
      "grad_norm": 0.5041172504425049,
      "learning_rate": 9.856927710843375e-07,
      "loss": 0.1472,
      "step": 5334
    },
    {
      "epoch": 3.213855421686747,
      "grad_norm": 0.46600812673568726,
      "learning_rate": 9.849397590361446e-07,
      "loss": 0.148,
      "step": 5335
    },
    {
      "epoch": 3.2144578313253014,
      "grad_norm": 0.5086433291435242,
      "learning_rate": 9.84186746987952e-07,
      "loss": 0.1538,
      "step": 5336
    },
    {
      "epoch": 3.2150602409638553,
      "grad_norm": 0.5053965449333191,
      "learning_rate": 9.83433734939759e-07,
      "loss": 0.1861,
      "step": 5337
    },
    {
      "epoch": 3.2156626506024097,
      "grad_norm": 0.8830500841140747,
      "learning_rate": 9.826807228915664e-07,
      "loss": 0.1679,
      "step": 5338
    },
    {
      "epoch": 3.2162650602409637,
      "grad_norm": 0.5513548851013184,
      "learning_rate": 9.819277108433736e-07,
      "loss": 0.1434,
      "step": 5339
    },
    {
      "epoch": 3.216867469879518,
      "grad_norm": 0.6778883337974548,
      "learning_rate": 9.811746987951807e-07,
      "loss": 0.1569,
      "step": 5340
    },
    {
      "epoch": 3.217469879518072,
      "grad_norm": 0.6147505044937134,
      "learning_rate": 9.80421686746988e-07,
      "loss": 0.1532,
      "step": 5341
    },
    {
      "epoch": 3.2180722891566265,
      "grad_norm": 0.42293021082878113,
      "learning_rate": 9.796686746987954e-07,
      "loss": 0.144,
      "step": 5342
    },
    {
      "epoch": 3.218674698795181,
      "grad_norm": 0.5143635869026184,
      "learning_rate": 9.789156626506025e-07,
      "loss": 0.1429,
      "step": 5343
    },
    {
      "epoch": 3.219277108433735,
      "grad_norm": 0.4871026277542114,
      "learning_rate": 9.781626506024097e-07,
      "loss": 0.1628,
      "step": 5344
    },
    {
      "epoch": 3.2198795180722892,
      "grad_norm": 0.5176563262939453,
      "learning_rate": 9.77409638554217e-07,
      "loss": 0.1625,
      "step": 5345
    },
    {
      "epoch": 3.220481927710843,
      "grad_norm": 0.5447868704795837,
      "learning_rate": 9.766566265060242e-07,
      "loss": 0.1634,
      "step": 5346
    },
    {
      "epoch": 3.2210843373493976,
      "grad_norm": 0.5397031903266907,
      "learning_rate": 9.759036144578315e-07,
      "loss": 0.1571,
      "step": 5347
    },
    {
      "epoch": 3.221686746987952,
      "grad_norm": 0.5579676628112793,
      "learning_rate": 9.751506024096386e-07,
      "loss": 0.1452,
      "step": 5348
    },
    {
      "epoch": 3.222289156626506,
      "grad_norm": 0.6469460725784302,
      "learning_rate": 9.743975903614458e-07,
      "loss": 0.1789,
      "step": 5349
    },
    {
      "epoch": 3.2228915662650603,
      "grad_norm": 0.5408207178115845,
      "learning_rate": 9.736445783132531e-07,
      "loss": 0.1201,
      "step": 5350
    },
    {
      "epoch": 3.2234939759036143,
      "grad_norm": 0.6490890979766846,
      "learning_rate": 9.728915662650605e-07,
      "loss": 0.1973,
      "step": 5351
    },
    {
      "epoch": 3.2240963855421687,
      "grad_norm": 0.8063200116157532,
      "learning_rate": 9.721385542168676e-07,
      "loss": 0.1962,
      "step": 5352
    },
    {
      "epoch": 3.224698795180723,
      "grad_norm": 0.5122345089912415,
      "learning_rate": 9.713855421686747e-07,
      "loss": 0.1233,
      "step": 5353
    },
    {
      "epoch": 3.225301204819277,
      "grad_norm": 0.5229964256286621,
      "learning_rate": 9.70632530120482e-07,
      "loss": 0.1467,
      "step": 5354
    },
    {
      "epoch": 3.2259036144578315,
      "grad_norm": 0.5102367401123047,
      "learning_rate": 9.698795180722892e-07,
      "loss": 0.1219,
      "step": 5355
    },
    {
      "epoch": 3.2265060240963854,
      "grad_norm": 0.4668486714363098,
      "learning_rate": 9.691265060240964e-07,
      "loss": 0.1466,
      "step": 5356
    },
    {
      "epoch": 3.22710843373494,
      "grad_norm": 0.5893415808677673,
      "learning_rate": 9.683734939759037e-07,
      "loss": 0.1566,
      "step": 5357
    },
    {
      "epoch": 3.227710843373494,
      "grad_norm": 0.6927124261856079,
      "learning_rate": 9.676204819277109e-07,
      "loss": 0.1958,
      "step": 5358
    },
    {
      "epoch": 3.228313253012048,
      "grad_norm": 0.5766952633857727,
      "learning_rate": 9.668674698795182e-07,
      "loss": 0.1693,
      "step": 5359
    },
    {
      "epoch": 3.2289156626506026,
      "grad_norm": 0.48394080996513367,
      "learning_rate": 9.661144578313253e-07,
      "loss": 0.1562,
      "step": 5360
    },
    {
      "epoch": 3.2295180722891565,
      "grad_norm": 0.47939950227737427,
      "learning_rate": 9.653614457831325e-07,
      "loss": 0.1339,
      "step": 5361
    },
    {
      "epoch": 3.230120481927711,
      "grad_norm": 0.6148399710655212,
      "learning_rate": 9.646084337349398e-07,
      "loss": 0.1417,
      "step": 5362
    },
    {
      "epoch": 3.230722891566265,
      "grad_norm": 0.5451731085777283,
      "learning_rate": 9.638554216867472e-07,
      "loss": 0.1605,
      "step": 5363
    },
    {
      "epoch": 3.2313253012048193,
      "grad_norm": 0.505782425403595,
      "learning_rate": 9.631024096385543e-07,
      "loss": 0.154,
      "step": 5364
    },
    {
      "epoch": 3.2319277108433733,
      "grad_norm": 0.6650817394256592,
      "learning_rate": 9.623493975903614e-07,
      "loss": 0.216,
      "step": 5365
    },
    {
      "epoch": 3.2325301204819277,
      "grad_norm": 0.5137913227081299,
      "learning_rate": 9.615963855421688e-07,
      "loss": 0.1347,
      "step": 5366
    },
    {
      "epoch": 3.233132530120482,
      "grad_norm": 0.5408756732940674,
      "learning_rate": 9.60843373493976e-07,
      "loss": 0.1357,
      "step": 5367
    },
    {
      "epoch": 3.233734939759036,
      "grad_norm": 0.4451289176940918,
      "learning_rate": 9.600903614457833e-07,
      "loss": 0.1548,
      "step": 5368
    },
    {
      "epoch": 3.2343373493975904,
      "grad_norm": 0.5119439363479614,
      "learning_rate": 9.593373493975904e-07,
      "loss": 0.1614,
      "step": 5369
    },
    {
      "epoch": 3.2349397590361444,
      "grad_norm": 0.4871600270271301,
      "learning_rate": 9.585843373493976e-07,
      "loss": 0.1306,
      "step": 5370
    },
    {
      "epoch": 3.235542168674699,
      "grad_norm": 0.429718017578125,
      "learning_rate": 9.57831325301205e-07,
      "loss": 0.1274,
      "step": 5371
    },
    {
      "epoch": 3.236144578313253,
      "grad_norm": 0.5059567093849182,
      "learning_rate": 9.570783132530122e-07,
      "loss": 0.1583,
      "step": 5372
    },
    {
      "epoch": 3.236746987951807,
      "grad_norm": 0.5433169603347778,
      "learning_rate": 9.563253012048194e-07,
      "loss": 0.1254,
      "step": 5373
    },
    {
      "epoch": 3.2373493975903616,
      "grad_norm": 0.49429458379745483,
      "learning_rate": 9.555722891566265e-07,
      "loss": 0.1479,
      "step": 5374
    },
    {
      "epoch": 3.2379518072289155,
      "grad_norm": 0.5232200622558594,
      "learning_rate": 9.548192771084339e-07,
      "loss": 0.1021,
      "step": 5375
    },
    {
      "epoch": 3.23855421686747,
      "grad_norm": 0.619857132434845,
      "learning_rate": 9.54066265060241e-07,
      "loss": 0.2053,
      "step": 5376
    },
    {
      "epoch": 3.2391566265060243,
      "grad_norm": 0.6345903873443604,
      "learning_rate": 9.533132530120482e-07,
      "loss": 0.1814,
      "step": 5377
    },
    {
      "epoch": 3.2397590361445783,
      "grad_norm": 0.7095826268196106,
      "learning_rate": 9.525602409638556e-07,
      "loss": 0.1916,
      "step": 5378
    },
    {
      "epoch": 3.2403614457831327,
      "grad_norm": 0.5966709852218628,
      "learning_rate": 9.518072289156627e-07,
      "loss": 0.1628,
      "step": 5379
    },
    {
      "epoch": 3.2409638554216866,
      "grad_norm": 0.589012086391449,
      "learning_rate": 9.5105421686747e-07,
      "loss": 0.1621,
      "step": 5380
    },
    {
      "epoch": 3.241566265060241,
      "grad_norm": 0.5049956440925598,
      "learning_rate": 9.503012048192772e-07,
      "loss": 0.1611,
      "step": 5381
    },
    {
      "epoch": 3.242168674698795,
      "grad_norm": 0.6032140254974365,
      "learning_rate": 9.495481927710844e-07,
      "loss": 0.1648,
      "step": 5382
    },
    {
      "epoch": 3.2427710843373494,
      "grad_norm": 0.4967530071735382,
      "learning_rate": 9.487951807228916e-07,
      "loss": 0.1736,
      "step": 5383
    },
    {
      "epoch": 3.243373493975904,
      "grad_norm": 0.5813627243041992,
      "learning_rate": 9.480421686746989e-07,
      "loss": 0.1438,
      "step": 5384
    },
    {
      "epoch": 3.2439759036144578,
      "grad_norm": 0.5259955525398254,
      "learning_rate": 9.472891566265061e-07,
      "loss": 0.1645,
      "step": 5385
    },
    {
      "epoch": 3.244578313253012,
      "grad_norm": 0.4841679632663727,
      "learning_rate": 9.465361445783133e-07,
      "loss": 0.1401,
      "step": 5386
    },
    {
      "epoch": 3.245180722891566,
      "grad_norm": 0.6590257883071899,
      "learning_rate": 9.457831325301206e-07,
      "loss": 0.1564,
      "step": 5387
    },
    {
      "epoch": 3.2457831325301205,
      "grad_norm": 0.5679601430892944,
      "learning_rate": 9.450301204819277e-07,
      "loss": 0.1931,
      "step": 5388
    },
    {
      "epoch": 3.2463855421686745,
      "grad_norm": 0.5258833765983582,
      "learning_rate": 9.442771084337351e-07,
      "loss": 0.1192,
      "step": 5389
    },
    {
      "epoch": 3.246987951807229,
      "grad_norm": 0.5043957233428955,
      "learning_rate": 9.435240963855423e-07,
      "loss": 0.1262,
      "step": 5390
    },
    {
      "epoch": 3.2475903614457833,
      "grad_norm": 0.4653366804122925,
      "learning_rate": 9.427710843373494e-07,
      "loss": 0.1485,
      "step": 5391
    },
    {
      "epoch": 3.2481927710843372,
      "grad_norm": 0.6111431121826172,
      "learning_rate": 9.420180722891567e-07,
      "loss": 0.1337,
      "step": 5392
    },
    {
      "epoch": 3.2487951807228916,
      "grad_norm": 0.4827294647693634,
      "learning_rate": 9.41265060240964e-07,
      "loss": 0.1714,
      "step": 5393
    },
    {
      "epoch": 3.2493975903614456,
      "grad_norm": 0.5462702512741089,
      "learning_rate": 9.405120481927712e-07,
      "loss": 0.1866,
      "step": 5394
    },
    {
      "epoch": 3.25,
      "grad_norm": 0.5081510543823242,
      "learning_rate": 9.397590361445784e-07,
      "loss": 0.1536,
      "step": 5395
    },
    {
      "epoch": 3.2506024096385544,
      "grad_norm": 0.6910670399665833,
      "learning_rate": 9.390060240963856e-07,
      "loss": 0.1842,
      "step": 5396
    },
    {
      "epoch": 3.2512048192771084,
      "grad_norm": 0.5877010822296143,
      "learning_rate": 9.382530120481928e-07,
      "loss": 0.1497,
      "step": 5397
    },
    {
      "epoch": 3.2518072289156628,
      "grad_norm": 0.590593695640564,
      "learning_rate": 9.375000000000001e-07,
      "loss": 0.1686,
      "step": 5398
    },
    {
      "epoch": 3.2524096385542167,
      "grad_norm": 0.5847012996673584,
      "learning_rate": 9.367469879518074e-07,
      "loss": 0.1794,
      "step": 5399
    },
    {
      "epoch": 3.253012048192771,
      "grad_norm": 0.6643991470336914,
      "learning_rate": 9.359939759036145e-07,
      "loss": 0.1815,
      "step": 5400
    },
    {
      "epoch": 3.2536144578313255,
      "grad_norm": 0.57949298620224,
      "learning_rate": 9.352409638554218e-07,
      "loss": 0.1596,
      "step": 5401
    },
    {
      "epoch": 3.2542168674698795,
      "grad_norm": 0.5110738277435303,
      "learning_rate": 9.34487951807229e-07,
      "loss": 0.1366,
      "step": 5402
    },
    {
      "epoch": 3.254819277108434,
      "grad_norm": 0.5731216073036194,
      "learning_rate": 9.337349397590361e-07,
      "loss": 0.1511,
      "step": 5403
    },
    {
      "epoch": 3.255421686746988,
      "grad_norm": 0.6851056814193726,
      "learning_rate": 9.329819277108435e-07,
      "loss": 0.1624,
      "step": 5404
    },
    {
      "epoch": 3.2560240963855422,
      "grad_norm": 0.5361918210983276,
      "learning_rate": 9.322289156626507e-07,
      "loss": 0.1284,
      "step": 5405
    },
    {
      "epoch": 3.256626506024096,
      "grad_norm": 0.5059031844139099,
      "learning_rate": 9.314759036144579e-07,
      "loss": 0.1393,
      "step": 5406
    },
    {
      "epoch": 3.2572289156626506,
      "grad_norm": 0.5880901217460632,
      "learning_rate": 9.307228915662651e-07,
      "loss": 0.1897,
      "step": 5407
    },
    {
      "epoch": 3.257831325301205,
      "grad_norm": 0.45190858840942383,
      "learning_rate": 9.299698795180724e-07,
      "loss": 0.1419,
      "step": 5408
    },
    {
      "epoch": 3.258433734939759,
      "grad_norm": 0.5056646466255188,
      "learning_rate": 9.292168674698796e-07,
      "loss": 0.149,
      "step": 5409
    },
    {
      "epoch": 3.2590361445783134,
      "grad_norm": 0.5602189302444458,
      "learning_rate": 9.284638554216868e-07,
      "loss": 0.161,
      "step": 5410
    },
    {
      "epoch": 3.2596385542168673,
      "grad_norm": 0.7119216322898865,
      "learning_rate": 9.277108433734941e-07,
      "loss": 0.2428,
      "step": 5411
    },
    {
      "epoch": 3.2602409638554217,
      "grad_norm": 0.5566887259483337,
      "learning_rate": 9.269578313253012e-07,
      "loss": 0.2303,
      "step": 5412
    },
    {
      "epoch": 3.2608433734939757,
      "grad_norm": 0.5389981269836426,
      "learning_rate": 9.262048192771086e-07,
      "loss": 0.1664,
      "step": 5413
    },
    {
      "epoch": 3.26144578313253,
      "grad_norm": 0.7649964690208435,
      "learning_rate": 9.254518072289158e-07,
      "loss": 0.213,
      "step": 5414
    },
    {
      "epoch": 3.2620481927710845,
      "grad_norm": 0.5665560960769653,
      "learning_rate": 9.246987951807229e-07,
      "loss": 0.1613,
      "step": 5415
    },
    {
      "epoch": 3.2626506024096384,
      "grad_norm": 0.5306661128997803,
      "learning_rate": 9.239457831325302e-07,
      "loss": 0.1803,
      "step": 5416
    },
    {
      "epoch": 3.263253012048193,
      "grad_norm": 0.6799613833427429,
      "learning_rate": 9.231927710843374e-07,
      "loss": 0.1898,
      "step": 5417
    },
    {
      "epoch": 3.263855421686747,
      "grad_norm": 0.568962574005127,
      "learning_rate": 9.224397590361446e-07,
      "loss": 0.1201,
      "step": 5418
    },
    {
      "epoch": 3.264457831325301,
      "grad_norm": 0.7268094420433044,
      "learning_rate": 9.216867469879519e-07,
      "loss": 0.1748,
      "step": 5419
    },
    {
      "epoch": 3.2650602409638556,
      "grad_norm": 0.4827359914779663,
      "learning_rate": 9.209337349397591e-07,
      "loss": 0.1269,
      "step": 5420
    },
    {
      "epoch": 3.2656626506024096,
      "grad_norm": 0.49731555581092834,
      "learning_rate": 9.201807228915663e-07,
      "loss": 0.1449,
      "step": 5421
    },
    {
      "epoch": 3.266265060240964,
      "grad_norm": 0.5028976798057556,
      "learning_rate": 9.194277108433735e-07,
      "loss": 0.1333,
      "step": 5422
    },
    {
      "epoch": 3.266867469879518,
      "grad_norm": 0.5078092813491821,
      "learning_rate": 9.186746987951809e-07,
      "loss": 0.1466,
      "step": 5423
    },
    {
      "epoch": 3.2674698795180723,
      "grad_norm": 0.5647149085998535,
      "learning_rate": 9.17921686746988e-07,
      "loss": 0.1678,
      "step": 5424
    },
    {
      "epoch": 3.2680722891566267,
      "grad_norm": 0.4618057906627655,
      "learning_rate": 9.171686746987953e-07,
      "loss": 0.1454,
      "step": 5425
    },
    {
      "epoch": 3.2686746987951807,
      "grad_norm": 0.5325570702552795,
      "learning_rate": 9.164156626506025e-07,
      "loss": 0.138,
      "step": 5426
    },
    {
      "epoch": 3.269277108433735,
      "grad_norm": 0.4967641532421112,
      "learning_rate": 9.156626506024096e-07,
      "loss": 0.1564,
      "step": 5427
    },
    {
      "epoch": 3.269879518072289,
      "grad_norm": 0.9069061875343323,
      "learning_rate": 9.14909638554217e-07,
      "loss": 0.1454,
      "step": 5428
    },
    {
      "epoch": 3.2704819277108435,
      "grad_norm": 0.5198642015457153,
      "learning_rate": 9.141566265060242e-07,
      "loss": 0.1698,
      "step": 5429
    },
    {
      "epoch": 3.2710843373493974,
      "grad_norm": 0.5134520530700684,
      "learning_rate": 9.134036144578314e-07,
      "loss": 0.1517,
      "step": 5430
    },
    {
      "epoch": 3.271686746987952,
      "grad_norm": 0.6676060557365417,
      "learning_rate": 9.126506024096386e-07,
      "loss": 0.1764,
      "step": 5431
    },
    {
      "epoch": 3.272289156626506,
      "grad_norm": 0.4672357141971588,
      "learning_rate": 9.11897590361446e-07,
      "loss": 0.1067,
      "step": 5432
    },
    {
      "epoch": 3.27289156626506,
      "grad_norm": 0.5246429443359375,
      "learning_rate": 9.111445783132531e-07,
      "loss": 0.1236,
      "step": 5433
    },
    {
      "epoch": 3.2734939759036146,
      "grad_norm": 0.5835838317871094,
      "learning_rate": 9.103915662650603e-07,
      "loss": 0.1446,
      "step": 5434
    },
    {
      "epoch": 3.2740963855421685,
      "grad_norm": 0.5966299176216125,
      "learning_rate": 9.096385542168676e-07,
      "loss": 0.18,
      "step": 5435
    },
    {
      "epoch": 3.274698795180723,
      "grad_norm": 0.49362173676490784,
      "learning_rate": 9.088855421686747e-07,
      "loss": 0.1133,
      "step": 5436
    },
    {
      "epoch": 3.275301204819277,
      "grad_norm": 0.554506778717041,
      "learning_rate": 9.08132530120482e-07,
      "loss": 0.1465,
      "step": 5437
    },
    {
      "epoch": 3.2759036144578313,
      "grad_norm": 0.47749993205070496,
      "learning_rate": 9.073795180722893e-07,
      "loss": 0.1438,
      "step": 5438
    },
    {
      "epoch": 3.2765060240963857,
      "grad_norm": 0.5806372761726379,
      "learning_rate": 9.066265060240964e-07,
      "loss": 0.2041,
      "step": 5439
    },
    {
      "epoch": 3.2771084337349397,
      "grad_norm": 0.6093831062316895,
      "learning_rate": 9.058734939759037e-07,
      "loss": 0.1757,
      "step": 5440
    },
    {
      "epoch": 3.277710843373494,
      "grad_norm": 0.5604934096336365,
      "learning_rate": 9.051204819277109e-07,
      "loss": 0.1585,
      "step": 5441
    },
    {
      "epoch": 3.278313253012048,
      "grad_norm": 0.6928605437278748,
      "learning_rate": 9.043674698795181e-07,
      "loss": 0.2393,
      "step": 5442
    },
    {
      "epoch": 3.2789156626506024,
      "grad_norm": 0.46374693512916565,
      "learning_rate": 9.036144578313254e-07,
      "loss": 0.1498,
      "step": 5443
    },
    {
      "epoch": 3.279518072289157,
      "grad_norm": 0.7096298336982727,
      "learning_rate": 9.028614457831326e-07,
      "loss": 0.2184,
      "step": 5444
    },
    {
      "epoch": 3.2801204819277108,
      "grad_norm": 0.5243439674377441,
      "learning_rate": 9.021084337349398e-07,
      "loss": 0.1602,
      "step": 5445
    },
    {
      "epoch": 3.280722891566265,
      "grad_norm": 0.5985483527183533,
      "learning_rate": 9.01355421686747e-07,
      "loss": 0.1359,
      "step": 5446
    },
    {
      "epoch": 3.281325301204819,
      "grad_norm": 0.6940009593963623,
      "learning_rate": 9.006024096385544e-07,
      "loss": 0.1426,
      "step": 5447
    },
    {
      "epoch": 3.2819277108433735,
      "grad_norm": 0.5146514177322388,
      "learning_rate": 8.998493975903615e-07,
      "loss": 0.1947,
      "step": 5448
    },
    {
      "epoch": 3.282530120481928,
      "grad_norm": 0.6615920066833496,
      "learning_rate": 8.990963855421688e-07,
      "loss": 0.1575,
      "step": 5449
    },
    {
      "epoch": 3.283132530120482,
      "grad_norm": 0.6661725640296936,
      "learning_rate": 8.98343373493976e-07,
      "loss": 0.1567,
      "step": 5450
    },
    {
      "epoch": 3.2837349397590363,
      "grad_norm": 0.7273116111755371,
      "learning_rate": 8.975903614457831e-07,
      "loss": 0.2243,
      "step": 5451
    },
    {
      "epoch": 3.2843373493975903,
      "grad_norm": 0.5107947587966919,
      "learning_rate": 8.968373493975904e-07,
      "loss": 0.1611,
      "step": 5452
    },
    {
      "epoch": 3.2849397590361447,
      "grad_norm": 0.5481055378913879,
      "learning_rate": 8.960843373493977e-07,
      "loss": 0.1276,
      "step": 5453
    },
    {
      "epoch": 3.2855421686746986,
      "grad_norm": 0.5527911186218262,
      "learning_rate": 8.953313253012049e-07,
      "loss": 0.1568,
      "step": 5454
    },
    {
      "epoch": 3.286144578313253,
      "grad_norm": 0.5112535953521729,
      "learning_rate": 8.945783132530121e-07,
      "loss": 0.1489,
      "step": 5455
    },
    {
      "epoch": 3.2867469879518074,
      "grad_norm": 0.6213029623031616,
      "learning_rate": 8.938253012048193e-07,
      "loss": 0.1761,
      "step": 5456
    },
    {
      "epoch": 3.2873493975903614,
      "grad_norm": 0.4709661602973938,
      "learning_rate": 8.930722891566265e-07,
      "loss": 0.1277,
      "step": 5457
    },
    {
      "epoch": 3.287951807228916,
      "grad_norm": 0.4522740840911865,
      "learning_rate": 8.923192771084338e-07,
      "loss": 0.1429,
      "step": 5458
    },
    {
      "epoch": 3.2885542168674697,
      "grad_norm": 0.560994029045105,
      "learning_rate": 8.915662650602411e-07,
      "loss": 0.1935,
      "step": 5459
    },
    {
      "epoch": 3.289156626506024,
      "grad_norm": 0.6192806959152222,
      "learning_rate": 8.908132530120482e-07,
      "loss": 0.1398,
      "step": 5460
    },
    {
      "epoch": 3.289759036144578,
      "grad_norm": 0.49843794107437134,
      "learning_rate": 8.900602409638555e-07,
      "loss": 0.1305,
      "step": 5461
    },
    {
      "epoch": 3.2903614457831325,
      "grad_norm": 0.4514630138874054,
      "learning_rate": 8.893072289156628e-07,
      "loss": 0.1113,
      "step": 5462
    },
    {
      "epoch": 3.290963855421687,
      "grad_norm": 0.6234986186027527,
      "learning_rate": 8.885542168674699e-07,
      "loss": 0.1389,
      "step": 5463
    },
    {
      "epoch": 3.291566265060241,
      "grad_norm": 0.48855575919151306,
      "learning_rate": 8.878012048192772e-07,
      "loss": 0.1447,
      "step": 5464
    },
    {
      "epoch": 3.2921686746987953,
      "grad_norm": 0.7193310260772705,
      "learning_rate": 8.870481927710844e-07,
      "loss": 0.1796,
      "step": 5465
    },
    {
      "epoch": 3.292771084337349,
      "grad_norm": 0.5674687623977661,
      "learning_rate": 8.862951807228916e-07,
      "loss": 0.1296,
      "step": 5466
    },
    {
      "epoch": 3.2933734939759036,
      "grad_norm": 0.5554099082946777,
      "learning_rate": 8.855421686746989e-07,
      "loss": 0.1586,
      "step": 5467
    },
    {
      "epoch": 3.293975903614458,
      "grad_norm": 0.541972279548645,
      "learning_rate": 8.847891566265062e-07,
      "loss": 0.1222,
      "step": 5468
    },
    {
      "epoch": 3.294578313253012,
      "grad_norm": 0.5182089805603027,
      "learning_rate": 8.840361445783133e-07,
      "loss": 0.1588,
      "step": 5469
    },
    {
      "epoch": 3.2951807228915664,
      "grad_norm": 0.5325104594230652,
      "learning_rate": 8.832831325301205e-07,
      "loss": 0.145,
      "step": 5470
    },
    {
      "epoch": 3.2957831325301203,
      "grad_norm": 0.4977307915687561,
      "learning_rate": 8.825301204819278e-07,
      "loss": 0.1464,
      "step": 5471
    },
    {
      "epoch": 3.2963855421686747,
      "grad_norm": 0.5001459121704102,
      "learning_rate": 8.817771084337349e-07,
      "loss": 0.1512,
      "step": 5472
    },
    {
      "epoch": 3.296987951807229,
      "grad_norm": 0.6627026796340942,
      "learning_rate": 8.810240963855423e-07,
      "loss": 0.1615,
      "step": 5473
    },
    {
      "epoch": 3.297590361445783,
      "grad_norm": 0.52114337682724,
      "learning_rate": 8.802710843373495e-07,
      "loss": 0.1306,
      "step": 5474
    },
    {
      "epoch": 3.2981927710843375,
      "grad_norm": 0.5290914177894592,
      "learning_rate": 8.795180722891566e-07,
      "loss": 0.1425,
      "step": 5475
    },
    {
      "epoch": 3.2987951807228915,
      "grad_norm": 0.5279620289802551,
      "learning_rate": 8.787650602409639e-07,
      "loss": 0.1274,
      "step": 5476
    },
    {
      "epoch": 3.299397590361446,
      "grad_norm": 0.49554207921028137,
      "learning_rate": 8.780120481927712e-07,
      "loss": 0.1314,
      "step": 5477
    },
    {
      "epoch": 3.3,
      "grad_norm": 0.6567044854164124,
      "learning_rate": 8.772590361445784e-07,
      "loss": 0.1911,
      "step": 5478
    },
    {
      "epoch": 3.3006024096385542,
      "grad_norm": 0.5292388796806335,
      "learning_rate": 8.765060240963856e-07,
      "loss": 0.1528,
      "step": 5479
    },
    {
      "epoch": 3.3012048192771086,
      "grad_norm": 0.5248234868049622,
      "learning_rate": 8.757530120481929e-07,
      "loss": 0.1326,
      "step": 5480
    },
    {
      "epoch": 3.3018072289156626,
      "grad_norm": 0.6010342836380005,
      "learning_rate": 8.75e-07,
      "loss": 0.1623,
      "step": 5481
    },
    {
      "epoch": 3.302409638554217,
      "grad_norm": 0.4920847713947296,
      "learning_rate": 8.742469879518073e-07,
      "loss": 0.1407,
      "step": 5482
    },
    {
      "epoch": 3.303012048192771,
      "grad_norm": 0.5001853704452515,
      "learning_rate": 8.734939759036146e-07,
      "loss": 0.1404,
      "step": 5483
    },
    {
      "epoch": 3.3036144578313253,
      "grad_norm": 0.5293214917182922,
      "learning_rate": 8.727409638554217e-07,
      "loss": 0.1327,
      "step": 5484
    },
    {
      "epoch": 3.3042168674698793,
      "grad_norm": 0.5272138118743896,
      "learning_rate": 8.71987951807229e-07,
      "loss": 0.1606,
      "step": 5485
    },
    {
      "epoch": 3.3048192771084337,
      "grad_norm": 0.4718495011329651,
      "learning_rate": 8.712349397590362e-07,
      "loss": 0.1465,
      "step": 5486
    },
    {
      "epoch": 3.305421686746988,
      "grad_norm": 0.584319531917572,
      "learning_rate": 8.704819277108433e-07,
      "loss": 0.1913,
      "step": 5487
    },
    {
      "epoch": 3.306024096385542,
      "grad_norm": 0.46163228154182434,
      "learning_rate": 8.697289156626507e-07,
      "loss": 0.1246,
      "step": 5488
    },
    {
      "epoch": 3.3066265060240965,
      "grad_norm": 0.4420205354690552,
      "learning_rate": 8.689759036144579e-07,
      "loss": 0.1445,
      "step": 5489
    },
    {
      "epoch": 3.3072289156626504,
      "grad_norm": 0.4957648813724518,
      "learning_rate": 8.682228915662651e-07,
      "loss": 0.1487,
      "step": 5490
    },
    {
      "epoch": 3.307831325301205,
      "grad_norm": 0.5491023063659668,
      "learning_rate": 8.674698795180723e-07,
      "loss": 0.1406,
      "step": 5491
    },
    {
      "epoch": 3.3084337349397592,
      "grad_norm": 0.4916948080062866,
      "learning_rate": 8.667168674698797e-07,
      "loss": 0.1264,
      "step": 5492
    },
    {
      "epoch": 3.309036144578313,
      "grad_norm": 0.5420597195625305,
      "learning_rate": 8.659638554216868e-07,
      "loss": 0.154,
      "step": 5493
    },
    {
      "epoch": 3.3096385542168676,
      "grad_norm": 0.5775115489959717,
      "learning_rate": 8.65210843373494e-07,
      "loss": 0.1838,
      "step": 5494
    },
    {
      "epoch": 3.3102409638554215,
      "grad_norm": 0.5056663751602173,
      "learning_rate": 8.644578313253013e-07,
      "loss": 0.115,
      "step": 5495
    },
    {
      "epoch": 3.310843373493976,
      "grad_norm": 0.5702375173568726,
      "learning_rate": 8.637048192771084e-07,
      "loss": 0.1439,
      "step": 5496
    },
    {
      "epoch": 3.3114457831325304,
      "grad_norm": 0.5080016851425171,
      "learning_rate": 8.629518072289158e-07,
      "loss": 0.1338,
      "step": 5497
    },
    {
      "epoch": 3.3120481927710843,
      "grad_norm": 0.6560328602790833,
      "learning_rate": 8.62198795180723e-07,
      "loss": 0.2112,
      "step": 5498
    },
    {
      "epoch": 3.3126506024096387,
      "grad_norm": 0.544178307056427,
      "learning_rate": 8.614457831325301e-07,
      "loss": 0.1448,
      "step": 5499
    },
    {
      "epoch": 3.3132530120481927,
      "grad_norm": 0.44995754957199097,
      "learning_rate": 8.606927710843374e-07,
      "loss": 0.1391,
      "step": 5500
    },
    {
      "epoch": 3.313855421686747,
      "grad_norm": 0.5134682059288025,
      "learning_rate": 8.599397590361447e-07,
      "loss": 0.1997,
      "step": 5501
    },
    {
      "epoch": 3.314457831325301,
      "grad_norm": 0.666782021522522,
      "learning_rate": 8.591867469879519e-07,
      "loss": 0.249,
      "step": 5502
    },
    {
      "epoch": 3.3150602409638554,
      "grad_norm": 0.5532210469245911,
      "learning_rate": 8.584337349397591e-07,
      "loss": 0.1624,
      "step": 5503
    },
    {
      "epoch": 3.31566265060241,
      "grad_norm": 0.49303749203681946,
      "learning_rate": 8.576807228915664e-07,
      "loss": 0.1499,
      "step": 5504
    },
    {
      "epoch": 3.316265060240964,
      "grad_norm": 0.6829290986061096,
      "learning_rate": 8.569277108433735e-07,
      "loss": 0.149,
      "step": 5505
    },
    {
      "epoch": 3.316867469879518,
      "grad_norm": 0.4822148084640503,
      "learning_rate": 8.561746987951807e-07,
      "loss": 0.144,
      "step": 5506
    },
    {
      "epoch": 3.317469879518072,
      "grad_norm": 0.537805438041687,
      "learning_rate": 8.554216867469881e-07,
      "loss": 0.1091,
      "step": 5507
    },
    {
      "epoch": 3.3180722891566266,
      "grad_norm": 0.6716569066047668,
      "learning_rate": 8.546686746987952e-07,
      "loss": 0.2046,
      "step": 5508
    },
    {
      "epoch": 3.3186746987951805,
      "grad_norm": 0.5664474368095398,
      "learning_rate": 8.539156626506025e-07,
      "loss": 0.1432,
      "step": 5509
    },
    {
      "epoch": 3.319277108433735,
      "grad_norm": 2.758384943008423,
      "learning_rate": 8.531626506024097e-07,
      "loss": 0.1512,
      "step": 5510
    },
    {
      "epoch": 3.3198795180722893,
      "grad_norm": 0.5538020133972168,
      "learning_rate": 8.524096385542168e-07,
      "loss": 0.1717,
      "step": 5511
    },
    {
      "epoch": 3.3204819277108433,
      "grad_norm": 0.5762724876403809,
      "learning_rate": 8.516566265060242e-07,
      "loss": 0.1633,
      "step": 5512
    },
    {
      "epoch": 3.3210843373493977,
      "grad_norm": 0.43139851093292236,
      "learning_rate": 8.509036144578314e-07,
      "loss": 0.1206,
      "step": 5513
    },
    {
      "epoch": 3.3216867469879516,
      "grad_norm": 0.5590554475784302,
      "learning_rate": 8.501506024096386e-07,
      "loss": 0.2151,
      "step": 5514
    },
    {
      "epoch": 3.322289156626506,
      "grad_norm": 0.8301869630813599,
      "learning_rate": 8.493975903614458e-07,
      "loss": 0.223,
      "step": 5515
    },
    {
      "epoch": 3.32289156626506,
      "grad_norm": 0.5814330577850342,
      "learning_rate": 8.486445783132532e-07,
      "loss": 0.1521,
      "step": 5516
    },
    {
      "epoch": 3.3234939759036144,
      "grad_norm": 0.6229331493377686,
      "learning_rate": 8.478915662650603e-07,
      "loss": 0.1784,
      "step": 5517
    },
    {
      "epoch": 3.324096385542169,
      "grad_norm": 0.5692133903503418,
      "learning_rate": 8.471385542168675e-07,
      "loss": 0.1609,
      "step": 5518
    },
    {
      "epoch": 3.3246987951807228,
      "grad_norm": 0.5007117390632629,
      "learning_rate": 8.463855421686748e-07,
      "loss": 0.1563,
      "step": 5519
    },
    {
      "epoch": 3.325301204819277,
      "grad_norm": 0.6110445261001587,
      "learning_rate": 8.456325301204819e-07,
      "loss": 0.1793,
      "step": 5520
    },
    {
      "epoch": 3.3259036144578316,
      "grad_norm": 0.5469576716423035,
      "learning_rate": 8.448795180722893e-07,
      "loss": 0.1971,
      "step": 5521
    },
    {
      "epoch": 3.3265060240963855,
      "grad_norm": 0.45559918880462646,
      "learning_rate": 8.441265060240965e-07,
      "loss": 0.1328,
      "step": 5522
    },
    {
      "epoch": 3.32710843373494,
      "grad_norm": 0.5271157622337341,
      "learning_rate": 8.433734939759036e-07,
      "loss": 0.1299,
      "step": 5523
    },
    {
      "epoch": 3.327710843373494,
      "grad_norm": 0.5666069388389587,
      "learning_rate": 8.426204819277109e-07,
      "loss": 0.1388,
      "step": 5524
    },
    {
      "epoch": 3.3283132530120483,
      "grad_norm": 0.7144994735717773,
      "learning_rate": 8.418674698795181e-07,
      "loss": 0.1759,
      "step": 5525
    },
    {
      "epoch": 3.3289156626506022,
      "grad_norm": 0.7296265959739685,
      "learning_rate": 8.411144578313253e-07,
      "loss": 0.197,
      "step": 5526
    },
    {
      "epoch": 3.3295180722891566,
      "grad_norm": 0.5421910881996155,
      "learning_rate": 8.403614457831326e-07,
      "loss": 0.164,
      "step": 5527
    },
    {
      "epoch": 3.330120481927711,
      "grad_norm": 0.5165014266967773,
      "learning_rate": 8.396084337349399e-07,
      "loss": 0.1569,
      "step": 5528
    },
    {
      "epoch": 3.330722891566265,
      "grad_norm": 0.5642591714859009,
      "learning_rate": 8.38855421686747e-07,
      "loss": 0.2008,
      "step": 5529
    },
    {
      "epoch": 3.3313253012048194,
      "grad_norm": 0.7399968504905701,
      "learning_rate": 8.381024096385542e-07,
      "loss": 0.2225,
      "step": 5530
    },
    {
      "epoch": 3.3319277108433734,
      "grad_norm": 0.6670552492141724,
      "learning_rate": 8.373493975903616e-07,
      "loss": 0.194,
      "step": 5531
    },
    {
      "epoch": 3.3325301204819278,
      "grad_norm": 0.5380212664604187,
      "learning_rate": 8.365963855421687e-07,
      "loss": 0.1336,
      "step": 5532
    },
    {
      "epoch": 3.3331325301204817,
      "grad_norm": 0.5034736394882202,
      "learning_rate": 8.35843373493976e-07,
      "loss": 0.1365,
      "step": 5533
    },
    {
      "epoch": 3.333734939759036,
      "grad_norm": 0.7398661971092224,
      "learning_rate": 8.350903614457832e-07,
      "loss": 0.2418,
      "step": 5534
    },
    {
      "epoch": 3.3343373493975905,
      "grad_norm": 0.5215522050857544,
      "learning_rate": 8.343373493975903e-07,
      "loss": 0.1298,
      "step": 5535
    },
    {
      "epoch": 3.3349397590361445,
      "grad_norm": 0.5909011960029602,
      "learning_rate": 8.335843373493977e-07,
      "loss": 0.187,
      "step": 5536
    },
    {
      "epoch": 3.335542168674699,
      "grad_norm": 0.5613116025924683,
      "learning_rate": 8.328313253012049e-07,
      "loss": 0.1609,
      "step": 5537
    },
    {
      "epoch": 3.336144578313253,
      "grad_norm": 0.5525236129760742,
      "learning_rate": 8.320783132530121e-07,
      "loss": 0.1345,
      "step": 5538
    },
    {
      "epoch": 3.3367469879518072,
      "grad_norm": 0.5365062355995178,
      "learning_rate": 8.313253012048193e-07,
      "loss": 0.1166,
      "step": 5539
    },
    {
      "epoch": 3.337349397590361,
      "grad_norm": 0.5288518071174622,
      "learning_rate": 8.305722891566266e-07,
      "loss": 0.1283,
      "step": 5540
    },
    {
      "epoch": 3.3379518072289156,
      "grad_norm": 0.4961419701576233,
      "learning_rate": 8.298192771084337e-07,
      "loss": 0.1341,
      "step": 5541
    },
    {
      "epoch": 3.33855421686747,
      "grad_norm": 0.5853180885314941,
      "learning_rate": 8.29066265060241e-07,
      "loss": 0.1533,
      "step": 5542
    },
    {
      "epoch": 3.339156626506024,
      "grad_norm": 0.5391954183578491,
      "learning_rate": 8.283132530120483e-07,
      "loss": 0.1434,
      "step": 5543
    },
    {
      "epoch": 3.3397590361445784,
      "grad_norm": 0.5606769323348999,
      "learning_rate": 8.275602409638554e-07,
      "loss": 0.1296,
      "step": 5544
    },
    {
      "epoch": 3.3403614457831328,
      "grad_norm": 0.5407536625862122,
      "learning_rate": 8.268072289156627e-07,
      "loss": 0.1067,
      "step": 5545
    },
    {
      "epoch": 3.3409638554216867,
      "grad_norm": 0.5615831613540649,
      "learning_rate": 8.2605421686747e-07,
      "loss": 0.136,
      "step": 5546
    },
    {
      "epoch": 3.341566265060241,
      "grad_norm": 0.5222396850585938,
      "learning_rate": 8.253012048192771e-07,
      "loss": 0.1468,
      "step": 5547
    },
    {
      "epoch": 3.342168674698795,
      "grad_norm": 0.4776115417480469,
      "learning_rate": 8.245481927710844e-07,
      "loss": 0.1562,
      "step": 5548
    },
    {
      "epoch": 3.3427710843373495,
      "grad_norm": 0.5212132334709167,
      "learning_rate": 8.237951807228916e-07,
      "loss": 0.1431,
      "step": 5549
    },
    {
      "epoch": 3.3433734939759034,
      "grad_norm": 0.5941473245620728,
      "learning_rate": 8.230421686746988e-07,
      "loss": 0.2145,
      "step": 5550
    },
    {
      "epoch": 3.343975903614458,
      "grad_norm": 0.5986342430114746,
      "learning_rate": 8.222891566265061e-07,
      "loss": 0.1402,
      "step": 5551
    },
    {
      "epoch": 3.3445783132530122,
      "grad_norm": 0.5052832365036011,
      "learning_rate": 8.215361445783134e-07,
      "loss": 0.1411,
      "step": 5552
    },
    {
      "epoch": 3.345180722891566,
      "grad_norm": 0.5388205051422119,
      "learning_rate": 8.207831325301205e-07,
      "loss": 0.1433,
      "step": 5553
    },
    {
      "epoch": 3.3457831325301206,
      "grad_norm": 0.6899920105934143,
      "learning_rate": 8.200301204819277e-07,
      "loss": 0.1935,
      "step": 5554
    },
    {
      "epoch": 3.3463855421686746,
      "grad_norm": 0.504493236541748,
      "learning_rate": 8.192771084337351e-07,
      "loss": 0.1476,
      "step": 5555
    },
    {
      "epoch": 3.346987951807229,
      "grad_norm": 0.5587342381477356,
      "learning_rate": 8.185240963855422e-07,
      "loss": 0.1701,
      "step": 5556
    },
    {
      "epoch": 3.347590361445783,
      "grad_norm": 0.5079954266548157,
      "learning_rate": 8.177710843373495e-07,
      "loss": 0.1544,
      "step": 5557
    },
    {
      "epoch": 3.3481927710843373,
      "grad_norm": 0.5380408763885498,
      "learning_rate": 8.170180722891567e-07,
      "loss": 0.1658,
      "step": 5558
    },
    {
      "epoch": 3.3487951807228917,
      "grad_norm": 0.7499865889549255,
      "learning_rate": 8.162650602409638e-07,
      "loss": 0.22,
      "step": 5559
    },
    {
      "epoch": 3.3493975903614457,
      "grad_norm": 0.5159826278686523,
      "learning_rate": 8.155120481927711e-07,
      "loss": 0.173,
      "step": 5560
    },
    {
      "epoch": 3.35,
      "grad_norm": 0.4693118929862976,
      "learning_rate": 8.147590361445784e-07,
      "loss": 0.1394,
      "step": 5561
    },
    {
      "epoch": 3.350602409638554,
      "grad_norm": 0.6337195634841919,
      "learning_rate": 8.140060240963856e-07,
      "loss": 0.1887,
      "step": 5562
    },
    {
      "epoch": 3.3512048192771084,
      "grad_norm": 0.45837607979774475,
      "learning_rate": 8.132530120481928e-07,
      "loss": 0.1014,
      "step": 5563
    },
    {
      "epoch": 3.3518072289156624,
      "grad_norm": 0.45325767993927,
      "learning_rate": 8.125000000000001e-07,
      "loss": 0.1076,
      "step": 5564
    },
    {
      "epoch": 3.352409638554217,
      "grad_norm": 0.5187080502510071,
      "learning_rate": 8.117469879518072e-07,
      "loss": 0.1649,
      "step": 5565
    },
    {
      "epoch": 3.353012048192771,
      "grad_norm": 0.4864588677883148,
      "learning_rate": 8.109939759036145e-07,
      "loss": 0.1353,
      "step": 5566
    },
    {
      "epoch": 3.353614457831325,
      "grad_norm": 0.5114638805389404,
      "learning_rate": 8.102409638554218e-07,
      "loss": 0.1363,
      "step": 5567
    },
    {
      "epoch": 3.3542168674698796,
      "grad_norm": 0.6485616564750671,
      "learning_rate": 8.094879518072289e-07,
      "loss": 0.1891,
      "step": 5568
    },
    {
      "epoch": 3.354819277108434,
      "grad_norm": 0.7306318879127502,
      "learning_rate": 8.087349397590362e-07,
      "loss": 0.2041,
      "step": 5569
    },
    {
      "epoch": 3.355421686746988,
      "grad_norm": 0.5601670742034912,
      "learning_rate": 8.079819277108435e-07,
      "loss": 0.1509,
      "step": 5570
    },
    {
      "epoch": 3.3560240963855423,
      "grad_norm": 0.6074143052101135,
      "learning_rate": 8.072289156626506e-07,
      "loss": 0.189,
      "step": 5571
    },
    {
      "epoch": 3.3566265060240963,
      "grad_norm": 0.5075787901878357,
      "learning_rate": 8.064759036144579e-07,
      "loss": 0.1507,
      "step": 5572
    },
    {
      "epoch": 3.3572289156626507,
      "grad_norm": 0.5015599131584167,
      "learning_rate": 8.057228915662651e-07,
      "loss": 0.1963,
      "step": 5573
    },
    {
      "epoch": 3.3578313253012047,
      "grad_norm": 0.5810133218765259,
      "learning_rate": 8.049698795180723e-07,
      "loss": 0.1946,
      "step": 5574
    },
    {
      "epoch": 3.358433734939759,
      "grad_norm": 0.4709461033344269,
      "learning_rate": 8.042168674698795e-07,
      "loss": 0.1044,
      "step": 5575
    },
    {
      "epoch": 3.3590361445783135,
      "grad_norm": 0.5043883323669434,
      "learning_rate": 8.034638554216869e-07,
      "loss": 0.1296,
      "step": 5576
    },
    {
      "epoch": 3.3596385542168674,
      "grad_norm": 0.6583317518234253,
      "learning_rate": 8.02710843373494e-07,
      "loss": 0.1959,
      "step": 5577
    },
    {
      "epoch": 3.360240963855422,
      "grad_norm": 0.5373551845550537,
      "learning_rate": 8.019578313253012e-07,
      "loss": 0.1357,
      "step": 5578
    },
    {
      "epoch": 3.3608433734939758,
      "grad_norm": 0.49229663610458374,
      "learning_rate": 8.012048192771085e-07,
      "loss": 0.1416,
      "step": 5579
    },
    {
      "epoch": 3.36144578313253,
      "grad_norm": 0.49073344469070435,
      "learning_rate": 8.004518072289156e-07,
      "loss": 0.1328,
      "step": 5580
    },
    {
      "epoch": 3.362048192771084,
      "grad_norm": 0.505675733089447,
      "learning_rate": 7.99698795180723e-07,
      "loss": 0.1591,
      "step": 5581
    },
    {
      "epoch": 3.3626506024096385,
      "grad_norm": 0.7040212154388428,
      "learning_rate": 7.989457831325302e-07,
      "loss": 0.1706,
      "step": 5582
    },
    {
      "epoch": 3.363253012048193,
      "grad_norm": 0.6128876805305481,
      "learning_rate": 7.981927710843373e-07,
      "loss": 0.1652,
      "step": 5583
    },
    {
      "epoch": 3.363855421686747,
      "grad_norm": 0.5511240363121033,
      "learning_rate": 7.974397590361446e-07,
      "loss": 0.1714,
      "step": 5584
    },
    {
      "epoch": 3.3644578313253013,
      "grad_norm": 0.6306807398796082,
      "learning_rate": 7.966867469879519e-07,
      "loss": 0.2391,
      "step": 5585
    },
    {
      "epoch": 3.3650602409638553,
      "grad_norm": 0.6056533455848694,
      "learning_rate": 7.959337349397591e-07,
      "loss": 0.2068,
      "step": 5586
    },
    {
      "epoch": 3.3656626506024097,
      "grad_norm": 0.47772565484046936,
      "learning_rate": 7.951807228915663e-07,
      "loss": 0.1551,
      "step": 5587
    },
    {
      "epoch": 3.3662650602409636,
      "grad_norm": 0.5505583882331848,
      "learning_rate": 7.944277108433736e-07,
      "loss": 0.1365,
      "step": 5588
    },
    {
      "epoch": 3.366867469879518,
      "grad_norm": 0.5040314793586731,
      "learning_rate": 7.936746987951807e-07,
      "loss": 0.1487,
      "step": 5589
    },
    {
      "epoch": 3.3674698795180724,
      "grad_norm": 0.427277147769928,
      "learning_rate": 7.92921686746988e-07,
      "loss": 0.1328,
      "step": 5590
    },
    {
      "epoch": 3.3680722891566264,
      "grad_norm": 0.4839366376399994,
      "learning_rate": 7.921686746987953e-07,
      "loss": 0.1579,
      "step": 5591
    },
    {
      "epoch": 3.3686746987951808,
      "grad_norm": 0.5032391548156738,
      "learning_rate": 7.914156626506024e-07,
      "loss": 0.1316,
      "step": 5592
    },
    {
      "epoch": 3.369277108433735,
      "grad_norm": 0.5533064603805542,
      "learning_rate": 7.906626506024097e-07,
      "loss": 0.168,
      "step": 5593
    },
    {
      "epoch": 3.369879518072289,
      "grad_norm": 0.545650064945221,
      "learning_rate": 7.899096385542169e-07,
      "loss": 0.2056,
      "step": 5594
    },
    {
      "epoch": 3.3704819277108435,
      "grad_norm": 0.4793742895126343,
      "learning_rate": 7.89156626506024e-07,
      "loss": 0.1456,
      "step": 5595
    },
    {
      "epoch": 3.3710843373493975,
      "grad_norm": 0.6093640923500061,
      "learning_rate": 7.884036144578314e-07,
      "loss": 0.1953,
      "step": 5596
    },
    {
      "epoch": 3.371686746987952,
      "grad_norm": 0.48590758442878723,
      "learning_rate": 7.876506024096386e-07,
      "loss": 0.1441,
      "step": 5597
    },
    {
      "epoch": 3.372289156626506,
      "grad_norm": 0.49067285656929016,
      "learning_rate": 7.868975903614458e-07,
      "loss": 0.1476,
      "step": 5598
    },
    {
      "epoch": 3.3728915662650603,
      "grad_norm": 0.5915565490722656,
      "learning_rate": 7.86144578313253e-07,
      "loss": 0.1262,
      "step": 5599
    },
    {
      "epoch": 3.3734939759036147,
      "grad_norm": 0.7197237610816956,
      "learning_rate": 7.853915662650604e-07,
      "loss": 0.1694,
      "step": 5600
    },
    {
      "epoch": 3.3740963855421686,
      "grad_norm": 0.5263139605522156,
      "learning_rate": 7.846385542168675e-07,
      "loss": 0.1536,
      "step": 5601
    },
    {
      "epoch": 3.374698795180723,
      "grad_norm": 0.5455508232116699,
      "learning_rate": 7.838855421686747e-07,
      "loss": 0.1656,
      "step": 5602
    },
    {
      "epoch": 3.375301204819277,
      "grad_norm": 0.599721372127533,
      "learning_rate": 7.83132530120482e-07,
      "loss": 0.1573,
      "step": 5603
    },
    {
      "epoch": 3.3759036144578314,
      "grad_norm": 0.4875374138355255,
      "learning_rate": 7.823795180722891e-07,
      "loss": 0.1405,
      "step": 5604
    },
    {
      "epoch": 3.3765060240963853,
      "grad_norm": 0.4997391104698181,
      "learning_rate": 7.816265060240965e-07,
      "loss": 0.1416,
      "step": 5605
    },
    {
      "epoch": 3.3771084337349397,
      "grad_norm": 0.5919883251190186,
      "learning_rate": 7.808734939759037e-07,
      "loss": 0.1494,
      "step": 5606
    },
    {
      "epoch": 3.377710843373494,
      "grad_norm": 0.5067762136459351,
      "learning_rate": 7.80120481927711e-07,
      "loss": 0.1647,
      "step": 5607
    },
    {
      "epoch": 3.378313253012048,
      "grad_norm": 0.5884168744087219,
      "learning_rate": 7.793674698795181e-07,
      "loss": 0.1798,
      "step": 5608
    },
    {
      "epoch": 3.3789156626506025,
      "grad_norm": 0.8135688900947571,
      "learning_rate": 7.786144578313254e-07,
      "loss": 0.1854,
      "step": 5609
    },
    {
      "epoch": 3.3795180722891565,
      "grad_norm": 0.4773922264575958,
      "learning_rate": 7.778614457831327e-07,
      "loss": 0.1401,
      "step": 5610
    },
    {
      "epoch": 3.380120481927711,
      "grad_norm": 0.5552026629447937,
      "learning_rate": 7.771084337349398e-07,
      "loss": 0.2065,
      "step": 5611
    },
    {
      "epoch": 3.380722891566265,
      "grad_norm": 0.5766453742980957,
      "learning_rate": 7.763554216867471e-07,
      "loss": 0.1259,
      "step": 5612
    },
    {
      "epoch": 3.3813253012048192,
      "grad_norm": 0.4756421446800232,
      "learning_rate": 7.756024096385543e-07,
      "loss": 0.1325,
      "step": 5613
    },
    {
      "epoch": 3.3819277108433736,
      "grad_norm": 0.5171892046928406,
      "learning_rate": 7.748493975903614e-07,
      "loss": 0.1157,
      "step": 5614
    },
    {
      "epoch": 3.3825301204819276,
      "grad_norm": 0.5070832371711731,
      "learning_rate": 7.740963855421688e-07,
      "loss": 0.1456,
      "step": 5615
    },
    {
      "epoch": 3.383132530120482,
      "grad_norm": 0.5141589641571045,
      "learning_rate": 7.73343373493976e-07,
      "loss": 0.1528,
      "step": 5616
    },
    {
      "epoch": 3.3837349397590364,
      "grad_norm": 0.5417319536209106,
      "learning_rate": 7.725903614457832e-07,
      "loss": 0.1539,
      "step": 5617
    },
    {
      "epoch": 3.3843373493975903,
      "grad_norm": 0.5638943314552307,
      "learning_rate": 7.718373493975904e-07,
      "loss": 0.1187,
      "step": 5618
    },
    {
      "epoch": 3.3849397590361447,
      "grad_norm": 0.5653254985809326,
      "learning_rate": 7.710843373493978e-07,
      "loss": 0.1572,
      "step": 5619
    },
    {
      "epoch": 3.3855421686746987,
      "grad_norm": 0.5514063835144043,
      "learning_rate": 7.703313253012049e-07,
      "loss": 0.1561,
      "step": 5620
    },
    {
      "epoch": 3.386144578313253,
      "grad_norm": 0.5410372614860535,
      "learning_rate": 7.695783132530121e-07,
      "loss": 0.1707,
      "step": 5621
    },
    {
      "epoch": 3.386746987951807,
      "grad_norm": 0.531964123249054,
      "learning_rate": 7.688253012048194e-07,
      "loss": 0.1738,
      "step": 5622
    },
    {
      "epoch": 3.3873493975903615,
      "grad_norm": 0.5926136374473572,
      "learning_rate": 7.680722891566265e-07,
      "loss": 0.1454,
      "step": 5623
    },
    {
      "epoch": 3.387951807228916,
      "grad_norm": 0.5585106611251831,
      "learning_rate": 7.673192771084339e-07,
      "loss": 0.1499,
      "step": 5624
    },
    {
      "epoch": 3.38855421686747,
      "grad_norm": 0.6099045276641846,
      "learning_rate": 7.665662650602411e-07,
      "loss": 0.231,
      "step": 5625
    },
    {
      "epoch": 3.3891566265060242,
      "grad_norm": 0.5712789297103882,
      "learning_rate": 7.658132530120482e-07,
      "loss": 0.1479,
      "step": 5626
    },
    {
      "epoch": 3.389759036144578,
      "grad_norm": 0.6259374022483826,
      "learning_rate": 7.650602409638555e-07,
      "loss": 0.1539,
      "step": 5627
    },
    {
      "epoch": 3.3903614457831326,
      "grad_norm": 0.6103661060333252,
      "learning_rate": 7.643072289156627e-07,
      "loss": 0.153,
      "step": 5628
    },
    {
      "epoch": 3.3909638554216865,
      "grad_norm": 0.841927170753479,
      "learning_rate": 7.635542168674699e-07,
      "loss": 0.1712,
      "step": 5629
    },
    {
      "epoch": 3.391566265060241,
      "grad_norm": 0.7148540616035461,
      "learning_rate": 7.628012048192772e-07,
      "loss": 0.2296,
      "step": 5630
    },
    {
      "epoch": 3.3921686746987953,
      "grad_norm": 0.5804458856582642,
      "learning_rate": 7.620481927710845e-07,
      "loss": 0.1635,
      "step": 5631
    },
    {
      "epoch": 3.3927710843373493,
      "grad_norm": 0.545458972454071,
      "learning_rate": 7.612951807228916e-07,
      "loss": 0.1289,
      "step": 5632
    },
    {
      "epoch": 3.3933734939759037,
      "grad_norm": 0.4931645691394806,
      "learning_rate": 7.605421686746988e-07,
      "loss": 0.1622,
      "step": 5633
    },
    {
      "epoch": 3.3939759036144577,
      "grad_norm": 0.5545263886451721,
      "learning_rate": 7.597891566265062e-07,
      "loss": 0.1992,
      "step": 5634
    },
    {
      "epoch": 3.394578313253012,
      "grad_norm": 0.617427408695221,
      "learning_rate": 7.590361445783133e-07,
      "loss": 0.1899,
      "step": 5635
    },
    {
      "epoch": 3.395180722891566,
      "grad_norm": 0.4502483904361725,
      "learning_rate": 7.582831325301206e-07,
      "loss": 0.147,
      "step": 5636
    },
    {
      "epoch": 3.3957831325301204,
      "grad_norm": 0.4788702726364136,
      "learning_rate": 7.575301204819278e-07,
      "loss": 0.1364,
      "step": 5637
    },
    {
      "epoch": 3.396385542168675,
      "grad_norm": 0.6199180483818054,
      "learning_rate": 7.567771084337349e-07,
      "loss": 0.1878,
      "step": 5638
    },
    {
      "epoch": 3.396987951807229,
      "grad_norm": 0.52248215675354,
      "learning_rate": 7.560240963855423e-07,
      "loss": 0.1493,
      "step": 5639
    },
    {
      "epoch": 3.397590361445783,
      "grad_norm": 1.0675638914108276,
      "learning_rate": 7.552710843373495e-07,
      "loss": 0.2496,
      "step": 5640
    },
    {
      "epoch": 3.3981927710843376,
      "grad_norm": 0.7385101914405823,
      "learning_rate": 7.545180722891567e-07,
      "loss": 0.2163,
      "step": 5641
    },
    {
      "epoch": 3.3987951807228916,
      "grad_norm": 0.7791475057601929,
      "learning_rate": 7.537650602409639e-07,
      "loss": 0.2774,
      "step": 5642
    },
    {
      "epoch": 3.399397590361446,
      "grad_norm": 0.7382897138595581,
      "learning_rate": 7.530120481927713e-07,
      "loss": 0.2367,
      "step": 5643
    },
    {
      "epoch": 3.4,
      "grad_norm": 0.7650682330131531,
      "learning_rate": 7.522590361445784e-07,
      "loss": 0.2635,
      "step": 5644
    },
    {
      "epoch": 3.4006024096385543,
      "grad_norm": 0.9048958420753479,
      "learning_rate": 7.515060240963856e-07,
      "loss": 0.2681,
      "step": 5645
    },
    {
      "epoch": 3.4012048192771083,
      "grad_norm": 0.8975972533226013,
      "learning_rate": 7.507530120481929e-07,
      "loss": 0.3036,
      "step": 5646
    },
    {
      "epoch": 3.4018072289156627,
      "grad_norm": 0.7115362882614136,
      "learning_rate": 7.5e-07,
      "loss": 0.2772,
      "step": 5647
    },
    {
      "epoch": 3.402409638554217,
      "grad_norm": 0.9827461242675781,
      "learning_rate": 7.492469879518073e-07,
      "loss": 0.2777,
      "step": 5648
    },
    {
      "epoch": 3.403012048192771,
      "grad_norm": 0.7708315849304199,
      "learning_rate": 7.484939759036146e-07,
      "loss": 0.2481,
      "step": 5649
    },
    {
      "epoch": 3.4036144578313254,
      "grad_norm": 0.7189053297042847,
      "learning_rate": 7.477409638554217e-07,
      "loss": 0.2526,
      "step": 5650
    },
    {
      "epoch": 3.4042168674698794,
      "grad_norm": 0.8190591335296631,
      "learning_rate": 7.46987951807229e-07,
      "loss": 0.2363,
      "step": 5651
    },
    {
      "epoch": 3.404819277108434,
      "grad_norm": 0.7564066648483276,
      "learning_rate": 7.462349397590362e-07,
      "loss": 0.1993,
      "step": 5652
    },
    {
      "epoch": 3.4054216867469878,
      "grad_norm": 0.6543512344360352,
      "learning_rate": 7.454819277108434e-07,
      "loss": 0.2303,
      "step": 5653
    },
    {
      "epoch": 3.406024096385542,
      "grad_norm": 0.8516320586204529,
      "learning_rate": 7.447289156626507e-07,
      "loss": 0.2296,
      "step": 5654
    },
    {
      "epoch": 3.4066265060240966,
      "grad_norm": 0.8882313966751099,
      "learning_rate": 7.43975903614458e-07,
      "loss": 0.2062,
      "step": 5655
    },
    {
      "epoch": 3.4072289156626505,
      "grad_norm": 0.8176718950271606,
      "learning_rate": 7.432228915662651e-07,
      "loss": 0.2643,
      "step": 5656
    },
    {
      "epoch": 3.407831325301205,
      "grad_norm": 0.6340091824531555,
      "learning_rate": 7.424698795180723e-07,
      "loss": 0.2072,
      "step": 5657
    },
    {
      "epoch": 3.408433734939759,
      "grad_norm": 0.741725742816925,
      "learning_rate": 7.417168674698797e-07,
      "loss": 0.2369,
      "step": 5658
    },
    {
      "epoch": 3.4090361445783133,
      "grad_norm": 0.638634979724884,
      "learning_rate": 7.409638554216868e-07,
      "loss": 0.2236,
      "step": 5659
    },
    {
      "epoch": 3.4096385542168672,
      "grad_norm": 0.7280805706977844,
      "learning_rate": 7.402108433734941e-07,
      "loss": 0.2057,
      "step": 5660
    },
    {
      "epoch": 3.4102409638554216,
      "grad_norm": 0.7209094166755676,
      "learning_rate": 7.394578313253013e-07,
      "loss": 0.2155,
      "step": 5661
    },
    {
      "epoch": 3.410843373493976,
      "grad_norm": 0.6740577220916748,
      "learning_rate": 7.387048192771084e-07,
      "loss": 0.2297,
      "step": 5662
    },
    {
      "epoch": 3.41144578313253,
      "grad_norm": 0.7105969190597534,
      "learning_rate": 7.379518072289157e-07,
      "loss": 0.2288,
      "step": 5663
    },
    {
      "epoch": 3.4120481927710844,
      "grad_norm": 0.6102157235145569,
      "learning_rate": 7.37198795180723e-07,
      "loss": 0.2428,
      "step": 5664
    },
    {
      "epoch": 3.412650602409639,
      "grad_norm": 0.7066091895103455,
      "learning_rate": 7.364457831325302e-07,
      "loss": 0.2341,
      "step": 5665
    },
    {
      "epoch": 3.4132530120481928,
      "grad_norm": 1.0053504705429077,
      "learning_rate": 7.356927710843374e-07,
      "loss": 0.2796,
      "step": 5666
    },
    {
      "epoch": 3.413855421686747,
      "grad_norm": 0.7012180685997009,
      "learning_rate": 7.349397590361447e-07,
      "loss": 0.2528,
      "step": 5667
    },
    {
      "epoch": 3.414457831325301,
      "grad_norm": 0.7210397124290466,
      "learning_rate": 7.341867469879518e-07,
      "loss": 0.2372,
      "step": 5668
    },
    {
      "epoch": 3.4150602409638555,
      "grad_norm": 0.656848132610321,
      "learning_rate": 7.334337349397591e-07,
      "loss": 0.2383,
      "step": 5669
    },
    {
      "epoch": 3.4156626506024095,
      "grad_norm": 0.7183695435523987,
      "learning_rate": 7.326807228915664e-07,
      "loss": 0.2685,
      "step": 5670
    },
    {
      "epoch": 3.416265060240964,
      "grad_norm": 0.67524653673172,
      "learning_rate": 7.319277108433735e-07,
      "loss": 0.225,
      "step": 5671
    },
    {
      "epoch": 3.4168674698795183,
      "grad_norm": 0.6499407887458801,
      "learning_rate": 7.311746987951808e-07,
      "loss": 0.2258,
      "step": 5672
    },
    {
      "epoch": 3.4174698795180722,
      "grad_norm": 0.6014948487281799,
      "learning_rate": 7.304216867469881e-07,
      "loss": 0.2181,
      "step": 5673
    },
    {
      "epoch": 3.4180722891566266,
      "grad_norm": 0.710176408290863,
      "learning_rate": 7.296686746987952e-07,
      "loss": 0.2579,
      "step": 5674
    },
    {
      "epoch": 3.4186746987951806,
      "grad_norm": 0.571748673915863,
      "learning_rate": 7.289156626506025e-07,
      "loss": 0.2213,
      "step": 5675
    },
    {
      "epoch": 3.419277108433735,
      "grad_norm": 0.5808070302009583,
      "learning_rate": 7.281626506024097e-07,
      "loss": 0.1993,
      "step": 5676
    },
    {
      "epoch": 3.419879518072289,
      "grad_norm": 0.74573814868927,
      "learning_rate": 7.274096385542169e-07,
      "loss": 0.2572,
      "step": 5677
    },
    {
      "epoch": 3.4204819277108434,
      "grad_norm": 0.6775930523872375,
      "learning_rate": 7.266566265060242e-07,
      "loss": 0.23,
      "step": 5678
    },
    {
      "epoch": 3.4210843373493978,
      "grad_norm": 6.719395160675049,
      "learning_rate": 7.259036144578315e-07,
      "loss": 0.2243,
      "step": 5679
    },
    {
      "epoch": 3.4216867469879517,
      "grad_norm": 0.6162102818489075,
      "learning_rate": 7.251506024096386e-07,
      "loss": 0.2477,
      "step": 5680
    },
    {
      "epoch": 3.422289156626506,
      "grad_norm": 0.675686240196228,
      "learning_rate": 7.243975903614458e-07,
      "loss": 0.2737,
      "step": 5681
    },
    {
      "epoch": 3.42289156626506,
      "grad_norm": 0.5893759727478027,
      "learning_rate": 7.236445783132531e-07,
      "loss": 0.2157,
      "step": 5682
    },
    {
      "epoch": 3.4234939759036145,
      "grad_norm": 0.5949205756187439,
      "learning_rate": 7.228915662650602e-07,
      "loss": 0.2531,
      "step": 5683
    },
    {
      "epoch": 3.4240963855421684,
      "grad_norm": 0.744749903678894,
      "learning_rate": 7.221385542168676e-07,
      "loss": 0.2545,
      "step": 5684
    },
    {
      "epoch": 3.424698795180723,
      "grad_norm": 0.559899628162384,
      "learning_rate": 7.213855421686748e-07,
      "loss": 0.2518,
      "step": 5685
    },
    {
      "epoch": 3.4253012048192772,
      "grad_norm": 0.5399686098098755,
      "learning_rate": 7.20632530120482e-07,
      "loss": 0.2237,
      "step": 5686
    },
    {
      "epoch": 3.425903614457831,
      "grad_norm": 0.6383747458457947,
      "learning_rate": 7.198795180722892e-07,
      "loss": 0.2576,
      "step": 5687
    },
    {
      "epoch": 3.4265060240963856,
      "grad_norm": 0.653704822063446,
      "learning_rate": 7.191265060240965e-07,
      "loss": 0.215,
      "step": 5688
    },
    {
      "epoch": 3.42710843373494,
      "grad_norm": 0.6510101556777954,
      "learning_rate": 7.183734939759037e-07,
      "loss": 0.2066,
      "step": 5689
    },
    {
      "epoch": 3.427710843373494,
      "grad_norm": 0.5940346121788025,
      "learning_rate": 7.176204819277109e-07,
      "loss": 0.2449,
      "step": 5690
    },
    {
      "epoch": 3.4283132530120484,
      "grad_norm": 0.6890468597412109,
      "learning_rate": 7.168674698795182e-07,
      "loss": 0.2604,
      "step": 5691
    },
    {
      "epoch": 3.4289156626506023,
      "grad_norm": 0.6259897947311401,
      "learning_rate": 7.161144578313253e-07,
      "loss": 0.2656,
      "step": 5692
    },
    {
      "epoch": 3.4295180722891567,
      "grad_norm": 0.7230246067047119,
      "learning_rate": 7.153614457831326e-07,
      "loss": 0.2257,
      "step": 5693
    },
    {
      "epoch": 3.4301204819277107,
      "grad_norm": 0.6931962966918945,
      "learning_rate": 7.146084337349399e-07,
      "loss": 0.2289,
      "step": 5694
    },
    {
      "epoch": 3.430722891566265,
      "grad_norm": 0.5410026907920837,
      "learning_rate": 7.13855421686747e-07,
      "loss": 0.2643,
      "step": 5695
    },
    {
      "epoch": 3.4313253012048195,
      "grad_norm": 0.5838910937309265,
      "learning_rate": 7.131024096385543e-07,
      "loss": 0.2019,
      "step": 5696
    },
    {
      "epoch": 3.4319277108433734,
      "grad_norm": 0.6133562922477722,
      "learning_rate": 7.123493975903616e-07,
      "loss": 0.1885,
      "step": 5697
    },
    {
      "epoch": 3.432530120481928,
      "grad_norm": 0.6255331635475159,
      "learning_rate": 7.115963855421688e-07,
      "loss": 0.1897,
      "step": 5698
    },
    {
      "epoch": 3.433132530120482,
      "grad_norm": 0.6079252362251282,
      "learning_rate": 7.10843373493976e-07,
      "loss": 0.2239,
      "step": 5699
    },
    {
      "epoch": 3.433734939759036,
      "grad_norm": 0.7538135647773743,
      "learning_rate": 7.100903614457832e-07,
      "loss": 0.3211,
      "step": 5700
    },
    {
      "epoch": 3.43433734939759,
      "grad_norm": 0.5417307019233704,
      "learning_rate": 7.093373493975904e-07,
      "loss": 0.238,
      "step": 5701
    },
    {
      "epoch": 3.4349397590361446,
      "grad_norm": 0.6738664507865906,
      "learning_rate": 7.085843373493976e-07,
      "loss": 0.295,
      "step": 5702
    },
    {
      "epoch": 3.435542168674699,
      "grad_norm": 0.7510374188423157,
      "learning_rate": 7.07831325301205e-07,
      "loss": 0.2112,
      "step": 5703
    },
    {
      "epoch": 3.436144578313253,
      "grad_norm": 0.693189263343811,
      "learning_rate": 7.070783132530121e-07,
      "loss": 0.2556,
      "step": 5704
    },
    {
      "epoch": 3.4367469879518073,
      "grad_norm": 0.5921676754951477,
      "learning_rate": 7.063253012048193e-07,
      "loss": 0.2206,
      "step": 5705
    },
    {
      "epoch": 3.4373493975903613,
      "grad_norm": 0.6322594285011292,
      "learning_rate": 7.055722891566266e-07,
      "loss": 0.2285,
      "step": 5706
    },
    {
      "epoch": 3.4379518072289157,
      "grad_norm": 0.6274979114532471,
      "learning_rate": 7.048192771084337e-07,
      "loss": 0.2781,
      "step": 5707
    },
    {
      "epoch": 3.4385542168674696,
      "grad_norm": 0.5833083987236023,
      "learning_rate": 7.040662650602411e-07,
      "loss": 0.2455,
      "step": 5708
    },
    {
      "epoch": 3.439156626506024,
      "grad_norm": 0.8319129943847656,
      "learning_rate": 7.033132530120483e-07,
      "loss": 0.1929,
      "step": 5709
    },
    {
      "epoch": 3.4397590361445785,
      "grad_norm": 0.5719918608665466,
      "learning_rate": 7.025602409638554e-07,
      "loss": 0.2355,
      "step": 5710
    },
    {
      "epoch": 3.4403614457831324,
      "grad_norm": 0.6918401122093201,
      "learning_rate": 7.018072289156627e-07,
      "loss": 0.2475,
      "step": 5711
    },
    {
      "epoch": 3.440963855421687,
      "grad_norm": 0.6040797829627991,
      "learning_rate": 7.0105421686747e-07,
      "loss": 0.2388,
      "step": 5712
    },
    {
      "epoch": 3.4415662650602408,
      "grad_norm": 0.6596565246582031,
      "learning_rate": 7.003012048192772e-07,
      "loss": 0.2613,
      "step": 5713
    },
    {
      "epoch": 3.442168674698795,
      "grad_norm": 0.651105523109436,
      "learning_rate": 6.995481927710844e-07,
      "loss": 0.2174,
      "step": 5714
    },
    {
      "epoch": 3.4427710843373496,
      "grad_norm": 0.7115989923477173,
      "learning_rate": 6.987951807228917e-07,
      "loss": 0.2516,
      "step": 5715
    },
    {
      "epoch": 3.4433734939759035,
      "grad_norm": 0.6477411985397339,
      "learning_rate": 6.980421686746988e-07,
      "loss": 0.2182,
      "step": 5716
    },
    {
      "epoch": 3.443975903614458,
      "grad_norm": 0.6124531626701355,
      "learning_rate": 6.97289156626506e-07,
      "loss": 0.3127,
      "step": 5717
    },
    {
      "epoch": 3.444578313253012,
      "grad_norm": 0.6670638918876648,
      "learning_rate": 6.965361445783134e-07,
      "loss": 0.2616,
      "step": 5718
    },
    {
      "epoch": 3.4451807228915663,
      "grad_norm": 0.6542385220527649,
      "learning_rate": 6.957831325301205e-07,
      "loss": 0.2576,
      "step": 5719
    },
    {
      "epoch": 3.4457831325301207,
      "grad_norm": 0.605582594871521,
      "learning_rate": 6.950301204819278e-07,
      "loss": 0.2323,
      "step": 5720
    },
    {
      "epoch": 3.4463855421686747,
      "grad_norm": 0.6052480340003967,
      "learning_rate": 6.94277108433735e-07,
      "loss": 0.1813,
      "step": 5721
    },
    {
      "epoch": 3.446987951807229,
      "grad_norm": 0.6093252897262573,
      "learning_rate": 6.935240963855421e-07,
      "loss": 0.2121,
      "step": 5722
    },
    {
      "epoch": 3.447590361445783,
      "grad_norm": 0.6477795243263245,
      "learning_rate": 6.927710843373495e-07,
      "loss": 0.223,
      "step": 5723
    },
    {
      "epoch": 3.4481927710843374,
      "grad_norm": 0.5937334895133972,
      "learning_rate": 6.920180722891567e-07,
      "loss": 0.2612,
      "step": 5724
    },
    {
      "epoch": 3.4487951807228914,
      "grad_norm": 0.5908938646316528,
      "learning_rate": 6.912650602409639e-07,
      "loss": 0.2329,
      "step": 5725
    },
    {
      "epoch": 3.4493975903614458,
      "grad_norm": 0.5727860927581787,
      "learning_rate": 6.905120481927711e-07,
      "loss": 0.2238,
      "step": 5726
    },
    {
      "epoch": 3.45,
      "grad_norm": 0.7063837647438049,
      "learning_rate": 6.897590361445785e-07,
      "loss": 0.2675,
      "step": 5727
    },
    {
      "epoch": 3.450602409638554,
      "grad_norm": 0.5494346022605896,
      "learning_rate": 6.890060240963856e-07,
      "loss": 0.2293,
      "step": 5728
    },
    {
      "epoch": 3.4512048192771085,
      "grad_norm": 0.5981898307800293,
      "learning_rate": 6.882530120481928e-07,
      "loss": 0.2308,
      "step": 5729
    },
    {
      "epoch": 3.4518072289156625,
      "grad_norm": 0.616172730922699,
      "learning_rate": 6.875000000000001e-07,
      "loss": 0.1889,
      "step": 5730
    },
    {
      "epoch": 3.452409638554217,
      "grad_norm": 0.6205232739448547,
      "learning_rate": 6.867469879518072e-07,
      "loss": 0.215,
      "step": 5731
    },
    {
      "epoch": 3.453012048192771,
      "grad_norm": 0.5962193012237549,
      "learning_rate": 6.859939759036146e-07,
      "loss": 0.2424,
      "step": 5732
    },
    {
      "epoch": 3.4536144578313253,
      "grad_norm": 0.5746405720710754,
      "learning_rate": 6.852409638554218e-07,
      "loss": 0.2618,
      "step": 5733
    },
    {
      "epoch": 3.4542168674698797,
      "grad_norm": 0.5526686906814575,
      "learning_rate": 6.84487951807229e-07,
      "loss": 0.1837,
      "step": 5734
    },
    {
      "epoch": 3.4548192771084336,
      "grad_norm": 0.7167919874191284,
      "learning_rate": 6.837349397590362e-07,
      "loss": 0.3467,
      "step": 5735
    },
    {
      "epoch": 3.455421686746988,
      "grad_norm": 0.6127782464027405,
      "learning_rate": 6.829819277108434e-07,
      "loss": 0.248,
      "step": 5736
    },
    {
      "epoch": 3.456024096385542,
      "grad_norm": 0.6505322456359863,
      "learning_rate": 6.822289156626506e-07,
      "loss": 0.2635,
      "step": 5737
    },
    {
      "epoch": 3.4566265060240964,
      "grad_norm": 0.6453145146369934,
      "learning_rate": 6.814759036144579e-07,
      "loss": 0.2014,
      "step": 5738
    },
    {
      "epoch": 3.457228915662651,
      "grad_norm": 0.5974470376968384,
      "learning_rate": 6.807228915662652e-07,
      "loss": 0.2239,
      "step": 5739
    },
    {
      "epoch": 3.4578313253012047,
      "grad_norm": 0.626982569694519,
      "learning_rate": 6.799698795180723e-07,
      "loss": 0.2707,
      "step": 5740
    },
    {
      "epoch": 3.458433734939759,
      "grad_norm": 0.6261764764785767,
      "learning_rate": 6.792168674698795e-07,
      "loss": 0.263,
      "step": 5741
    },
    {
      "epoch": 3.459036144578313,
      "grad_norm": 0.6237385869026184,
      "learning_rate": 6.784638554216869e-07,
      "loss": 0.2618,
      "step": 5742
    },
    {
      "epoch": 3.4596385542168675,
      "grad_norm": 0.5741864442825317,
      "learning_rate": 6.77710843373494e-07,
      "loss": 0.2004,
      "step": 5743
    },
    {
      "epoch": 3.460240963855422,
      "grad_norm": 0.6480135917663574,
      "learning_rate": 6.769578313253013e-07,
      "loss": 0.2628,
      "step": 5744
    },
    {
      "epoch": 3.460843373493976,
      "grad_norm": 0.5582969784736633,
      "learning_rate": 6.762048192771085e-07,
      "loss": 0.1908,
      "step": 5745
    },
    {
      "epoch": 3.4614457831325303,
      "grad_norm": 0.6633247137069702,
      "learning_rate": 6.754518072289157e-07,
      "loss": 0.2484,
      "step": 5746
    },
    {
      "epoch": 3.462048192771084,
      "grad_norm": 0.6314475536346436,
      "learning_rate": 6.74698795180723e-07,
      "loss": 0.2236,
      "step": 5747
    },
    {
      "epoch": 3.4626506024096386,
      "grad_norm": 0.5913751125335693,
      "learning_rate": 6.739457831325302e-07,
      "loss": 0.2526,
      "step": 5748
    },
    {
      "epoch": 3.4632530120481926,
      "grad_norm": 0.5782867074012756,
      "learning_rate": 6.731927710843374e-07,
      "loss": 0.2403,
      "step": 5749
    },
    {
      "epoch": 3.463855421686747,
      "grad_norm": 0.6545400023460388,
      "learning_rate": 6.724397590361446e-07,
      "loss": 0.2457,
      "step": 5750
    },
    {
      "epoch": 3.4644578313253014,
      "grad_norm": 0.557191789150238,
      "learning_rate": 6.716867469879519e-07,
      "loss": 0.2328,
      "step": 5751
    },
    {
      "epoch": 3.4650602409638553,
      "grad_norm": 0.5641355514526367,
      "learning_rate": 6.70933734939759e-07,
      "loss": 0.2367,
      "step": 5752
    },
    {
      "epoch": 3.4656626506024097,
      "grad_norm": 0.5922801494598389,
      "learning_rate": 6.701807228915663e-07,
      "loss": 0.2423,
      "step": 5753
    },
    {
      "epoch": 3.4662650602409637,
      "grad_norm": 0.4823647141456604,
      "learning_rate": 6.694277108433736e-07,
      "loss": 0.2062,
      "step": 5754
    },
    {
      "epoch": 3.466867469879518,
      "grad_norm": 0.6475037932395935,
      "learning_rate": 6.686746987951807e-07,
      "loss": 0.2012,
      "step": 5755
    },
    {
      "epoch": 3.467469879518072,
      "grad_norm": 0.5934068560600281,
      "learning_rate": 6.67921686746988e-07,
      "loss": 0.2087,
      "step": 5756
    },
    {
      "epoch": 3.4680722891566265,
      "grad_norm": 0.5708239674568176,
      "learning_rate": 6.671686746987953e-07,
      "loss": 0.2474,
      "step": 5757
    },
    {
      "epoch": 3.468674698795181,
      "grad_norm": 0.6222886443138123,
      "learning_rate": 6.664156626506025e-07,
      "loss": 0.2328,
      "step": 5758
    },
    {
      "epoch": 3.469277108433735,
      "grad_norm": 0.5596348643302917,
      "learning_rate": 6.656626506024097e-07,
      "loss": 0.2144,
      "step": 5759
    },
    {
      "epoch": 3.4698795180722892,
      "grad_norm": 0.6561126112937927,
      "learning_rate": 6.649096385542169e-07,
      "loss": 0.2842,
      "step": 5760
    },
    {
      "epoch": 3.470481927710843,
      "grad_norm": 0.6464396119117737,
      "learning_rate": 6.641566265060241e-07,
      "loss": 0.2159,
      "step": 5761
    },
    {
      "epoch": 3.4710843373493976,
      "grad_norm": 0.5424851179122925,
      "learning_rate": 6.634036144578314e-07,
      "loss": 0.208,
      "step": 5762
    },
    {
      "epoch": 3.471686746987952,
      "grad_norm": 0.5395544767379761,
      "learning_rate": 6.626506024096387e-07,
      "loss": 0.2194,
      "step": 5763
    },
    {
      "epoch": 3.472289156626506,
      "grad_norm": 0.627244234085083,
      "learning_rate": 6.618975903614458e-07,
      "loss": 0.2439,
      "step": 5764
    },
    {
      "epoch": 3.4728915662650603,
      "grad_norm": 0.5744998455047607,
      "learning_rate": 6.61144578313253e-07,
      "loss": 0.2009,
      "step": 5765
    },
    {
      "epoch": 3.4734939759036143,
      "grad_norm": 0.6377681493759155,
      "learning_rate": 6.603915662650604e-07,
      "loss": 0.2412,
      "step": 5766
    },
    {
      "epoch": 3.4740963855421687,
      "grad_norm": 0.631551206111908,
      "learning_rate": 6.596385542168675e-07,
      "loss": 0.2202,
      "step": 5767
    },
    {
      "epoch": 3.474698795180723,
      "grad_norm": 0.5554107427597046,
      "learning_rate": 6.588855421686748e-07,
      "loss": 0.2479,
      "step": 5768
    },
    {
      "epoch": 3.475301204819277,
      "grad_norm": 0.5929173827171326,
      "learning_rate": 6.58132530120482e-07,
      "loss": 0.2335,
      "step": 5769
    },
    {
      "epoch": 3.4759036144578315,
      "grad_norm": 0.5498242378234863,
      "learning_rate": 6.573795180722892e-07,
      "loss": 0.2022,
      "step": 5770
    },
    {
      "epoch": 3.4765060240963854,
      "grad_norm": 0.7136525511741638,
      "learning_rate": 6.566265060240964e-07,
      "loss": 0.2788,
      "step": 5771
    },
    {
      "epoch": 3.47710843373494,
      "grad_norm": 0.6531137228012085,
      "learning_rate": 6.558734939759037e-07,
      "loss": 0.2555,
      "step": 5772
    },
    {
      "epoch": 3.477710843373494,
      "grad_norm": 0.548387348651886,
      "learning_rate": 6.551204819277109e-07,
      "loss": 0.2022,
      "step": 5773
    },
    {
      "epoch": 3.478313253012048,
      "grad_norm": 0.6702755689620972,
      "learning_rate": 6.543674698795181e-07,
      "loss": 0.254,
      "step": 5774
    },
    {
      "epoch": 3.4789156626506026,
      "grad_norm": 1.057377576828003,
      "learning_rate": 6.536144578313254e-07,
      "loss": 0.2039,
      "step": 5775
    },
    {
      "epoch": 3.4795180722891565,
      "grad_norm": 0.640406608581543,
      "learning_rate": 6.528614457831325e-07,
      "loss": 0.2807,
      "step": 5776
    },
    {
      "epoch": 3.480120481927711,
      "grad_norm": 0.5415136218070984,
      "learning_rate": 6.521084337349399e-07,
      "loss": 0.1999,
      "step": 5777
    },
    {
      "epoch": 3.480722891566265,
      "grad_norm": 0.5995690822601318,
      "learning_rate": 6.513554216867471e-07,
      "loss": 0.2729,
      "step": 5778
    },
    {
      "epoch": 3.4813253012048193,
      "grad_norm": 0.7603762149810791,
      "learning_rate": 6.506024096385542e-07,
      "loss": 0.2607,
      "step": 5779
    },
    {
      "epoch": 3.4819277108433733,
      "grad_norm": 0.5647261738777161,
      "learning_rate": 6.498493975903615e-07,
      "loss": 0.2246,
      "step": 5780
    },
    {
      "epoch": 3.4825301204819277,
      "grad_norm": 0.6000229716300964,
      "learning_rate": 6.490963855421688e-07,
      "loss": 0.2937,
      "step": 5781
    },
    {
      "epoch": 3.483132530120482,
      "grad_norm": 0.5315688252449036,
      "learning_rate": 6.48343373493976e-07,
      "loss": 0.1915,
      "step": 5782
    },
    {
      "epoch": 3.483734939759036,
      "grad_norm": 0.5673438906669617,
      "learning_rate": 6.475903614457832e-07,
      "loss": 0.2253,
      "step": 5783
    },
    {
      "epoch": 3.4843373493975904,
      "grad_norm": 0.6197393536567688,
      "learning_rate": 6.468373493975904e-07,
      "loss": 0.2469,
      "step": 5784
    },
    {
      "epoch": 3.4849397590361444,
      "grad_norm": 0.57905513048172,
      "learning_rate": 6.460843373493976e-07,
      "loss": 0.2188,
      "step": 5785
    },
    {
      "epoch": 3.485542168674699,
      "grad_norm": 0.6691941022872925,
      "learning_rate": 6.453313253012049e-07,
      "loss": 0.299,
      "step": 5786
    },
    {
      "epoch": 3.486144578313253,
      "grad_norm": 0.6245282888412476,
      "learning_rate": 6.445783132530122e-07,
      "loss": 0.2573,
      "step": 5787
    },
    {
      "epoch": 3.486746987951807,
      "grad_norm": 0.5954912900924683,
      "learning_rate": 6.438253012048193e-07,
      "loss": 0.1889,
      "step": 5788
    },
    {
      "epoch": 3.4873493975903616,
      "grad_norm": 0.6608679294586182,
      "learning_rate": 6.430722891566265e-07,
      "loss": 0.2914,
      "step": 5789
    },
    {
      "epoch": 3.4879518072289155,
      "grad_norm": 0.5805898308753967,
      "learning_rate": 6.423192771084338e-07,
      "loss": 0.2241,
      "step": 5790
    },
    {
      "epoch": 3.48855421686747,
      "grad_norm": 0.5436156988143921,
      "learning_rate": 6.415662650602409e-07,
      "loss": 0.227,
      "step": 5791
    },
    {
      "epoch": 3.4891566265060243,
      "grad_norm": 0.6385448575019836,
      "learning_rate": 6.408132530120483e-07,
      "loss": 0.2395,
      "step": 5792
    },
    {
      "epoch": 3.4897590361445783,
      "grad_norm": 0.6527423858642578,
      "learning_rate": 6.400602409638555e-07,
      "loss": 0.2876,
      "step": 5793
    },
    {
      "epoch": 3.4903614457831327,
      "grad_norm": 0.5239158272743225,
      "learning_rate": 6.393072289156627e-07,
      "loss": 0.2064,
      "step": 5794
    },
    {
      "epoch": 3.4909638554216866,
      "grad_norm": 0.628440797328949,
      "learning_rate": 6.385542168674699e-07,
      "loss": 0.2271,
      "step": 5795
    },
    {
      "epoch": 3.491566265060241,
      "grad_norm": 0.644817054271698,
      "learning_rate": 6.378012048192772e-07,
      "loss": 0.261,
      "step": 5796
    },
    {
      "epoch": 3.492168674698795,
      "grad_norm": 0.5560671091079712,
      "learning_rate": 6.370481927710844e-07,
      "loss": 0.2077,
      "step": 5797
    },
    {
      "epoch": 3.4927710843373494,
      "grad_norm": 0.5835533738136292,
      "learning_rate": 6.362951807228916e-07,
      "loss": 0.2781,
      "step": 5798
    },
    {
      "epoch": 3.493373493975904,
      "grad_norm": 0.6573776602745056,
      "learning_rate": 6.355421686746989e-07,
      "loss": 0.2493,
      "step": 5799
    },
    {
      "epoch": 3.4939759036144578,
      "grad_norm": 0.6165353655815125,
      "learning_rate": 6.34789156626506e-07,
      "loss": 0.2434,
      "step": 5800
    },
    {
      "epoch": 3.494578313253012,
      "grad_norm": 0.6274452209472656,
      "learning_rate": 6.340361445783134e-07,
      "loss": 0.2572,
      "step": 5801
    },
    {
      "epoch": 3.495180722891566,
      "grad_norm": 0.6172385811805725,
      "learning_rate": 6.332831325301206e-07,
      "loss": 0.2949,
      "step": 5802
    },
    {
      "epoch": 3.4957831325301205,
      "grad_norm": 0.5899211764335632,
      "learning_rate": 6.325301204819277e-07,
      "loss": 0.2136,
      "step": 5803
    },
    {
      "epoch": 3.4963855421686745,
      "grad_norm": 0.5144281983375549,
      "learning_rate": 6.31777108433735e-07,
      "loss": 0.2116,
      "step": 5804
    },
    {
      "epoch": 3.496987951807229,
      "grad_norm": 0.6228379011154175,
      "learning_rate": 6.310240963855422e-07,
      "loss": 0.2731,
      "step": 5805
    },
    {
      "epoch": 3.4975903614457833,
      "grad_norm": 0.6204511523246765,
      "learning_rate": 6.302710843373494e-07,
      "loss": 0.2945,
      "step": 5806
    },
    {
      "epoch": 3.4981927710843372,
      "grad_norm": 0.5608797669410706,
      "learning_rate": 6.295180722891567e-07,
      "loss": 0.2238,
      "step": 5807
    },
    {
      "epoch": 3.4987951807228916,
      "grad_norm": 0.5724847316741943,
      "learning_rate": 6.287650602409639e-07,
      "loss": 0.1989,
      "step": 5808
    },
    {
      "epoch": 3.4993975903614456,
      "grad_norm": 0.5496184229850769,
      "learning_rate": 6.280120481927711e-07,
      "loss": 0.2123,
      "step": 5809
    },
    {
      "epoch": 3.5,
      "grad_norm": 0.6025842428207397,
      "learning_rate": 6.272590361445783e-07,
      "loss": 0.2224,
      "step": 5810
    },
    {
      "epoch": 3.500602409638554,
      "grad_norm": 0.5277771949768066,
      "learning_rate": 6.265060240963857e-07,
      "loss": 0.1858,
      "step": 5811
    },
    {
      "epoch": 3.5012048192771084,
      "grad_norm": 0.5637776255607605,
      "learning_rate": 6.257530120481928e-07,
      "loss": 0.1975,
      "step": 5812
    },
    {
      "epoch": 3.5018072289156628,
      "grad_norm": 0.5121724605560303,
      "learning_rate": 6.25e-07,
      "loss": 0.1936,
      "step": 5813
    },
    {
      "epoch": 3.5024096385542167,
      "grad_norm": 0.5176687240600586,
      "learning_rate": 6.242469879518073e-07,
      "loss": 0.2224,
      "step": 5814
    },
    {
      "epoch": 3.503012048192771,
      "grad_norm": 0.5617456436157227,
      "learning_rate": 6.234939759036145e-07,
      "loss": 0.2145,
      "step": 5815
    },
    {
      "epoch": 3.5036144578313255,
      "grad_norm": 0.6276901364326477,
      "learning_rate": 6.227409638554218e-07,
      "loss": 0.2201,
      "step": 5816
    },
    {
      "epoch": 3.5042168674698795,
      "grad_norm": 0.538088321685791,
      "learning_rate": 6.219879518072289e-07,
      "loss": 0.198,
      "step": 5817
    },
    {
      "epoch": 3.504819277108434,
      "grad_norm": 1.1834415197372437,
      "learning_rate": 6.212349397590363e-07,
      "loss": 0.2655,
      "step": 5818
    },
    {
      "epoch": 3.505421686746988,
      "grad_norm": 0.5897021889686584,
      "learning_rate": 6.204819277108434e-07,
      "loss": 0.2377,
      "step": 5819
    },
    {
      "epoch": 3.5060240963855422,
      "grad_norm": 0.5267965197563171,
      "learning_rate": 6.197289156626506e-07,
      "loss": 0.2093,
      "step": 5820
    },
    {
      "epoch": 3.506626506024096,
      "grad_norm": 0.5563318133354187,
      "learning_rate": 6.189759036144579e-07,
      "loss": 0.2213,
      "step": 5821
    },
    {
      "epoch": 3.5072289156626506,
      "grad_norm": 0.5581346154212952,
      "learning_rate": 6.182228915662651e-07,
      "loss": 0.2204,
      "step": 5822
    },
    {
      "epoch": 3.507831325301205,
      "grad_norm": 0.6250479817390442,
      "learning_rate": 6.174698795180723e-07,
      "loss": 0.1972,
      "step": 5823
    },
    {
      "epoch": 3.508433734939759,
      "grad_norm": 0.5205838084220886,
      "learning_rate": 6.167168674698796e-07,
      "loss": 0.2025,
      "step": 5824
    },
    {
      "epoch": 3.5090361445783134,
      "grad_norm": 0.581666886806488,
      "learning_rate": 6.159638554216867e-07,
      "loss": 0.2397,
      "step": 5825
    },
    {
      "epoch": 3.5096385542168673,
      "grad_norm": 0.5240224003791809,
      "learning_rate": 6.15210843373494e-07,
      "loss": 0.2137,
      "step": 5826
    },
    {
      "epoch": 3.5102409638554217,
      "grad_norm": 0.5686402916908264,
      "learning_rate": 6.144578313253012e-07,
      "loss": 0.2239,
      "step": 5827
    },
    {
      "epoch": 3.5108433734939757,
      "grad_norm": 0.6087338924407959,
      "learning_rate": 6.137048192771085e-07,
      "loss": 0.2643,
      "step": 5828
    },
    {
      "epoch": 3.51144578313253,
      "grad_norm": 0.7485793828964233,
      "learning_rate": 6.129518072289157e-07,
      "loss": 0.2525,
      "step": 5829
    },
    {
      "epoch": 3.5120481927710845,
      "grad_norm": 0.6154823899269104,
      "learning_rate": 6.12198795180723e-07,
      "loss": 0.2395,
      "step": 5830
    },
    {
      "epoch": 3.5126506024096384,
      "grad_norm": 0.5779367685317993,
      "learning_rate": 6.114457831325302e-07,
      "loss": 0.2232,
      "step": 5831
    },
    {
      "epoch": 3.513253012048193,
      "grad_norm": 0.6301184892654419,
      "learning_rate": 6.106927710843373e-07,
      "loss": 0.2084,
      "step": 5832
    },
    {
      "epoch": 3.5138554216867472,
      "grad_norm": 0.5816925168037415,
      "learning_rate": 6.099397590361447e-07,
      "loss": 0.2156,
      "step": 5833
    },
    {
      "epoch": 3.514457831325301,
      "grad_norm": 0.5460559725761414,
      "learning_rate": 6.091867469879518e-07,
      "loss": 0.2491,
      "step": 5834
    },
    {
      "epoch": 3.515060240963855,
      "grad_norm": 0.5500957369804382,
      "learning_rate": 6.084337349397591e-07,
      "loss": 0.2095,
      "step": 5835
    },
    {
      "epoch": 3.5156626506024096,
      "grad_norm": 0.8469275832176208,
      "learning_rate": 6.076807228915663e-07,
      "loss": 0.2424,
      "step": 5836
    },
    {
      "epoch": 3.516265060240964,
      "grad_norm": 0.5349922180175781,
      "learning_rate": 6.069277108433736e-07,
      "loss": 0.1982,
      "step": 5837
    },
    {
      "epoch": 3.516867469879518,
      "grad_norm": 0.601000964641571,
      "learning_rate": 6.061746987951808e-07,
      "loss": 0.2529,
      "step": 5838
    },
    {
      "epoch": 3.5174698795180723,
      "grad_norm": 0.5752898454666138,
      "learning_rate": 6.05421686746988e-07,
      "loss": 0.2674,
      "step": 5839
    },
    {
      "epoch": 3.5180722891566267,
      "grad_norm": 0.5985049605369568,
      "learning_rate": 6.046686746987952e-07,
      "loss": 0.2152,
      "step": 5840
    },
    {
      "epoch": 3.5186746987951807,
      "grad_norm": 0.5777679681777954,
      "learning_rate": 6.039156626506024e-07,
      "loss": 0.2011,
      "step": 5841
    },
    {
      "epoch": 3.519277108433735,
      "grad_norm": 0.5912371277809143,
      "learning_rate": 6.031626506024097e-07,
      "loss": 0.2111,
      "step": 5842
    },
    {
      "epoch": 3.519879518072289,
      "grad_norm": 0.5320109724998474,
      "learning_rate": 6.024096385542169e-07,
      "loss": 0.2063,
      "step": 5843
    },
    {
      "epoch": 3.5204819277108435,
      "grad_norm": 0.5445524454116821,
      "learning_rate": 6.016566265060241e-07,
      "loss": 0.2412,
      "step": 5844
    },
    {
      "epoch": 3.5210843373493974,
      "grad_norm": 0.5715729594230652,
      "learning_rate": 6.009036144578314e-07,
      "loss": 0.2024,
      "step": 5845
    },
    {
      "epoch": 3.521686746987952,
      "grad_norm": 0.5617504715919495,
      "learning_rate": 6.001506024096386e-07,
      "loss": 0.2099,
      "step": 5846
    },
    {
      "epoch": 3.522289156626506,
      "grad_norm": 1.097030520439148,
      "learning_rate": 5.993975903614458e-07,
      "loss": 0.2948,
      "step": 5847
    },
    {
      "epoch": 3.52289156626506,
      "grad_norm": 0.6267825365066528,
      "learning_rate": 5.986445783132531e-07,
      "loss": 0.2439,
      "step": 5848
    },
    {
      "epoch": 3.5234939759036146,
      "grad_norm": 0.5981611013412476,
      "learning_rate": 5.978915662650603e-07,
      "loss": 0.2883,
      "step": 5849
    },
    {
      "epoch": 3.5240963855421685,
      "grad_norm": 0.49099937081336975,
      "learning_rate": 5.971385542168675e-07,
      "loss": 0.1666,
      "step": 5850
    },
    {
      "epoch": 3.524698795180723,
      "grad_norm": 0.553501307964325,
      "learning_rate": 5.963855421686747e-07,
      "loss": 0.23,
      "step": 5851
    },
    {
      "epoch": 3.525301204819277,
      "grad_norm": 0.5949428081512451,
      "learning_rate": 5.95632530120482e-07,
      "loss": 0.2537,
      "step": 5852
    },
    {
      "epoch": 3.5259036144578313,
      "grad_norm": 0.6132751703262329,
      "learning_rate": 5.948795180722892e-07,
      "loss": 0.2337,
      "step": 5853
    },
    {
      "epoch": 3.5265060240963857,
      "grad_norm": 0.6620480418205261,
      "learning_rate": 5.941265060240965e-07,
      "loss": 0.2251,
      "step": 5854
    },
    {
      "epoch": 3.5271084337349397,
      "grad_norm": 0.6169425845146179,
      "learning_rate": 5.933734939759037e-07,
      "loss": 0.2767,
      "step": 5855
    },
    {
      "epoch": 3.527710843373494,
      "grad_norm": 0.6635388731956482,
      "learning_rate": 5.926204819277108e-07,
      "loss": 0.2653,
      "step": 5856
    },
    {
      "epoch": 3.5283132530120485,
      "grad_norm": 0.53709477186203,
      "learning_rate": 5.918674698795181e-07,
      "loss": 0.1728,
      "step": 5857
    },
    {
      "epoch": 3.5289156626506024,
      "grad_norm": 0.5483604669570923,
      "learning_rate": 5.911144578313253e-07,
      "loss": 0.2026,
      "step": 5858
    },
    {
      "epoch": 3.5295180722891564,
      "grad_norm": 0.5686277747154236,
      "learning_rate": 5.903614457831326e-07,
      "loss": 0.251,
      "step": 5859
    },
    {
      "epoch": 3.5301204819277108,
      "grad_norm": 0.6064891219139099,
      "learning_rate": 5.896084337349398e-07,
      "loss": 0.2339,
      "step": 5860
    },
    {
      "epoch": 3.530722891566265,
      "grad_norm": 0.6654832363128662,
      "learning_rate": 5.888554216867471e-07,
      "loss": 0.2561,
      "step": 5861
    },
    {
      "epoch": 3.531325301204819,
      "grad_norm": 0.5586887001991272,
      "learning_rate": 5.881024096385542e-07,
      "loss": 0.2157,
      "step": 5862
    },
    {
      "epoch": 3.5319277108433735,
      "grad_norm": 0.7328075766563416,
      "learning_rate": 5.873493975903615e-07,
      "loss": 0.29,
      "step": 5863
    },
    {
      "epoch": 3.532530120481928,
      "grad_norm": 0.5873900651931763,
      "learning_rate": 5.865963855421687e-07,
      "loss": 0.2703,
      "step": 5864
    },
    {
      "epoch": 3.533132530120482,
      "grad_norm": 0.5523403882980347,
      "learning_rate": 5.858433734939759e-07,
      "loss": 0.1877,
      "step": 5865
    },
    {
      "epoch": 3.5337349397590363,
      "grad_norm": 0.5524805784225464,
      "learning_rate": 5.850903614457832e-07,
      "loss": 0.2444,
      "step": 5866
    },
    {
      "epoch": 3.5343373493975903,
      "grad_norm": 0.49955976009368896,
      "learning_rate": 5.843373493975904e-07,
      "loss": 0.1792,
      "step": 5867
    },
    {
      "epoch": 3.5349397590361447,
      "grad_norm": 0.6313786506652832,
      "learning_rate": 5.835843373493976e-07,
      "loss": 0.2461,
      "step": 5868
    },
    {
      "epoch": 3.5355421686746986,
      "grad_norm": 0.5743398070335388,
      "learning_rate": 5.828313253012049e-07,
      "loss": 0.2346,
      "step": 5869
    },
    {
      "epoch": 3.536144578313253,
      "grad_norm": 0.5315790772438049,
      "learning_rate": 5.820783132530121e-07,
      "loss": 0.2223,
      "step": 5870
    },
    {
      "epoch": 3.5367469879518074,
      "grad_norm": 0.8237851858139038,
      "learning_rate": 5.813253012048193e-07,
      "loss": 0.2645,
      "step": 5871
    },
    {
      "epoch": 3.5373493975903614,
      "grad_norm": 0.5652778148651123,
      "learning_rate": 5.805722891566266e-07,
      "loss": 0.1989,
      "step": 5872
    },
    {
      "epoch": 3.537951807228916,
      "grad_norm": 0.6875870823860168,
      "learning_rate": 5.798192771084338e-07,
      "loss": 0.2543,
      "step": 5873
    },
    {
      "epoch": 3.5385542168674697,
      "grad_norm": 0.567614734172821,
      "learning_rate": 5.79066265060241e-07,
      "loss": 0.2381,
      "step": 5874
    },
    {
      "epoch": 3.539156626506024,
      "grad_norm": 0.5737734436988831,
      "learning_rate": 5.783132530120482e-07,
      "loss": 0.2477,
      "step": 5875
    },
    {
      "epoch": 3.539759036144578,
      "grad_norm": 0.5197315812110901,
      "learning_rate": 5.775602409638555e-07,
      "loss": 0.2327,
      "step": 5876
    },
    {
      "epoch": 3.5403614457831325,
      "grad_norm": 0.5328311920166016,
      "learning_rate": 5.768072289156626e-07,
      "loss": 0.2144,
      "step": 5877
    },
    {
      "epoch": 3.540963855421687,
      "grad_norm": 0.5738335251808167,
      "learning_rate": 5.7605421686747e-07,
      "loss": 0.2225,
      "step": 5878
    },
    {
      "epoch": 3.541566265060241,
      "grad_norm": 0.5415815114974976,
      "learning_rate": 5.753012048192771e-07,
      "loss": 0.2557,
      "step": 5879
    },
    {
      "epoch": 3.5421686746987953,
      "grad_norm": 0.6393153667449951,
      "learning_rate": 5.745481927710843e-07,
      "loss": 0.2702,
      "step": 5880
    },
    {
      "epoch": 3.5427710843373497,
      "grad_norm": 0.5957725644111633,
      "learning_rate": 5.737951807228916e-07,
      "loss": 0.2528,
      "step": 5881
    },
    {
      "epoch": 3.5433734939759036,
      "grad_norm": 0.6057679057121277,
      "learning_rate": 5.730421686746988e-07,
      "loss": 0.2191,
      "step": 5882
    },
    {
      "epoch": 3.5439759036144576,
      "grad_norm": 0.583077609539032,
      "learning_rate": 5.722891566265061e-07,
      "loss": 0.2397,
      "step": 5883
    },
    {
      "epoch": 3.544578313253012,
      "grad_norm": 0.6250572204589844,
      "learning_rate": 5.715361445783133e-07,
      "loss": 0.2573,
      "step": 5884
    },
    {
      "epoch": 3.5451807228915664,
      "grad_norm": 0.5850579142570496,
      "learning_rate": 5.707831325301206e-07,
      "loss": 0.2483,
      "step": 5885
    },
    {
      "epoch": 3.5457831325301203,
      "grad_norm": 0.6097108125686646,
      "learning_rate": 5.700301204819277e-07,
      "loss": 0.2685,
      "step": 5886
    },
    {
      "epoch": 3.5463855421686747,
      "grad_norm": 0.5928585529327393,
      "learning_rate": 5.69277108433735e-07,
      "loss": 0.2542,
      "step": 5887
    },
    {
      "epoch": 3.546987951807229,
      "grad_norm": 0.9479601979255676,
      "learning_rate": 5.685240963855422e-07,
      "loss": 0.2071,
      "step": 5888
    },
    {
      "epoch": 3.547590361445783,
      "grad_norm": 0.6141074895858765,
      "learning_rate": 5.677710843373494e-07,
      "loss": 0.2712,
      "step": 5889
    },
    {
      "epoch": 3.5481927710843375,
      "grad_norm": 0.5797693133354187,
      "learning_rate": 5.670180722891567e-07,
      "loss": 0.2123,
      "step": 5890
    },
    {
      "epoch": 3.5487951807228915,
      "grad_norm": 0.5193167924880981,
      "learning_rate": 5.662650602409639e-07,
      "loss": 0.2084,
      "step": 5891
    },
    {
      "epoch": 3.549397590361446,
      "grad_norm": 0.6445576548576355,
      "learning_rate": 5.655120481927712e-07,
      "loss": 0.2406,
      "step": 5892
    },
    {
      "epoch": 3.55,
      "grad_norm": 0.5928071737289429,
      "learning_rate": 5.647590361445784e-07,
      "loss": 0.2449,
      "step": 5893
    },
    {
      "epoch": 3.5506024096385542,
      "grad_norm": 0.6861808896064758,
      "learning_rate": 5.640060240963855e-07,
      "loss": 0.2878,
      "step": 5894
    },
    {
      "epoch": 3.5512048192771086,
      "grad_norm": 0.5893197059631348,
      "learning_rate": 5.632530120481928e-07,
      "loss": 0.2697,
      "step": 5895
    },
    {
      "epoch": 3.5518072289156626,
      "grad_norm": 0.5493655204772949,
      "learning_rate": 5.625e-07,
      "loss": 0.2182,
      "step": 5896
    },
    {
      "epoch": 3.552409638554217,
      "grad_norm": 0.6628054976463318,
      "learning_rate": 5.617469879518073e-07,
      "loss": 0.3454,
      "step": 5897
    },
    {
      "epoch": 3.553012048192771,
      "grad_norm": 0.530325710773468,
      "learning_rate": 5.609939759036145e-07,
      "loss": 0.2139,
      "step": 5898
    },
    {
      "epoch": 3.5536144578313253,
      "grad_norm": 0.6304166913032532,
      "learning_rate": 5.602409638554217e-07,
      "loss": 0.2171,
      "step": 5899
    },
    {
      "epoch": 3.5542168674698793,
      "grad_norm": 0.6039038896560669,
      "learning_rate": 5.59487951807229e-07,
      "loss": 0.2292,
      "step": 5900
    },
    {
      "epoch": 3.5548192771084337,
      "grad_norm": 0.5692105889320374,
      "learning_rate": 5.587349397590361e-07,
      "loss": 0.2533,
      "step": 5901
    },
    {
      "epoch": 3.555421686746988,
      "grad_norm": 0.5753409266471863,
      "learning_rate": 5.579819277108435e-07,
      "loss": 0.2613,
      "step": 5902
    },
    {
      "epoch": 3.556024096385542,
      "grad_norm": 0.6234985589981079,
      "learning_rate": 5.572289156626506e-07,
      "loss": 0.2158,
      "step": 5903
    },
    {
      "epoch": 3.5566265060240965,
      "grad_norm": 0.6113038063049316,
      "learning_rate": 5.564759036144578e-07,
      "loss": 0.2222,
      "step": 5904
    },
    {
      "epoch": 3.557228915662651,
      "grad_norm": 0.60397869348526,
      "learning_rate": 5.557228915662651e-07,
      "loss": 0.2388,
      "step": 5905
    },
    {
      "epoch": 3.557831325301205,
      "grad_norm": 0.5839128494262695,
      "learning_rate": 5.549698795180723e-07,
      "loss": 0.2019,
      "step": 5906
    },
    {
      "epoch": 3.558433734939759,
      "grad_norm": 0.6023313403129578,
      "learning_rate": 5.542168674698796e-07,
      "loss": 0.1974,
      "step": 5907
    },
    {
      "epoch": 3.559036144578313,
      "grad_norm": 0.5936350226402283,
      "learning_rate": 5.534638554216868e-07,
      "loss": 0.2278,
      "step": 5908
    },
    {
      "epoch": 3.5596385542168676,
      "grad_norm": 0.5306086540222168,
      "learning_rate": 5.527108433734941e-07,
      "loss": 0.2017,
      "step": 5909
    },
    {
      "epoch": 3.5602409638554215,
      "grad_norm": 0.5105878710746765,
      "learning_rate": 5.519578313253012e-07,
      "loss": 0.1961,
      "step": 5910
    },
    {
      "epoch": 3.560843373493976,
      "grad_norm": 0.5358631610870361,
      "learning_rate": 5.512048192771084e-07,
      "loss": 0.1833,
      "step": 5911
    },
    {
      "epoch": 3.5614457831325304,
      "grad_norm": 0.6086709499359131,
      "learning_rate": 5.504518072289157e-07,
      "loss": 0.2209,
      "step": 5912
    },
    {
      "epoch": 3.5620481927710843,
      "grad_norm": 0.5693867206573486,
      "learning_rate": 5.496987951807229e-07,
      "loss": 0.2348,
      "step": 5913
    },
    {
      "epoch": 3.5626506024096387,
      "grad_norm": 0.5944000482559204,
      "learning_rate": 5.489457831325302e-07,
      "loss": 0.1976,
      "step": 5914
    },
    {
      "epoch": 3.5632530120481927,
      "grad_norm": 0.5785903334617615,
      "learning_rate": 5.481927710843374e-07,
      "loss": 0.2004,
      "step": 5915
    },
    {
      "epoch": 3.563855421686747,
      "grad_norm": 0.5027782320976257,
      "learning_rate": 5.474397590361445e-07,
      "loss": 0.1756,
      "step": 5916
    },
    {
      "epoch": 3.564457831325301,
      "grad_norm": 0.6400183439254761,
      "learning_rate": 5.466867469879519e-07,
      "loss": 0.1921,
      "step": 5917
    },
    {
      "epoch": 3.5650602409638554,
      "grad_norm": 0.5308400988578796,
      "learning_rate": 5.45933734939759e-07,
      "loss": 0.1995,
      "step": 5918
    },
    {
      "epoch": 3.56566265060241,
      "grad_norm": 0.6081380844116211,
      "learning_rate": 5.451807228915664e-07,
      "loss": 0.2016,
      "step": 5919
    },
    {
      "epoch": 3.566265060240964,
      "grad_norm": 0.5699024200439453,
      "learning_rate": 5.444277108433735e-07,
      "loss": 0.2568,
      "step": 5920
    },
    {
      "epoch": 3.566867469879518,
      "grad_norm": 0.5162636637687683,
      "learning_rate": 5.436746987951808e-07,
      "loss": 0.2394,
      "step": 5921
    },
    {
      "epoch": 3.567469879518072,
      "grad_norm": 0.6487014293670654,
      "learning_rate": 5.42921686746988e-07,
      "loss": 0.2277,
      "step": 5922
    },
    {
      "epoch": 3.5680722891566266,
      "grad_norm": 0.5749929547309875,
      "learning_rate": 5.421686746987952e-07,
      "loss": 0.2355,
      "step": 5923
    },
    {
      "epoch": 3.5686746987951805,
      "grad_norm": 0.5773779153823853,
      "learning_rate": 5.414156626506025e-07,
      "loss": 0.2202,
      "step": 5924
    },
    {
      "epoch": 3.569277108433735,
      "grad_norm": 0.553223192691803,
      "learning_rate": 5.406626506024097e-07,
      "loss": 0.2001,
      "step": 5925
    },
    {
      "epoch": 3.5698795180722893,
      "grad_norm": 0.6660017371177673,
      "learning_rate": 5.39909638554217e-07,
      "loss": 0.2735,
      "step": 5926
    },
    {
      "epoch": 3.5704819277108433,
      "grad_norm": 0.5893004536628723,
      "learning_rate": 5.391566265060241e-07,
      "loss": 0.2654,
      "step": 5927
    },
    {
      "epoch": 3.5710843373493977,
      "grad_norm": 0.5165941119194031,
      "learning_rate": 5.384036144578314e-07,
      "loss": 0.182,
      "step": 5928
    },
    {
      "epoch": 3.571686746987952,
      "grad_norm": 0.613955557346344,
      "learning_rate": 5.376506024096386e-07,
      "loss": 0.278,
      "step": 5929
    },
    {
      "epoch": 3.572289156626506,
      "grad_norm": 0.5989885926246643,
      "learning_rate": 5.368975903614458e-07,
      "loss": 0.2261,
      "step": 5930
    },
    {
      "epoch": 3.57289156626506,
      "grad_norm": 0.5995867848396301,
      "learning_rate": 5.361445783132531e-07,
      "loss": 0.2159,
      "step": 5931
    },
    {
      "epoch": 3.5734939759036144,
      "grad_norm": 0.6311723589897156,
      "learning_rate": 5.353915662650603e-07,
      "loss": 0.2025,
      "step": 5932
    },
    {
      "epoch": 3.574096385542169,
      "grad_norm": 0.5719785690307617,
      "learning_rate": 5.346385542168675e-07,
      "loss": 0.1945,
      "step": 5933
    },
    {
      "epoch": 3.5746987951807228,
      "grad_norm": 0.6390679478645325,
      "learning_rate": 5.338855421686748e-07,
      "loss": 0.2319,
      "step": 5934
    },
    {
      "epoch": 3.575301204819277,
      "grad_norm": 0.601629376411438,
      "learning_rate": 5.331325301204819e-07,
      "loss": 0.229,
      "step": 5935
    },
    {
      "epoch": 3.5759036144578316,
      "grad_norm": 0.5730005502700806,
      "learning_rate": 5.323795180722892e-07,
      "loss": 0.1848,
      "step": 5936
    },
    {
      "epoch": 3.5765060240963855,
      "grad_norm": 0.5323200225830078,
      "learning_rate": 5.316265060240964e-07,
      "loss": 0.1884,
      "step": 5937
    },
    {
      "epoch": 3.57710843373494,
      "grad_norm": 0.6161383390426636,
      "learning_rate": 5.308734939759037e-07,
      "loss": 0.234,
      "step": 5938
    },
    {
      "epoch": 3.577710843373494,
      "grad_norm": 0.5352950692176819,
      "learning_rate": 5.301204819277109e-07,
      "loss": 0.1995,
      "step": 5939
    },
    {
      "epoch": 3.5783132530120483,
      "grad_norm": 0.6768661141395569,
      "learning_rate": 5.293674698795182e-07,
      "loss": 0.2493,
      "step": 5940
    },
    {
      "epoch": 3.5789156626506022,
      "grad_norm": 0.6760388612747192,
      "learning_rate": 5.286144578313254e-07,
      "loss": 0.2202,
      "step": 5941
    },
    {
      "epoch": 3.5795180722891566,
      "grad_norm": 0.5738533735275269,
      "learning_rate": 5.278614457831325e-07,
      "loss": 0.2423,
      "step": 5942
    },
    {
      "epoch": 3.580120481927711,
      "grad_norm": 0.5129070281982422,
      "learning_rate": 5.271084337349399e-07,
      "loss": 0.2009,
      "step": 5943
    },
    {
      "epoch": 3.580722891566265,
      "grad_norm": 0.6169455647468567,
      "learning_rate": 5.26355421686747e-07,
      "loss": 0.2236,
      "step": 5944
    },
    {
      "epoch": 3.5813253012048194,
      "grad_norm": 0.4994966685771942,
      "learning_rate": 5.256024096385543e-07,
      "loss": 0.205,
      "step": 5945
    },
    {
      "epoch": 3.5819277108433734,
      "grad_norm": 0.5852400660514832,
      "learning_rate": 5.248493975903615e-07,
      "loss": 0.2213,
      "step": 5946
    },
    {
      "epoch": 3.5825301204819278,
      "grad_norm": 0.6190152764320374,
      "learning_rate": 5.240963855421687e-07,
      "loss": 0.2346,
      "step": 5947
    },
    {
      "epoch": 3.5831325301204817,
      "grad_norm": 0.58469557762146,
      "learning_rate": 5.233433734939759e-07,
      "loss": 0.1988,
      "step": 5948
    },
    {
      "epoch": 3.583734939759036,
      "grad_norm": 0.6082526445388794,
      "learning_rate": 5.225903614457832e-07,
      "loss": 0.2511,
      "step": 5949
    },
    {
      "epoch": 3.5843373493975905,
      "grad_norm": 0.5408200025558472,
      "learning_rate": 5.218373493975904e-07,
      "loss": 0.229,
      "step": 5950
    },
    {
      "epoch": 3.5849397590361445,
      "grad_norm": 0.5423884987831116,
      "learning_rate": 5.210843373493976e-07,
      "loss": 0.2457,
      "step": 5951
    },
    {
      "epoch": 3.585542168674699,
      "grad_norm": 0.6227640509605408,
      "learning_rate": 5.203313253012049e-07,
      "loss": 0.2565,
      "step": 5952
    },
    {
      "epoch": 3.5861445783132533,
      "grad_norm": 0.590614378452301,
      "learning_rate": 5.195783132530121e-07,
      "loss": 0.2127,
      "step": 5953
    },
    {
      "epoch": 3.5867469879518072,
      "grad_norm": 0.634627640247345,
      "learning_rate": 5.188253012048193e-07,
      "loss": 0.2462,
      "step": 5954
    },
    {
      "epoch": 3.587349397590361,
      "grad_norm": 0.5961629748344421,
      "learning_rate": 5.180722891566266e-07,
      "loss": 0.241,
      "step": 5955
    },
    {
      "epoch": 3.5879518072289156,
      "grad_norm": 0.7665550708770752,
      "learning_rate": 5.173192771084338e-07,
      "loss": 0.2688,
      "step": 5956
    },
    {
      "epoch": 3.58855421686747,
      "grad_norm": 0.5197238922119141,
      "learning_rate": 5.16566265060241e-07,
      "loss": 0.2194,
      "step": 5957
    },
    {
      "epoch": 3.589156626506024,
      "grad_norm": 0.6389101147651672,
      "learning_rate": 5.158132530120483e-07,
      "loss": 0.2225,
      "step": 5958
    },
    {
      "epoch": 3.5897590361445784,
      "grad_norm": 0.5860353708267212,
      "learning_rate": 5.150602409638554e-07,
      "loss": 0.1961,
      "step": 5959
    },
    {
      "epoch": 3.5903614457831328,
      "grad_norm": 0.6142898201942444,
      "learning_rate": 5.143072289156627e-07,
      "loss": 0.2437,
      "step": 5960
    },
    {
      "epoch": 3.5909638554216867,
      "grad_norm": 0.6940957307815552,
      "learning_rate": 5.135542168674699e-07,
      "loss": 0.2438,
      "step": 5961
    },
    {
      "epoch": 3.591566265060241,
      "grad_norm": 0.5592869520187378,
      "learning_rate": 5.128012048192772e-07,
      "loss": 0.2349,
      "step": 5962
    },
    {
      "epoch": 3.592168674698795,
      "grad_norm": 0.5966408848762512,
      "learning_rate": 5.120481927710844e-07,
      "loss": 0.2028,
      "step": 5963
    },
    {
      "epoch": 3.5927710843373495,
      "grad_norm": 0.5643348693847656,
      "learning_rate": 5.112951807228917e-07,
      "loss": 0.2337,
      "step": 5964
    },
    {
      "epoch": 3.5933734939759034,
      "grad_norm": 0.6357585787773132,
      "learning_rate": 5.105421686746988e-07,
      "loss": 0.2339,
      "step": 5965
    },
    {
      "epoch": 3.593975903614458,
      "grad_norm": 0.6063879132270813,
      "learning_rate": 5.09789156626506e-07,
      "loss": 0.2462,
      "step": 5966
    },
    {
      "epoch": 3.5945783132530122,
      "grad_norm": 0.4877367615699768,
      "learning_rate": 5.090361445783133e-07,
      "loss": 0.2197,
      "step": 5967
    },
    {
      "epoch": 3.595180722891566,
      "grad_norm": 0.5604512095451355,
      "learning_rate": 5.082831325301205e-07,
      "loss": 0.2293,
      "step": 5968
    },
    {
      "epoch": 3.5957831325301206,
      "grad_norm": 0.5608038902282715,
      "learning_rate": 5.075301204819278e-07,
      "loss": 0.2414,
      "step": 5969
    },
    {
      "epoch": 3.5963855421686746,
      "grad_norm": 0.5440539717674255,
      "learning_rate": 5.06777108433735e-07,
      "loss": 0.2175,
      "step": 5970
    },
    {
      "epoch": 3.596987951807229,
      "grad_norm": 0.55645751953125,
      "learning_rate": 5.060240963855422e-07,
      "loss": 0.2307,
      "step": 5971
    },
    {
      "epoch": 3.597590361445783,
      "grad_norm": 0.5688267350196838,
      "learning_rate": 5.052710843373494e-07,
      "loss": 0.2071,
      "step": 5972
    },
    {
      "epoch": 3.5981927710843373,
      "grad_norm": 0.6735396981239319,
      "learning_rate": 5.045180722891567e-07,
      "loss": 0.2807,
      "step": 5973
    },
    {
      "epoch": 3.5987951807228917,
      "grad_norm": 12.67762279510498,
      "learning_rate": 5.037650602409639e-07,
      "loss": 0.238,
      "step": 5974
    },
    {
      "epoch": 3.5993975903614457,
      "grad_norm": 0.5387870669364929,
      "learning_rate": 5.030120481927711e-07,
      "loss": 0.2102,
      "step": 5975
    },
    {
      "epoch": 3.6,
      "grad_norm": 0.5883277654647827,
      "learning_rate": 5.022590361445784e-07,
      "loss": 0.2126,
      "step": 5976
    },
    {
      "epoch": 3.6006024096385545,
      "grad_norm": 0.5795376896858215,
      "learning_rate": 5.015060240963856e-07,
      "loss": 0.2608,
      "step": 5977
    },
    {
      "epoch": 3.6012048192771084,
      "grad_norm": 0.5856425166130066,
      "learning_rate": 5.007530120481928e-07,
      "loss": 0.2317,
      "step": 5978
    },
    {
      "epoch": 3.6018072289156624,
      "grad_norm": 0.6073141694068909,
      "learning_rate": 5.000000000000001e-07,
      "loss": 0.2306,
      "step": 5979
    },
    {
      "epoch": 3.602409638554217,
      "grad_norm": 0.5681648850440979,
      "learning_rate": 4.992469879518073e-07,
      "loss": 0.1994,
      "step": 5980
    },
    {
      "epoch": 3.603012048192771,
      "grad_norm": 0.6193187832832336,
      "learning_rate": 4.984939759036145e-07,
      "loss": 0.2327,
      "step": 5981
    },
    {
      "epoch": 3.603614457831325,
      "grad_norm": 0.6758262515068054,
      "learning_rate": 4.977409638554217e-07,
      "loss": 0.2703,
      "step": 5982
    },
    {
      "epoch": 3.6042168674698796,
      "grad_norm": 0.6629311442375183,
      "learning_rate": 4.96987951807229e-07,
      "loss": 0.2624,
      "step": 5983
    },
    {
      "epoch": 3.604819277108434,
      "grad_norm": 0.5407150983810425,
      "learning_rate": 4.962349397590362e-07,
      "loss": 0.1914,
      "step": 5984
    },
    {
      "epoch": 3.605421686746988,
      "grad_norm": 0.5922883152961731,
      "learning_rate": 4.954819277108434e-07,
      "loss": 0.2187,
      "step": 5985
    },
    {
      "epoch": 3.6060240963855423,
      "grad_norm": 0.5357046723365784,
      "learning_rate": 4.947289156626507e-07,
      "loss": 0.2088,
      "step": 5986
    },
    {
      "epoch": 3.6066265060240963,
      "grad_norm": 0.6436832547187805,
      "learning_rate": 4.939759036144578e-07,
      "loss": 0.2764,
      "step": 5987
    },
    {
      "epoch": 3.6072289156626507,
      "grad_norm": 0.6189866065979004,
      "learning_rate": 4.932228915662652e-07,
      "loss": 0.2454,
      "step": 5988
    },
    {
      "epoch": 3.6078313253012047,
      "grad_norm": 0.5630638599395752,
      "learning_rate": 4.924698795180723e-07,
      "loss": 0.2535,
      "step": 5989
    },
    {
      "epoch": 3.608433734939759,
      "grad_norm": 0.5996418595314026,
      "learning_rate": 4.917168674698795e-07,
      "loss": 0.2178,
      "step": 5990
    },
    {
      "epoch": 3.6090361445783135,
      "grad_norm": 0.4765646755695343,
      "learning_rate": 4.909638554216868e-07,
      "loss": 0.2019,
      "step": 5991
    },
    {
      "epoch": 3.6096385542168674,
      "grad_norm": 0.581601083278656,
      "learning_rate": 4.90210843373494e-07,
      "loss": 0.2128,
      "step": 5992
    },
    {
      "epoch": 3.610240963855422,
      "grad_norm": 0.6927174925804138,
      "learning_rate": 4.894578313253013e-07,
      "loss": 0.2741,
      "step": 5993
    },
    {
      "epoch": 3.6108433734939758,
      "grad_norm": 0.5701903700828552,
      "learning_rate": 4.887048192771085e-07,
      "loss": 0.1646,
      "step": 5994
    },
    {
      "epoch": 3.61144578313253,
      "grad_norm": 0.5329499244689941,
      "learning_rate": 4.879518072289158e-07,
      "loss": 0.1925,
      "step": 5995
    },
    {
      "epoch": 3.612048192771084,
      "grad_norm": 0.5949278473854065,
      "learning_rate": 4.871987951807229e-07,
      "loss": 0.2162,
      "step": 5996
    },
    {
      "epoch": 3.6126506024096385,
      "grad_norm": 0.6388112902641296,
      "learning_rate": 4.864457831325302e-07,
      "loss": 0.2431,
      "step": 5997
    },
    {
      "epoch": 3.613253012048193,
      "grad_norm": 0.7247172594070435,
      "learning_rate": 4.856927710843374e-07,
      "loss": 0.244,
      "step": 5998
    },
    {
      "epoch": 3.613855421686747,
      "grad_norm": 0.5277430415153503,
      "learning_rate": 4.849397590361446e-07,
      "loss": 0.2138,
      "step": 5999
    },
    {
      "epoch": 3.6144578313253013,
      "grad_norm": 0.5068359375,
      "learning_rate": 4.841867469879519e-07,
      "loss": 0.1985,
      "step": 6000
    },
    {
      "epoch": 3.6150602409638557,
      "grad_norm": 0.563339352607727,
      "learning_rate": 4.834337349397591e-07,
      "loss": 0.2363,
      "step": 6001
    },
    {
      "epoch": 3.6156626506024097,
      "grad_norm": 0.49698585271835327,
      "learning_rate": 4.826807228915662e-07,
      "loss": 0.1821,
      "step": 6002
    },
    {
      "epoch": 3.6162650602409636,
      "grad_norm": 0.5933457612991333,
      "learning_rate": 4.819277108433736e-07,
      "loss": 0.2722,
      "step": 6003
    },
    {
      "epoch": 3.616867469879518,
      "grad_norm": 0.531734824180603,
      "learning_rate": 4.811746987951807e-07,
      "loss": 0.1808,
      "step": 6004
    },
    {
      "epoch": 3.6174698795180724,
      "grad_norm": 0.5297520756721497,
      "learning_rate": 4.80421686746988e-07,
      "loss": 0.2442,
      "step": 6005
    },
    {
      "epoch": 3.6180722891566264,
      "grad_norm": 0.5884556174278259,
      "learning_rate": 4.796686746987952e-07,
      "loss": 0.2163,
      "step": 6006
    },
    {
      "epoch": 3.6186746987951808,
      "grad_norm": 0.5729572176933289,
      "learning_rate": 4.789156626506024e-07,
      "loss": 0.2898,
      "step": 6007
    },
    {
      "epoch": 3.619277108433735,
      "grad_norm": 0.6259982585906982,
      "learning_rate": 4.781626506024097e-07,
      "loss": 0.2492,
      "step": 6008
    },
    {
      "epoch": 3.619879518072289,
      "grad_norm": 0.6903988122940063,
      "learning_rate": 4.774096385542169e-07,
      "loss": 0.2564,
      "step": 6009
    },
    {
      "epoch": 3.6204819277108435,
      "grad_norm": 0.5574882626533508,
      "learning_rate": 4.766566265060241e-07,
      "loss": 0.2221,
      "step": 6010
    },
    {
      "epoch": 3.6210843373493975,
      "grad_norm": 0.5717760324478149,
      "learning_rate": 4.7590361445783137e-07,
      "loss": 0.1792,
      "step": 6011
    },
    {
      "epoch": 3.621686746987952,
      "grad_norm": 0.525922954082489,
      "learning_rate": 4.751506024096386e-07,
      "loss": 0.1855,
      "step": 6012
    },
    {
      "epoch": 3.622289156626506,
      "grad_norm": 0.5660861730575562,
      "learning_rate": 4.743975903614458e-07,
      "loss": 0.2308,
      "step": 6013
    },
    {
      "epoch": 3.6228915662650603,
      "grad_norm": 0.5790531039237976,
      "learning_rate": 4.7364457831325304e-07,
      "loss": 0.2311,
      "step": 6014
    },
    {
      "epoch": 3.6234939759036147,
      "grad_norm": 0.6411142349243164,
      "learning_rate": 4.728915662650603e-07,
      "loss": 0.2717,
      "step": 6015
    },
    {
      "epoch": 3.6240963855421686,
      "grad_norm": 0.5624011158943176,
      "learning_rate": 4.7213855421686753e-07,
      "loss": 0.1996,
      "step": 6016
    },
    {
      "epoch": 3.624698795180723,
      "grad_norm": 0.6023302674293518,
      "learning_rate": 4.713855421686747e-07,
      "loss": 0.217,
      "step": 6017
    },
    {
      "epoch": 3.625301204819277,
      "grad_norm": 0.5826624631881714,
      "learning_rate": 4.70632530120482e-07,
      "loss": 0.2418,
      "step": 6018
    },
    {
      "epoch": 3.6259036144578314,
      "grad_norm": 0.6163136959075928,
      "learning_rate": 4.698795180722892e-07,
      "loss": 0.2176,
      "step": 6019
    },
    {
      "epoch": 3.6265060240963853,
      "grad_norm": 0.4987475574016571,
      "learning_rate": 4.691265060240964e-07,
      "loss": 0.2123,
      "step": 6020
    },
    {
      "epoch": 3.6271084337349397,
      "grad_norm": 0.6297460794448853,
      "learning_rate": 4.683734939759037e-07,
      "loss": 0.2729,
      "step": 6021
    },
    {
      "epoch": 3.627710843373494,
      "grad_norm": 0.5767580270767212,
      "learning_rate": 4.676204819277109e-07,
      "loss": 0.2055,
      "step": 6022
    },
    {
      "epoch": 3.628313253012048,
      "grad_norm": 0.5230602025985718,
      "learning_rate": 4.6686746987951807e-07,
      "loss": 0.2276,
      "step": 6023
    },
    {
      "epoch": 3.6289156626506025,
      "grad_norm": 0.6080834269523621,
      "learning_rate": 4.6611445783132536e-07,
      "loss": 0.2479,
      "step": 6024
    },
    {
      "epoch": 3.6295180722891565,
      "grad_norm": 0.6599578261375427,
      "learning_rate": 4.6536144578313255e-07,
      "loss": 0.2727,
      "step": 6025
    },
    {
      "epoch": 3.630120481927711,
      "grad_norm": 0.5375178456306458,
      "learning_rate": 4.646084337349398e-07,
      "loss": 0.213,
      "step": 6026
    },
    {
      "epoch": 3.630722891566265,
      "grad_norm": 0.6485161781311035,
      "learning_rate": 4.6385542168674704e-07,
      "loss": 0.222,
      "step": 6027
    },
    {
      "epoch": 3.6313253012048192,
      "grad_norm": 0.5044320821762085,
      "learning_rate": 4.631024096385543e-07,
      "loss": 0.178,
      "step": 6028
    },
    {
      "epoch": 3.6319277108433736,
      "grad_norm": 0.5874873399734497,
      "learning_rate": 4.6234939759036147e-07,
      "loss": 0.218,
      "step": 6029
    },
    {
      "epoch": 3.6325301204819276,
      "grad_norm": 0.5795036554336548,
      "learning_rate": 4.615963855421687e-07,
      "loss": 0.1965,
      "step": 6030
    },
    {
      "epoch": 3.633132530120482,
      "grad_norm": 0.6151930689811707,
      "learning_rate": 4.6084337349397595e-07,
      "loss": 0.2067,
      "step": 6031
    },
    {
      "epoch": 3.6337349397590364,
      "grad_norm": 0.5925535559654236,
      "learning_rate": 4.6009036144578314e-07,
      "loss": 0.1871,
      "step": 6032
    },
    {
      "epoch": 3.6343373493975903,
      "grad_norm": 0.5476959347724915,
      "learning_rate": 4.5933734939759044e-07,
      "loss": 0.1968,
      "step": 6033
    },
    {
      "epoch": 3.6349397590361443,
      "grad_norm": 0.5396899580955505,
      "learning_rate": 4.5858433734939763e-07,
      "loss": 0.214,
      "step": 6034
    },
    {
      "epoch": 3.6355421686746987,
      "grad_norm": 0.542471170425415,
      "learning_rate": 4.578313253012048e-07,
      "loss": 0.2025,
      "step": 6035
    },
    {
      "epoch": 3.636144578313253,
      "grad_norm": 0.593967854976654,
      "learning_rate": 4.570783132530121e-07,
      "loss": 0.2402,
      "step": 6036
    },
    {
      "epoch": 3.636746987951807,
      "grad_norm": 0.861811101436615,
      "learning_rate": 4.563253012048193e-07,
      "loss": 0.1994,
      "step": 6037
    },
    {
      "epoch": 3.6373493975903615,
      "grad_norm": 0.570406973361969,
      "learning_rate": 4.5557228915662654e-07,
      "loss": 0.204,
      "step": 6038
    },
    {
      "epoch": 3.637951807228916,
      "grad_norm": 2.7520124912261963,
      "learning_rate": 4.548192771084338e-07,
      "loss": 0.2245,
      "step": 6039
    },
    {
      "epoch": 3.63855421686747,
      "grad_norm": 0.560547947883606,
      "learning_rate": 4.54066265060241e-07,
      "loss": 0.1945,
      "step": 6040
    },
    {
      "epoch": 3.6391566265060242,
      "grad_norm": 0.5978498458862305,
      "learning_rate": 4.533132530120482e-07,
      "loss": 0.2576,
      "step": 6041
    },
    {
      "epoch": 3.639759036144578,
      "grad_norm": 0.5482798218727112,
      "learning_rate": 4.5256024096385546e-07,
      "loss": 0.2189,
      "step": 6042
    },
    {
      "epoch": 3.6403614457831326,
      "grad_norm": 0.5418506860733032,
      "learning_rate": 4.518072289156627e-07,
      "loss": 0.2111,
      "step": 6043
    },
    {
      "epoch": 3.6409638554216865,
      "grad_norm": 0.5937535762786865,
      "learning_rate": 4.510542168674699e-07,
      "loss": 0.2453,
      "step": 6044
    },
    {
      "epoch": 3.641566265060241,
      "grad_norm": 0.5502737760543823,
      "learning_rate": 4.503012048192772e-07,
      "loss": 0.2008,
      "step": 6045
    },
    {
      "epoch": 3.6421686746987953,
      "grad_norm": 0.5706498026847839,
      "learning_rate": 4.495481927710844e-07,
      "loss": 0.2121,
      "step": 6046
    },
    {
      "epoch": 3.6427710843373493,
      "grad_norm": 0.6396578550338745,
      "learning_rate": 4.4879518072289157e-07,
      "loss": 0.223,
      "step": 6047
    },
    {
      "epoch": 3.6433734939759037,
      "grad_norm": 0.5883439779281616,
      "learning_rate": 4.4804216867469886e-07,
      "loss": 0.2405,
      "step": 6048
    },
    {
      "epoch": 3.6439759036144577,
      "grad_norm": 0.5873821377754211,
      "learning_rate": 4.4728915662650605e-07,
      "loss": 0.2033,
      "step": 6049
    },
    {
      "epoch": 3.644578313253012,
      "grad_norm": 0.5477879643440247,
      "learning_rate": 4.4653614457831324e-07,
      "loss": 0.2083,
      "step": 6050
    },
    {
      "epoch": 3.645180722891566,
      "grad_norm": 0.5433998703956604,
      "learning_rate": 4.4578313253012054e-07,
      "loss": 0.1781,
      "step": 6051
    },
    {
      "epoch": 3.6457831325301204,
      "grad_norm": 0.6575783491134644,
      "learning_rate": 4.4503012048192773e-07,
      "loss": 0.2519,
      "step": 6052
    },
    {
      "epoch": 3.646385542168675,
      "grad_norm": 0.5700235366821289,
      "learning_rate": 4.4427710843373497e-07,
      "loss": 0.2406,
      "step": 6053
    },
    {
      "epoch": 3.646987951807229,
      "grad_norm": 0.4957565665245056,
      "learning_rate": 4.435240963855422e-07,
      "loss": 0.2089,
      "step": 6054
    },
    {
      "epoch": 3.647590361445783,
      "grad_norm": 0.568957507610321,
      "learning_rate": 4.4277108433734945e-07,
      "loss": 0.2171,
      "step": 6055
    },
    {
      "epoch": 3.6481927710843376,
      "grad_norm": 0.5159533023834229,
      "learning_rate": 4.4201807228915664e-07,
      "loss": 0.1881,
      "step": 6056
    },
    {
      "epoch": 3.6487951807228916,
      "grad_norm": 0.4819573760032654,
      "learning_rate": 4.412650602409639e-07,
      "loss": 0.1766,
      "step": 6057
    },
    {
      "epoch": 3.6493975903614455,
      "grad_norm": 0.5968288779258728,
      "learning_rate": 4.4051204819277113e-07,
      "loss": 0.2249,
      "step": 6058
    },
    {
      "epoch": 3.65,
      "grad_norm": 0.5861393213272095,
      "learning_rate": 4.397590361445783e-07,
      "loss": 0.238,
      "step": 6059
    },
    {
      "epoch": 3.6506024096385543,
      "grad_norm": 0.7327666878700256,
      "learning_rate": 4.390060240963856e-07,
      "loss": 0.2329,
      "step": 6060
    },
    {
      "epoch": 3.6512048192771083,
      "grad_norm": 0.7988992929458618,
      "learning_rate": 4.382530120481928e-07,
      "loss": 0.2365,
      "step": 6061
    },
    {
      "epoch": 3.6518072289156627,
      "grad_norm": 0.715453565120697,
      "learning_rate": 4.375e-07,
      "loss": 0.2832,
      "step": 6062
    },
    {
      "epoch": 3.652409638554217,
      "grad_norm": 0.6886708736419678,
      "learning_rate": 4.367469879518073e-07,
      "loss": 0.188,
      "step": 6063
    },
    {
      "epoch": 3.653012048192771,
      "grad_norm": 0.8115904331207275,
      "learning_rate": 4.359939759036145e-07,
      "loss": 0.2406,
      "step": 6064
    },
    {
      "epoch": 3.6536144578313254,
      "grad_norm": 0.691872775554657,
      "learning_rate": 4.3524096385542167e-07,
      "loss": 0.2331,
      "step": 6065
    },
    {
      "epoch": 3.6542168674698794,
      "grad_norm": 0.8228543996810913,
      "learning_rate": 4.3448795180722896e-07,
      "loss": 0.3058,
      "step": 6066
    },
    {
      "epoch": 3.654819277108434,
      "grad_norm": 0.6216363906860352,
      "learning_rate": 4.3373493975903615e-07,
      "loss": 0.2813,
      "step": 6067
    },
    {
      "epoch": 3.6554216867469878,
      "grad_norm": 0.6649448871612549,
      "learning_rate": 4.329819277108434e-07,
      "loss": 0.3494,
      "step": 6068
    },
    {
      "epoch": 3.656024096385542,
      "grad_norm": 0.6904292106628418,
      "learning_rate": 4.3222891566265064e-07,
      "loss": 0.2623,
      "step": 6069
    },
    {
      "epoch": 3.6566265060240966,
      "grad_norm": 0.8077489733695984,
      "learning_rate": 4.314759036144579e-07,
      "loss": 0.1931,
      "step": 6070
    },
    {
      "epoch": 3.6572289156626505,
      "grad_norm": 0.7052459716796875,
      "learning_rate": 4.3072289156626507e-07,
      "loss": 0.2434,
      "step": 6071
    },
    {
      "epoch": 3.657831325301205,
      "grad_norm": 0.7170957326889038,
      "learning_rate": 4.2996987951807237e-07,
      "loss": 0.2517,
      "step": 6072
    },
    {
      "epoch": 3.658433734939759,
      "grad_norm": 0.7775900959968567,
      "learning_rate": 4.2921686746987956e-07,
      "loss": 0.3004,
      "step": 6073
    },
    {
      "epoch": 3.6590361445783133,
      "grad_norm": 0.7350589036941528,
      "learning_rate": 4.2846385542168674e-07,
      "loss": 0.2637,
      "step": 6074
    },
    {
      "epoch": 3.6596385542168672,
      "grad_norm": 0.724332332611084,
      "learning_rate": 4.2771084337349404e-07,
      "loss": 0.2457,
      "step": 6075
    },
    {
      "epoch": 3.6602409638554216,
      "grad_norm": 0.7810484170913696,
      "learning_rate": 4.2695783132530123e-07,
      "loss": 0.2229,
      "step": 6076
    },
    {
      "epoch": 3.660843373493976,
      "grad_norm": 0.7277129292488098,
      "learning_rate": 4.262048192771084e-07,
      "loss": 0.2238,
      "step": 6077
    },
    {
      "epoch": 3.66144578313253,
      "grad_norm": 0.6586880087852478,
      "learning_rate": 4.254518072289157e-07,
      "loss": 0.2469,
      "step": 6078
    },
    {
      "epoch": 3.6620481927710844,
      "grad_norm": 0.7366456389427185,
      "learning_rate": 4.246987951807229e-07,
      "loss": 0.2638,
      "step": 6079
    },
    {
      "epoch": 3.662650602409639,
      "grad_norm": 0.752901017665863,
      "learning_rate": 4.2394578313253015e-07,
      "loss": 0.2469,
      "step": 6080
    },
    {
      "epoch": 3.6632530120481928,
      "grad_norm": 0.7045218348503113,
      "learning_rate": 4.231927710843374e-07,
      "loss": 0.2219,
      "step": 6081
    },
    {
      "epoch": 3.6638554216867467,
      "grad_norm": 0.6514692902565002,
      "learning_rate": 4.2243975903614463e-07,
      "loss": 0.2904,
      "step": 6082
    },
    {
      "epoch": 3.664457831325301,
      "grad_norm": 0.6594619154930115,
      "learning_rate": 4.216867469879518e-07,
      "loss": 0.223,
      "step": 6083
    },
    {
      "epoch": 3.6650602409638555,
      "grad_norm": 0.6252641677856445,
      "learning_rate": 4.2093373493975906e-07,
      "loss": 0.2464,
      "step": 6084
    },
    {
      "epoch": 3.6656626506024095,
      "grad_norm": 0.7606671452522278,
      "learning_rate": 4.201807228915663e-07,
      "loss": 0.2413,
      "step": 6085
    },
    {
      "epoch": 3.666265060240964,
      "grad_norm": 0.7586857676506042,
      "learning_rate": 4.194277108433735e-07,
      "loss": 0.2465,
      "step": 6086
    },
    {
      "epoch": 3.6668674698795183,
      "grad_norm": 0.7964144349098206,
      "learning_rate": 4.186746987951808e-07,
      "loss": 0.2546,
      "step": 6087
    },
    {
      "epoch": 3.6674698795180722,
      "grad_norm": 0.6895636320114136,
      "learning_rate": 4.17921686746988e-07,
      "loss": 0.2922,
      "step": 6088
    },
    {
      "epoch": 3.6680722891566266,
      "grad_norm": 0.7290224432945251,
      "learning_rate": 4.1716867469879517e-07,
      "loss": 0.1949,
      "step": 6089
    },
    {
      "epoch": 3.6686746987951806,
      "grad_norm": 0.7754240036010742,
      "learning_rate": 4.1641566265060247e-07,
      "loss": 0.2992,
      "step": 6090
    },
    {
      "epoch": 3.669277108433735,
      "grad_norm": 0.7579939961433411,
      "learning_rate": 4.1566265060240966e-07,
      "loss": 0.2177,
      "step": 6091
    },
    {
      "epoch": 3.669879518072289,
      "grad_norm": 0.6350082755088806,
      "learning_rate": 4.1490963855421685e-07,
      "loss": 0.2695,
      "step": 6092
    },
    {
      "epoch": 3.6704819277108434,
      "grad_norm": 0.681782603263855,
      "learning_rate": 4.1415662650602414e-07,
      "loss": 0.2612,
      "step": 6093
    },
    {
      "epoch": 3.6710843373493978,
      "grad_norm": 0.6239641904830933,
      "learning_rate": 4.1340361445783133e-07,
      "loss": 0.1969,
      "step": 6094
    },
    {
      "epoch": 3.6716867469879517,
      "grad_norm": 0.6909138560295105,
      "learning_rate": 4.1265060240963857e-07,
      "loss": 0.296,
      "step": 6095
    },
    {
      "epoch": 3.672289156626506,
      "grad_norm": 0.7370089888572693,
      "learning_rate": 4.118975903614458e-07,
      "loss": 0.2972,
      "step": 6096
    },
    {
      "epoch": 3.67289156626506,
      "grad_norm": 0.6621876358985901,
      "learning_rate": 4.1114457831325306e-07,
      "loss": 0.2425,
      "step": 6097
    },
    {
      "epoch": 3.6734939759036145,
      "grad_norm": 0.6197009682655334,
      "learning_rate": 4.1039156626506025e-07,
      "loss": 0.262,
      "step": 6098
    },
    {
      "epoch": 3.6740963855421684,
      "grad_norm": 0.7296699285507202,
      "learning_rate": 4.0963855421686754e-07,
      "loss": 0.2134,
      "step": 6099
    },
    {
      "epoch": 3.674698795180723,
      "grad_norm": 0.7020837664604187,
      "learning_rate": 4.0888554216867473e-07,
      "loss": 0.314,
      "step": 6100
    },
    {
      "epoch": 3.6753012048192772,
      "grad_norm": 0.721651017665863,
      "learning_rate": 4.081325301204819e-07,
      "loss": 0.255,
      "step": 6101
    },
    {
      "epoch": 3.675903614457831,
      "grad_norm": 0.5776212215423584,
      "learning_rate": 4.073795180722892e-07,
      "loss": 0.2569,
      "step": 6102
    },
    {
      "epoch": 3.6765060240963856,
      "grad_norm": 0.6894077658653259,
      "learning_rate": 4.066265060240964e-07,
      "loss": 0.2576,
      "step": 6103
    },
    {
      "epoch": 3.67710843373494,
      "grad_norm": 0.6315294504165649,
      "learning_rate": 4.058734939759036e-07,
      "loss": 0.2402,
      "step": 6104
    },
    {
      "epoch": 3.677710843373494,
      "grad_norm": 0.6902249455451965,
      "learning_rate": 4.051204819277109e-07,
      "loss": 0.273,
      "step": 6105
    },
    {
      "epoch": 3.678313253012048,
      "grad_norm": 0.6347999572753906,
      "learning_rate": 4.043674698795181e-07,
      "loss": 0.2164,
      "step": 6106
    },
    {
      "epoch": 3.6789156626506023,
      "grad_norm": 0.6808695793151855,
      "learning_rate": 4.036144578313253e-07,
      "loss": 0.2507,
      "step": 6107
    },
    {
      "epoch": 3.6795180722891567,
      "grad_norm": 0.7383054494857788,
      "learning_rate": 4.0286144578313257e-07,
      "loss": 0.2612,
      "step": 6108
    },
    {
      "epoch": 3.6801204819277107,
      "grad_norm": 0.8109772205352783,
      "learning_rate": 4.0210843373493976e-07,
      "loss": 0.2114,
      "step": 6109
    },
    {
      "epoch": 3.680722891566265,
      "grad_norm": 0.814175546169281,
      "learning_rate": 4.01355421686747e-07,
      "loss": 0.2215,
      "step": 6110
    },
    {
      "epoch": 3.6813253012048195,
      "grad_norm": 0.7746143937110901,
      "learning_rate": 4.0060240963855424e-07,
      "loss": 0.2818,
      "step": 6111
    },
    {
      "epoch": 3.6819277108433734,
      "grad_norm": 0.6652129888534546,
      "learning_rate": 3.998493975903615e-07,
      "loss": 0.2711,
      "step": 6112
    },
    {
      "epoch": 3.682530120481928,
      "grad_norm": 0.7047048211097717,
      "learning_rate": 3.9909638554216867e-07,
      "loss": 0.2553,
      "step": 6113
    },
    {
      "epoch": 3.683132530120482,
      "grad_norm": 0.7648025155067444,
      "learning_rate": 3.9834337349397597e-07,
      "loss": 0.2297,
      "step": 6114
    },
    {
      "epoch": 3.683734939759036,
      "grad_norm": 0.6455638408660889,
      "learning_rate": 3.9759036144578316e-07,
      "loss": 0.2684,
      "step": 6115
    },
    {
      "epoch": 3.68433734939759,
      "grad_norm": 0.8055972456932068,
      "learning_rate": 3.9683734939759035e-07,
      "loss": 0.3011,
      "step": 6116
    },
    {
      "epoch": 3.6849397590361446,
      "grad_norm": 0.6611191034317017,
      "learning_rate": 3.9608433734939764e-07,
      "loss": 0.2299,
      "step": 6117
    },
    {
      "epoch": 3.685542168674699,
      "grad_norm": 0.6618172526359558,
      "learning_rate": 3.9533132530120483e-07,
      "loss": 0.2343,
      "step": 6118
    },
    {
      "epoch": 3.686144578313253,
      "grad_norm": 0.7515342235565186,
      "learning_rate": 3.94578313253012e-07,
      "loss": 0.2809,
      "step": 6119
    },
    {
      "epoch": 3.6867469879518073,
      "grad_norm": 0.6381164789199829,
      "learning_rate": 3.938253012048193e-07,
      "loss": 0.2288,
      "step": 6120
    },
    {
      "epoch": 3.6873493975903613,
      "grad_norm": 0.6884912848472595,
      "learning_rate": 3.930722891566265e-07,
      "loss": 0.2074,
      "step": 6121
    },
    {
      "epoch": 3.6879518072289157,
      "grad_norm": 0.6453267931938171,
      "learning_rate": 3.9231927710843375e-07,
      "loss": 0.1897,
      "step": 6122
    },
    {
      "epoch": 3.6885542168674696,
      "grad_norm": 0.6933861970901489,
      "learning_rate": 3.91566265060241e-07,
      "loss": 0.3106,
      "step": 6123
    },
    {
      "epoch": 3.689156626506024,
      "grad_norm": 0.6605834364891052,
      "learning_rate": 3.9081325301204823e-07,
      "loss": 0.1897,
      "step": 6124
    },
    {
      "epoch": 3.6897590361445785,
      "grad_norm": 0.6606494188308716,
      "learning_rate": 3.900602409638555e-07,
      "loss": 0.2067,
      "step": 6125
    },
    {
      "epoch": 3.6903614457831324,
      "grad_norm": 0.584884524345398,
      "learning_rate": 3.893072289156627e-07,
      "loss": 0.2546,
      "step": 6126
    },
    {
      "epoch": 3.690963855421687,
      "grad_norm": 0.6294376254081726,
      "learning_rate": 3.885542168674699e-07,
      "loss": 0.1876,
      "step": 6127
    },
    {
      "epoch": 3.691566265060241,
      "grad_norm": 0.6810605525970459,
      "learning_rate": 3.8780120481927715e-07,
      "loss": 0.2306,
      "step": 6128
    },
    {
      "epoch": 3.692168674698795,
      "grad_norm": 0.6724029779434204,
      "learning_rate": 3.870481927710844e-07,
      "loss": 0.2536,
      "step": 6129
    },
    {
      "epoch": 3.692771084337349,
      "grad_norm": 0.6627454161643982,
      "learning_rate": 3.862951807228916e-07,
      "loss": 0.2829,
      "step": 6130
    },
    {
      "epoch": 3.6933734939759035,
      "grad_norm": 0.7401951551437378,
      "learning_rate": 3.855421686746989e-07,
      "loss": 0.2072,
      "step": 6131
    },
    {
      "epoch": 3.693975903614458,
      "grad_norm": 0.6526739001274109,
      "learning_rate": 3.8478915662650607e-07,
      "loss": 0.2307,
      "step": 6132
    },
    {
      "epoch": 3.694578313253012,
      "grad_norm": 0.642607569694519,
      "learning_rate": 3.8403614457831326e-07,
      "loss": 0.256,
      "step": 6133
    },
    {
      "epoch": 3.6951807228915663,
      "grad_norm": 0.6981551647186279,
      "learning_rate": 3.8328313253012055e-07,
      "loss": 0.2672,
      "step": 6134
    },
    {
      "epoch": 3.6957831325301207,
      "grad_norm": 0.8046422600746155,
      "learning_rate": 3.8253012048192774e-07,
      "loss": 0.2358,
      "step": 6135
    },
    {
      "epoch": 3.6963855421686747,
      "grad_norm": 0.7758426070213318,
      "learning_rate": 3.8177710843373493e-07,
      "loss": 0.262,
      "step": 6136
    },
    {
      "epoch": 3.696987951807229,
      "grad_norm": 0.6360689401626587,
      "learning_rate": 3.8102409638554223e-07,
      "loss": 0.306,
      "step": 6137
    },
    {
      "epoch": 3.697590361445783,
      "grad_norm": 0.6723427772521973,
      "learning_rate": 3.802710843373494e-07,
      "loss": 0.2457,
      "step": 6138
    },
    {
      "epoch": 3.6981927710843374,
      "grad_norm": 0.7199810147285461,
      "learning_rate": 3.7951807228915666e-07,
      "loss": 0.208,
      "step": 6139
    },
    {
      "epoch": 3.6987951807228914,
      "grad_norm": 0.6130066514015198,
      "learning_rate": 3.787650602409639e-07,
      "loss": 0.2693,
      "step": 6140
    },
    {
      "epoch": 3.6993975903614458,
      "grad_norm": 0.611351490020752,
      "learning_rate": 3.7801204819277115e-07,
      "loss": 0.2228,
      "step": 6141
    },
    {
      "epoch": 3.7,
      "grad_norm": 0.6130699515342712,
      "learning_rate": 3.7725903614457833e-07,
      "loss": 0.2184,
      "step": 6142
    },
    {
      "epoch": 3.700602409638554,
      "grad_norm": 0.6234947443008423,
      "learning_rate": 3.7650602409638563e-07,
      "loss": 0.254,
      "step": 6143
    },
    {
      "epoch": 3.7012048192771085,
      "grad_norm": 0.6649953126907349,
      "learning_rate": 3.757530120481928e-07,
      "loss": 0.22,
      "step": 6144
    },
    {
      "epoch": 3.7018072289156625,
      "grad_norm": 0.6406407952308655,
      "learning_rate": 3.75e-07,
      "loss": 0.235,
      "step": 6145
    },
    {
      "epoch": 3.702409638554217,
      "grad_norm": 0.6681469678878784,
      "learning_rate": 3.742469879518073e-07,
      "loss": 0.2988,
      "step": 6146
    },
    {
      "epoch": 3.703012048192771,
      "grad_norm": 0.6439985036849976,
      "learning_rate": 3.734939759036145e-07,
      "loss": 0.2239,
      "step": 6147
    },
    {
      "epoch": 3.7036144578313253,
      "grad_norm": 0.6337771415710449,
      "learning_rate": 3.727409638554217e-07,
      "loss": 0.2303,
      "step": 6148
    },
    {
      "epoch": 3.7042168674698797,
      "grad_norm": 1.154646635055542,
      "learning_rate": 3.71987951807229e-07,
      "loss": 0.197,
      "step": 6149
    },
    {
      "epoch": 3.7048192771084336,
      "grad_norm": 0.6665990948677063,
      "learning_rate": 3.7123493975903617e-07,
      "loss": 0.24,
      "step": 6150
    },
    {
      "epoch": 3.705421686746988,
      "grad_norm": 0.6538288593292236,
      "learning_rate": 3.704819277108434e-07,
      "loss": 0.231,
      "step": 6151
    },
    {
      "epoch": 3.7060240963855424,
      "grad_norm": 0.8814547061920166,
      "learning_rate": 3.6972891566265065e-07,
      "loss": 0.2682,
      "step": 6152
    },
    {
      "epoch": 3.7066265060240964,
      "grad_norm": 0.940530002117157,
      "learning_rate": 3.6897590361445784e-07,
      "loss": 0.2381,
      "step": 6153
    },
    {
      "epoch": 3.7072289156626503,
      "grad_norm": 0.5761659145355225,
      "learning_rate": 3.682228915662651e-07,
      "loss": 0.2067,
      "step": 6154
    },
    {
      "epoch": 3.7078313253012047,
      "grad_norm": 0.594404399394989,
      "learning_rate": 3.6746987951807233e-07,
      "loss": 0.2085,
      "step": 6155
    },
    {
      "epoch": 3.708433734939759,
      "grad_norm": 0.6321672797203064,
      "learning_rate": 3.6671686746987957e-07,
      "loss": 0.3072,
      "step": 6156
    },
    {
      "epoch": 3.709036144578313,
      "grad_norm": 0.6894967555999756,
      "learning_rate": 3.6596385542168676e-07,
      "loss": 0.249,
      "step": 6157
    },
    {
      "epoch": 3.7096385542168675,
      "grad_norm": 2.073134660720825,
      "learning_rate": 3.6521084337349406e-07,
      "loss": 0.326,
      "step": 6158
    },
    {
      "epoch": 3.710240963855422,
      "grad_norm": 0.6717959046363831,
      "learning_rate": 3.6445783132530125e-07,
      "loss": 0.2414,
      "step": 6159
    },
    {
      "epoch": 3.710843373493976,
      "grad_norm": 0.5774306058883667,
      "learning_rate": 3.6370481927710844e-07,
      "loss": 0.1888,
      "step": 6160
    },
    {
      "epoch": 3.7114457831325303,
      "grad_norm": 0.642763614654541,
      "learning_rate": 3.6295180722891573e-07,
      "loss": 0.2056,
      "step": 6161
    },
    {
      "epoch": 3.712048192771084,
      "grad_norm": 0.6257266402244568,
      "learning_rate": 3.621987951807229e-07,
      "loss": 0.2804,
      "step": 6162
    },
    {
      "epoch": 3.7126506024096386,
      "grad_norm": 0.5798061490058899,
      "learning_rate": 3.614457831325301e-07,
      "loss": 0.2197,
      "step": 6163
    },
    {
      "epoch": 3.7132530120481926,
      "grad_norm": 0.6854901909828186,
      "learning_rate": 3.606927710843374e-07,
      "loss": 0.2162,
      "step": 6164
    },
    {
      "epoch": 3.713855421686747,
      "grad_norm": 0.6798616647720337,
      "learning_rate": 3.599397590361446e-07,
      "loss": 0.2466,
      "step": 6165
    },
    {
      "epoch": 3.7144578313253014,
      "grad_norm": 0.6651175618171692,
      "learning_rate": 3.5918674698795184e-07,
      "loss": 0.2492,
      "step": 6166
    },
    {
      "epoch": 3.7150602409638553,
      "grad_norm": 0.6061909198760986,
      "learning_rate": 3.584337349397591e-07,
      "loss": 0.2285,
      "step": 6167
    },
    {
      "epoch": 3.7156626506024097,
      "grad_norm": 0.6503111124038696,
      "learning_rate": 3.576807228915663e-07,
      "loss": 0.242,
      "step": 6168
    },
    {
      "epoch": 3.7162650602409637,
      "grad_norm": 0.626340389251709,
      "learning_rate": 3.569277108433735e-07,
      "loss": 0.2584,
      "step": 6169
    },
    {
      "epoch": 3.716867469879518,
      "grad_norm": 0.6303118467330933,
      "learning_rate": 3.561746987951808e-07,
      "loss": 0.3019,
      "step": 6170
    },
    {
      "epoch": 3.717469879518072,
      "grad_norm": 0.8187382221221924,
      "learning_rate": 3.55421686746988e-07,
      "loss": 0.2515,
      "step": 6171
    },
    {
      "epoch": 3.7180722891566265,
      "grad_norm": 0.6085314154624939,
      "learning_rate": 3.546686746987952e-07,
      "loss": 0.2474,
      "step": 6172
    },
    {
      "epoch": 3.718674698795181,
      "grad_norm": 0.8374213576316833,
      "learning_rate": 3.539156626506025e-07,
      "loss": 0.2668,
      "step": 6173
    },
    {
      "epoch": 3.719277108433735,
      "grad_norm": 0.6557044982910156,
      "learning_rate": 3.5316265060240967e-07,
      "loss": 0.2942,
      "step": 6174
    },
    {
      "epoch": 3.7198795180722892,
      "grad_norm": 0.6647636890411377,
      "learning_rate": 3.5240963855421686e-07,
      "loss": 0.2499,
      "step": 6175
    },
    {
      "epoch": 3.7204819277108436,
      "grad_norm": 0.6424885988235474,
      "learning_rate": 3.5165662650602416e-07,
      "loss": 0.2458,
      "step": 6176
    },
    {
      "epoch": 3.7210843373493976,
      "grad_norm": 0.6289132237434387,
      "learning_rate": 3.5090361445783135e-07,
      "loss": 0.2496,
      "step": 6177
    },
    {
      "epoch": 3.7216867469879515,
      "grad_norm": 0.634912371635437,
      "learning_rate": 3.501506024096386e-07,
      "loss": 0.2672,
      "step": 6178
    },
    {
      "epoch": 3.722289156626506,
      "grad_norm": 0.6673129200935364,
      "learning_rate": 3.4939759036144583e-07,
      "loss": 0.2883,
      "step": 6179
    },
    {
      "epoch": 3.7228915662650603,
      "grad_norm": 0.6889695525169373,
      "learning_rate": 3.48644578313253e-07,
      "loss": 0.2089,
      "step": 6180
    },
    {
      "epoch": 3.7234939759036143,
      "grad_norm": 0.6371517777442932,
      "learning_rate": 3.4789156626506026e-07,
      "loss": 0.194,
      "step": 6181
    },
    {
      "epoch": 3.7240963855421687,
      "grad_norm": 0.6787481904029846,
      "learning_rate": 3.471385542168675e-07,
      "loss": 0.2553,
      "step": 6182
    },
    {
      "epoch": 3.724698795180723,
      "grad_norm": 0.6092185974121094,
      "learning_rate": 3.4638554216867475e-07,
      "loss": 0.2523,
      "step": 6183
    },
    {
      "epoch": 3.725301204819277,
      "grad_norm": 0.6332097053527832,
      "learning_rate": 3.4563253012048194e-07,
      "loss": 0.2044,
      "step": 6184
    },
    {
      "epoch": 3.7259036144578315,
      "grad_norm": 0.5802538990974426,
      "learning_rate": 3.4487951807228923e-07,
      "loss": 0.218,
      "step": 6185
    },
    {
      "epoch": 3.7265060240963854,
      "grad_norm": 0.6234059929847717,
      "learning_rate": 3.441265060240964e-07,
      "loss": 0.2604,
      "step": 6186
    },
    {
      "epoch": 3.72710843373494,
      "grad_norm": 0.6068536043167114,
      "learning_rate": 3.433734939759036e-07,
      "loss": 0.2079,
      "step": 6187
    },
    {
      "epoch": 3.727710843373494,
      "grad_norm": 0.6493853330612183,
      "learning_rate": 3.426204819277109e-07,
      "loss": 0.2611,
      "step": 6188
    },
    {
      "epoch": 3.728313253012048,
      "grad_norm": 0.6886168122291565,
      "learning_rate": 3.418674698795181e-07,
      "loss": 0.2276,
      "step": 6189
    },
    {
      "epoch": 3.7289156626506026,
      "grad_norm": 0.570641279220581,
      "learning_rate": 3.411144578313253e-07,
      "loss": 0.2529,
      "step": 6190
    },
    {
      "epoch": 3.7295180722891565,
      "grad_norm": 0.6418777108192444,
      "learning_rate": 3.403614457831326e-07,
      "loss": 0.2612,
      "step": 6191
    },
    {
      "epoch": 3.730120481927711,
      "grad_norm": 0.6423041224479675,
      "learning_rate": 3.3960843373493977e-07,
      "loss": 0.1961,
      "step": 6192
    },
    {
      "epoch": 3.730722891566265,
      "grad_norm": 0.6734845042228699,
      "learning_rate": 3.38855421686747e-07,
      "loss": 0.2363,
      "step": 6193
    },
    {
      "epoch": 3.7313253012048193,
      "grad_norm": 0.630579948425293,
      "learning_rate": 3.3810240963855426e-07,
      "loss": 0.2291,
      "step": 6194
    },
    {
      "epoch": 3.7319277108433733,
      "grad_norm": 0.6259524822235107,
      "learning_rate": 3.373493975903615e-07,
      "loss": 0.2791,
      "step": 6195
    },
    {
      "epoch": 3.7325301204819277,
      "grad_norm": 0.6481187343597412,
      "learning_rate": 3.365963855421687e-07,
      "loss": 0.2157,
      "step": 6196
    },
    {
      "epoch": 3.733132530120482,
      "grad_norm": 0.6478493809700012,
      "learning_rate": 3.3584337349397593e-07,
      "loss": 0.215,
      "step": 6197
    },
    {
      "epoch": 3.733734939759036,
      "grad_norm": 0.6393579840660095,
      "learning_rate": 3.350903614457832e-07,
      "loss": 0.2018,
      "step": 6198
    },
    {
      "epoch": 3.7343373493975904,
      "grad_norm": 0.5813111066818237,
      "learning_rate": 3.3433734939759036e-07,
      "loss": 0.2283,
      "step": 6199
    },
    {
      "epoch": 3.734939759036145,
      "grad_norm": 0.6185809373855591,
      "learning_rate": 3.3358433734939766e-07,
      "loss": 0.1844,
      "step": 6200
    },
    {
      "epoch": 3.735542168674699,
      "grad_norm": 0.6071762442588806,
      "learning_rate": 3.3283132530120485e-07,
      "loss": 0.2323,
      "step": 6201
    },
    {
      "epoch": 3.7361445783132528,
      "grad_norm": 0.5801642537117004,
      "learning_rate": 3.3207831325301204e-07,
      "loss": 0.229,
      "step": 6202
    },
    {
      "epoch": 3.736746987951807,
      "grad_norm": 0.6289119124412537,
      "learning_rate": 3.3132530120481933e-07,
      "loss": 0.2647,
      "step": 6203
    },
    {
      "epoch": 3.7373493975903616,
      "grad_norm": 0.6116672158241272,
      "learning_rate": 3.305722891566265e-07,
      "loss": 0.2161,
      "step": 6204
    },
    {
      "epoch": 3.7379518072289155,
      "grad_norm": 0.6527804136276245,
      "learning_rate": 3.2981927710843377e-07,
      "loss": 0.2081,
      "step": 6205
    },
    {
      "epoch": 3.73855421686747,
      "grad_norm": 0.663763701915741,
      "learning_rate": 3.29066265060241e-07,
      "loss": 0.2404,
      "step": 6206
    },
    {
      "epoch": 3.7391566265060243,
      "grad_norm": 0.6151711344718933,
      "learning_rate": 3.283132530120482e-07,
      "loss": 0.2986,
      "step": 6207
    },
    {
      "epoch": 3.7397590361445783,
      "grad_norm": 0.5834944248199463,
      "learning_rate": 3.2756024096385544e-07,
      "loss": 0.2393,
      "step": 6208
    },
    {
      "epoch": 3.7403614457831327,
      "grad_norm": 0.6141234040260315,
      "learning_rate": 3.268072289156627e-07,
      "loss": 0.2605,
      "step": 6209
    },
    {
      "epoch": 3.7409638554216866,
      "grad_norm": 0.6384271383285522,
      "learning_rate": 3.260542168674699e-07,
      "loss": 0.2059,
      "step": 6210
    },
    {
      "epoch": 3.741566265060241,
      "grad_norm": 0.7759705781936646,
      "learning_rate": 3.253012048192771e-07,
      "loss": 0.1923,
      "step": 6211
    },
    {
      "epoch": 3.742168674698795,
      "grad_norm": 0.657088041305542,
      "learning_rate": 3.245481927710844e-07,
      "loss": 0.2544,
      "step": 6212
    },
    {
      "epoch": 3.7427710843373494,
      "grad_norm": 0.7271444797515869,
      "learning_rate": 3.237951807228916e-07,
      "loss": 0.2245,
      "step": 6213
    },
    {
      "epoch": 3.743373493975904,
      "grad_norm": 0.6898295879364014,
      "learning_rate": 3.230421686746988e-07,
      "loss": 0.2509,
      "step": 6214
    },
    {
      "epoch": 3.7439759036144578,
      "grad_norm": 0.5547879338264465,
      "learning_rate": 3.222891566265061e-07,
      "loss": 0.2396,
      "step": 6215
    },
    {
      "epoch": 3.744578313253012,
      "grad_norm": 0.6055706739425659,
      "learning_rate": 3.215361445783133e-07,
      "loss": 0.2733,
      "step": 6216
    },
    {
      "epoch": 3.745180722891566,
      "grad_norm": 0.654911994934082,
      "learning_rate": 3.2078313253012046e-07,
      "loss": 0.2831,
      "step": 6217
    },
    {
      "epoch": 3.7457831325301205,
      "grad_norm": 0.6576191186904907,
      "learning_rate": 3.2003012048192776e-07,
      "loss": 0.2787,
      "step": 6218
    },
    {
      "epoch": 3.7463855421686745,
      "grad_norm": 0.6110174655914307,
      "learning_rate": 3.1927710843373495e-07,
      "loss": 0.225,
      "step": 6219
    },
    {
      "epoch": 3.746987951807229,
      "grad_norm": 0.5982339382171631,
      "learning_rate": 3.185240963855422e-07,
      "loss": 0.2539,
      "step": 6220
    },
    {
      "epoch": 3.7475903614457833,
      "grad_norm": 0.7545375823974609,
      "learning_rate": 3.1777108433734943e-07,
      "loss": 0.2729,
      "step": 6221
    },
    {
      "epoch": 3.7481927710843372,
      "grad_norm": 0.6046295762062073,
      "learning_rate": 3.170180722891567e-07,
      "loss": 0.2025,
      "step": 6222
    },
    {
      "epoch": 3.7487951807228916,
      "grad_norm": 0.6003223061561584,
      "learning_rate": 3.1626506024096387e-07,
      "loss": 0.2238,
      "step": 6223
    },
    {
      "epoch": 3.749397590361446,
      "grad_norm": 0.6019262075424194,
      "learning_rate": 3.155120481927711e-07,
      "loss": 0.2664,
      "step": 6224
    },
    {
      "epoch": 3.75,
      "grad_norm": 0.6218079924583435,
      "learning_rate": 3.1475903614457835e-07,
      "loss": 0.2698,
      "step": 6225
    },
    {
      "epoch": 3.750602409638554,
      "grad_norm": 0.6360893249511719,
      "learning_rate": 3.1400602409638554e-07,
      "loss": 0.1885,
      "step": 6226
    },
    {
      "epoch": 3.7512048192771084,
      "grad_norm": 0.6526708006858826,
      "learning_rate": 3.1325301204819284e-07,
      "loss": 0.2404,
      "step": 6227
    },
    {
      "epoch": 3.7518072289156628,
      "grad_norm": 0.690222978591919,
      "learning_rate": 3.125e-07,
      "loss": 0.257,
      "step": 6228
    },
    {
      "epoch": 3.7524096385542167,
      "grad_norm": 0.6842232346534729,
      "learning_rate": 3.1174698795180727e-07,
      "loss": 0.2806,
      "step": 6229
    },
    {
      "epoch": 3.753012048192771,
      "grad_norm": 0.6669611930847168,
      "learning_rate": 3.1099397590361446e-07,
      "loss": 0.2495,
      "step": 6230
    },
    {
      "epoch": 3.7536144578313255,
      "grad_norm": 0.5820742845535278,
      "learning_rate": 3.102409638554217e-07,
      "loss": 0.2462,
      "step": 6231
    },
    {
      "epoch": 3.7542168674698795,
      "grad_norm": 0.5814048051834106,
      "learning_rate": 3.0948795180722894e-07,
      "loss": 0.1787,
      "step": 6232
    },
    {
      "epoch": 3.754819277108434,
      "grad_norm": 0.7805889248847961,
      "learning_rate": 3.0873493975903613e-07,
      "loss": 0.3072,
      "step": 6233
    },
    {
      "epoch": 3.755421686746988,
      "grad_norm": 0.6495766043663025,
      "learning_rate": 3.079819277108434e-07,
      "loss": 0.248,
      "step": 6234
    },
    {
      "epoch": 3.7560240963855422,
      "grad_norm": 0.6219698190689087,
      "learning_rate": 3.072289156626506e-07,
      "loss": 0.1974,
      "step": 6235
    },
    {
      "epoch": 3.756626506024096,
      "grad_norm": 0.6329715847969055,
      "learning_rate": 3.0647590361445786e-07,
      "loss": 0.2311,
      "step": 6236
    },
    {
      "epoch": 3.7572289156626506,
      "grad_norm": 0.6812490820884705,
      "learning_rate": 3.057228915662651e-07,
      "loss": 0.304,
      "step": 6237
    },
    {
      "epoch": 3.757831325301205,
      "grad_norm": 0.7235338687896729,
      "learning_rate": 3.0496987951807234e-07,
      "loss": 0.2556,
      "step": 6238
    },
    {
      "epoch": 3.758433734939759,
      "grad_norm": 0.6750979423522949,
      "learning_rate": 3.0421686746987953e-07,
      "loss": 0.2304,
      "step": 6239
    },
    {
      "epoch": 3.7590361445783134,
      "grad_norm": 0.6960793733596802,
      "learning_rate": 3.034638554216868e-07,
      "loss": 0.2654,
      "step": 6240
    },
    {
      "epoch": 3.7596385542168673,
      "grad_norm": 0.6288833618164062,
      "learning_rate": 3.02710843373494e-07,
      "loss": 0.1945,
      "step": 6241
    },
    {
      "epoch": 3.7602409638554217,
      "grad_norm": 0.5504589080810547,
      "learning_rate": 3.019578313253012e-07,
      "loss": 0.1703,
      "step": 6242
    },
    {
      "epoch": 3.7608433734939757,
      "grad_norm": 0.6459094285964966,
      "learning_rate": 3.0120481927710845e-07,
      "loss": 0.238,
      "step": 6243
    },
    {
      "epoch": 3.76144578313253,
      "grad_norm": 0.6378899216651917,
      "learning_rate": 3.004518072289157e-07,
      "loss": 0.2248,
      "step": 6244
    },
    {
      "epoch": 3.7620481927710845,
      "grad_norm": 0.6576427817344666,
      "learning_rate": 2.996987951807229e-07,
      "loss": 0.2575,
      "step": 6245
    },
    {
      "epoch": 3.7626506024096384,
      "grad_norm": 0.5765683650970459,
      "learning_rate": 2.989457831325301e-07,
      "loss": 0.2599,
      "step": 6246
    },
    {
      "epoch": 3.763253012048193,
      "grad_norm": 0.7860718965530396,
      "learning_rate": 2.9819277108433737e-07,
      "loss": 0.2514,
      "step": 6247
    },
    {
      "epoch": 3.7638554216867472,
      "grad_norm": 0.6619374752044678,
      "learning_rate": 2.974397590361446e-07,
      "loss": 0.2919,
      "step": 6248
    },
    {
      "epoch": 3.764457831325301,
      "grad_norm": 0.6779150366783142,
      "learning_rate": 2.9668674698795185e-07,
      "loss": 0.2861,
      "step": 6249
    },
    {
      "epoch": 3.765060240963855,
      "grad_norm": 0.7661870121955872,
      "learning_rate": 2.9593373493975904e-07,
      "loss": 0.3085,
      "step": 6250
    },
    {
      "epoch": 3.7656626506024096,
      "grad_norm": 0.618423342704773,
      "learning_rate": 2.951807228915663e-07,
      "loss": 0.221,
      "step": 6251
    },
    {
      "epoch": 3.766265060240964,
      "grad_norm": 0.7288746237754822,
      "learning_rate": 2.9442771084337353e-07,
      "loss": 0.2091,
      "step": 6252
    },
    {
      "epoch": 3.766867469879518,
      "grad_norm": 0.5898259282112122,
      "learning_rate": 2.9367469879518077e-07,
      "loss": 0.2127,
      "step": 6253
    },
    {
      "epoch": 3.7674698795180723,
      "grad_norm": 0.5696120262145996,
      "learning_rate": 2.9292168674698796e-07,
      "loss": 0.1953,
      "step": 6254
    },
    {
      "epoch": 3.7680722891566267,
      "grad_norm": 0.633249819278717,
      "learning_rate": 2.921686746987952e-07,
      "loss": 0.2586,
      "step": 6255
    },
    {
      "epoch": 3.7686746987951807,
      "grad_norm": 0.5899896025657654,
      "learning_rate": 2.9141566265060245e-07,
      "loss": 0.3138,
      "step": 6256
    },
    {
      "epoch": 3.769277108433735,
      "grad_norm": 0.635404646396637,
      "learning_rate": 2.9066265060240963e-07,
      "loss": 0.1682,
      "step": 6257
    },
    {
      "epoch": 3.769879518072289,
      "grad_norm": 0.6155489683151245,
      "learning_rate": 2.899096385542169e-07,
      "loss": 0.2599,
      "step": 6258
    },
    {
      "epoch": 3.7704819277108435,
      "grad_norm": 0.5780730247497559,
      "learning_rate": 2.891566265060241e-07,
      "loss": 0.2107,
      "step": 6259
    },
    {
      "epoch": 3.7710843373493974,
      "grad_norm": 0.699903666973114,
      "learning_rate": 2.884036144578313e-07,
      "loss": 0.272,
      "step": 6260
    },
    {
      "epoch": 3.771686746987952,
      "grad_norm": 0.5670779943466187,
      "learning_rate": 2.8765060240963855e-07,
      "loss": 0.247,
      "step": 6261
    },
    {
      "epoch": 3.772289156626506,
      "grad_norm": 0.6389556527137756,
      "learning_rate": 2.868975903614458e-07,
      "loss": 0.2115,
      "step": 6262
    },
    {
      "epoch": 3.77289156626506,
      "grad_norm": 0.5643499493598938,
      "learning_rate": 2.8614457831325304e-07,
      "loss": 0.2527,
      "step": 6263
    },
    {
      "epoch": 3.7734939759036146,
      "grad_norm": 0.6428888440132141,
      "learning_rate": 2.853915662650603e-07,
      "loss": 0.2861,
      "step": 6264
    },
    {
      "epoch": 3.7740963855421685,
      "grad_norm": 0.6501458287239075,
      "learning_rate": 2.846385542168675e-07,
      "loss": 0.2587,
      "step": 6265
    },
    {
      "epoch": 3.774698795180723,
      "grad_norm": 0.6901559829711914,
      "learning_rate": 2.838855421686747e-07,
      "loss": 0.2147,
      "step": 6266
    },
    {
      "epoch": 3.775301204819277,
      "grad_norm": 0.6830667853355408,
      "learning_rate": 2.8313253012048195e-07,
      "loss": 0.257,
      "step": 6267
    },
    {
      "epoch": 3.7759036144578313,
      "grad_norm": 0.6854691505432129,
      "learning_rate": 2.823795180722892e-07,
      "loss": 0.2792,
      "step": 6268
    },
    {
      "epoch": 3.7765060240963857,
      "grad_norm": 0.5408909916877747,
      "learning_rate": 2.816265060240964e-07,
      "loss": 0.2414,
      "step": 6269
    },
    {
      "epoch": 3.7771084337349397,
      "grad_norm": 0.5617907643318176,
      "learning_rate": 2.8087349397590363e-07,
      "loss": 0.2434,
      "step": 6270
    },
    {
      "epoch": 3.777710843373494,
      "grad_norm": 0.7854933738708496,
      "learning_rate": 2.8012048192771087e-07,
      "loss": 0.3524,
      "step": 6271
    },
    {
      "epoch": 3.7783132530120485,
      "grad_norm": 0.669989824295044,
      "learning_rate": 2.7936746987951806e-07,
      "loss": 0.2952,
      "step": 6272
    },
    {
      "epoch": 3.7789156626506024,
      "grad_norm": 0.6506847739219666,
      "learning_rate": 2.786144578313253e-07,
      "loss": 0.229,
      "step": 6273
    },
    {
      "epoch": 3.7795180722891564,
      "grad_norm": 0.6185352206230164,
      "learning_rate": 2.7786144578313255e-07,
      "loss": 0.2781,
      "step": 6274
    },
    {
      "epoch": 3.7801204819277108,
      "grad_norm": 0.6137779951095581,
      "learning_rate": 2.771084337349398e-07,
      "loss": 0.2798,
      "step": 6275
    },
    {
      "epoch": 3.780722891566265,
      "grad_norm": 0.6293784976005554,
      "learning_rate": 2.7635542168674703e-07,
      "loss": 0.2609,
      "step": 6276
    },
    {
      "epoch": 3.781325301204819,
      "grad_norm": 0.6047323346138,
      "learning_rate": 2.756024096385542e-07,
      "loss": 0.2915,
      "step": 6277
    },
    {
      "epoch": 3.7819277108433735,
      "grad_norm": 0.5789786577224731,
      "learning_rate": 2.7484939759036146e-07,
      "loss": 0.2401,
      "step": 6278
    },
    {
      "epoch": 3.782530120481928,
      "grad_norm": 0.5748123526573181,
      "learning_rate": 2.740963855421687e-07,
      "loss": 0.2702,
      "step": 6279
    },
    {
      "epoch": 3.783132530120482,
      "grad_norm": 0.6687440872192383,
      "learning_rate": 2.7334337349397595e-07,
      "loss": 0.2018,
      "step": 6280
    },
    {
      "epoch": 3.7837349397590363,
      "grad_norm": 0.6689586639404297,
      "learning_rate": 2.725903614457832e-07,
      "loss": 0.293,
      "step": 6281
    },
    {
      "epoch": 3.7843373493975903,
      "grad_norm": 0.6782371997833252,
      "learning_rate": 2.718373493975904e-07,
      "loss": 0.2791,
      "step": 6282
    },
    {
      "epoch": 3.7849397590361447,
      "grad_norm": 0.6180403828620911,
      "learning_rate": 2.710843373493976e-07,
      "loss": 0.2728,
      "step": 6283
    },
    {
      "epoch": 3.7855421686746986,
      "grad_norm": 0.6607357263565063,
      "learning_rate": 2.7033132530120486e-07,
      "loss": 0.2859,
      "step": 6284
    },
    {
      "epoch": 3.786144578313253,
      "grad_norm": 0.5563267469406128,
      "learning_rate": 2.6957831325301205e-07,
      "loss": 0.2206,
      "step": 6285
    },
    {
      "epoch": 3.7867469879518074,
      "grad_norm": 0.6177639961242676,
      "learning_rate": 2.688253012048193e-07,
      "loss": 0.2458,
      "step": 6286
    },
    {
      "epoch": 3.7873493975903614,
      "grad_norm": 0.6252807378768921,
      "learning_rate": 2.6807228915662654e-07,
      "loss": 0.2707,
      "step": 6287
    },
    {
      "epoch": 3.787951807228916,
      "grad_norm": 0.588600754737854,
      "learning_rate": 2.6731927710843373e-07,
      "loss": 0.2656,
      "step": 6288
    },
    {
      "epoch": 3.7885542168674697,
      "grad_norm": 0.5733714699745178,
      "learning_rate": 2.6656626506024097e-07,
      "loss": 0.2004,
      "step": 6289
    },
    {
      "epoch": 3.789156626506024,
      "grad_norm": 0.6987447738647461,
      "learning_rate": 2.658132530120482e-07,
      "loss": 0.2637,
      "step": 6290
    },
    {
      "epoch": 3.789759036144578,
      "grad_norm": 0.6207006573677063,
      "learning_rate": 2.6506024096385546e-07,
      "loss": 0.2034,
      "step": 6291
    },
    {
      "epoch": 3.7903614457831325,
      "grad_norm": 0.7349815368652344,
      "learning_rate": 2.643072289156627e-07,
      "loss": 0.248,
      "step": 6292
    },
    {
      "epoch": 3.790963855421687,
      "grad_norm": 0.6177015900611877,
      "learning_rate": 2.6355421686746994e-07,
      "loss": 0.2098,
      "step": 6293
    },
    {
      "epoch": 3.791566265060241,
      "grad_norm": 0.559916079044342,
      "learning_rate": 2.6280120481927713e-07,
      "loss": 0.2265,
      "step": 6294
    },
    {
      "epoch": 3.7921686746987953,
      "grad_norm": 0.6438844799995422,
      "learning_rate": 2.6204819277108437e-07,
      "loss": 0.2239,
      "step": 6295
    },
    {
      "epoch": 3.7927710843373497,
      "grad_norm": 0.5901525020599365,
      "learning_rate": 2.612951807228916e-07,
      "loss": 0.2296,
      "step": 6296
    },
    {
      "epoch": 3.7933734939759036,
      "grad_norm": 0.6694943308830261,
      "learning_rate": 2.605421686746988e-07,
      "loss": 0.2594,
      "step": 6297
    },
    {
      "epoch": 3.7939759036144576,
      "grad_norm": 0.6270760297775269,
      "learning_rate": 2.5978915662650605e-07,
      "loss": 0.1977,
      "step": 6298
    },
    {
      "epoch": 3.794578313253012,
      "grad_norm": 0.6969672441482544,
      "learning_rate": 2.590361445783133e-07,
      "loss": 0.2612,
      "step": 6299
    },
    {
      "epoch": 3.7951807228915664,
      "grad_norm": 0.5637562274932861,
      "learning_rate": 2.582831325301205e-07,
      "loss": 0.1859,
      "step": 6300
    },
    {
      "epoch": 3.7957831325301203,
      "grad_norm": 0.7374825477600098,
      "learning_rate": 2.575301204819277e-07,
      "loss": 0.3369,
      "step": 6301
    },
    {
      "epoch": 3.7963855421686747,
      "grad_norm": 0.6141011118888855,
      "learning_rate": 2.5677710843373496e-07,
      "loss": 0.2002,
      "step": 6302
    },
    {
      "epoch": 3.796987951807229,
      "grad_norm": 0.6385869979858398,
      "learning_rate": 2.560240963855422e-07,
      "loss": 0.2786,
      "step": 6303
    },
    {
      "epoch": 3.797590361445783,
      "grad_norm": 0.6359076499938965,
      "learning_rate": 2.552710843373494e-07,
      "loss": 0.2353,
      "step": 6304
    },
    {
      "epoch": 3.7981927710843375,
      "grad_norm": 0.6098027229309082,
      "learning_rate": 2.5451807228915664e-07,
      "loss": 0.2452,
      "step": 6305
    },
    {
      "epoch": 3.7987951807228915,
      "grad_norm": 0.6012584567070007,
      "learning_rate": 2.537650602409639e-07,
      "loss": 0.2167,
      "step": 6306
    },
    {
      "epoch": 3.799397590361446,
      "grad_norm": 0.6248943209648132,
      "learning_rate": 2.530120481927711e-07,
      "loss": 0.1972,
      "step": 6307
    },
    {
      "epoch": 3.8,
      "grad_norm": 0.6888543963432312,
      "learning_rate": 2.5225903614457837e-07,
      "loss": 0.2067,
      "step": 6308
    },
    {
      "epoch": 3.8006024096385542,
      "grad_norm": 0.6461058259010315,
      "learning_rate": 2.5150602409638556e-07,
      "loss": 0.2612,
      "step": 6309
    },
    {
      "epoch": 3.8012048192771086,
      "grad_norm": 0.649147629737854,
      "learning_rate": 2.507530120481928e-07,
      "loss": 0.216,
      "step": 6310
    },
    {
      "epoch": 3.8018072289156626,
      "grad_norm": 0.6299676895141602,
      "learning_rate": 2.5000000000000004e-07,
      "loss": 0.2188,
      "step": 6311
    },
    {
      "epoch": 3.802409638554217,
      "grad_norm": 0.6513371467590332,
      "learning_rate": 2.4924698795180723e-07,
      "loss": 0.235,
      "step": 6312
    },
    {
      "epoch": 3.803012048192771,
      "grad_norm": 0.6061967611312866,
      "learning_rate": 2.484939759036145e-07,
      "loss": 0.3035,
      "step": 6313
    },
    {
      "epoch": 3.8036144578313253,
      "grad_norm": 0.6365006566047668,
      "learning_rate": 2.477409638554217e-07,
      "loss": 0.2918,
      "step": 6314
    },
    {
      "epoch": 3.8042168674698793,
      "grad_norm": 0.6552149057388306,
      "learning_rate": 2.469879518072289e-07,
      "loss": 0.2533,
      "step": 6315
    },
    {
      "epoch": 3.8048192771084337,
      "grad_norm": 0.6987353563308716,
      "learning_rate": 2.4623493975903615e-07,
      "loss": 0.2904,
      "step": 6316
    },
    {
      "epoch": 3.805421686746988,
      "grad_norm": 0.709583044052124,
      "learning_rate": 2.454819277108434e-07,
      "loss": 0.3197,
      "step": 6317
    },
    {
      "epoch": 3.806024096385542,
      "grad_norm": 0.6303027868270874,
      "learning_rate": 2.4472891566265063e-07,
      "loss": 0.2492,
      "step": 6318
    },
    {
      "epoch": 3.8066265060240965,
      "grad_norm": 0.7055338025093079,
      "learning_rate": 2.439759036144579e-07,
      "loss": 0.2933,
      "step": 6319
    },
    {
      "epoch": 3.807228915662651,
      "grad_norm": 0.575721263885498,
      "learning_rate": 2.432228915662651e-07,
      "loss": 0.2692,
      "step": 6320
    },
    {
      "epoch": 3.807831325301205,
      "grad_norm": 0.6067265868186951,
      "learning_rate": 2.424698795180723e-07,
      "loss": 0.2214,
      "step": 6321
    },
    {
      "epoch": 3.808433734939759,
      "grad_norm": 0.6201292276382446,
      "learning_rate": 2.4171686746987955e-07,
      "loss": 0.2747,
      "step": 6322
    },
    {
      "epoch": 3.809036144578313,
      "grad_norm": 0.6017180681228638,
      "learning_rate": 2.409638554216868e-07,
      "loss": 0.2708,
      "step": 6323
    },
    {
      "epoch": 3.8096385542168676,
      "grad_norm": 0.6777636408805847,
      "learning_rate": 2.40210843373494e-07,
      "loss": 0.2808,
      "step": 6324
    },
    {
      "epoch": 3.8102409638554215,
      "grad_norm": 0.5870823264122009,
      "learning_rate": 2.394578313253012e-07,
      "loss": 0.2477,
      "step": 6325
    },
    {
      "epoch": 3.810843373493976,
      "grad_norm": 0.8080339431762695,
      "learning_rate": 2.3870481927710847e-07,
      "loss": 0.2999,
      "step": 6326
    },
    {
      "epoch": 3.8114457831325304,
      "grad_norm": 0.6447430849075317,
      "learning_rate": 2.3795180722891568e-07,
      "loss": 0.2574,
      "step": 6327
    },
    {
      "epoch": 3.8120481927710843,
      "grad_norm": 0.6316183805465698,
      "learning_rate": 2.371987951807229e-07,
      "loss": 0.242,
      "step": 6328
    },
    {
      "epoch": 3.8126506024096387,
      "grad_norm": 0.6076071262359619,
      "learning_rate": 2.3644578313253014e-07,
      "loss": 0.2442,
      "step": 6329
    },
    {
      "epoch": 3.8132530120481927,
      "grad_norm": 0.6530215740203857,
      "learning_rate": 2.3569277108433736e-07,
      "loss": 0.1974,
      "step": 6330
    },
    {
      "epoch": 3.813855421686747,
      "grad_norm": 0.6008425951004028,
      "learning_rate": 2.349397590361446e-07,
      "loss": 0.2508,
      "step": 6331
    },
    {
      "epoch": 3.814457831325301,
      "grad_norm": 0.6513193249702454,
      "learning_rate": 2.3418674698795184e-07,
      "loss": 0.1999,
      "step": 6332
    },
    {
      "epoch": 3.8150602409638554,
      "grad_norm": 0.5791225433349609,
      "learning_rate": 2.3343373493975903e-07,
      "loss": 0.2171,
      "step": 6333
    },
    {
      "epoch": 3.81566265060241,
      "grad_norm": 0.6735280156135559,
      "learning_rate": 2.3268072289156628e-07,
      "loss": 0.2323,
      "step": 6334
    },
    {
      "epoch": 3.816265060240964,
      "grad_norm": 0.6560626029968262,
      "learning_rate": 2.3192771084337352e-07,
      "loss": 0.2518,
      "step": 6335
    },
    {
      "epoch": 3.816867469879518,
      "grad_norm": 0.6788633465766907,
      "learning_rate": 2.3117469879518073e-07,
      "loss": 0.2787,
      "step": 6336
    },
    {
      "epoch": 3.817469879518072,
      "grad_norm": 0.6026866436004639,
      "learning_rate": 2.3042168674698798e-07,
      "loss": 0.2286,
      "step": 6337
    },
    {
      "epoch": 3.8180722891566266,
      "grad_norm": 0.5384342074394226,
      "learning_rate": 2.2966867469879522e-07,
      "loss": 0.2552,
      "step": 6338
    },
    {
      "epoch": 3.8186746987951805,
      "grad_norm": 0.5940157771110535,
      "learning_rate": 2.289156626506024e-07,
      "loss": 0.237,
      "step": 6339
    },
    {
      "epoch": 3.819277108433735,
      "grad_norm": 0.6404162645339966,
      "learning_rate": 2.2816265060240965e-07,
      "loss": 0.2535,
      "step": 6340
    },
    {
      "epoch": 3.8198795180722893,
      "grad_norm": 0.6015584468841553,
      "learning_rate": 2.274096385542169e-07,
      "loss": 0.2653,
      "step": 6341
    },
    {
      "epoch": 3.8204819277108433,
      "grad_norm": 0.6501786112785339,
      "learning_rate": 2.266566265060241e-07,
      "loss": 0.2797,
      "step": 6342
    },
    {
      "epoch": 3.8210843373493977,
      "grad_norm": 0.6277514696121216,
      "learning_rate": 2.2590361445783135e-07,
      "loss": 0.2082,
      "step": 6343
    },
    {
      "epoch": 3.821686746987952,
      "grad_norm": 0.6185612082481384,
      "learning_rate": 2.251506024096386e-07,
      "loss": 0.2608,
      "step": 6344
    },
    {
      "epoch": 3.822289156626506,
      "grad_norm": 0.7676328420639038,
      "learning_rate": 2.2439759036144578e-07,
      "loss": 0.3199,
      "step": 6345
    },
    {
      "epoch": 3.82289156626506,
      "grad_norm": 0.7407426238059998,
      "learning_rate": 2.2364457831325303e-07,
      "loss": 0.2715,
      "step": 6346
    },
    {
      "epoch": 3.8234939759036144,
      "grad_norm": 0.5949681401252747,
      "learning_rate": 2.2289156626506027e-07,
      "loss": 0.2324,
      "step": 6347
    },
    {
      "epoch": 3.824096385542169,
      "grad_norm": 0.5582978129386902,
      "learning_rate": 2.2213855421686748e-07,
      "loss": 0.2433,
      "step": 6348
    },
    {
      "epoch": 3.8246987951807228,
      "grad_norm": 0.6134968996047974,
      "learning_rate": 2.2138554216867473e-07,
      "loss": 0.2574,
      "step": 6349
    },
    {
      "epoch": 3.825301204819277,
      "grad_norm": 0.6205039620399475,
      "learning_rate": 2.2063253012048194e-07,
      "loss": 0.276,
      "step": 6350
    },
    {
      "epoch": 3.8259036144578316,
      "grad_norm": 0.604884147644043,
      "learning_rate": 2.1987951807228916e-07,
      "loss": 0.2218,
      "step": 6351
    },
    {
      "epoch": 3.8265060240963855,
      "grad_norm": 0.6281223297119141,
      "learning_rate": 2.191265060240964e-07,
      "loss": 0.2203,
      "step": 6352
    },
    {
      "epoch": 3.82710843373494,
      "grad_norm": 0.6590340733528137,
      "learning_rate": 2.1837349397590364e-07,
      "loss": 0.2613,
      "step": 6353
    },
    {
      "epoch": 3.827710843373494,
      "grad_norm": 0.6487218141555786,
      "learning_rate": 2.1762048192771083e-07,
      "loss": 0.2745,
      "step": 6354
    },
    {
      "epoch": 3.8283132530120483,
      "grad_norm": 0.6419521570205688,
      "learning_rate": 2.1686746987951808e-07,
      "loss": 0.2423,
      "step": 6355
    },
    {
      "epoch": 3.8289156626506022,
      "grad_norm": 0.6255156993865967,
      "learning_rate": 2.1611445783132532e-07,
      "loss": 0.2315,
      "step": 6356
    },
    {
      "epoch": 3.8295180722891566,
      "grad_norm": 0.6764911413192749,
      "learning_rate": 2.1536144578313254e-07,
      "loss": 0.2688,
      "step": 6357
    },
    {
      "epoch": 3.830120481927711,
      "grad_norm": 0.5997076034545898,
      "learning_rate": 2.1460843373493978e-07,
      "loss": 0.2624,
      "step": 6358
    },
    {
      "epoch": 3.830722891566265,
      "grad_norm": 0.6551225185394287,
      "learning_rate": 2.1385542168674702e-07,
      "loss": 0.2931,
      "step": 6359
    },
    {
      "epoch": 3.8313253012048194,
      "grad_norm": 0.5710499882698059,
      "learning_rate": 2.131024096385542e-07,
      "loss": 0.2298,
      "step": 6360
    },
    {
      "epoch": 3.8319277108433734,
      "grad_norm": 0.8262230753898621,
      "learning_rate": 2.1234939759036145e-07,
      "loss": 0.2607,
      "step": 6361
    },
    {
      "epoch": 3.8325301204819278,
      "grad_norm": 0.592617928981781,
      "learning_rate": 2.115963855421687e-07,
      "loss": 0.2555,
      "step": 6362
    },
    {
      "epoch": 3.8331325301204817,
      "grad_norm": 0.5834618210792542,
      "learning_rate": 2.108433734939759e-07,
      "loss": 0.2266,
      "step": 6363
    },
    {
      "epoch": 3.833734939759036,
      "grad_norm": 0.6196004748344421,
      "learning_rate": 2.1009036144578315e-07,
      "loss": 0.1938,
      "step": 6364
    },
    {
      "epoch": 3.8343373493975905,
      "grad_norm": 0.5945333242416382,
      "learning_rate": 2.093373493975904e-07,
      "loss": 0.232,
      "step": 6365
    },
    {
      "epoch": 3.8349397590361445,
      "grad_norm": 1.0824509859085083,
      "learning_rate": 2.0858433734939759e-07,
      "loss": 0.2706,
      "step": 6366
    },
    {
      "epoch": 3.835542168674699,
      "grad_norm": 0.678810179233551,
      "learning_rate": 2.0783132530120483e-07,
      "loss": 0.3083,
      "step": 6367
    },
    {
      "epoch": 3.8361445783132533,
      "grad_norm": 0.6140271425247192,
      "learning_rate": 2.0707831325301207e-07,
      "loss": 0.2337,
      "step": 6368
    },
    {
      "epoch": 3.8367469879518072,
      "grad_norm": 0.6760694980621338,
      "learning_rate": 2.0632530120481929e-07,
      "loss": 0.2987,
      "step": 6369
    },
    {
      "epoch": 3.837349397590361,
      "grad_norm": 0.5991008877754211,
      "learning_rate": 2.0557228915662653e-07,
      "loss": 0.1997,
      "step": 6370
    },
    {
      "epoch": 3.8379518072289156,
      "grad_norm": 0.5376571416854858,
      "learning_rate": 2.0481927710843377e-07,
      "loss": 0.195,
      "step": 6371
    },
    {
      "epoch": 3.83855421686747,
      "grad_norm": 0.6666827201843262,
      "learning_rate": 2.0406626506024096e-07,
      "loss": 0.2319,
      "step": 6372
    },
    {
      "epoch": 3.839156626506024,
      "grad_norm": 0.6491261124610901,
      "learning_rate": 2.033132530120482e-07,
      "loss": 0.2762,
      "step": 6373
    },
    {
      "epoch": 3.8397590361445784,
      "grad_norm": 0.6618915796279907,
      "learning_rate": 2.0256024096385545e-07,
      "loss": 0.2793,
      "step": 6374
    },
    {
      "epoch": 3.8403614457831328,
      "grad_norm": 0.642613410949707,
      "learning_rate": 2.0180722891566266e-07,
      "loss": 0.3,
      "step": 6375
    },
    {
      "epoch": 3.8409638554216867,
      "grad_norm": 0.5469167828559875,
      "learning_rate": 2.0105421686746988e-07,
      "loss": 0.2022,
      "step": 6376
    },
    {
      "epoch": 3.841566265060241,
      "grad_norm": 0.612676739692688,
      "learning_rate": 2.0030120481927712e-07,
      "loss": 0.2581,
      "step": 6377
    },
    {
      "epoch": 3.842168674698795,
      "grad_norm": 0.5732482075691223,
      "learning_rate": 1.9954819277108434e-07,
      "loss": 0.2105,
      "step": 6378
    },
    {
      "epoch": 3.8427710843373495,
      "grad_norm": 0.5732973217964172,
      "learning_rate": 1.9879518072289158e-07,
      "loss": 0.2513,
      "step": 6379
    },
    {
      "epoch": 3.8433734939759034,
      "grad_norm": 0.5891682505607605,
      "learning_rate": 1.9804216867469882e-07,
      "loss": 0.2664,
      "step": 6380
    },
    {
      "epoch": 3.843975903614458,
      "grad_norm": 0.6665663123130798,
      "learning_rate": 1.97289156626506e-07,
      "loss": 0.3145,
      "step": 6381
    },
    {
      "epoch": 3.8445783132530122,
      "grad_norm": 0.6346067786216736,
      "learning_rate": 1.9653614457831325e-07,
      "loss": 0.2651,
      "step": 6382
    },
    {
      "epoch": 3.845180722891566,
      "grad_norm": 0.5327807664871216,
      "learning_rate": 1.957831325301205e-07,
      "loss": 0.2313,
      "step": 6383
    },
    {
      "epoch": 3.8457831325301206,
      "grad_norm": 0.6754117608070374,
      "learning_rate": 1.9503012048192774e-07,
      "loss": 0.2823,
      "step": 6384
    },
    {
      "epoch": 3.8463855421686746,
      "grad_norm": 0.5910751223564148,
      "learning_rate": 1.9427710843373495e-07,
      "loss": 0.2605,
      "step": 6385
    },
    {
      "epoch": 3.846987951807229,
      "grad_norm": 0.586107075214386,
      "learning_rate": 1.935240963855422e-07,
      "loss": 0.2441,
      "step": 6386
    },
    {
      "epoch": 3.847590361445783,
      "grad_norm": 0.5984276533126831,
      "learning_rate": 1.9277108433734944e-07,
      "loss": 0.2757,
      "step": 6387
    },
    {
      "epoch": 3.8481927710843373,
      "grad_norm": 0.5890230536460876,
      "learning_rate": 1.9201807228915663e-07,
      "loss": 0.2314,
      "step": 6388
    },
    {
      "epoch": 3.8487951807228917,
      "grad_norm": 0.624774158000946,
      "learning_rate": 1.9126506024096387e-07,
      "loss": 0.2744,
      "step": 6389
    },
    {
      "epoch": 3.8493975903614457,
      "grad_norm": 0.6539976000785828,
      "learning_rate": 1.9051204819277111e-07,
      "loss": 0.2803,
      "step": 6390
    },
    {
      "epoch": 3.85,
      "grad_norm": 0.7281762361526489,
      "learning_rate": 1.8975903614457833e-07,
      "loss": 0.2261,
      "step": 6391
    },
    {
      "epoch": 3.8506024096385545,
      "grad_norm": 0.6331362128257751,
      "learning_rate": 1.8900602409638557e-07,
      "loss": 0.2608,
      "step": 6392
    },
    {
      "epoch": 3.8512048192771084,
      "grad_norm": 0.5690335035324097,
      "learning_rate": 1.8825301204819282e-07,
      "loss": 0.2238,
      "step": 6393
    },
    {
      "epoch": 3.8518072289156624,
      "grad_norm": 0.6860098242759705,
      "learning_rate": 1.875e-07,
      "loss": 0.3034,
      "step": 6394
    },
    {
      "epoch": 3.852409638554217,
      "grad_norm": 0.545555591583252,
      "learning_rate": 1.8674698795180725e-07,
      "loss": 0.1962,
      "step": 6395
    },
    {
      "epoch": 3.853012048192771,
      "grad_norm": 0.6207715272903442,
      "learning_rate": 1.859939759036145e-07,
      "loss": 0.2765,
      "step": 6396
    },
    {
      "epoch": 3.853614457831325,
      "grad_norm": 0.5947195887565613,
      "learning_rate": 1.852409638554217e-07,
      "loss": 0.2205,
      "step": 6397
    },
    {
      "epoch": 3.8542168674698796,
      "grad_norm": 0.6618115305900574,
      "learning_rate": 1.8448795180722892e-07,
      "loss": 0.2393,
      "step": 6398
    },
    {
      "epoch": 3.854819277108434,
      "grad_norm": 0.578235924243927,
      "learning_rate": 1.8373493975903616e-07,
      "loss": 0.2384,
      "step": 6399
    },
    {
      "epoch": 3.855421686746988,
      "grad_norm": 0.7279845476150513,
      "learning_rate": 1.8298192771084338e-07,
      "loss": 0.2865,
      "step": 6400
    },
    {
      "epoch": 3.8560240963855423,
      "grad_norm": 0.6591054201126099,
      "learning_rate": 1.8222891566265062e-07,
      "loss": 0.2213,
      "step": 6401
    },
    {
      "epoch": 3.8566265060240963,
      "grad_norm": 0.5522985458374023,
      "learning_rate": 1.8147590361445787e-07,
      "loss": 0.2275,
      "step": 6402
    },
    {
      "epoch": 3.8572289156626507,
      "grad_norm": 0.6973588466644287,
      "learning_rate": 1.8072289156626505e-07,
      "loss": 0.2281,
      "step": 6403
    },
    {
      "epoch": 3.8578313253012047,
      "grad_norm": 0.6502994298934937,
      "learning_rate": 1.799698795180723e-07,
      "loss": 0.2443,
      "step": 6404
    },
    {
      "epoch": 3.858433734939759,
      "grad_norm": 0.8357093334197998,
      "learning_rate": 1.7921686746987954e-07,
      "loss": 0.2501,
      "step": 6405
    },
    {
      "epoch": 3.8590361445783135,
      "grad_norm": 0.581233024597168,
      "learning_rate": 1.7846385542168676e-07,
      "loss": 0.2477,
      "step": 6406
    },
    {
      "epoch": 3.8596385542168674,
      "grad_norm": 0.6935917139053345,
      "learning_rate": 1.77710843373494e-07,
      "loss": 0.254,
      "step": 6407
    },
    {
      "epoch": 3.860240963855422,
      "grad_norm": 0.6156632900238037,
      "learning_rate": 1.7695783132530124e-07,
      "loss": 0.2471,
      "step": 6408
    },
    {
      "epoch": 3.8608433734939758,
      "grad_norm": 0.599769651889801,
      "learning_rate": 1.7620481927710843e-07,
      "loss": 0.2782,
      "step": 6409
    },
    {
      "epoch": 3.86144578313253,
      "grad_norm": 0.6114542484283447,
      "learning_rate": 1.7545180722891567e-07,
      "loss": 0.2697,
      "step": 6410
    },
    {
      "epoch": 3.862048192771084,
      "grad_norm": 0.671053946018219,
      "learning_rate": 1.7469879518072292e-07,
      "loss": 0.2785,
      "step": 6411
    },
    {
      "epoch": 3.8626506024096385,
      "grad_norm": 0.6237685680389404,
      "learning_rate": 1.7394578313253013e-07,
      "loss": 0.2304,
      "step": 6412
    },
    {
      "epoch": 3.863253012048193,
      "grad_norm": 0.6353553533554077,
      "learning_rate": 1.7319277108433737e-07,
      "loss": 0.2362,
      "step": 6413
    },
    {
      "epoch": 3.863855421686747,
      "grad_norm": 0.5735547542572021,
      "learning_rate": 1.7243975903614462e-07,
      "loss": 0.2281,
      "step": 6414
    },
    {
      "epoch": 3.8644578313253013,
      "grad_norm": 0.6627862453460693,
      "learning_rate": 1.716867469879518e-07,
      "loss": 0.2849,
      "step": 6415
    },
    {
      "epoch": 3.8650602409638557,
      "grad_norm": 0.7800773978233337,
      "learning_rate": 1.7093373493975905e-07,
      "loss": 0.3079,
      "step": 6416
    },
    {
      "epoch": 3.8656626506024097,
      "grad_norm": 0.6184359788894653,
      "learning_rate": 1.701807228915663e-07,
      "loss": 0.2748,
      "step": 6417
    },
    {
      "epoch": 3.8662650602409636,
      "grad_norm": 0.5925016403198242,
      "learning_rate": 1.694277108433735e-07,
      "loss": 0.2783,
      "step": 6418
    },
    {
      "epoch": 3.866867469879518,
      "grad_norm": 0.6278877258300781,
      "learning_rate": 1.6867469879518075e-07,
      "loss": 0.2449,
      "step": 6419
    },
    {
      "epoch": 3.8674698795180724,
      "grad_norm": 1.4835635423660278,
      "learning_rate": 1.6792168674698797e-07,
      "loss": 0.304,
      "step": 6420
    },
    {
      "epoch": 3.8680722891566264,
      "grad_norm": 0.6498656272888184,
      "learning_rate": 1.6716867469879518e-07,
      "loss": 0.2018,
      "step": 6421
    },
    {
      "epoch": 3.8686746987951808,
      "grad_norm": 0.6482415795326233,
      "learning_rate": 1.6641566265060242e-07,
      "loss": 0.3179,
      "step": 6422
    },
    {
      "epoch": 3.869277108433735,
      "grad_norm": 0.6605572700500488,
      "learning_rate": 1.6566265060240967e-07,
      "loss": 0.2144,
      "step": 6423
    },
    {
      "epoch": 3.869879518072289,
      "grad_norm": 0.5994843244552612,
      "learning_rate": 1.6490963855421688e-07,
      "loss": 0.2094,
      "step": 6424
    },
    {
      "epoch": 3.8704819277108435,
      "grad_norm": 0.6005122065544128,
      "learning_rate": 1.641566265060241e-07,
      "loss": 0.2043,
      "step": 6425
    },
    {
      "epoch": 3.8710843373493975,
      "grad_norm": 0.6018524765968323,
      "learning_rate": 1.6340361445783134e-07,
      "loss": 0.2387,
      "step": 6426
    },
    {
      "epoch": 3.871686746987952,
      "grad_norm": 0.8221748471260071,
      "learning_rate": 1.6265060240963856e-07,
      "loss": 0.3012,
      "step": 6427
    },
    {
      "epoch": 3.872289156626506,
      "grad_norm": 0.7298389673233032,
      "learning_rate": 1.618975903614458e-07,
      "loss": 0.2682,
      "step": 6428
    },
    {
      "epoch": 3.8728915662650603,
      "grad_norm": 0.5735292434692383,
      "learning_rate": 1.6114457831325304e-07,
      "loss": 0.2199,
      "step": 6429
    },
    {
      "epoch": 3.8734939759036147,
      "grad_norm": 0.9048432111740112,
      "learning_rate": 1.6039156626506023e-07,
      "loss": 0.343,
      "step": 6430
    },
    {
      "epoch": 3.8740963855421686,
      "grad_norm": 0.689859926700592,
      "learning_rate": 1.5963855421686747e-07,
      "loss": 0.2451,
      "step": 6431
    },
    {
      "epoch": 3.874698795180723,
      "grad_norm": 0.5964613556861877,
      "learning_rate": 1.5888554216867472e-07,
      "loss": 0.268,
      "step": 6432
    },
    {
      "epoch": 3.875301204819277,
      "grad_norm": 0.6763572692871094,
      "learning_rate": 1.5813253012048193e-07,
      "loss": 0.2154,
      "step": 6433
    },
    {
      "epoch": 3.8759036144578314,
      "grad_norm": 0.5935840606689453,
      "learning_rate": 1.5737951807228918e-07,
      "loss": 0.2538,
      "step": 6434
    },
    {
      "epoch": 3.8765060240963853,
      "grad_norm": 0.7511098980903625,
      "learning_rate": 1.5662650602409642e-07,
      "loss": 0.306,
      "step": 6435
    },
    {
      "epoch": 3.8771084337349397,
      "grad_norm": 0.6097205877304077,
      "learning_rate": 1.5587349397590363e-07,
      "loss": 0.2202,
      "step": 6436
    },
    {
      "epoch": 3.877710843373494,
      "grad_norm": 0.5819433331489563,
      "learning_rate": 1.5512048192771085e-07,
      "loss": 0.2469,
      "step": 6437
    },
    {
      "epoch": 3.878313253012048,
      "grad_norm": 0.6224888563156128,
      "learning_rate": 1.5436746987951807e-07,
      "loss": 0.1995,
      "step": 6438
    },
    {
      "epoch": 3.8789156626506025,
      "grad_norm": 0.5631318688392639,
      "learning_rate": 1.536144578313253e-07,
      "loss": 0.2063,
      "step": 6439
    },
    {
      "epoch": 3.8795180722891565,
      "grad_norm": 0.6185988783836365,
      "learning_rate": 1.5286144578313255e-07,
      "loss": 0.3139,
      "step": 6440
    },
    {
      "epoch": 3.880120481927711,
      "grad_norm": 0.6873582601547241,
      "learning_rate": 1.5210843373493977e-07,
      "loss": 0.2688,
      "step": 6441
    },
    {
      "epoch": 3.880722891566265,
      "grad_norm": 0.6146360635757446,
      "learning_rate": 1.51355421686747e-07,
      "loss": 0.2656,
      "step": 6442
    },
    {
      "epoch": 3.8813253012048192,
      "grad_norm": 0.6548255085945129,
      "learning_rate": 1.5060240963855423e-07,
      "loss": 0.2813,
      "step": 6443
    },
    {
      "epoch": 3.8819277108433736,
      "grad_norm": 0.6581025719642639,
      "learning_rate": 1.4984939759036144e-07,
      "loss": 0.26,
      "step": 6444
    },
    {
      "epoch": 3.8825301204819276,
      "grad_norm": 0.6847738027572632,
      "learning_rate": 1.4909638554216868e-07,
      "loss": 0.3147,
      "step": 6445
    },
    {
      "epoch": 3.883132530120482,
      "grad_norm": 0.5847508311271667,
      "learning_rate": 1.4834337349397593e-07,
      "loss": 0.2754,
      "step": 6446
    },
    {
      "epoch": 3.8837349397590364,
      "grad_norm": 0.6883130669593811,
      "learning_rate": 1.4759036144578314e-07,
      "loss": 0.2478,
      "step": 6447
    },
    {
      "epoch": 3.8843373493975903,
      "grad_norm": 0.6249864101409912,
      "learning_rate": 1.4683734939759039e-07,
      "loss": 0.2313,
      "step": 6448
    },
    {
      "epoch": 3.8849397590361443,
      "grad_norm": 0.5907880067825317,
      "learning_rate": 1.460843373493976e-07,
      "loss": 0.235,
      "step": 6449
    },
    {
      "epoch": 3.8855421686746987,
      "grad_norm": 0.6390424370765686,
      "learning_rate": 1.4533132530120482e-07,
      "loss": 0.3132,
      "step": 6450
    },
    {
      "epoch": 3.886144578313253,
      "grad_norm": 0.6056640148162842,
      "learning_rate": 1.4457831325301206e-07,
      "loss": 0.2296,
      "step": 6451
    },
    {
      "epoch": 3.886746987951807,
      "grad_norm": 0.6755487322807312,
      "learning_rate": 1.4382530120481928e-07,
      "loss": 0.2843,
      "step": 6452
    },
    {
      "epoch": 3.8873493975903615,
      "grad_norm": 0.6650024056434631,
      "learning_rate": 1.4307228915662652e-07,
      "loss": 0.2747,
      "step": 6453
    },
    {
      "epoch": 3.887951807228916,
      "grad_norm": 0.6152667999267578,
      "learning_rate": 1.4231927710843376e-07,
      "loss": 0.2661,
      "step": 6454
    },
    {
      "epoch": 3.88855421686747,
      "grad_norm": 0.7404707670211792,
      "learning_rate": 1.4156626506024098e-07,
      "loss": 0.2767,
      "step": 6455
    },
    {
      "epoch": 3.8891566265060242,
      "grad_norm": 0.6574030518531799,
      "learning_rate": 1.408132530120482e-07,
      "loss": 0.2836,
      "step": 6456
    },
    {
      "epoch": 3.889759036144578,
      "grad_norm": 0.6774113178253174,
      "learning_rate": 1.4006024096385544e-07,
      "loss": 0.2739,
      "step": 6457
    },
    {
      "epoch": 3.8903614457831326,
      "grad_norm": 0.5942016243934631,
      "learning_rate": 1.3930722891566265e-07,
      "loss": 0.2463,
      "step": 6458
    },
    {
      "epoch": 3.8909638554216865,
      "grad_norm": 0.6055424213409424,
      "learning_rate": 1.385542168674699e-07,
      "loss": 0.2119,
      "step": 6459
    },
    {
      "epoch": 3.891566265060241,
      "grad_norm": 0.6860093474388123,
      "learning_rate": 1.378012048192771e-07,
      "loss": 0.2998,
      "step": 6460
    },
    {
      "epoch": 3.8921686746987953,
      "grad_norm": 0.5492768287658691,
      "learning_rate": 1.3704819277108435e-07,
      "loss": 0.2616,
      "step": 6461
    },
    {
      "epoch": 3.8927710843373493,
      "grad_norm": 0.6249667406082153,
      "learning_rate": 1.362951807228916e-07,
      "loss": 0.2404,
      "step": 6462
    },
    {
      "epoch": 3.8933734939759037,
      "grad_norm": 0.6794984936714172,
      "learning_rate": 1.355421686746988e-07,
      "loss": 0.239,
      "step": 6463
    },
    {
      "epoch": 3.8939759036144577,
      "grad_norm": 0.6374698877334595,
      "learning_rate": 1.3478915662650603e-07,
      "loss": 0.2165,
      "step": 6464
    },
    {
      "epoch": 3.894578313253012,
      "grad_norm": 0.5611562728881836,
      "learning_rate": 1.3403614457831327e-07,
      "loss": 0.2851,
      "step": 6465
    },
    {
      "epoch": 3.895180722891566,
      "grad_norm": 0.6052350997924805,
      "learning_rate": 1.3328313253012049e-07,
      "loss": 0.2343,
      "step": 6466
    },
    {
      "epoch": 3.8957831325301204,
      "grad_norm": 0.6319916844367981,
      "learning_rate": 1.3253012048192773e-07,
      "loss": 0.2,
      "step": 6467
    },
    {
      "epoch": 3.896385542168675,
      "grad_norm": 0.6779952049255371,
      "learning_rate": 1.3177710843373497e-07,
      "loss": 0.2381,
      "step": 6468
    },
    {
      "epoch": 3.896987951807229,
      "grad_norm": 0.7462678551673889,
      "learning_rate": 1.3102409638554219e-07,
      "loss": 0.3437,
      "step": 6469
    },
    {
      "epoch": 3.897590361445783,
      "grad_norm": 0.6751783490180969,
      "learning_rate": 1.302710843373494e-07,
      "loss": 0.265,
      "step": 6470
    },
    {
      "epoch": 3.8981927710843376,
      "grad_norm": 0.6055657863616943,
      "learning_rate": 1.2951807228915665e-07,
      "loss": 0.1876,
      "step": 6471
    },
    {
      "epoch": 3.8987951807228916,
      "grad_norm": 0.54167240858078,
      "learning_rate": 1.2876506024096386e-07,
      "loss": 0.2677,
      "step": 6472
    },
    {
      "epoch": 3.8993975903614455,
      "grad_norm": 0.6827008724212646,
      "learning_rate": 1.280120481927711e-07,
      "loss": 0.28,
      "step": 6473
    },
    {
      "epoch": 3.9,
      "grad_norm": 0.6142973303794861,
      "learning_rate": 1.2725903614457832e-07,
      "loss": 0.2669,
      "step": 6474
    },
    {
      "epoch": 3.9006024096385543,
      "grad_norm": 0.6818557381629944,
      "learning_rate": 1.2650602409638556e-07,
      "loss": 0.2693,
      "step": 6475
    },
    {
      "epoch": 3.9012048192771083,
      "grad_norm": 0.6081026196479797,
      "learning_rate": 1.2575301204819278e-07,
      "loss": 0.2359,
      "step": 6476
    },
    {
      "epoch": 3.9018072289156627,
      "grad_norm": 0.6754383444786072,
      "learning_rate": 1.2500000000000002e-07,
      "loss": 0.2733,
      "step": 6477
    },
    {
      "epoch": 3.902409638554217,
      "grad_norm": 0.5747378468513489,
      "learning_rate": 1.2424698795180724e-07,
      "loss": 0.2996,
      "step": 6478
    },
    {
      "epoch": 3.903012048192771,
      "grad_norm": 0.7192755937576294,
      "learning_rate": 1.2349397590361445e-07,
      "loss": 0.2836,
      "step": 6479
    },
    {
      "epoch": 3.9036144578313254,
      "grad_norm": 0.6130698919296265,
      "learning_rate": 1.227409638554217e-07,
      "loss": 0.319,
      "step": 6480
    },
    {
      "epoch": 3.9042168674698794,
      "grad_norm": 0.7998738288879395,
      "learning_rate": 1.2198795180722894e-07,
      "loss": 0.2588,
      "step": 6481
    },
    {
      "epoch": 3.904819277108434,
      "grad_norm": 0.6892238855361938,
      "learning_rate": 1.2123493975903615e-07,
      "loss": 0.2541,
      "step": 6482
    },
    {
      "epoch": 3.9054216867469878,
      "grad_norm": 0.6142672300338745,
      "learning_rate": 1.204819277108434e-07,
      "loss": 0.2502,
      "step": 6483
    },
    {
      "epoch": 3.906024096385542,
      "grad_norm": 0.6395397782325745,
      "learning_rate": 1.197289156626506e-07,
      "loss": 0.2565,
      "step": 6484
    },
    {
      "epoch": 3.9066265060240966,
      "grad_norm": 0.5604417324066162,
      "learning_rate": 1.1897590361445784e-07,
      "loss": 0.2223,
      "step": 6485
    },
    {
      "epoch": 3.9072289156626505,
      "grad_norm": 0.684394359588623,
      "learning_rate": 1.1822289156626507e-07,
      "loss": 0.3302,
      "step": 6486
    },
    {
      "epoch": 3.907831325301205,
      "grad_norm": 0.5817155838012695,
      "learning_rate": 1.174698795180723e-07,
      "loss": 0.2687,
      "step": 6487
    },
    {
      "epoch": 3.908433734939759,
      "grad_norm": 0.6333428025245667,
      "learning_rate": 1.1671686746987952e-07,
      "loss": 0.2711,
      "step": 6488
    },
    {
      "epoch": 3.9090361445783133,
      "grad_norm": 0.6379318237304688,
      "learning_rate": 1.1596385542168676e-07,
      "loss": 0.2238,
      "step": 6489
    },
    {
      "epoch": 3.9096385542168672,
      "grad_norm": 0.63720703125,
      "learning_rate": 1.1521084337349399e-07,
      "loss": 0.2137,
      "step": 6490
    },
    {
      "epoch": 3.9102409638554216,
      "grad_norm": 0.6903573870658875,
      "learning_rate": 1.144578313253012e-07,
      "loss": 0.2816,
      "step": 6491
    },
    {
      "epoch": 3.910843373493976,
      "grad_norm": 0.6118676662445068,
      "learning_rate": 1.1370481927710845e-07,
      "loss": 0.2113,
      "step": 6492
    },
    {
      "epoch": 3.91144578313253,
      "grad_norm": 0.5462414622306824,
      "learning_rate": 1.1295180722891568e-07,
      "loss": 0.2256,
      "step": 6493
    },
    {
      "epoch": 3.9120481927710844,
      "grad_norm": 0.6196199655532837,
      "learning_rate": 1.1219879518072289e-07,
      "loss": 0.2342,
      "step": 6494
    },
    {
      "epoch": 3.912650602409639,
      "grad_norm": 0.6513418555259705,
      "learning_rate": 1.1144578313253013e-07,
      "loss": 0.2455,
      "step": 6495
    },
    {
      "epoch": 3.9132530120481928,
      "grad_norm": 0.5623270869255066,
      "learning_rate": 1.1069277108433736e-07,
      "loss": 0.2325,
      "step": 6496
    },
    {
      "epoch": 3.9138554216867467,
      "grad_norm": 0.5892037749290466,
      "learning_rate": 1.0993975903614458e-07,
      "loss": 0.2346,
      "step": 6497
    },
    {
      "epoch": 3.914457831325301,
      "grad_norm": 0.6522407531738281,
      "learning_rate": 1.0918674698795182e-07,
      "loss": 0.2741,
      "step": 6498
    },
    {
      "epoch": 3.9150602409638555,
      "grad_norm": 0.587108314037323,
      "learning_rate": 1.0843373493975904e-07,
      "loss": 0.2781,
      "step": 6499
    },
    {
      "epoch": 3.9156626506024095,
      "grad_norm": 0.6008151769638062,
      "learning_rate": 1.0768072289156627e-07,
      "loss": 0.27,
      "step": 6500
    }
  ],
  "logging_steps": 1,
  "max_steps": 6640,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 4.534966190560248e+18,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
