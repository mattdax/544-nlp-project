{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 0.30120481927710846,
  "eval_steps": 500,
  "global_step": 500,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.0006024096385542169,
      "grad_norm": 1.5560017824172974,
      "learning_rate": 4.999246987951807e-06,
      "loss": 3.2004,
      "step": 1
    },
    {
      "epoch": 0.0012048192771084338,
      "grad_norm": 1.997064471244812,
      "learning_rate": 4.998493975903615e-06,
      "loss": 3.1482,
      "step": 2
    },
    {
      "epoch": 0.0018072289156626507,
      "grad_norm": 1.5352808237075806,
      "learning_rate": 4.997740963855422e-06,
      "loss": 3.1304,
      "step": 3
    },
    {
      "epoch": 0.0024096385542168677,
      "grad_norm": 1.4374537467956543,
      "learning_rate": 4.99698795180723e-06,
      "loss": 2.9942,
      "step": 4
    },
    {
      "epoch": 0.0030120481927710845,
      "grad_norm": 1.7295955419540405,
      "learning_rate": 4.996234939759037e-06,
      "loss": 3.1322,
      "step": 5
    },
    {
      "epoch": 0.0036144578313253013,
      "grad_norm": 2.4129886627197266,
      "learning_rate": 4.995481927710844e-06,
      "loss": 3.0901,
      "step": 6
    },
    {
      "epoch": 0.004216867469879518,
      "grad_norm": 1.53774094581604,
      "learning_rate": 4.9947289156626514e-06,
      "loss": 3.0746,
      "step": 7
    },
    {
      "epoch": 0.004819277108433735,
      "grad_norm": 1.5671591758728027,
      "learning_rate": 4.993975903614458e-06,
      "loss": 3.1166,
      "step": 8
    },
    {
      "epoch": 0.005421686746987952,
      "grad_norm": 1.5100337266921997,
      "learning_rate": 4.993222891566265e-06,
      "loss": 3.0484,
      "step": 9
    },
    {
      "epoch": 0.006024096385542169,
      "grad_norm": 1.6100335121154785,
      "learning_rate": 4.992469879518072e-06,
      "loss": 3.1846,
      "step": 10
    },
    {
      "epoch": 0.006626506024096385,
      "grad_norm": 1.5346754789352417,
      "learning_rate": 4.99171686746988e-06,
      "loss": 3.0907,
      "step": 11
    },
    {
      "epoch": 0.007228915662650603,
      "grad_norm": 1.6097053289413452,
      "learning_rate": 4.990963855421687e-06,
      "loss": 3.1056,
      "step": 12
    },
    {
      "epoch": 0.00783132530120482,
      "grad_norm": 1.5273281335830688,
      "learning_rate": 4.990210843373494e-06,
      "loss": 3.0029,
      "step": 13
    },
    {
      "epoch": 0.008433734939759036,
      "grad_norm": 1.6634138822555542,
      "learning_rate": 4.989457831325302e-06,
      "loss": 3.1393,
      "step": 14
    },
    {
      "epoch": 0.009036144578313253,
      "grad_norm": 1.5672446489334106,
      "learning_rate": 4.9887048192771085e-06,
      "loss": 3.0395,
      "step": 15
    },
    {
      "epoch": 0.00963855421686747,
      "grad_norm": 1.6599860191345215,
      "learning_rate": 4.987951807228916e-06,
      "loss": 3.17,
      "step": 16
    },
    {
      "epoch": 0.010240963855421687,
      "grad_norm": 1.6183897256851196,
      "learning_rate": 4.987198795180723e-06,
      "loss": 3.0149,
      "step": 17
    },
    {
      "epoch": 0.010843373493975903,
      "grad_norm": 1.6367567777633667,
      "learning_rate": 4.986445783132531e-06,
      "loss": 3.0557,
      "step": 18
    },
    {
      "epoch": 0.01144578313253012,
      "grad_norm": 1.5787116289138794,
      "learning_rate": 4.985692771084338e-06,
      "loss": 2.9972,
      "step": 19
    },
    {
      "epoch": 0.012048192771084338,
      "grad_norm": 1.6632744073867798,
      "learning_rate": 4.984939759036145e-06,
      "loss": 2.9813,
      "step": 20
    },
    {
      "epoch": 0.012650602409638554,
      "grad_norm": 1.6701604127883911,
      "learning_rate": 4.984186746987953e-06,
      "loss": 3.063,
      "step": 21
    },
    {
      "epoch": 0.01325301204819277,
      "grad_norm": 2.0289077758789062,
      "learning_rate": 4.9834337349397595e-06,
      "loss": 3.1063,
      "step": 22
    },
    {
      "epoch": 0.013855421686746987,
      "grad_norm": 1.7468914985656738,
      "learning_rate": 4.982680722891567e-06,
      "loss": 3.0317,
      "step": 23
    },
    {
      "epoch": 0.014457831325301205,
      "grad_norm": 1.7177053689956665,
      "learning_rate": 4.981927710843374e-06,
      "loss": 3.0626,
      "step": 24
    },
    {
      "epoch": 0.015060240963855422,
      "grad_norm": 1.685558795928955,
      "learning_rate": 4.981174698795181e-06,
      "loss": 3.0317,
      "step": 25
    },
    {
      "epoch": 0.01566265060240964,
      "grad_norm": 1.805503249168396,
      "learning_rate": 4.980421686746988e-06,
      "loss": 3.0812,
      "step": 26
    },
    {
      "epoch": 0.016265060240963854,
      "grad_norm": 1.6212949752807617,
      "learning_rate": 4.979668674698796e-06,
      "loss": 2.9552,
      "step": 27
    },
    {
      "epoch": 0.016867469879518072,
      "grad_norm": 2.0517477989196777,
      "learning_rate": 4.978915662650603e-06,
      "loss": 3.0266,
      "step": 28
    },
    {
      "epoch": 0.01746987951807229,
      "grad_norm": 1.6428290605545044,
      "learning_rate": 4.97816265060241e-06,
      "loss": 2.9747,
      "step": 29
    },
    {
      "epoch": 0.018072289156626505,
      "grad_norm": 1.7700673341751099,
      "learning_rate": 4.9774096385542175e-06,
      "loss": 3.0747,
      "step": 30
    },
    {
      "epoch": 0.018674698795180723,
      "grad_norm": 1.7667503356933594,
      "learning_rate": 4.976656626506024e-06,
      "loss": 3.0569,
      "step": 31
    },
    {
      "epoch": 0.01927710843373494,
      "grad_norm": 1.7524465322494507,
      "learning_rate": 4.975903614457831e-06,
      "loss": 3.0153,
      "step": 32
    },
    {
      "epoch": 0.019879518072289156,
      "grad_norm": 1.774735689163208,
      "learning_rate": 4.975150602409639e-06,
      "loss": 3.037,
      "step": 33
    },
    {
      "epoch": 0.020481927710843374,
      "grad_norm": 1.7779752016067505,
      "learning_rate": 4.974397590361446e-06,
      "loss": 2.9809,
      "step": 34
    },
    {
      "epoch": 0.02108433734939759,
      "grad_norm": 1.8699010610580444,
      "learning_rate": 4.973644578313254e-06,
      "loss": 3.0567,
      "step": 35
    },
    {
      "epoch": 0.021686746987951807,
      "grad_norm": 1.7334027290344238,
      "learning_rate": 4.972891566265061e-06,
      "loss": 2.9463,
      "step": 36
    },
    {
      "epoch": 0.022289156626506025,
      "grad_norm": 1.7609328031539917,
      "learning_rate": 4.972138554216868e-06,
      "loss": 2.9326,
      "step": 37
    },
    {
      "epoch": 0.02289156626506024,
      "grad_norm": 1.814315676689148,
      "learning_rate": 4.971385542168675e-06,
      "loss": 2.9606,
      "step": 38
    },
    {
      "epoch": 0.023493975903614458,
      "grad_norm": 1.823574185371399,
      "learning_rate": 4.970632530120482e-06,
      "loss": 3.0073,
      "step": 39
    },
    {
      "epoch": 0.024096385542168676,
      "grad_norm": 2.6629130840301514,
      "learning_rate": 4.96987951807229e-06,
      "loss": 3.0191,
      "step": 40
    },
    {
      "epoch": 0.02469879518072289,
      "grad_norm": 1.8284250497817993,
      "learning_rate": 4.969126506024097e-06,
      "loss": 3.0019,
      "step": 41
    },
    {
      "epoch": 0.02530120481927711,
      "grad_norm": 1.8359827995300293,
      "learning_rate": 4.968373493975904e-06,
      "loss": 2.9233,
      "step": 42
    },
    {
      "epoch": 0.025903614457831327,
      "grad_norm": 2.3709397315979004,
      "learning_rate": 4.967620481927711e-06,
      "loss": 2.9344,
      "step": 43
    },
    {
      "epoch": 0.02650602409638554,
      "grad_norm": 1.7280223369598389,
      "learning_rate": 4.966867469879519e-06,
      "loss": 2.7996,
      "step": 44
    },
    {
      "epoch": 0.02710843373493976,
      "grad_norm": 1.9490025043487549,
      "learning_rate": 4.966114457831326e-06,
      "loss": 2.9419,
      "step": 45
    },
    {
      "epoch": 0.027710843373493974,
      "grad_norm": 1.8118245601654053,
      "learning_rate": 4.9653614457831325e-06,
      "loss": 2.8691,
      "step": 46
    },
    {
      "epoch": 0.028313253012048192,
      "grad_norm": 1.9268324375152588,
      "learning_rate": 4.96460843373494e-06,
      "loss": 2.8751,
      "step": 47
    },
    {
      "epoch": 0.02891566265060241,
      "grad_norm": 1.8548219203948975,
      "learning_rate": 4.963855421686747e-06,
      "loss": 2.9031,
      "step": 48
    },
    {
      "epoch": 0.029518072289156625,
      "grad_norm": 1.9112457036972046,
      "learning_rate": 4.963102409638554e-06,
      "loss": 2.9107,
      "step": 49
    },
    {
      "epoch": 0.030120481927710843,
      "grad_norm": 1.8848193883895874,
      "learning_rate": 4.962349397590362e-06,
      "loss": 2.9058,
      "step": 50
    },
    {
      "epoch": 0.03072289156626506,
      "grad_norm": 1.9256013631820679,
      "learning_rate": 4.961596385542169e-06,
      "loss": 2.9399,
      "step": 51
    },
    {
      "epoch": 0.03132530120481928,
      "grad_norm": 1.993452548980713,
      "learning_rate": 4.960843373493977e-06,
      "loss": 2.9217,
      "step": 52
    },
    {
      "epoch": 0.031927710843373494,
      "grad_norm": 1.9353128671646118,
      "learning_rate": 4.9600903614457835e-06,
      "loss": 2.9403,
      "step": 53
    },
    {
      "epoch": 0.03253012048192771,
      "grad_norm": 1.9440993070602417,
      "learning_rate": 4.959337349397591e-06,
      "loss": 2.8833,
      "step": 54
    },
    {
      "epoch": 0.03313253012048193,
      "grad_norm": 1.9619643688201904,
      "learning_rate": 4.958584337349398e-06,
      "loss": 2.9449,
      "step": 55
    },
    {
      "epoch": 0.033734939759036145,
      "grad_norm": 1.8817287683486938,
      "learning_rate": 4.957831325301205e-06,
      "loss": 2.8913,
      "step": 56
    },
    {
      "epoch": 0.03433734939759036,
      "grad_norm": 2.5624420642852783,
      "learning_rate": 4.957078313253013e-06,
      "loss": 2.9439,
      "step": 57
    },
    {
      "epoch": 0.03493975903614458,
      "grad_norm": 1.958603024482727,
      "learning_rate": 4.95632530120482e-06,
      "loss": 2.8326,
      "step": 58
    },
    {
      "epoch": 0.035542168674698796,
      "grad_norm": 2.0451064109802246,
      "learning_rate": 4.955572289156627e-06,
      "loss": 2.9386,
      "step": 59
    },
    {
      "epoch": 0.03614457831325301,
      "grad_norm": 1.9563013315200806,
      "learning_rate": 4.9548192771084345e-06,
      "loss": 2.8671,
      "step": 60
    },
    {
      "epoch": 0.03674698795180723,
      "grad_norm": 2.115953207015991,
      "learning_rate": 4.9540662650602415e-06,
      "loss": 2.9424,
      "step": 61
    },
    {
      "epoch": 0.03734939759036145,
      "grad_norm": 1.972489833831787,
      "learning_rate": 4.953313253012048e-06,
      "loss": 2.7965,
      "step": 62
    },
    {
      "epoch": 0.03795180722891566,
      "grad_norm": 2.1234753131866455,
      "learning_rate": 4.952560240963855e-06,
      "loss": 2.8227,
      "step": 63
    },
    {
      "epoch": 0.03855421686746988,
      "grad_norm": 1.9756735563278198,
      "learning_rate": 4.951807228915663e-06,
      "loss": 2.8408,
      "step": 64
    },
    {
      "epoch": 0.0391566265060241,
      "grad_norm": 2.0340046882629395,
      "learning_rate": 4.95105421686747e-06,
      "loss": 2.8616,
      "step": 65
    },
    {
      "epoch": 0.03975903614457831,
      "grad_norm": 2.019714117050171,
      "learning_rate": 4.950301204819278e-06,
      "loss": 2.8578,
      "step": 66
    },
    {
      "epoch": 0.04036144578313253,
      "grad_norm": 2.019116163253784,
      "learning_rate": 4.949548192771085e-06,
      "loss": 2.8288,
      "step": 67
    },
    {
      "epoch": 0.04096385542168675,
      "grad_norm": 1.9843062162399292,
      "learning_rate": 4.948795180722892e-06,
      "loss": 2.8236,
      "step": 68
    },
    {
      "epoch": 0.04156626506024096,
      "grad_norm": 2.0338430404663086,
      "learning_rate": 4.948042168674699e-06,
      "loss": 2.7741,
      "step": 69
    },
    {
      "epoch": 0.04216867469879518,
      "grad_norm": 2.3002982139587402,
      "learning_rate": 4.947289156626506e-06,
      "loss": 2.8032,
      "step": 70
    },
    {
      "epoch": 0.0427710843373494,
      "grad_norm": 2.77919340133667,
      "learning_rate": 4.946536144578314e-06,
      "loss": 2.6654,
      "step": 71
    },
    {
      "epoch": 0.043373493975903614,
      "grad_norm": 2.038694381713867,
      "learning_rate": 4.945783132530121e-06,
      "loss": 2.8343,
      "step": 72
    },
    {
      "epoch": 0.04397590361445783,
      "grad_norm": 2.03530216217041,
      "learning_rate": 4.945030120481928e-06,
      "loss": 2.7558,
      "step": 73
    },
    {
      "epoch": 0.04457831325301205,
      "grad_norm": 2.009891986846924,
      "learning_rate": 4.944277108433736e-06,
      "loss": 2.7467,
      "step": 74
    },
    {
      "epoch": 0.045180722891566265,
      "grad_norm": 1.9370596408843994,
      "learning_rate": 4.943524096385543e-06,
      "loss": 2.6901,
      "step": 75
    },
    {
      "epoch": 0.04578313253012048,
      "grad_norm": 2.1392924785614014,
      "learning_rate": 4.9427710843373496e-06,
      "loss": 2.7825,
      "step": 76
    },
    {
      "epoch": 0.0463855421686747,
      "grad_norm": 2.181187152862549,
      "learning_rate": 4.942018072289157e-06,
      "loss": 2.7199,
      "step": 77
    },
    {
      "epoch": 0.046987951807228916,
      "grad_norm": 2.059657573699951,
      "learning_rate": 4.941265060240964e-06,
      "loss": 2.7017,
      "step": 78
    },
    {
      "epoch": 0.04759036144578313,
      "grad_norm": 2.0000810623168945,
      "learning_rate": 4.940512048192771e-06,
      "loss": 2.7297,
      "step": 79
    },
    {
      "epoch": 0.04819277108433735,
      "grad_norm": 2.0452146530151367,
      "learning_rate": 4.939759036144578e-06,
      "loss": 2.7294,
      "step": 80
    },
    {
      "epoch": 0.04879518072289157,
      "grad_norm": 2.025296926498413,
      "learning_rate": 4.939006024096386e-06,
      "loss": 2.709,
      "step": 81
    },
    {
      "epoch": 0.04939759036144578,
      "grad_norm": 1.9991015195846558,
      "learning_rate": 4.938253012048193e-06,
      "loss": 2.7013,
      "step": 82
    },
    {
      "epoch": 0.05,
      "grad_norm": 2.1129090785980225,
      "learning_rate": 4.937500000000001e-06,
      "loss": 2.7777,
      "step": 83
    },
    {
      "epoch": 0.05060240963855422,
      "grad_norm": 1.9001072645187378,
      "learning_rate": 4.9367469879518075e-06,
      "loss": 2.6266,
      "step": 84
    },
    {
      "epoch": 0.05120481927710843,
      "grad_norm": 2.0370075702667236,
      "learning_rate": 4.9359939759036144e-06,
      "loss": 2.6731,
      "step": 85
    },
    {
      "epoch": 0.051807228915662654,
      "grad_norm": 2.113426685333252,
      "learning_rate": 4.935240963855422e-06,
      "loss": 2.6682,
      "step": 86
    },
    {
      "epoch": 0.05240963855421687,
      "grad_norm": 2.028594493865967,
      "learning_rate": 4.934487951807229e-06,
      "loss": 2.6077,
      "step": 87
    },
    {
      "epoch": 0.05301204819277108,
      "grad_norm": 2.107243776321411,
      "learning_rate": 4.933734939759037e-06,
      "loss": 2.6638,
      "step": 88
    },
    {
      "epoch": 0.053614457831325305,
      "grad_norm": 2.032470941543579,
      "learning_rate": 4.932981927710844e-06,
      "loss": 2.632,
      "step": 89
    },
    {
      "epoch": 0.05421686746987952,
      "grad_norm": 2.035618305206299,
      "learning_rate": 4.932228915662652e-06,
      "loss": 2.6337,
      "step": 90
    },
    {
      "epoch": 0.054819277108433734,
      "grad_norm": 2.0753800868988037,
      "learning_rate": 4.9314759036144585e-06,
      "loss": 2.6409,
      "step": 91
    },
    {
      "epoch": 0.05542168674698795,
      "grad_norm": 2.0134119987487793,
      "learning_rate": 4.9307228915662654e-06,
      "loss": 2.5818,
      "step": 92
    },
    {
      "epoch": 0.05602409638554217,
      "grad_norm": 2.088212490081787,
      "learning_rate": 4.929969879518073e-06,
      "loss": 2.6167,
      "step": 93
    },
    {
      "epoch": 0.056626506024096385,
      "grad_norm": 2.1010773181915283,
      "learning_rate": 4.92921686746988e-06,
      "loss": 2.5543,
      "step": 94
    },
    {
      "epoch": 0.0572289156626506,
      "grad_norm": 2.039689540863037,
      "learning_rate": 4.928463855421687e-06,
      "loss": 2.5772,
      "step": 95
    },
    {
      "epoch": 0.05783132530120482,
      "grad_norm": 2.0662152767181396,
      "learning_rate": 4.927710843373494e-06,
      "loss": 2.5832,
      "step": 96
    },
    {
      "epoch": 0.058433734939759036,
      "grad_norm": 2.0541329383850098,
      "learning_rate": 4.926957831325302e-06,
      "loss": 2.5983,
      "step": 97
    },
    {
      "epoch": 0.05903614457831325,
      "grad_norm": 1.9729784727096558,
      "learning_rate": 4.926204819277109e-06,
      "loss": 2.5724,
      "step": 98
    },
    {
      "epoch": 0.05963855421686747,
      "grad_norm": 2.0437204837799072,
      "learning_rate": 4.925451807228916e-06,
      "loss": 2.5535,
      "step": 99
    },
    {
      "epoch": 0.060240963855421686,
      "grad_norm": 2.0962624549865723,
      "learning_rate": 4.924698795180723e-06,
      "loss": 2.5762,
      "step": 100
    },
    {
      "epoch": 0.0608433734939759,
      "grad_norm": 2.101814031600952,
      "learning_rate": 4.92394578313253e-06,
      "loss": 2.5978,
      "step": 101
    },
    {
      "epoch": 0.06144578313253012,
      "grad_norm": 1.958775281906128,
      "learning_rate": 4.923192771084338e-06,
      "loss": 2.5598,
      "step": 102
    },
    {
      "epoch": 0.06204819277108434,
      "grad_norm": 1.9599649906158447,
      "learning_rate": 4.922439759036145e-06,
      "loss": 2.5176,
      "step": 103
    },
    {
      "epoch": 0.06265060240963856,
      "grad_norm": 2.0039255619049072,
      "learning_rate": 4.921686746987952e-06,
      "loss": 2.5377,
      "step": 104
    },
    {
      "epoch": 0.06325301204819277,
      "grad_norm": 3.2920899391174316,
      "learning_rate": 4.92093373493976e-06,
      "loss": 2.5399,
      "step": 105
    },
    {
      "epoch": 0.06385542168674699,
      "grad_norm": 2.010145664215088,
      "learning_rate": 4.920180722891567e-06,
      "loss": 2.5805,
      "step": 106
    },
    {
      "epoch": 0.06445783132530121,
      "grad_norm": 1.9549479484558105,
      "learning_rate": 4.919427710843374e-06,
      "loss": 2.4889,
      "step": 107
    },
    {
      "epoch": 0.06506024096385542,
      "grad_norm": 1.9183729887008667,
      "learning_rate": 4.918674698795181e-06,
      "loss": 2.4688,
      "step": 108
    },
    {
      "epoch": 0.06566265060240964,
      "grad_norm": 2.0119619369506836,
      "learning_rate": 4.917921686746988e-06,
      "loss": 2.5069,
      "step": 109
    },
    {
      "epoch": 0.06626506024096386,
      "grad_norm": 1.99326753616333,
      "learning_rate": 4.917168674698796e-06,
      "loss": 2.5252,
      "step": 110
    },
    {
      "epoch": 0.06686746987951807,
      "grad_norm": 1.9048348665237427,
      "learning_rate": 4.916415662650603e-06,
      "loss": 2.4236,
      "step": 111
    },
    {
      "epoch": 0.06746987951807229,
      "grad_norm": 1.9281142950057983,
      "learning_rate": 4.91566265060241e-06,
      "loss": 2.4867,
      "step": 112
    },
    {
      "epoch": 0.06807228915662651,
      "grad_norm": 1.8916959762573242,
      "learning_rate": 4.914909638554217e-06,
      "loss": 2.4362,
      "step": 113
    },
    {
      "epoch": 0.06867469879518072,
      "grad_norm": 2.005871295928955,
      "learning_rate": 4.9141566265060246e-06,
      "loss": 2.4842,
      "step": 114
    },
    {
      "epoch": 0.06927710843373494,
      "grad_norm": 1.8948609828948975,
      "learning_rate": 4.9134036144578315e-06,
      "loss": 2.394,
      "step": 115
    },
    {
      "epoch": 0.06987951807228916,
      "grad_norm": 2.2376580238342285,
      "learning_rate": 4.912650602409638e-06,
      "loss": 2.4407,
      "step": 116
    },
    {
      "epoch": 0.07048192771084337,
      "grad_norm": 2.0686135292053223,
      "learning_rate": 4.911897590361446e-06,
      "loss": 2.4062,
      "step": 117
    },
    {
      "epoch": 0.07108433734939759,
      "grad_norm": 1.930152416229248,
      "learning_rate": 4.911144578313253e-06,
      "loss": 2.4261,
      "step": 118
    },
    {
      "epoch": 0.07168674698795181,
      "grad_norm": 1.875993013381958,
      "learning_rate": 4.910391566265061e-06,
      "loss": 2.3722,
      "step": 119
    },
    {
      "epoch": 0.07228915662650602,
      "grad_norm": 1.8852531909942627,
      "learning_rate": 4.909638554216868e-06,
      "loss": 2.3569,
      "step": 120
    },
    {
      "epoch": 0.07289156626506024,
      "grad_norm": 2.092510461807251,
      "learning_rate": 4.908885542168675e-06,
      "loss": 2.3888,
      "step": 121
    },
    {
      "epoch": 0.07349397590361446,
      "grad_norm": 1.8730748891830444,
      "learning_rate": 4.9081325301204825e-06,
      "loss": 2.4182,
      "step": 122
    },
    {
      "epoch": 0.07409638554216867,
      "grad_norm": 1.8035399913787842,
      "learning_rate": 4.9073795180722894e-06,
      "loss": 2.2984,
      "step": 123
    },
    {
      "epoch": 0.0746987951807229,
      "grad_norm": 1.9557102918624878,
      "learning_rate": 4.906626506024097e-06,
      "loss": 2.4341,
      "step": 124
    },
    {
      "epoch": 0.07530120481927711,
      "grad_norm": 1.8813270330429077,
      "learning_rate": 4.905873493975904e-06,
      "loss": 2.383,
      "step": 125
    },
    {
      "epoch": 0.07590361445783132,
      "grad_norm": 1.813943862915039,
      "learning_rate": 4.905120481927712e-06,
      "loss": 2.3538,
      "step": 126
    },
    {
      "epoch": 0.07650602409638554,
      "grad_norm": 1.7292146682739258,
      "learning_rate": 4.904367469879519e-06,
      "loss": 2.2667,
      "step": 127
    },
    {
      "epoch": 0.07710843373493977,
      "grad_norm": 1.861366629600525,
      "learning_rate": 4.903614457831326e-06,
      "loss": 2.3727,
      "step": 128
    },
    {
      "epoch": 0.07771084337349397,
      "grad_norm": 1.74802827835083,
      "learning_rate": 4.902861445783133e-06,
      "loss": 2.2513,
      "step": 129
    },
    {
      "epoch": 0.0783132530120482,
      "grad_norm": 1.7850054502487183,
      "learning_rate": 4.9021084337349405e-06,
      "loss": 2.2218,
      "step": 130
    },
    {
      "epoch": 0.0789156626506024,
      "grad_norm": 1.7506104707717896,
      "learning_rate": 4.901355421686747e-06,
      "loss": 2.2828,
      "step": 131
    },
    {
      "epoch": 0.07951807228915662,
      "grad_norm": 1.731820821762085,
      "learning_rate": 4.900602409638554e-06,
      "loss": 2.2761,
      "step": 132
    },
    {
      "epoch": 0.08012048192771085,
      "grad_norm": 1.755720853805542,
      "learning_rate": 4.899849397590361e-06,
      "loss": 2.3186,
      "step": 133
    },
    {
      "epoch": 0.08072289156626505,
      "grad_norm": 1.7338565587997437,
      "learning_rate": 4.899096385542169e-06,
      "loss": 2.2804,
      "step": 134
    },
    {
      "epoch": 0.08132530120481928,
      "grad_norm": 1.8071579933166504,
      "learning_rate": 4.898343373493976e-06,
      "loss": 2.2959,
      "step": 135
    },
    {
      "epoch": 0.0819277108433735,
      "grad_norm": 1.9786641597747803,
      "learning_rate": 4.897590361445784e-06,
      "loss": 2.2409,
      "step": 136
    },
    {
      "epoch": 0.0825301204819277,
      "grad_norm": 1.6879152059555054,
      "learning_rate": 4.896837349397591e-06,
      "loss": 2.2382,
      "step": 137
    },
    {
      "epoch": 0.08313253012048193,
      "grad_norm": 1.8779938220977783,
      "learning_rate": 4.896084337349398e-06,
      "loss": 2.2671,
      "step": 138
    },
    {
      "epoch": 0.08373493975903615,
      "grad_norm": 1.8117834329605103,
      "learning_rate": 4.895331325301205e-06,
      "loss": 2.2668,
      "step": 139
    },
    {
      "epoch": 0.08433734939759036,
      "grad_norm": 1.6286499500274658,
      "learning_rate": 4.894578313253012e-06,
      "loss": 2.1936,
      "step": 140
    },
    {
      "epoch": 0.08493975903614458,
      "grad_norm": 1.636011004447937,
      "learning_rate": 4.89382530120482e-06,
      "loss": 2.1925,
      "step": 141
    },
    {
      "epoch": 0.0855421686746988,
      "grad_norm": 1.6798195838928223,
      "learning_rate": 4.893072289156627e-06,
      "loss": 2.2347,
      "step": 142
    },
    {
      "epoch": 0.086144578313253,
      "grad_norm": 1.6778078079223633,
      "learning_rate": 4.892319277108435e-06,
      "loss": 2.1811,
      "step": 143
    },
    {
      "epoch": 0.08674698795180723,
      "grad_norm": 1.6967830657958984,
      "learning_rate": 4.891566265060242e-06,
      "loss": 2.2221,
      "step": 144
    },
    {
      "epoch": 0.08734939759036145,
      "grad_norm": 1.6377365589141846,
      "learning_rate": 4.8908132530120486e-06,
      "loss": 2.214,
      "step": 145
    },
    {
      "epoch": 0.08795180722891566,
      "grad_norm": 1.6111297607421875,
      "learning_rate": 4.8900602409638555e-06,
      "loss": 2.1416,
      "step": 146
    },
    {
      "epoch": 0.08855421686746988,
      "grad_norm": 1.6616981029510498,
      "learning_rate": 4.889307228915663e-06,
      "loss": 2.2005,
      "step": 147
    },
    {
      "epoch": 0.0891566265060241,
      "grad_norm": 1.702279806137085,
      "learning_rate": 4.88855421686747e-06,
      "loss": 2.2599,
      "step": 148
    },
    {
      "epoch": 0.08975903614457831,
      "grad_norm": 1.6837502717971802,
      "learning_rate": 4.887801204819277e-06,
      "loss": 2.2017,
      "step": 149
    },
    {
      "epoch": 0.09036144578313253,
      "grad_norm": 1.6179723739624023,
      "learning_rate": 4.887048192771085e-06,
      "loss": 2.1898,
      "step": 150
    },
    {
      "epoch": 0.09096385542168675,
      "grad_norm": 1.6871484518051147,
      "learning_rate": 4.886295180722892e-06,
      "loss": 2.2026,
      "step": 151
    },
    {
      "epoch": 0.09156626506024096,
      "grad_norm": 1.5723150968551636,
      "learning_rate": 4.885542168674699e-06,
      "loss": 2.1576,
      "step": 152
    },
    {
      "epoch": 0.09216867469879518,
      "grad_norm": 1.7300187349319458,
      "learning_rate": 4.8847891566265065e-06,
      "loss": 2.1398,
      "step": 153
    },
    {
      "epoch": 0.0927710843373494,
      "grad_norm": 1.5798197984695435,
      "learning_rate": 4.8840361445783134e-06,
      "loss": 2.1461,
      "step": 154
    },
    {
      "epoch": 0.09337349397590361,
      "grad_norm": 1.6042051315307617,
      "learning_rate": 4.883283132530121e-06,
      "loss": 2.1018,
      "step": 155
    },
    {
      "epoch": 0.09397590361445783,
      "grad_norm": 1.5775691270828247,
      "learning_rate": 4.882530120481928e-06,
      "loss": 2.1388,
      "step": 156
    },
    {
      "epoch": 0.09457831325301205,
      "grad_norm": 1.5323243141174316,
      "learning_rate": 4.881777108433735e-06,
      "loss": 2.1614,
      "step": 157
    },
    {
      "epoch": 0.09518072289156626,
      "grad_norm": 1.5488330125808716,
      "learning_rate": 4.881024096385543e-06,
      "loss": 2.1201,
      "step": 158
    },
    {
      "epoch": 0.09578313253012048,
      "grad_norm": 1.5187963247299194,
      "learning_rate": 4.88027108433735e-06,
      "loss": 2.0941,
      "step": 159
    },
    {
      "epoch": 0.0963855421686747,
      "grad_norm": 1.5431574583053589,
      "learning_rate": 4.8795180722891575e-06,
      "loss": 2.1005,
      "step": 160
    },
    {
      "epoch": 0.09698795180722891,
      "grad_norm": 1.570328712463379,
      "learning_rate": 4.8787650602409644e-06,
      "loss": 2.1341,
      "step": 161
    },
    {
      "epoch": 0.09759036144578313,
      "grad_norm": 1.5035520792007446,
      "learning_rate": 4.878012048192771e-06,
      "loss": 2.1305,
      "step": 162
    },
    {
      "epoch": 0.09819277108433735,
      "grad_norm": 1.465175747871399,
      "learning_rate": 4.877259036144579e-06,
      "loss": 2.0771,
      "step": 163
    },
    {
      "epoch": 0.09879518072289156,
      "grad_norm": 1.6254162788391113,
      "learning_rate": 4.876506024096386e-06,
      "loss": 2.0199,
      "step": 164
    },
    {
      "epoch": 0.09939759036144578,
      "grad_norm": 1.4805916547775269,
      "learning_rate": 4.875753012048193e-06,
      "loss": 2.0465,
      "step": 165
    },
    {
      "epoch": 0.1,
      "grad_norm": 1.4420905113220215,
      "learning_rate": 4.875e-06,
      "loss": 2.0727,
      "step": 166
    },
    {
      "epoch": 0.10060240963855421,
      "grad_norm": 1.395176649093628,
      "learning_rate": 4.874246987951808e-06,
      "loss": 2.0347,
      "step": 167
    },
    {
      "epoch": 0.10120481927710843,
      "grad_norm": 1.520964503288269,
      "learning_rate": 4.873493975903615e-06,
      "loss": 2.0657,
      "step": 168
    },
    {
      "epoch": 0.10180722891566266,
      "grad_norm": 1.4806395769119263,
      "learning_rate": 4.8727409638554215e-06,
      "loss": 2.0843,
      "step": 169
    },
    {
      "epoch": 0.10240963855421686,
      "grad_norm": 1.4548052549362183,
      "learning_rate": 4.871987951807229e-06,
      "loss": 2.031,
      "step": 170
    },
    {
      "epoch": 0.10301204819277109,
      "grad_norm": 1.4452883005142212,
      "learning_rate": 4.871234939759036e-06,
      "loss": 2.0503,
      "step": 171
    },
    {
      "epoch": 0.10361445783132531,
      "grad_norm": 1.3989262580871582,
      "learning_rate": 4.870481927710844e-06,
      "loss": 2.0321,
      "step": 172
    },
    {
      "epoch": 0.10421686746987951,
      "grad_norm": 1.412711262702942,
      "learning_rate": 4.869728915662651e-06,
      "loss": 2.013,
      "step": 173
    },
    {
      "epoch": 0.10481927710843374,
      "grad_norm": 1.3780540227890015,
      "learning_rate": 4.868975903614459e-06,
      "loss": 2.0583,
      "step": 174
    },
    {
      "epoch": 0.10542168674698796,
      "grad_norm": 1.3271026611328125,
      "learning_rate": 4.868222891566266e-06,
      "loss": 1.9821,
      "step": 175
    },
    {
      "epoch": 0.10602409638554217,
      "grad_norm": 1.431795358657837,
      "learning_rate": 4.8674698795180725e-06,
      "loss": 2.0173,
      "step": 176
    },
    {
      "epoch": 0.10662650602409639,
      "grad_norm": 1.3380274772644043,
      "learning_rate": 4.86671686746988e-06,
      "loss": 2.003,
      "step": 177
    },
    {
      "epoch": 0.10722891566265061,
      "grad_norm": 1.2584476470947266,
      "learning_rate": 4.865963855421687e-06,
      "loss": 1.909,
      "step": 178
    },
    {
      "epoch": 0.10783132530120482,
      "grad_norm": 1.4187318086624146,
      "learning_rate": 4.865210843373494e-06,
      "loss": 2.0355,
      "step": 179
    },
    {
      "epoch": 0.10843373493975904,
      "grad_norm": 1.361886739730835,
      "learning_rate": 4.864457831325302e-06,
      "loss": 1.9713,
      "step": 180
    },
    {
      "epoch": 0.10903614457831326,
      "grad_norm": 1.4159613847732544,
      "learning_rate": 4.863704819277109e-06,
      "loss": 1.9387,
      "step": 181
    },
    {
      "epoch": 0.10963855421686747,
      "grad_norm": 1.3011329174041748,
      "learning_rate": 4.862951807228916e-06,
      "loss": 1.9765,
      "step": 182
    },
    {
      "epoch": 0.11024096385542169,
      "grad_norm": 1.2086681127548218,
      "learning_rate": 4.862198795180723e-06,
      "loss": 1.9255,
      "step": 183
    },
    {
      "epoch": 0.1108433734939759,
      "grad_norm": 1.3825139999389648,
      "learning_rate": 4.8614457831325305e-06,
      "loss": 1.9819,
      "step": 184
    },
    {
      "epoch": 0.11144578313253012,
      "grad_norm": 1.257860541343689,
      "learning_rate": 4.860692771084337e-06,
      "loss": 1.9878,
      "step": 185
    },
    {
      "epoch": 0.11204819277108434,
      "grad_norm": 1.2405449151992798,
      "learning_rate": 4.859939759036145e-06,
      "loss": 1.9199,
      "step": 186
    },
    {
      "epoch": 0.11265060240963855,
      "grad_norm": 1.3239364624023438,
      "learning_rate": 4.859186746987952e-06,
      "loss": 2.0082,
      "step": 187
    },
    {
      "epoch": 0.11325301204819277,
      "grad_norm": 1.1693154573440552,
      "learning_rate": 4.858433734939759e-06,
      "loss": 1.915,
      "step": 188
    },
    {
      "epoch": 0.11385542168674699,
      "grad_norm": 1.1413384675979614,
      "learning_rate": 4.857680722891567e-06,
      "loss": 1.936,
      "step": 189
    },
    {
      "epoch": 0.1144578313253012,
      "grad_norm": 1.2409249544143677,
      "learning_rate": 4.856927710843374e-06,
      "loss": 1.98,
      "step": 190
    },
    {
      "epoch": 0.11506024096385542,
      "grad_norm": 1.262948751449585,
      "learning_rate": 4.8561746987951815e-06,
      "loss": 1.9579,
      "step": 191
    },
    {
      "epoch": 0.11566265060240964,
      "grad_norm": 1.3258872032165527,
      "learning_rate": 4.8554216867469884e-06,
      "loss": 1.94,
      "step": 192
    },
    {
      "epoch": 0.11626506024096385,
      "grad_norm": 1.110916256904602,
      "learning_rate": 4.854668674698795e-06,
      "loss": 1.9427,
      "step": 193
    },
    {
      "epoch": 0.11686746987951807,
      "grad_norm": 1.1721619367599487,
      "learning_rate": 4.853915662650603e-06,
      "loss": 1.9126,
      "step": 194
    },
    {
      "epoch": 0.11746987951807229,
      "grad_norm": 1.1373347043991089,
      "learning_rate": 4.85316265060241e-06,
      "loss": 1.903,
      "step": 195
    },
    {
      "epoch": 0.1180722891566265,
      "grad_norm": 1.1013853549957275,
      "learning_rate": 4.852409638554218e-06,
      "loss": 1.9345,
      "step": 196
    },
    {
      "epoch": 0.11867469879518072,
      "grad_norm": 1.0667864084243774,
      "learning_rate": 4.851656626506025e-06,
      "loss": 1.8671,
      "step": 197
    },
    {
      "epoch": 0.11927710843373494,
      "grad_norm": 1.0770890712738037,
      "learning_rate": 4.850903614457832e-06,
      "loss": 1.9074,
      "step": 198
    },
    {
      "epoch": 0.11987951807228915,
      "grad_norm": 1.009749174118042,
      "learning_rate": 4.850150602409639e-06,
      "loss": 1.8508,
      "step": 199
    },
    {
      "epoch": 0.12048192771084337,
      "grad_norm": 1.0740361213684082,
      "learning_rate": 4.849397590361446e-06,
      "loss": 1.8899,
      "step": 200
    },
    {
      "epoch": 0.1210843373493976,
      "grad_norm": 1.0050240755081177,
      "learning_rate": 4.848644578313253e-06,
      "loss": 1.8798,
      "step": 201
    },
    {
      "epoch": 0.1216867469879518,
      "grad_norm": 1.0541584491729736,
      "learning_rate": 4.84789156626506e-06,
      "loss": 1.9042,
      "step": 202
    },
    {
      "epoch": 0.12228915662650602,
      "grad_norm": 0.9949057102203369,
      "learning_rate": 4.847138554216868e-06,
      "loss": 1.8468,
      "step": 203
    },
    {
      "epoch": 0.12289156626506025,
      "grad_norm": 1.0123581886291504,
      "learning_rate": 4.846385542168675e-06,
      "loss": 1.8818,
      "step": 204
    },
    {
      "epoch": 0.12349397590361445,
      "grad_norm": 0.9042607545852661,
      "learning_rate": 4.845632530120482e-06,
      "loss": 1.815,
      "step": 205
    },
    {
      "epoch": 0.12409638554216867,
      "grad_norm": 1.0103472471237183,
      "learning_rate": 4.84487951807229e-06,
      "loss": 1.8368,
      "step": 206
    },
    {
      "epoch": 0.1246987951807229,
      "grad_norm": 0.9077780246734619,
      "learning_rate": 4.8441265060240965e-06,
      "loss": 1.804,
      "step": 207
    },
    {
      "epoch": 0.12530120481927712,
      "grad_norm": 0.9505817890167236,
      "learning_rate": 4.843373493975904e-06,
      "loss": 1.8615,
      "step": 208
    },
    {
      "epoch": 0.12590361445783133,
      "grad_norm": 0.9575837850570679,
      "learning_rate": 4.842620481927711e-06,
      "loss": 1.856,
      "step": 209
    },
    {
      "epoch": 0.12650602409638553,
      "grad_norm": 0.9176722168922424,
      "learning_rate": 4.841867469879519e-06,
      "loss": 1.8496,
      "step": 210
    },
    {
      "epoch": 0.12710843373493977,
      "grad_norm": 0.9278918504714966,
      "learning_rate": 4.841114457831326e-06,
      "loss": 1.8675,
      "step": 211
    },
    {
      "epoch": 0.12771084337349398,
      "grad_norm": 0.9137035608291626,
      "learning_rate": 4.840361445783133e-06,
      "loss": 1.7916,
      "step": 212
    },
    {
      "epoch": 0.12831325301204818,
      "grad_norm": 0.9672578573226929,
      "learning_rate": 4.839608433734941e-06,
      "loss": 1.8276,
      "step": 213
    },
    {
      "epoch": 0.12891566265060242,
      "grad_norm": 0.8599427342414856,
      "learning_rate": 4.8388554216867476e-06,
      "loss": 1.7928,
      "step": 214
    },
    {
      "epoch": 0.12951807228915663,
      "grad_norm": 0.9550036191940308,
      "learning_rate": 4.8381024096385545e-06,
      "loss": 1.852,
      "step": 215
    },
    {
      "epoch": 0.13012048192771083,
      "grad_norm": 0.8712965250015259,
      "learning_rate": 4.837349397590361e-06,
      "loss": 1.7794,
      "step": 216
    },
    {
      "epoch": 0.13072289156626507,
      "grad_norm": 0.875115692615509,
      "learning_rate": 4.836596385542169e-06,
      "loss": 1.8266,
      "step": 217
    },
    {
      "epoch": 0.13132530120481928,
      "grad_norm": 0.852411687374115,
      "learning_rate": 4.835843373493976e-06,
      "loss": 1.8206,
      "step": 218
    },
    {
      "epoch": 0.13192771084337349,
      "grad_norm": 0.8348486423492432,
      "learning_rate": 4.835090361445783e-06,
      "loss": 1.8134,
      "step": 219
    },
    {
      "epoch": 0.13253012048192772,
      "grad_norm": 0.7793241739273071,
      "learning_rate": 4.834337349397591e-06,
      "loss": 1.7362,
      "step": 220
    },
    {
      "epoch": 0.13313253012048193,
      "grad_norm": 0.8342352509498596,
      "learning_rate": 4.833584337349398e-06,
      "loss": 1.7996,
      "step": 221
    },
    {
      "epoch": 0.13373493975903614,
      "grad_norm": 0.8212642073631287,
      "learning_rate": 4.8328313253012055e-06,
      "loss": 1.799,
      "step": 222
    },
    {
      "epoch": 0.13433734939759037,
      "grad_norm": 0.8465393781661987,
      "learning_rate": 4.832078313253012e-06,
      "loss": 1.7914,
      "step": 223
    },
    {
      "epoch": 0.13493975903614458,
      "grad_norm": 0.7977269291877747,
      "learning_rate": 4.831325301204819e-06,
      "loss": 1.8053,
      "step": 224
    },
    {
      "epoch": 0.1355421686746988,
      "grad_norm": 0.7921637892723083,
      "learning_rate": 4.830572289156627e-06,
      "loss": 1.7695,
      "step": 225
    },
    {
      "epoch": 0.13614457831325302,
      "grad_norm": 0.7832058668136597,
      "learning_rate": 4.829819277108434e-06,
      "loss": 1.799,
      "step": 226
    },
    {
      "epoch": 0.13674698795180723,
      "grad_norm": 0.8296300172805786,
      "learning_rate": 4.829066265060242e-06,
      "loss": 1.7622,
      "step": 227
    },
    {
      "epoch": 0.13734939759036144,
      "grad_norm": 0.7828813195228577,
      "learning_rate": 4.828313253012049e-06,
      "loss": 1.7706,
      "step": 228
    },
    {
      "epoch": 0.13795180722891567,
      "grad_norm": 0.7815297245979309,
      "learning_rate": 4.827560240963856e-06,
      "loss": 1.79,
      "step": 229
    },
    {
      "epoch": 0.13855421686746988,
      "grad_norm": 0.7838123440742493,
      "learning_rate": 4.8268072289156634e-06,
      "loss": 1.789,
      "step": 230
    },
    {
      "epoch": 0.1391566265060241,
      "grad_norm": 0.7792511582374573,
      "learning_rate": 4.82605421686747e-06,
      "loss": 1.7937,
      "step": 231
    },
    {
      "epoch": 0.13975903614457832,
      "grad_norm": 0.8035470843315125,
      "learning_rate": 4.825301204819277e-06,
      "loss": 1.7949,
      "step": 232
    },
    {
      "epoch": 0.14036144578313253,
      "grad_norm": 0.7542542815208435,
      "learning_rate": 4.824548192771085e-06,
      "loss": 1.7282,
      "step": 233
    },
    {
      "epoch": 0.14096385542168674,
      "grad_norm": 0.7674682140350342,
      "learning_rate": 4.823795180722892e-06,
      "loss": 1.7515,
      "step": 234
    },
    {
      "epoch": 0.14156626506024098,
      "grad_norm": 0.7248489260673523,
      "learning_rate": 4.823042168674699e-06,
      "loss": 1.7266,
      "step": 235
    },
    {
      "epoch": 0.14216867469879518,
      "grad_norm": 0.7419578433036804,
      "learning_rate": 4.822289156626506e-06,
      "loss": 1.7683,
      "step": 236
    },
    {
      "epoch": 0.1427710843373494,
      "grad_norm": 0.7516714334487915,
      "learning_rate": 4.821536144578314e-06,
      "loss": 1.7499,
      "step": 237
    },
    {
      "epoch": 0.14337349397590363,
      "grad_norm": 0.7608193755149841,
      "learning_rate": 4.8207831325301205e-06,
      "loss": 1.763,
      "step": 238
    },
    {
      "epoch": 0.14397590361445783,
      "grad_norm": 0.7405287027359009,
      "learning_rate": 4.820030120481928e-06,
      "loss": 1.7826,
      "step": 239
    },
    {
      "epoch": 0.14457831325301204,
      "grad_norm": 0.7617663741111755,
      "learning_rate": 4.819277108433735e-06,
      "loss": 1.7692,
      "step": 240
    },
    {
      "epoch": 0.14518072289156628,
      "grad_norm": 0.7266189455986023,
      "learning_rate": 4.818524096385542e-06,
      "loss": 1.7425,
      "step": 241
    },
    {
      "epoch": 0.14578313253012049,
      "grad_norm": 0.7304509878158569,
      "learning_rate": 4.81777108433735e-06,
      "loss": 1.7665,
      "step": 242
    },
    {
      "epoch": 0.1463855421686747,
      "grad_norm": 0.7530302405357361,
      "learning_rate": 4.817018072289157e-06,
      "loss": 1.7465,
      "step": 243
    },
    {
      "epoch": 0.14698795180722893,
      "grad_norm": 0.748790979385376,
      "learning_rate": 4.816265060240965e-06,
      "loss": 1.7618,
      "step": 244
    },
    {
      "epoch": 0.14759036144578314,
      "grad_norm": 0.7156896591186523,
      "learning_rate": 4.8155120481927715e-06,
      "loss": 1.7582,
      "step": 245
    },
    {
      "epoch": 0.14819277108433734,
      "grad_norm": 0.7198463082313538,
      "learning_rate": 4.814759036144579e-06,
      "loss": 1.7199,
      "step": 246
    },
    {
      "epoch": 0.14879518072289158,
      "grad_norm": 0.7159889936447144,
      "learning_rate": 4.814006024096386e-06,
      "loss": 1.7125,
      "step": 247
    },
    {
      "epoch": 0.1493975903614458,
      "grad_norm": 0.7478316426277161,
      "learning_rate": 4.813253012048193e-06,
      "loss": 1.7325,
      "step": 248
    },
    {
      "epoch": 0.15,
      "grad_norm": 0.7034206986427307,
      "learning_rate": 4.8125e-06,
      "loss": 1.6775,
      "step": 249
    },
    {
      "epoch": 0.15060240963855423,
      "grad_norm": 0.7154672741889954,
      "learning_rate": 4.811746987951808e-06,
      "loss": 1.7079,
      "step": 250
    },
    {
      "epoch": 0.15120481927710844,
      "grad_norm": 0.7286857962608337,
      "learning_rate": 4.810993975903615e-06,
      "loss": 1.7452,
      "step": 251
    },
    {
      "epoch": 0.15180722891566265,
      "grad_norm": 0.7306095957756042,
      "learning_rate": 4.810240963855422e-06,
      "loss": 1.7389,
      "step": 252
    },
    {
      "epoch": 0.15240963855421688,
      "grad_norm": 0.7658929824829102,
      "learning_rate": 4.809487951807229e-06,
      "loss": 1.7538,
      "step": 253
    },
    {
      "epoch": 0.1530120481927711,
      "grad_norm": 0.7986821532249451,
      "learning_rate": 4.808734939759036e-06,
      "loss": 1.7607,
      "step": 254
    },
    {
      "epoch": 0.1536144578313253,
      "grad_norm": 0.7916812896728516,
      "learning_rate": 4.807981927710843e-06,
      "loss": 1.7161,
      "step": 255
    },
    {
      "epoch": 0.15421686746987953,
      "grad_norm": 0.9134896397590637,
      "learning_rate": 4.807228915662651e-06,
      "loss": 1.6001,
      "step": 256
    },
    {
      "epoch": 0.15481927710843374,
      "grad_norm": 0.6852250099182129,
      "learning_rate": 4.806475903614458e-06,
      "loss": 1.7377,
      "step": 257
    },
    {
      "epoch": 0.15542168674698795,
      "grad_norm": 0.7006720304489136,
      "learning_rate": 4.805722891566266e-06,
      "loss": 1.6864,
      "step": 258
    },
    {
      "epoch": 0.15602409638554218,
      "grad_norm": 0.6734626293182373,
      "learning_rate": 4.804969879518073e-06,
      "loss": 1.6787,
      "step": 259
    },
    {
      "epoch": 0.1566265060240964,
      "grad_norm": 0.6498069763183594,
      "learning_rate": 4.80421686746988e-06,
      "loss": 1.6754,
      "step": 260
    },
    {
      "epoch": 0.1572289156626506,
      "grad_norm": 0.6874427199363708,
      "learning_rate": 4.803463855421687e-06,
      "loss": 1.6744,
      "step": 261
    },
    {
      "epoch": 0.1578313253012048,
      "grad_norm": 0.737357497215271,
      "learning_rate": 4.802710843373494e-06,
      "loss": 1.7087,
      "step": 262
    },
    {
      "epoch": 0.15843373493975904,
      "grad_norm": 0.6797679662704468,
      "learning_rate": 4.801957831325302e-06,
      "loss": 1.7166,
      "step": 263
    },
    {
      "epoch": 0.15903614457831325,
      "grad_norm": 0.6966806054115295,
      "learning_rate": 4.801204819277109e-06,
      "loss": 1.6967,
      "step": 264
    },
    {
      "epoch": 0.15963855421686746,
      "grad_norm": 0.6827394962310791,
      "learning_rate": 4.800451807228916e-06,
      "loss": 1.6597,
      "step": 265
    },
    {
      "epoch": 0.1602409638554217,
      "grad_norm": 0.7116414904594421,
      "learning_rate": 4.799698795180724e-06,
      "loss": 1.7002,
      "step": 266
    },
    {
      "epoch": 0.1608433734939759,
      "grad_norm": 0.6779251098632812,
      "learning_rate": 4.798945783132531e-06,
      "loss": 1.7055,
      "step": 267
    },
    {
      "epoch": 0.1614457831325301,
      "grad_norm": 0.6708039045333862,
      "learning_rate": 4.798192771084338e-06,
      "loss": 1.6679,
      "step": 268
    },
    {
      "epoch": 0.16204819277108434,
      "grad_norm": 0.6839370727539062,
      "learning_rate": 4.7974397590361445e-06,
      "loss": 1.6921,
      "step": 269
    },
    {
      "epoch": 0.16265060240963855,
      "grad_norm": 0.6977958083152771,
      "learning_rate": 4.796686746987952e-06,
      "loss": 1.6964,
      "step": 270
    },
    {
      "epoch": 0.16325301204819276,
      "grad_norm": 0.6544438004493713,
      "learning_rate": 4.795933734939759e-06,
      "loss": 1.6635,
      "step": 271
    },
    {
      "epoch": 0.163855421686747,
      "grad_norm": 0.6762298345565796,
      "learning_rate": 4.795180722891566e-06,
      "loss": 1.6713,
      "step": 272
    },
    {
      "epoch": 0.1644578313253012,
      "grad_norm": 0.7012321949005127,
      "learning_rate": 4.794427710843374e-06,
      "loss": 1.6868,
      "step": 273
    },
    {
      "epoch": 0.1650602409638554,
      "grad_norm": 0.6606985926628113,
      "learning_rate": 4.793674698795181e-06,
      "loss": 1.6682,
      "step": 274
    },
    {
      "epoch": 0.16566265060240964,
      "grad_norm": 0.6576200127601624,
      "learning_rate": 4.792921686746989e-06,
      "loss": 1.6666,
      "step": 275
    },
    {
      "epoch": 0.16626506024096385,
      "grad_norm": 0.7273927927017212,
      "learning_rate": 4.7921686746987955e-06,
      "loss": 1.6765,
      "step": 276
    },
    {
      "epoch": 0.16686746987951806,
      "grad_norm": 0.6670618057250977,
      "learning_rate": 4.7914156626506025e-06,
      "loss": 1.6845,
      "step": 277
    },
    {
      "epoch": 0.1674698795180723,
      "grad_norm": 0.6406273245811462,
      "learning_rate": 4.79066265060241e-06,
      "loss": 1.6227,
      "step": 278
    },
    {
      "epoch": 0.1680722891566265,
      "grad_norm": 0.6692442297935486,
      "learning_rate": 4.789909638554217e-06,
      "loss": 1.6482,
      "step": 279
    },
    {
      "epoch": 0.1686746987951807,
      "grad_norm": 0.6585025191307068,
      "learning_rate": 4.789156626506025e-06,
      "loss": 1.6574,
      "step": 280
    },
    {
      "epoch": 0.16927710843373495,
      "grad_norm": 0.697080135345459,
      "learning_rate": 4.788403614457832e-06,
      "loss": 1.6336,
      "step": 281
    },
    {
      "epoch": 0.16987951807228915,
      "grad_norm": 0.6588965654373169,
      "learning_rate": 4.787650602409639e-06,
      "loss": 1.6491,
      "step": 282
    },
    {
      "epoch": 0.17048192771084336,
      "grad_norm": 0.6678246259689331,
      "learning_rate": 4.7868975903614465e-06,
      "loss": 1.6352,
      "step": 283
    },
    {
      "epoch": 0.1710843373493976,
      "grad_norm": 0.6675540804862976,
      "learning_rate": 4.7861445783132535e-06,
      "loss": 1.6593,
      "step": 284
    },
    {
      "epoch": 0.1716867469879518,
      "grad_norm": 0.6648253202438354,
      "learning_rate": 4.78539156626506e-06,
      "loss": 1.6625,
      "step": 285
    },
    {
      "epoch": 0.172289156626506,
      "grad_norm": 0.660615861415863,
      "learning_rate": 4.784638554216867e-06,
      "loss": 1.6681,
      "step": 286
    },
    {
      "epoch": 0.17289156626506025,
      "grad_norm": 0.6819944977760315,
      "learning_rate": 4.783885542168675e-06,
      "loss": 1.6714,
      "step": 287
    },
    {
      "epoch": 0.17349397590361446,
      "grad_norm": 0.671136200428009,
      "learning_rate": 4.783132530120482e-06,
      "loss": 1.6377,
      "step": 288
    },
    {
      "epoch": 0.17409638554216866,
      "grad_norm": 0.61184161901474,
      "learning_rate": 4.782379518072289e-06,
      "loss": 1.58,
      "step": 289
    },
    {
      "epoch": 0.1746987951807229,
      "grad_norm": 0.6526268720626831,
      "learning_rate": 4.781626506024097e-06,
      "loss": 1.6385,
      "step": 290
    },
    {
      "epoch": 0.1753012048192771,
      "grad_norm": 0.642365574836731,
      "learning_rate": 4.780873493975904e-06,
      "loss": 1.6191,
      "step": 291
    },
    {
      "epoch": 0.17590361445783131,
      "grad_norm": 0.6718357801437378,
      "learning_rate": 4.780120481927711e-06,
      "loss": 1.6605,
      "step": 292
    },
    {
      "epoch": 0.17650602409638555,
      "grad_norm": 0.6541979312896729,
      "learning_rate": 4.779367469879518e-06,
      "loss": 1.6293,
      "step": 293
    },
    {
      "epoch": 0.17710843373493976,
      "grad_norm": 0.6586394309997559,
      "learning_rate": 4.778614457831326e-06,
      "loss": 1.6176,
      "step": 294
    },
    {
      "epoch": 0.17771084337349397,
      "grad_norm": 0.6500979661941528,
      "learning_rate": 4.777861445783133e-06,
      "loss": 1.6348,
      "step": 295
    },
    {
      "epoch": 0.1783132530120482,
      "grad_norm": 0.6391447186470032,
      "learning_rate": 4.77710843373494e-06,
      "loss": 1.5877,
      "step": 296
    },
    {
      "epoch": 0.1789156626506024,
      "grad_norm": 0.6656926274299622,
      "learning_rate": 4.776355421686748e-06,
      "loss": 1.6451,
      "step": 297
    },
    {
      "epoch": 0.17951807228915662,
      "grad_norm": 0.6461007595062256,
      "learning_rate": 4.775602409638555e-06,
      "loss": 1.6238,
      "step": 298
    },
    {
      "epoch": 0.18012048192771085,
      "grad_norm": 0.6284456849098206,
      "learning_rate": 4.7748493975903624e-06,
      "loss": 1.5773,
      "step": 299
    },
    {
      "epoch": 0.18072289156626506,
      "grad_norm": 0.6400514841079712,
      "learning_rate": 4.774096385542169e-06,
      "loss": 1.6096,
      "step": 300
    },
    {
      "epoch": 0.18132530120481927,
      "grad_norm": 0.6357744336128235,
      "learning_rate": 4.773343373493976e-06,
      "loss": 1.6174,
      "step": 301
    },
    {
      "epoch": 0.1819277108433735,
      "grad_norm": 0.6255476474761963,
      "learning_rate": 4.772590361445783e-06,
      "loss": 1.6065,
      "step": 302
    },
    {
      "epoch": 0.1825301204819277,
      "grad_norm": 0.6425718665122986,
      "learning_rate": 4.771837349397591e-06,
      "loss": 1.5976,
      "step": 303
    },
    {
      "epoch": 0.18313253012048192,
      "grad_norm": 0.5990505218505859,
      "learning_rate": 4.771084337349398e-06,
      "loss": 1.5839,
      "step": 304
    },
    {
      "epoch": 0.18373493975903615,
      "grad_norm": 0.6406679749488831,
      "learning_rate": 4.770331325301205e-06,
      "loss": 1.5903,
      "step": 305
    },
    {
      "epoch": 0.18433734939759036,
      "grad_norm": 0.6475541591644287,
      "learning_rate": 4.769578313253013e-06,
      "loss": 1.6086,
      "step": 306
    },
    {
      "epoch": 0.18493975903614457,
      "grad_norm": 0.6213065385818481,
      "learning_rate": 4.7688253012048195e-06,
      "loss": 1.5811,
      "step": 307
    },
    {
      "epoch": 0.1855421686746988,
      "grad_norm": 0.6599918007850647,
      "learning_rate": 4.7680722891566264e-06,
      "loss": 1.6204,
      "step": 308
    },
    {
      "epoch": 0.186144578313253,
      "grad_norm": 0.7024031281471252,
      "learning_rate": 4.767319277108434e-06,
      "loss": 1.5912,
      "step": 309
    },
    {
      "epoch": 0.18674698795180722,
      "grad_norm": 0.6702051758766174,
      "learning_rate": 4.766566265060241e-06,
      "loss": 1.6281,
      "step": 310
    },
    {
      "epoch": 0.18734939759036146,
      "grad_norm": 0.6451951265335083,
      "learning_rate": 4.765813253012049e-06,
      "loss": 1.5694,
      "step": 311
    },
    {
      "epoch": 0.18795180722891566,
      "grad_norm": 0.6359463930130005,
      "learning_rate": 4.765060240963856e-06,
      "loss": 1.5843,
      "step": 312
    },
    {
      "epoch": 0.18855421686746987,
      "grad_norm": 0.6530444025993347,
      "learning_rate": 4.764307228915663e-06,
      "loss": 1.5817,
      "step": 313
    },
    {
      "epoch": 0.1891566265060241,
      "grad_norm": 0.6461654305458069,
      "learning_rate": 4.7635542168674705e-06,
      "loss": 1.594,
      "step": 314
    },
    {
      "epoch": 0.1897590361445783,
      "grad_norm": 0.6297623515129089,
      "learning_rate": 4.7628012048192775e-06,
      "loss": 1.5633,
      "step": 315
    },
    {
      "epoch": 0.19036144578313252,
      "grad_norm": 0.6362635493278503,
      "learning_rate": 4.762048192771085e-06,
      "loss": 1.5812,
      "step": 316
    },
    {
      "epoch": 0.19096385542168676,
      "grad_norm": 0.6120848059654236,
      "learning_rate": 4.761295180722892e-06,
      "loss": 1.5595,
      "step": 317
    },
    {
      "epoch": 0.19156626506024096,
      "grad_norm": 0.6225551962852478,
      "learning_rate": 4.760542168674699e-06,
      "loss": 1.5783,
      "step": 318
    },
    {
      "epoch": 0.19216867469879517,
      "grad_norm": 0.6688928604125977,
      "learning_rate": 4.759789156626506e-06,
      "loss": 1.5967,
      "step": 319
    },
    {
      "epoch": 0.1927710843373494,
      "grad_norm": 0.6598610281944275,
      "learning_rate": 4.759036144578314e-06,
      "loss": 1.6214,
      "step": 320
    },
    {
      "epoch": 0.19337349397590362,
      "grad_norm": 0.6592398285865784,
      "learning_rate": 4.758283132530121e-06,
      "loss": 1.6104,
      "step": 321
    },
    {
      "epoch": 0.19397590361445782,
      "grad_norm": 0.6635907292366028,
      "learning_rate": 4.757530120481928e-06,
      "loss": 1.5348,
      "step": 322
    },
    {
      "epoch": 0.19457831325301206,
      "grad_norm": 0.6335883736610413,
      "learning_rate": 4.756777108433735e-06,
      "loss": 1.5675,
      "step": 323
    },
    {
      "epoch": 0.19518072289156627,
      "grad_norm": 0.6404081583023071,
      "learning_rate": 4.756024096385542e-06,
      "loss": 1.5806,
      "step": 324
    },
    {
      "epoch": 0.19578313253012047,
      "grad_norm": 0.829918384552002,
      "learning_rate": 4.755271084337349e-06,
      "loss": 1.5913,
      "step": 325
    },
    {
      "epoch": 0.1963855421686747,
      "grad_norm": 0.6443366408348083,
      "learning_rate": 4.754518072289157e-06,
      "loss": 1.5576,
      "step": 326
    },
    {
      "epoch": 0.19698795180722892,
      "grad_norm": 0.6491392850875854,
      "learning_rate": 4.753765060240964e-06,
      "loss": 1.5359,
      "step": 327
    },
    {
      "epoch": 0.19759036144578312,
      "grad_norm": 0.6451538801193237,
      "learning_rate": 4.753012048192772e-06,
      "loss": 1.5618,
      "step": 328
    },
    {
      "epoch": 0.19819277108433736,
      "grad_norm": 0.6561552882194519,
      "learning_rate": 4.752259036144579e-06,
      "loss": 1.5651,
      "step": 329
    },
    {
      "epoch": 0.19879518072289157,
      "grad_norm": 0.6456325054168701,
      "learning_rate": 4.751506024096386e-06,
      "loss": 1.5567,
      "step": 330
    },
    {
      "epoch": 0.19939759036144578,
      "grad_norm": 0.6588553786277771,
      "learning_rate": 4.750753012048193e-06,
      "loss": 1.5959,
      "step": 331
    },
    {
      "epoch": 0.2,
      "grad_norm": 0.6509483456611633,
      "learning_rate": 4.75e-06,
      "loss": 1.5742,
      "step": 332
    },
    {
      "epoch": 0.20060240963855422,
      "grad_norm": 0.6219142079353333,
      "learning_rate": 4.749246987951808e-06,
      "loss": 1.5571,
      "step": 333
    },
    {
      "epoch": 0.20120481927710843,
      "grad_norm": 0.6430069208145142,
      "learning_rate": 4.748493975903615e-06,
      "loss": 1.5397,
      "step": 334
    },
    {
      "epoch": 0.20180722891566266,
      "grad_norm": 0.6167206168174744,
      "learning_rate": 4.747740963855422e-06,
      "loss": 1.5558,
      "step": 335
    },
    {
      "epoch": 0.20240963855421687,
      "grad_norm": 0.6544647216796875,
      "learning_rate": 4.74698795180723e-06,
      "loss": 1.5603,
      "step": 336
    },
    {
      "epoch": 0.20301204819277108,
      "grad_norm": 0.684609591960907,
      "learning_rate": 4.746234939759037e-06,
      "loss": 1.525,
      "step": 337
    },
    {
      "epoch": 0.2036144578313253,
      "grad_norm": 0.6527585983276367,
      "learning_rate": 4.7454819277108435e-06,
      "loss": 1.5503,
      "step": 338
    },
    {
      "epoch": 0.20421686746987952,
      "grad_norm": 0.6695069670677185,
      "learning_rate": 4.7447289156626504e-06,
      "loss": 1.5858,
      "step": 339
    },
    {
      "epoch": 0.20481927710843373,
      "grad_norm": 0.6157159805297852,
      "learning_rate": 4.743975903614458e-06,
      "loss": 1.5405,
      "step": 340
    },
    {
      "epoch": 0.20542168674698796,
      "grad_norm": 0.6423202753067017,
      "learning_rate": 4.743222891566265e-06,
      "loss": 1.534,
      "step": 341
    },
    {
      "epoch": 0.20602409638554217,
      "grad_norm": 0.6362714767456055,
      "learning_rate": 4.742469879518073e-06,
      "loss": 1.5294,
      "step": 342
    },
    {
      "epoch": 0.20662650602409638,
      "grad_norm": 0.6461687684059143,
      "learning_rate": 4.74171686746988e-06,
      "loss": 1.5208,
      "step": 343
    },
    {
      "epoch": 0.20722891566265061,
      "grad_norm": 0.6433520913124084,
      "learning_rate": 4.740963855421687e-06,
      "loss": 1.5267,
      "step": 344
    },
    {
      "epoch": 0.20783132530120482,
      "grad_norm": 0.6207682490348816,
      "learning_rate": 4.7402108433734945e-06,
      "loss": 1.5138,
      "step": 345
    },
    {
      "epoch": 0.20843373493975903,
      "grad_norm": 0.6161406636238098,
      "learning_rate": 4.7394578313253014e-06,
      "loss": 1.5034,
      "step": 346
    },
    {
      "epoch": 0.20903614457831327,
      "grad_norm": 0.64574134349823,
      "learning_rate": 4.738704819277109e-06,
      "loss": 1.5531,
      "step": 347
    },
    {
      "epoch": 0.20963855421686747,
      "grad_norm": 0.6376998424530029,
      "learning_rate": 4.737951807228916e-06,
      "loss": 1.5378,
      "step": 348
    },
    {
      "epoch": 0.21024096385542168,
      "grad_norm": 0.5982925891876221,
      "learning_rate": 4.737198795180723e-06,
      "loss": 1.4712,
      "step": 349
    },
    {
      "epoch": 0.21084337349397592,
      "grad_norm": 0.6326965093612671,
      "learning_rate": 4.736445783132531e-06,
      "loss": 1.5181,
      "step": 350
    },
    {
      "epoch": 0.21144578313253012,
      "grad_norm": 0.6496576070785522,
      "learning_rate": 4.735692771084338e-06,
      "loss": 1.5407,
      "step": 351
    },
    {
      "epoch": 0.21204819277108433,
      "grad_norm": 0.6260280013084412,
      "learning_rate": 4.734939759036145e-06,
      "loss": 1.4836,
      "step": 352
    },
    {
      "epoch": 0.21265060240963857,
      "grad_norm": 0.6155536770820618,
      "learning_rate": 4.7341867469879525e-06,
      "loss": 1.5073,
      "step": 353
    },
    {
      "epoch": 0.21325301204819277,
      "grad_norm": 0.6185526847839355,
      "learning_rate": 4.733433734939759e-06,
      "loss": 1.477,
      "step": 354
    },
    {
      "epoch": 0.21385542168674698,
      "grad_norm": 0.6486453413963318,
      "learning_rate": 4.732680722891566e-06,
      "loss": 1.4951,
      "step": 355
    },
    {
      "epoch": 0.21445783132530122,
      "grad_norm": 0.6380505561828613,
      "learning_rate": 4.731927710843373e-06,
      "loss": 1.4814,
      "step": 356
    },
    {
      "epoch": 0.21506024096385543,
      "grad_norm": 0.6255105137825012,
      "learning_rate": 4.731174698795181e-06,
      "loss": 1.4791,
      "step": 357
    },
    {
      "epoch": 0.21566265060240963,
      "grad_norm": 0.6287629008293152,
      "learning_rate": 4.730421686746988e-06,
      "loss": 1.4868,
      "step": 358
    },
    {
      "epoch": 0.21626506024096387,
      "grad_norm": 0.6419431567192078,
      "learning_rate": 4.729668674698796e-06,
      "loss": 1.4912,
      "step": 359
    },
    {
      "epoch": 0.21686746987951808,
      "grad_norm": 0.7530532479286194,
      "learning_rate": 4.728915662650603e-06,
      "loss": 1.5267,
      "step": 360
    },
    {
      "epoch": 0.21746987951807228,
      "grad_norm": 0.7297770380973816,
      "learning_rate": 4.7281626506024096e-06,
      "loss": 1.5409,
      "step": 361
    },
    {
      "epoch": 0.21807228915662652,
      "grad_norm": 0.6409830451011658,
      "learning_rate": 4.727409638554217e-06,
      "loss": 1.4688,
      "step": 362
    },
    {
      "epoch": 0.21867469879518073,
      "grad_norm": 0.6544075012207031,
      "learning_rate": 4.726656626506024e-06,
      "loss": 1.4872,
      "step": 363
    },
    {
      "epoch": 0.21927710843373494,
      "grad_norm": 0.6264719367027283,
      "learning_rate": 4.725903614457832e-06,
      "loss": 1.4943,
      "step": 364
    },
    {
      "epoch": 0.21987951807228914,
      "grad_norm": 0.6438235640525818,
      "learning_rate": 4.725150602409639e-06,
      "loss": 1.4854,
      "step": 365
    },
    {
      "epoch": 0.22048192771084338,
      "grad_norm": 0.6482366919517517,
      "learning_rate": 4.724397590361447e-06,
      "loss": 1.4896,
      "step": 366
    },
    {
      "epoch": 0.22108433734939759,
      "grad_norm": 0.6416745781898499,
      "learning_rate": 4.723644578313254e-06,
      "loss": 1.451,
      "step": 367
    },
    {
      "epoch": 0.2216867469879518,
      "grad_norm": 0.6397807002067566,
      "learning_rate": 4.7228915662650606e-06,
      "loss": 1.4765,
      "step": 368
    },
    {
      "epoch": 0.22228915662650603,
      "grad_norm": 0.6592069864273071,
      "learning_rate": 4.722138554216868e-06,
      "loss": 1.4787,
      "step": 369
    },
    {
      "epoch": 0.22289156626506024,
      "grad_norm": 0.7139462232589722,
      "learning_rate": 4.721385542168675e-06,
      "loss": 1.5071,
      "step": 370
    },
    {
      "epoch": 0.22349397590361444,
      "grad_norm": 0.623958945274353,
      "learning_rate": 4.720632530120482e-06,
      "loss": 1.457,
      "step": 371
    },
    {
      "epoch": 0.22409638554216868,
      "grad_norm": 0.6212629675865173,
      "learning_rate": 4.719879518072289e-06,
      "loss": 1.4666,
      "step": 372
    },
    {
      "epoch": 0.2246987951807229,
      "grad_norm": 0.7842098474502563,
      "learning_rate": 4.719126506024097e-06,
      "loss": 1.4939,
      "step": 373
    },
    {
      "epoch": 0.2253012048192771,
      "grad_norm": 0.6521069407463074,
      "learning_rate": 4.718373493975904e-06,
      "loss": 1.4768,
      "step": 374
    },
    {
      "epoch": 0.22590361445783133,
      "grad_norm": 0.6809759736061096,
      "learning_rate": 4.717620481927711e-06,
      "loss": 1.4788,
      "step": 375
    },
    {
      "epoch": 0.22650602409638554,
      "grad_norm": 0.6498954892158508,
      "learning_rate": 4.7168674698795185e-06,
      "loss": 1.4681,
      "step": 376
    },
    {
      "epoch": 0.22710843373493975,
      "grad_norm": 0.6468263268470764,
      "learning_rate": 4.7161144578313254e-06,
      "loss": 1.4697,
      "step": 377
    },
    {
      "epoch": 0.22771084337349398,
      "grad_norm": 0.6433398127555847,
      "learning_rate": 4.715361445783133e-06,
      "loss": 1.4695,
      "step": 378
    },
    {
      "epoch": 0.2283132530120482,
      "grad_norm": 0.658553957939148,
      "learning_rate": 4.71460843373494e-06,
      "loss": 1.4828,
      "step": 379
    },
    {
      "epoch": 0.2289156626506024,
      "grad_norm": 0.652323842048645,
      "learning_rate": 4.713855421686747e-06,
      "loss": 1.4792,
      "step": 380
    },
    {
      "epoch": 0.22951807228915663,
      "grad_norm": 0.6653844714164734,
      "learning_rate": 4.713102409638555e-06,
      "loss": 1.4792,
      "step": 381
    },
    {
      "epoch": 0.23012048192771084,
      "grad_norm": 0.6484766006469727,
      "learning_rate": 4.712349397590362e-06,
      "loss": 1.4725,
      "step": 382
    },
    {
      "epoch": 0.23072289156626505,
      "grad_norm": 0.6362417936325073,
      "learning_rate": 4.7115963855421695e-06,
      "loss": 1.4438,
      "step": 383
    },
    {
      "epoch": 0.23132530120481928,
      "grad_norm": 0.6443678736686707,
      "learning_rate": 4.7108433734939764e-06,
      "loss": 1.4481,
      "step": 384
    },
    {
      "epoch": 0.2319277108433735,
      "grad_norm": 0.6164745092391968,
      "learning_rate": 4.710090361445783e-06,
      "loss": 1.4363,
      "step": 385
    },
    {
      "epoch": 0.2325301204819277,
      "grad_norm": 0.6805216670036316,
      "learning_rate": 4.709337349397591e-06,
      "loss": 1.478,
      "step": 386
    },
    {
      "epoch": 0.23313253012048193,
      "grad_norm": 0.6527292132377625,
      "learning_rate": 4.708584337349398e-06,
      "loss": 1.45,
      "step": 387
    },
    {
      "epoch": 0.23373493975903614,
      "grad_norm": 0.6436319947242737,
      "learning_rate": 4.707831325301205e-06,
      "loss": 1.4401,
      "step": 388
    },
    {
      "epoch": 0.23433734939759035,
      "grad_norm": 0.6378951668739319,
      "learning_rate": 4.707078313253013e-06,
      "loss": 1.4388,
      "step": 389
    },
    {
      "epoch": 0.23493975903614459,
      "grad_norm": 0.6975602507591248,
      "learning_rate": 4.70632530120482e-06,
      "loss": 1.4458,
      "step": 390
    },
    {
      "epoch": 0.2355421686746988,
      "grad_norm": 0.6798909902572632,
      "learning_rate": 4.705572289156627e-06,
      "loss": 1.4306,
      "step": 391
    },
    {
      "epoch": 0.236144578313253,
      "grad_norm": 0.6244096755981445,
      "learning_rate": 4.7048192771084335e-06,
      "loss": 1.4082,
      "step": 392
    },
    {
      "epoch": 0.23674698795180724,
      "grad_norm": 0.6536766886711121,
      "learning_rate": 4.704066265060241e-06,
      "loss": 1.4142,
      "step": 393
    },
    {
      "epoch": 0.23734939759036144,
      "grad_norm": 0.6715525388717651,
      "learning_rate": 4.703313253012048e-06,
      "loss": 1.4416,
      "step": 394
    },
    {
      "epoch": 0.23795180722891565,
      "grad_norm": 0.6854484677314758,
      "learning_rate": 4.702560240963856e-06,
      "loss": 1.4591,
      "step": 395
    },
    {
      "epoch": 0.2385542168674699,
      "grad_norm": 0.6372882127761841,
      "learning_rate": 4.701807228915663e-06,
      "loss": 1.4125,
      "step": 396
    },
    {
      "epoch": 0.2391566265060241,
      "grad_norm": 0.6718167662620544,
      "learning_rate": 4.70105421686747e-06,
      "loss": 1.4605,
      "step": 397
    },
    {
      "epoch": 0.2397590361445783,
      "grad_norm": 0.665308952331543,
      "learning_rate": 4.700301204819278e-06,
      "loss": 1.4518,
      "step": 398
    },
    {
      "epoch": 0.24036144578313254,
      "grad_norm": 0.6598243117332458,
      "learning_rate": 4.6995481927710846e-06,
      "loss": 1.4508,
      "step": 399
    },
    {
      "epoch": 0.24096385542168675,
      "grad_norm": 0.65450119972229,
      "learning_rate": 4.698795180722892e-06,
      "loss": 1.4276,
      "step": 400
    },
    {
      "epoch": 0.24156626506024095,
      "grad_norm": 0.6503952741622925,
      "learning_rate": 4.698042168674699e-06,
      "loss": 1.419,
      "step": 401
    },
    {
      "epoch": 0.2421686746987952,
      "grad_norm": 0.606131911277771,
      "learning_rate": 4.697289156626507e-06,
      "loss": 1.3597,
      "step": 402
    },
    {
      "epoch": 0.2427710843373494,
      "grad_norm": 0.6401098370552063,
      "learning_rate": 4.696536144578314e-06,
      "loss": 1.363,
      "step": 403
    },
    {
      "epoch": 0.2433734939759036,
      "grad_norm": 0.7056542038917542,
      "learning_rate": 4.695783132530121e-06,
      "loss": 1.4047,
      "step": 404
    },
    {
      "epoch": 0.24397590361445784,
      "grad_norm": 0.6579391360282898,
      "learning_rate": 4.695030120481928e-06,
      "loss": 1.4165,
      "step": 405
    },
    {
      "epoch": 0.24457831325301205,
      "grad_norm": 0.6766225695610046,
      "learning_rate": 4.6942771084337356e-06,
      "loss": 1.428,
      "step": 406
    },
    {
      "epoch": 0.24518072289156626,
      "grad_norm": 0.7448626756668091,
      "learning_rate": 4.6935240963855425e-06,
      "loss": 1.4026,
      "step": 407
    },
    {
      "epoch": 0.2457831325301205,
      "grad_norm": 0.6427358388900757,
      "learning_rate": 4.692771084337349e-06,
      "loss": 1.3784,
      "step": 408
    },
    {
      "epoch": 0.2463855421686747,
      "grad_norm": 0.6683297753334045,
      "learning_rate": 4.692018072289156e-06,
      "loss": 1.3994,
      "step": 409
    },
    {
      "epoch": 0.2469879518072289,
      "grad_norm": 0.6842496395111084,
      "learning_rate": 4.691265060240964e-06,
      "loss": 1.3979,
      "step": 410
    },
    {
      "epoch": 0.24759036144578314,
      "grad_norm": 0.6649302244186401,
      "learning_rate": 4.690512048192771e-06,
      "loss": 1.3698,
      "step": 411
    },
    {
      "epoch": 0.24819277108433735,
      "grad_norm": 0.7221450209617615,
      "learning_rate": 4.689759036144579e-06,
      "loss": 1.4015,
      "step": 412
    },
    {
      "epoch": 0.24879518072289156,
      "grad_norm": 0.6628255248069763,
      "learning_rate": 4.689006024096386e-06,
      "loss": 1.3892,
      "step": 413
    },
    {
      "epoch": 0.2493975903614458,
      "grad_norm": 0.7052865028381348,
      "learning_rate": 4.6882530120481935e-06,
      "loss": 1.4037,
      "step": 414
    },
    {
      "epoch": 0.25,
      "grad_norm": 0.6725109815597534,
      "learning_rate": 4.6875000000000004e-06,
      "loss": 1.3813,
      "step": 415
    },
    {
      "epoch": 0.25060240963855424,
      "grad_norm": 0.7037453055381775,
      "learning_rate": 4.686746987951807e-06,
      "loss": 1.4082,
      "step": 416
    },
    {
      "epoch": 0.2512048192771084,
      "grad_norm": 0.682462215423584,
      "learning_rate": 4.685993975903615e-06,
      "loss": 1.3844,
      "step": 417
    },
    {
      "epoch": 0.25180722891566265,
      "grad_norm": 0.6489384770393372,
      "learning_rate": 4.685240963855422e-06,
      "loss": 1.3704,
      "step": 418
    },
    {
      "epoch": 0.2524096385542169,
      "grad_norm": 0.6836550235748291,
      "learning_rate": 4.68448795180723e-06,
      "loss": 1.3628,
      "step": 419
    },
    {
      "epoch": 0.25301204819277107,
      "grad_norm": 0.6634193658828735,
      "learning_rate": 4.683734939759037e-06,
      "loss": 1.3687,
      "step": 420
    },
    {
      "epoch": 0.2536144578313253,
      "grad_norm": 0.6690682172775269,
      "learning_rate": 4.682981927710844e-06,
      "loss": 1.3645,
      "step": 421
    },
    {
      "epoch": 0.25421686746987954,
      "grad_norm": 0.7435281276702881,
      "learning_rate": 4.6822289156626515e-06,
      "loss": 1.4076,
      "step": 422
    },
    {
      "epoch": 0.2548192771084337,
      "grad_norm": 0.6612210869789124,
      "learning_rate": 4.681475903614458e-06,
      "loss": 1.3464,
      "step": 423
    },
    {
      "epoch": 0.25542168674698795,
      "grad_norm": 0.7181046009063721,
      "learning_rate": 4.680722891566265e-06,
      "loss": 1.3975,
      "step": 424
    },
    {
      "epoch": 0.2560240963855422,
      "grad_norm": 0.7023417353630066,
      "learning_rate": 4.679969879518072e-06,
      "loss": 1.3777,
      "step": 425
    },
    {
      "epoch": 0.25662650602409637,
      "grad_norm": 0.7121264338493347,
      "learning_rate": 4.67921686746988e-06,
      "loss": 1.3819,
      "step": 426
    },
    {
      "epoch": 0.2572289156626506,
      "grad_norm": 0.664839506149292,
      "learning_rate": 4.678463855421687e-06,
      "loss": 1.4063,
      "step": 427
    },
    {
      "epoch": 0.25783132530120484,
      "grad_norm": 0.6752731800079346,
      "learning_rate": 4.677710843373494e-06,
      "loss": 1.3606,
      "step": 428
    },
    {
      "epoch": 0.258433734939759,
      "grad_norm": 0.6757628321647644,
      "learning_rate": 4.676957831325302e-06,
      "loss": 1.3312,
      "step": 429
    },
    {
      "epoch": 0.25903614457831325,
      "grad_norm": 0.6671711802482605,
      "learning_rate": 4.6762048192771085e-06,
      "loss": 1.3333,
      "step": 430
    },
    {
      "epoch": 0.2596385542168675,
      "grad_norm": 0.6762487888336182,
      "learning_rate": 4.675451807228916e-06,
      "loss": 1.3519,
      "step": 431
    },
    {
      "epoch": 0.26024096385542167,
      "grad_norm": 0.6368926167488098,
      "learning_rate": 4.674698795180723e-06,
      "loss": 1.3852,
      "step": 432
    },
    {
      "epoch": 0.2608433734939759,
      "grad_norm": 0.7183334231376648,
      "learning_rate": 4.673945783132531e-06,
      "loss": 1.3441,
      "step": 433
    },
    {
      "epoch": 0.26144578313253014,
      "grad_norm": 1.0045826435089111,
      "learning_rate": 4.673192771084338e-06,
      "loss": 1.3471,
      "step": 434
    },
    {
      "epoch": 0.2620481927710843,
      "grad_norm": 0.7425513863563538,
      "learning_rate": 4.672439759036145e-06,
      "loss": 1.3465,
      "step": 435
    },
    {
      "epoch": 0.26265060240963856,
      "grad_norm": 0.6605783104896545,
      "learning_rate": 4.671686746987953e-06,
      "loss": 1.3459,
      "step": 436
    },
    {
      "epoch": 0.2632530120481928,
      "grad_norm": 0.6908897757530212,
      "learning_rate": 4.6709337349397596e-06,
      "loss": 1.3708,
      "step": 437
    },
    {
      "epoch": 0.26385542168674697,
      "grad_norm": 0.7091141939163208,
      "learning_rate": 4.6701807228915665e-06,
      "loss": 1.3439,
      "step": 438
    },
    {
      "epoch": 0.2644578313253012,
      "grad_norm": 0.7621722221374512,
      "learning_rate": 4.669427710843374e-06,
      "loss": 1.3213,
      "step": 439
    },
    {
      "epoch": 0.26506024096385544,
      "grad_norm": 0.7582409381866455,
      "learning_rate": 4.668674698795181e-06,
      "loss": 1.3623,
      "step": 440
    },
    {
      "epoch": 0.2656626506024096,
      "grad_norm": 0.7061888575553894,
      "learning_rate": 4.667921686746988e-06,
      "loss": 1.3331,
      "step": 441
    },
    {
      "epoch": 0.26626506024096386,
      "grad_norm": 0.6889800429344177,
      "learning_rate": 4.667168674698795e-06,
      "loss": 1.3545,
      "step": 442
    },
    {
      "epoch": 0.2668674698795181,
      "grad_norm": 0.6855157613754272,
      "learning_rate": 4.666415662650603e-06,
      "loss": 1.3314,
      "step": 443
    },
    {
      "epoch": 0.2674698795180723,
      "grad_norm": 0.7147547006607056,
      "learning_rate": 4.66566265060241e-06,
      "loss": 1.3596,
      "step": 444
    },
    {
      "epoch": 0.2680722891566265,
      "grad_norm": 0.723124086856842,
      "learning_rate": 4.6649096385542175e-06,
      "loss": 1.3116,
      "step": 445
    },
    {
      "epoch": 0.26867469879518074,
      "grad_norm": 0.7121570706367493,
      "learning_rate": 4.6641566265060244e-06,
      "loss": 1.3487,
      "step": 446
    },
    {
      "epoch": 0.2692771084337349,
      "grad_norm": 0.6966265439987183,
      "learning_rate": 4.663403614457831e-06,
      "loss": 1.3382,
      "step": 447
    },
    {
      "epoch": 0.26987951807228916,
      "grad_norm": 0.73429274559021,
      "learning_rate": 4.662650602409639e-06,
      "loss": 1.3471,
      "step": 448
    },
    {
      "epoch": 0.2704819277108434,
      "grad_norm": 0.6960325241088867,
      "learning_rate": 4.661897590361446e-06,
      "loss": 1.3229,
      "step": 449
    },
    {
      "epoch": 0.2710843373493976,
      "grad_norm": 0.7126370072364807,
      "learning_rate": 4.661144578313254e-06,
      "loss": 1.3231,
      "step": 450
    },
    {
      "epoch": 0.2716867469879518,
      "grad_norm": 0.7032334804534912,
      "learning_rate": 4.660391566265061e-06,
      "loss": 1.3313,
      "step": 451
    },
    {
      "epoch": 0.27228915662650605,
      "grad_norm": 0.7691775560379028,
      "learning_rate": 4.659638554216868e-06,
      "loss": 1.3257,
      "step": 452
    },
    {
      "epoch": 0.2728915662650602,
      "grad_norm": 0.7335044145584106,
      "learning_rate": 4.6588855421686754e-06,
      "loss": 1.3261,
      "step": 453
    },
    {
      "epoch": 0.27349397590361446,
      "grad_norm": 0.700809895992279,
      "learning_rate": 4.658132530120482e-06,
      "loss": 1.3036,
      "step": 454
    },
    {
      "epoch": 0.2740963855421687,
      "grad_norm": 0.6737030148506165,
      "learning_rate": 4.65737951807229e-06,
      "loss": 1.2997,
      "step": 455
    },
    {
      "epoch": 0.2746987951807229,
      "grad_norm": 0.8478635549545288,
      "learning_rate": 4.656626506024097e-06,
      "loss": 1.3218,
      "step": 456
    },
    {
      "epoch": 0.2753012048192771,
      "grad_norm": 0.6802839636802673,
      "learning_rate": 4.655873493975904e-06,
      "loss": 1.294,
      "step": 457
    },
    {
      "epoch": 0.27590361445783135,
      "grad_norm": 0.6938044428825378,
      "learning_rate": 4.655120481927711e-06,
      "loss": 1.3092,
      "step": 458
    },
    {
      "epoch": 0.2765060240963855,
      "grad_norm": 0.7576228380203247,
      "learning_rate": 4.654367469879519e-06,
      "loss": 1.2819,
      "step": 459
    },
    {
      "epoch": 0.27710843373493976,
      "grad_norm": 0.795172929763794,
      "learning_rate": 4.653614457831326e-06,
      "loss": 1.3076,
      "step": 460
    },
    {
      "epoch": 0.277710843373494,
      "grad_norm": 0.7527379393577576,
      "learning_rate": 4.6528614457831325e-06,
      "loss": 1.3194,
      "step": 461
    },
    {
      "epoch": 0.2783132530120482,
      "grad_norm": 0.6936380863189697,
      "learning_rate": 4.65210843373494e-06,
      "loss": 1.2759,
      "step": 462
    },
    {
      "epoch": 0.2789156626506024,
      "grad_norm": 0.7290310263633728,
      "learning_rate": 4.651355421686747e-06,
      "loss": 1.3042,
      "step": 463
    },
    {
      "epoch": 0.27951807228915665,
      "grad_norm": 0.7192020416259766,
      "learning_rate": 4.650602409638554e-06,
      "loss": 1.2775,
      "step": 464
    },
    {
      "epoch": 0.28012048192771083,
      "grad_norm": 0.7727175951004028,
      "learning_rate": 4.649849397590362e-06,
      "loss": 1.3059,
      "step": 465
    },
    {
      "epoch": 0.28072289156626506,
      "grad_norm": 0.7462296485900879,
      "learning_rate": 4.649096385542169e-06,
      "loss": 1.3091,
      "step": 466
    },
    {
      "epoch": 0.2813253012048193,
      "grad_norm": 0.7823005318641663,
      "learning_rate": 4.648343373493977e-06,
      "loss": 1.3072,
      "step": 467
    },
    {
      "epoch": 0.2819277108433735,
      "grad_norm": 0.7252394556999207,
      "learning_rate": 4.6475903614457835e-06,
      "loss": 1.3137,
      "step": 468
    },
    {
      "epoch": 0.2825301204819277,
      "grad_norm": 0.7515267729759216,
      "learning_rate": 4.646837349397591e-06,
      "loss": 1.3118,
      "step": 469
    },
    {
      "epoch": 0.28313253012048195,
      "grad_norm": 0.7366926074028015,
      "learning_rate": 4.646084337349398e-06,
      "loss": 1.2643,
      "step": 470
    },
    {
      "epoch": 0.28373493975903613,
      "grad_norm": 0.899003267288208,
      "learning_rate": 4.645331325301205e-06,
      "loss": 1.2794,
      "step": 471
    },
    {
      "epoch": 0.28433734939759037,
      "grad_norm": 0.7598603367805481,
      "learning_rate": 4.644578313253013e-06,
      "loss": 1.2812,
      "step": 472
    },
    {
      "epoch": 0.2849397590361446,
      "grad_norm": 0.7439104914665222,
      "learning_rate": 4.64382530120482e-06,
      "loss": 1.271,
      "step": 473
    },
    {
      "epoch": 0.2855421686746988,
      "grad_norm": 0.7227540016174316,
      "learning_rate": 4.643072289156627e-06,
      "loss": 1.2725,
      "step": 474
    },
    {
      "epoch": 0.286144578313253,
      "grad_norm": 0.756925642490387,
      "learning_rate": 4.642319277108434e-06,
      "loss": 1.2725,
      "step": 475
    },
    {
      "epoch": 0.28674698795180725,
      "grad_norm": 0.7776544690132141,
      "learning_rate": 4.6415662650602415e-06,
      "loss": 1.267,
      "step": 476
    },
    {
      "epoch": 0.28734939759036143,
      "grad_norm": 0.7618106007575989,
      "learning_rate": 4.640813253012048e-06,
      "loss": 1.2444,
      "step": 477
    },
    {
      "epoch": 0.28795180722891567,
      "grad_norm": 0.7443186044692993,
      "learning_rate": 4.640060240963855e-06,
      "loss": 1.2573,
      "step": 478
    },
    {
      "epoch": 0.2885542168674699,
      "grad_norm": 0.847170889377594,
      "learning_rate": 4.639307228915663e-06,
      "loss": 1.2683,
      "step": 479
    },
    {
      "epoch": 0.2891566265060241,
      "grad_norm": 0.7935969233512878,
      "learning_rate": 4.63855421686747e-06,
      "loss": 1.2703,
      "step": 480
    },
    {
      "epoch": 0.2897590361445783,
      "grad_norm": 0.838478684425354,
      "learning_rate": 4.637801204819278e-06,
      "loss": 1.2397,
      "step": 481
    },
    {
      "epoch": 0.29036144578313255,
      "grad_norm": 0.8000442981719971,
      "learning_rate": 4.637048192771085e-06,
      "loss": 1.2362,
      "step": 482
    },
    {
      "epoch": 0.29096385542168673,
      "grad_norm": 0.7502771615982056,
      "learning_rate": 4.636295180722892e-06,
      "loss": 1.2522,
      "step": 483
    },
    {
      "epoch": 0.29156626506024097,
      "grad_norm": 0.721977949142456,
      "learning_rate": 4.6355421686746994e-06,
      "loss": 1.2276,
      "step": 484
    },
    {
      "epoch": 0.2921686746987952,
      "grad_norm": 0.7902247309684753,
      "learning_rate": 4.634789156626506e-06,
      "loss": 1.2726,
      "step": 485
    },
    {
      "epoch": 0.2927710843373494,
      "grad_norm": 0.8303613066673279,
      "learning_rate": 4.634036144578314e-06,
      "loss": 1.2493,
      "step": 486
    },
    {
      "epoch": 0.2933734939759036,
      "grad_norm": 0.7572912573814392,
      "learning_rate": 4.633283132530121e-06,
      "loss": 1.2372,
      "step": 487
    },
    {
      "epoch": 0.29397590361445786,
      "grad_norm": 0.7693661451339722,
      "learning_rate": 4.632530120481928e-06,
      "loss": 1.236,
      "step": 488
    },
    {
      "epoch": 0.29457831325301204,
      "grad_norm": 0.7457924485206604,
      "learning_rate": 4.631777108433736e-06,
      "loss": 1.2084,
      "step": 489
    },
    {
      "epoch": 0.29518072289156627,
      "grad_norm": 0.7683013677597046,
      "learning_rate": 4.631024096385543e-06,
      "loss": 1.228,
      "step": 490
    },
    {
      "epoch": 0.2957831325301205,
      "grad_norm": 0.7842846512794495,
      "learning_rate": 4.63027108433735e-06,
      "loss": 1.2092,
      "step": 491
    },
    {
      "epoch": 0.2963855421686747,
      "grad_norm": 0.7988995909690857,
      "learning_rate": 4.629518072289157e-06,
      "loss": 1.1987,
      "step": 492
    },
    {
      "epoch": 0.2969879518072289,
      "grad_norm": 0.7974557280540466,
      "learning_rate": 4.628765060240964e-06,
      "loss": 1.2046,
      "step": 493
    },
    {
      "epoch": 0.29759036144578316,
      "grad_norm": 0.8083837032318115,
      "learning_rate": 4.628012048192771e-06,
      "loss": 1.2179,
      "step": 494
    },
    {
      "epoch": 0.29819277108433734,
      "grad_norm": 0.8177149891853333,
      "learning_rate": 4.627259036144578e-06,
      "loss": 1.235,
      "step": 495
    },
    {
      "epoch": 0.2987951807228916,
      "grad_norm": 0.774157702922821,
      "learning_rate": 4.626506024096386e-06,
      "loss": 1.2061,
      "step": 496
    },
    {
      "epoch": 0.2993975903614458,
      "grad_norm": 0.7774245142936707,
      "learning_rate": 4.625753012048193e-06,
      "loss": 1.2128,
      "step": 497
    },
    {
      "epoch": 0.3,
      "grad_norm": 0.7715277671813965,
      "learning_rate": 4.625000000000001e-06,
      "loss": 1.2154,
      "step": 498
    },
    {
      "epoch": 0.3006024096385542,
      "grad_norm": 0.7642433047294617,
      "learning_rate": 4.6242469879518075e-06,
      "loss": 1.1755,
      "step": 499
    },
    {
      "epoch": 0.30120481927710846,
      "grad_norm": 0.7985989451408386,
      "learning_rate": 4.6234939759036145e-06,
      "loss": 1.1925,
      "step": 500
    }
  ],
  "logging_steps": 1,
  "max_steps": 6640,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 4,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 3.48883808944128e+17,
  "train_batch_size": 4,
  "trial_name": null,
  "trial_params": null
}
